// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package components

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/criblio/cribl-control-plane-sdk-go/internal/utils"
)

type TypeCloudflareHec string

const (
	TypeCloudflareHecCloudflareHec TypeCloudflareHec = "cloudflare_hec"
)

func (e TypeCloudflareHec) ToPointer() *TypeCloudflareHec {
	return &e
}
func (e *TypeCloudflareHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cloudflare_hec":
		*e = TypeCloudflareHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCloudflareHec: %v", v)
	}
}

type ConnectionCloudflareHec struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionCloudflareHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionCloudflareHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionCloudflareHec) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionCloudflareHec) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeCloudflareHec - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeCloudflareHec string

const (
	// ModeCloudflareHecSmart Smart
	ModeCloudflareHecSmart ModeCloudflareHec = "smart"
	// ModeCloudflareHecAlways Always On
	ModeCloudflareHecAlways ModeCloudflareHec = "always"
)

func (e ModeCloudflareHec) ToPointer() *ModeCloudflareHec {
	return &e
}

// CompressionCloudflareHec - Codec to use to compress the persisted data
type CompressionCloudflareHec string

const (
	// CompressionCloudflareHecNone None
	CompressionCloudflareHecNone CompressionCloudflareHec = "none"
	// CompressionCloudflareHecGzip Gzip
	CompressionCloudflareHecGzip CompressionCloudflareHec = "gzip"
)

func (e CompressionCloudflareHec) ToPointer() *CompressionCloudflareHec {
	return &e
}

type PqControlsCloudflareHec struct {
}

func (p PqControlsCloudflareHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsCloudflareHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqCloudflareHec struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeCloudflareHec `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionCloudflareHec `default:"none" json:"compress"`
	PqControls *PqControlsCloudflareHec  `json:"pqControls,omitempty"`
}

func (p PqCloudflareHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqCloudflareHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqCloudflareHec) GetMode() *ModeCloudflareHec {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqCloudflareHec) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqCloudflareHec) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqCloudflareHec) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqCloudflareHec) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqCloudflareHec) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqCloudflareHec) GetCompress() *CompressionCloudflareHec {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqCloudflareHec) GetPqControls() *PqControlsCloudflareHec {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// AuthenticationMethodCloudflareHec - Select Secret to use a text secret to authenticate
type AuthenticationMethodCloudflareHec string

const (
	AuthenticationMethodCloudflareHecSecret AuthenticationMethodCloudflareHec = "secret"
)

func (e AuthenticationMethodCloudflareHec) ToPointer() *AuthenticationMethodCloudflareHec {
	return &e
}

type AuthTokenMetadatumCloudflareHec struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (a AuthTokenMetadatumCloudflareHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokenMetadatumCloudflareHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokenMetadatumCloudflareHec) GetName() string {
	if a == nil {
		return ""
	}
	return a.Name
}

func (a *AuthTokenMetadatumCloudflareHec) GetValue() string {
	if a == nil {
		return ""
	}
	return a.Value
}

type AuthTokenCloudflareHec struct {
	// Select Secret to use a text secret to authenticate
	AuthType    *AuthenticationMethodCloudflareHec `default:"secret" json:"authType"`
	TokenSecret any                                `json:"tokenSecret,omitempty"`
	Token       any                                `json:"token,omitempty"`
	Enabled     *bool                              `default:"true" json:"enabled"`
	Description *string                            `json:"description,omitempty"`
	// Enter the values you want to allow in the HEC event index field at the token level. Supports wildcards. To skip validation, leave blank.
	AllowedIndexesAtToken []string `json:"allowedIndexesAtToken,omitempty"`
	// Fields to add to events referencing this token
	Metadata []AuthTokenMetadatumCloudflareHec `json:"metadata,omitempty"`
}

func (a AuthTokenCloudflareHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokenCloudflareHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokenCloudflareHec) GetAuthType() *AuthenticationMethodCloudflareHec {
	if a == nil {
		return nil
	}
	return a.AuthType
}

func (a *AuthTokenCloudflareHec) GetTokenSecret() any {
	if a == nil {
		return nil
	}
	return a.TokenSecret
}

func (a *AuthTokenCloudflareHec) GetToken() any {
	if a == nil {
		return nil
	}
	return a.Token
}

func (a *AuthTokenCloudflareHec) GetEnabled() *bool {
	if a == nil {
		return nil
	}
	return a.Enabled
}

func (a *AuthTokenCloudflareHec) GetDescription() *string {
	if a == nil {
		return nil
	}
	return a.Description
}

func (a *AuthTokenCloudflareHec) GetAllowedIndexesAtToken() []string {
	if a == nil {
		return nil
	}
	return a.AllowedIndexesAtToken
}

func (a *AuthTokenCloudflareHec) GetMetadata() []AuthTokenMetadatumCloudflareHec {
	if a == nil {
		return nil
	}
	return a.Metadata
}

type MinimumTLSVersionCloudflareHec string

const (
	MinimumTLSVersionCloudflareHecTlSv1  MinimumTLSVersionCloudflareHec = "TLSv1"
	MinimumTLSVersionCloudflareHecTlSv11 MinimumTLSVersionCloudflareHec = "TLSv1.1"
	MinimumTLSVersionCloudflareHecTlSv12 MinimumTLSVersionCloudflareHec = "TLSv1.2"
	MinimumTLSVersionCloudflareHecTlSv13 MinimumTLSVersionCloudflareHec = "TLSv1.3"
)

func (e MinimumTLSVersionCloudflareHec) ToPointer() *MinimumTLSVersionCloudflareHec {
	return &e
}

type MaximumTLSVersionCloudflareHec string

const (
	MaximumTLSVersionCloudflareHecTlSv1  MaximumTLSVersionCloudflareHec = "TLSv1"
	MaximumTLSVersionCloudflareHecTlSv11 MaximumTLSVersionCloudflareHec = "TLSv1.1"
	MaximumTLSVersionCloudflareHecTlSv12 MaximumTLSVersionCloudflareHec = "TLSv1.2"
	MaximumTLSVersionCloudflareHecTlSv13 MaximumTLSVersionCloudflareHec = "TLSv1.3"
)

func (e MaximumTLSVersionCloudflareHec) ToPointer() *MaximumTLSVersionCloudflareHec {
	return &e
}

type TLSSettingsServerSideCloudflareHec struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                         `json:"caPath,omitempty"`
	MinVersion *MinimumTLSVersionCloudflareHec `json:"minVersion,omitempty"`
	MaxVersion *MaximumTLSVersionCloudflareHec `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideCloudflareHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideCloudflareHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideCloudflareHec) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideCloudflareHec) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideCloudflareHec) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideCloudflareHec) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideCloudflareHec) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideCloudflareHec) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideCloudflareHec) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideCloudflareHec) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideCloudflareHec) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideCloudflareHec) GetMinVersion() *MinimumTLSVersionCloudflareHec {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideCloudflareHec) GetMaxVersion() *MaximumTLSVersionCloudflareHec {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

type MetadatumCloudflareHec struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumCloudflareHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumCloudflareHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumCloudflareHec) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumCloudflareHec) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputCloudflareHec struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     TypeCloudflareHec `json:"type"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionCloudflareHec `json:"connections,omitempty"`
	Pq          *PqCloudflareHec          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []AuthTokenCloudflareHec            `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideCloudflareHec `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout  *float64 `default:"5" json:"keepAliveTimeout"`
	EnableHealthCheck any      `json:"enableHealthCheck,omitempty"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for the Cloudflare HTTP Event Collector API requests. This input supports the /event endpoint.
	HecAPI string `json:"hecAPI"`
	// Fields to add to every event. May be overridden by fields added at the token or request level.
	Metadata []MetadatumCloudflareHec `json:"metadata,omitempty"`
	// List values allowed in HEC event index field. Leave blank to skip validation. Supports wildcards. The values here can expand index validation at the token level.
	AllowedIndexes []string `json:"allowedIndexes,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// HTTP origins to which @{product} should send CORS (cross-origin resource sharing) Access-Control-Allow-* headers. Supports wildcards.
	AccessControlAllowOrigin []string `json:"accessControlAllowOrigin,omitempty"`
	// HTTP headers that @{product} will send to allowed origins as "Access-Control-Allow-Headers" in a CORS preflight response. Use "*" to allow all headers.
	AccessControlAllowHeaders []string `json:"accessControlAllowHeaders,omitempty"`
	// Emit per-token (<prefix>.http.perToken) and summary (<prefix>.http.summary) request metrics
	EmitTokenMetrics     *bool          `default:"false" json:"emitTokenMetrics"`
	Description          *string        `json:"description,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputCloudflareHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCloudflareHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port", "hecAPI"}); err != nil {
		return err
	}
	return nil
}

func (i *InputCloudflareHec) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputCloudflareHec) GetType() TypeCloudflareHec {
	if i == nil {
		return TypeCloudflareHec("")
	}
	return i.Type
}

func (i *InputCloudflareHec) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputCloudflareHec) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputCloudflareHec) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputCloudflareHec) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputCloudflareHec) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputCloudflareHec) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputCloudflareHec) GetConnections() []ConnectionCloudflareHec {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputCloudflareHec) GetPq() *PqCloudflareHec {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputCloudflareHec) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputCloudflareHec) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputCloudflareHec) GetAuthTokens() []AuthTokenCloudflareHec {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputCloudflareHec) GetTLS() *TLSSettingsServerSideCloudflareHec {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputCloudflareHec) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputCloudflareHec) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputCloudflareHec) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputCloudflareHec) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputCloudflareHec) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputCloudflareHec) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputCloudflareHec) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputCloudflareHec) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputCloudflareHec) GetEnableHealthCheck() any {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputCloudflareHec) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputCloudflareHec) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputCloudflareHec) GetHecAPI() string {
	if i == nil {
		return ""
	}
	return i.HecAPI
}

func (i *InputCloudflareHec) GetMetadata() []MetadatumCloudflareHec {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputCloudflareHec) GetAllowedIndexes() []string {
	if i == nil {
		return nil
	}
	return i.AllowedIndexes
}

func (i *InputCloudflareHec) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputCloudflareHec) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputCloudflareHec) GetAccessControlAllowOrigin() []string {
	if i == nil {
		return nil
	}
	return i.AccessControlAllowOrigin
}

func (i *InputCloudflareHec) GetAccessControlAllowHeaders() []string {
	if i == nil {
		return nil
	}
	return i.AccessControlAllowHeaders
}

func (i *InputCloudflareHec) GetEmitTokenMetrics() *bool {
	if i == nil {
		return nil
	}
	return i.EmitTokenMetrics
}

func (i *InputCloudflareHec) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputCloudflareHec) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeZscalerHec string

const (
	TypeZscalerHecZscalerHec TypeZscalerHec = "zscaler_hec"
)

func (e TypeZscalerHec) ToPointer() *TypeZscalerHec {
	return &e
}
func (e *TypeZscalerHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "zscaler_hec":
		*e = TypeZscalerHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeZscalerHec: %v", v)
	}
}

type ConnectionZscalerHec struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionZscalerHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionZscalerHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionZscalerHec) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionZscalerHec) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeZscalerHec - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeZscalerHec string

const (
	// ModeZscalerHecSmart Smart
	ModeZscalerHecSmart ModeZscalerHec = "smart"
	// ModeZscalerHecAlways Always On
	ModeZscalerHecAlways ModeZscalerHec = "always"
)

func (e ModeZscalerHec) ToPointer() *ModeZscalerHec {
	return &e
}

// CompressionZscalerHec - Codec to use to compress the persisted data
type CompressionZscalerHec string

const (
	// CompressionZscalerHecNone None
	CompressionZscalerHecNone CompressionZscalerHec = "none"
	// CompressionZscalerHecGzip Gzip
	CompressionZscalerHecGzip CompressionZscalerHec = "gzip"
)

func (e CompressionZscalerHec) ToPointer() *CompressionZscalerHec {
	return &e
}

type PqControlsZscalerHec struct {
}

func (p PqControlsZscalerHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsZscalerHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqZscalerHec struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeZscalerHec `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionZscalerHec `default:"none" json:"compress"`
	PqControls *PqControlsZscalerHec  `json:"pqControls,omitempty"`
}

func (p PqZscalerHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqZscalerHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqZscalerHec) GetMode() *ModeZscalerHec {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqZscalerHec) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqZscalerHec) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqZscalerHec) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqZscalerHec) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqZscalerHec) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqZscalerHec) GetCompress() *CompressionZscalerHec {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqZscalerHec) GetPqControls() *PqControlsZscalerHec {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// AuthenticationMethodZscalerHec - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type AuthenticationMethodZscalerHec string

const (
	AuthenticationMethodZscalerHecManual AuthenticationMethodZscalerHec = "manual"
	AuthenticationMethodZscalerHecSecret AuthenticationMethodZscalerHec = "secret"
)

func (e AuthenticationMethodZscalerHec) ToPointer() *AuthenticationMethodZscalerHec {
	return &e
}

type AuthTokenMetadatumZscalerHec struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (a AuthTokenMetadatumZscalerHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokenMetadatumZscalerHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokenMetadatumZscalerHec) GetName() string {
	if a == nil {
		return ""
	}
	return a.Name
}

func (a *AuthTokenMetadatumZscalerHec) GetValue() string {
	if a == nil {
		return ""
	}
	return a.Value
}

type AuthTokenZscalerHec struct {
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *AuthenticationMethodZscalerHec `default:"manual" json:"authType"`
	TokenSecret any                             `json:"tokenSecret,omitempty"`
	Token       any                             `json:"token"`
	Enabled     *bool                           `default:"true" json:"enabled"`
	Description *string                         `json:"description,omitempty"`
	// Enter the values you want to allow in the HEC event index field at the token level. Supports wildcards. To skip validation, leave blank.
	AllowedIndexesAtToken []string `json:"allowedIndexesAtToken,omitempty"`
	// Fields to add to events referencing this token
	Metadata []AuthTokenMetadatumZscalerHec `json:"metadata,omitempty"`
}

func (a AuthTokenZscalerHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokenZscalerHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, []string{"token"}); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokenZscalerHec) GetAuthType() *AuthenticationMethodZscalerHec {
	if a == nil {
		return nil
	}
	return a.AuthType
}

func (a *AuthTokenZscalerHec) GetTokenSecret() any {
	if a == nil {
		return nil
	}
	return a.TokenSecret
}

func (a *AuthTokenZscalerHec) GetToken() any {
	if a == nil {
		return nil
	}
	return a.Token
}

func (a *AuthTokenZscalerHec) GetEnabled() *bool {
	if a == nil {
		return nil
	}
	return a.Enabled
}

func (a *AuthTokenZscalerHec) GetDescription() *string {
	if a == nil {
		return nil
	}
	return a.Description
}

func (a *AuthTokenZscalerHec) GetAllowedIndexesAtToken() []string {
	if a == nil {
		return nil
	}
	return a.AllowedIndexesAtToken
}

func (a *AuthTokenZscalerHec) GetMetadata() []AuthTokenMetadatumZscalerHec {
	if a == nil {
		return nil
	}
	return a.Metadata
}

type MinimumTLSVersionZscalerHec string

const (
	MinimumTLSVersionZscalerHecTlSv1  MinimumTLSVersionZscalerHec = "TLSv1"
	MinimumTLSVersionZscalerHecTlSv11 MinimumTLSVersionZscalerHec = "TLSv1.1"
	MinimumTLSVersionZscalerHecTlSv12 MinimumTLSVersionZscalerHec = "TLSv1.2"
	MinimumTLSVersionZscalerHecTlSv13 MinimumTLSVersionZscalerHec = "TLSv1.3"
)

func (e MinimumTLSVersionZscalerHec) ToPointer() *MinimumTLSVersionZscalerHec {
	return &e
}

type MaximumTLSVersionZscalerHec string

const (
	MaximumTLSVersionZscalerHecTlSv1  MaximumTLSVersionZscalerHec = "TLSv1"
	MaximumTLSVersionZscalerHecTlSv11 MaximumTLSVersionZscalerHec = "TLSv1.1"
	MaximumTLSVersionZscalerHecTlSv12 MaximumTLSVersionZscalerHec = "TLSv1.2"
	MaximumTLSVersionZscalerHecTlSv13 MaximumTLSVersionZscalerHec = "TLSv1.3"
)

func (e MaximumTLSVersionZscalerHec) ToPointer() *MaximumTLSVersionZscalerHec {
	return &e
}

type TLSSettingsServerSideZscalerHec struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                      `json:"caPath,omitempty"`
	MinVersion *MinimumTLSVersionZscalerHec `json:"minVersion,omitempty"`
	MaxVersion *MaximumTLSVersionZscalerHec `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideZscalerHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideZscalerHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideZscalerHec) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideZscalerHec) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideZscalerHec) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideZscalerHec) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideZscalerHec) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideZscalerHec) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideZscalerHec) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideZscalerHec) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideZscalerHec) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideZscalerHec) GetMinVersion() *MinimumTLSVersionZscalerHec {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideZscalerHec) GetMaxVersion() *MaximumTLSVersionZscalerHec {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

type MetadatumZscalerHec struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumZscalerHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumZscalerHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumZscalerHec) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumZscalerHec) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputZscalerHec struct {
	// Unique ID for this input
	ID       *string        `json:"id,omitempty"`
	Type     TypeZscalerHec `json:"type"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionZscalerHec `json:"connections,omitempty"`
	Pq          *PqZscalerHec          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []AuthTokenZscalerHec            `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideZscalerHec `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout  *float64 `default:"5" json:"keepAliveTimeout"`
	EnableHealthCheck any      `json:"enableHealthCheck,omitempty"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for the Zscaler HTTP Event Collector API requests. This input supports the /event endpoint.
	HecAPI *string `default:"/services/collector" json:"hecAPI"`
	// Fields to add to every event. May be overridden by fields added at the token or request level.
	Metadata []MetadatumZscalerHec `json:"metadata,omitempty"`
	// List values allowed in HEC event index field. Leave blank to skip validation. Supports wildcards. The values here can expand index validation at the token level.
	AllowedIndexes []string `json:"allowedIndexes,omitempty"`
	// Whether to enable Zscaler HEC acknowledgements
	HecAcks *bool `default:"false" json:"hecAcks"`
	// Optionally, list HTTP origins to which @{product} should send CORS (cross-origin resource sharing) Access-Control-Allow-* headers. Supports wildcards.
	AccessControlAllowOrigin []string `json:"accessControlAllowOrigin,omitempty"`
	// Optionally, list HTTP headers that @{product} will send to allowed origins as "Access-Control-Allow-Headers" in a CORS preflight response. Use "*" to allow all headers.
	AccessControlAllowHeaders []string `json:"accessControlAllowHeaders,omitempty"`
	// Enable to emit per-token (<prefix>.http.perToken) and summary (<prefix>.http.summary) request metrics
	EmitTokenMetrics     *bool          `default:"false" json:"emitTokenMetrics"`
	Description          *string        `json:"description,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputZscalerHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputZscalerHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port"}); err != nil {
		return err
	}
	return nil
}

func (i *InputZscalerHec) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputZscalerHec) GetType() TypeZscalerHec {
	if i == nil {
		return TypeZscalerHec("")
	}
	return i.Type
}

func (i *InputZscalerHec) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputZscalerHec) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputZscalerHec) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputZscalerHec) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputZscalerHec) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputZscalerHec) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputZscalerHec) GetConnections() []ConnectionZscalerHec {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputZscalerHec) GetPq() *PqZscalerHec {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputZscalerHec) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputZscalerHec) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputZscalerHec) GetAuthTokens() []AuthTokenZscalerHec {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputZscalerHec) GetTLS() *TLSSettingsServerSideZscalerHec {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputZscalerHec) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputZscalerHec) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputZscalerHec) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputZscalerHec) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputZscalerHec) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputZscalerHec) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputZscalerHec) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputZscalerHec) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputZscalerHec) GetEnableHealthCheck() any {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputZscalerHec) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputZscalerHec) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputZscalerHec) GetHecAPI() *string {
	if i == nil {
		return nil
	}
	return i.HecAPI
}

func (i *InputZscalerHec) GetMetadata() []MetadatumZscalerHec {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputZscalerHec) GetAllowedIndexes() []string {
	if i == nil {
		return nil
	}
	return i.AllowedIndexes
}

func (i *InputZscalerHec) GetHecAcks() *bool {
	if i == nil {
		return nil
	}
	return i.HecAcks
}

func (i *InputZscalerHec) GetAccessControlAllowOrigin() []string {
	if i == nil {
		return nil
	}
	return i.AccessControlAllowOrigin
}

func (i *InputZscalerHec) GetAccessControlAllowHeaders() []string {
	if i == nil {
		return nil
	}
	return i.AccessControlAllowHeaders
}

func (i *InputZscalerHec) GetEmitTokenMetrics() *bool {
	if i == nil {
		return nil
	}
	return i.EmitTokenMetrics
}

func (i *InputZscalerHec) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputZscalerHec) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputTypeSecurityLake string

const (
	InputTypeSecurityLakeSecurityLake InputTypeSecurityLake = "security_lake"
)

func (e InputTypeSecurityLake) ToPointer() *InputTypeSecurityLake {
	return &e
}
func (e *InputTypeSecurityLake) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "security_lake":
		*e = InputTypeSecurityLake(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeSecurityLake: %v", v)
	}
}

type ConnectionSecurityLake struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionSecurityLake) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionSecurityLake) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeSecurityLake - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeSecurityLake string

const (
	// ModeSecurityLakeSmart Smart
	ModeSecurityLakeSmart ModeSecurityLake = "smart"
	// ModeSecurityLakeAlways Always On
	ModeSecurityLakeAlways ModeSecurityLake = "always"
)

func (e ModeSecurityLake) ToPointer() *ModeSecurityLake {
	return &e
}

// CompressionSecurityLake - Codec to use to compress the persisted data
type CompressionSecurityLake string

const (
	// CompressionSecurityLakeNone None
	CompressionSecurityLakeNone CompressionSecurityLake = "none"
	// CompressionSecurityLakeGzip Gzip
	CompressionSecurityLakeGzip CompressionSecurityLake = "gzip"
)

func (e CompressionSecurityLake) ToPointer() *CompressionSecurityLake {
	return &e
}

type PqControlsSecurityLake struct {
}

func (p PqControlsSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqSecurityLake struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeSecurityLake `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionSecurityLake `default:"none" json:"compress"`
	PqControls *PqControlsSecurityLake  `json:"pqControls,omitempty"`
}

func (p PqSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqSecurityLake) GetMode() *ModeSecurityLake {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqSecurityLake) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqSecurityLake) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqSecurityLake) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqSecurityLake) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqSecurityLake) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqSecurityLake) GetCompress() *CompressionSecurityLake {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqSecurityLake) GetPqControls() *PqControlsSecurityLake {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// InputAuthenticationMethodSecurityLake - AWS authentication method. Choose Auto to use IAM roles.
type InputAuthenticationMethodSecurityLake string

const (
	// InputAuthenticationMethodSecurityLakeAuto Auto
	InputAuthenticationMethodSecurityLakeAuto InputAuthenticationMethodSecurityLake = "auto"
	// InputAuthenticationMethodSecurityLakeManual Manual
	InputAuthenticationMethodSecurityLakeManual InputAuthenticationMethodSecurityLake = "manual"
	// InputAuthenticationMethodSecurityLakeSecret Secret Key pair
	InputAuthenticationMethodSecurityLakeSecret InputAuthenticationMethodSecurityLake = "secret"
)

func (e InputAuthenticationMethodSecurityLake) ToPointer() *InputAuthenticationMethodSecurityLake {
	return &e
}

// InputSignatureVersionSecurityLake - Signature version to use for signing S3 requests
type InputSignatureVersionSecurityLake string

const (
	InputSignatureVersionSecurityLakeV2 InputSignatureVersionSecurityLake = "v2"
	InputSignatureVersionSecurityLakeV4 InputSignatureVersionSecurityLake = "v4"
)

func (e InputSignatureVersionSecurityLake) ToPointer() *InputSignatureVersionSecurityLake {
	return &e
}

type PreprocessSecurityLake struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (p PreprocessSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PreprocessSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PreprocessSecurityLake) GetDisabled() *bool {
	if p == nil {
		return nil
	}
	return p.Disabled
}

func (p *PreprocessSecurityLake) GetCommand() *string {
	if p == nil {
		return nil
	}
	return p.Command
}

func (p *PreprocessSecurityLake) GetArgs() []string {
	if p == nil {
		return nil
	}
	return p.Args
}

type MetadatumSecurityLake struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumSecurityLake) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumSecurityLake) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type CheckpointingSecurityLake struct {
	// Resume processing files after an interruption
	Enabled *bool `default:"false" json:"enabled"`
	// The number of times to retry processing when a processing error occurs. If Skip file on error is enabled, this setting is ignored.
	Retries *float64 `default:"5" json:"retries"`
}

func (c CheckpointingSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CheckpointingSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *CheckpointingSecurityLake) GetEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.Enabled
}

func (c *CheckpointingSecurityLake) GetRetries() *float64 {
	if c == nil {
		return nil
	}
	return c.Retries
}

type TagAfterProcessingSecurityLake string

const (
	TagAfterProcessingSecurityLakeFalse TagAfterProcessingSecurityLake = "false"
	TagAfterProcessingSecurityLakeTrue  TagAfterProcessingSecurityLake = "true"
)

func (e TagAfterProcessingSecurityLake) ToPointer() *TagAfterProcessingSecurityLake {
	return &e
}

type InputSecurityLake struct {
	// Unique ID for this input
	ID       *string               `json:"id,omitempty"`
	Type     InputTypeSecurityLake `json:"type"`
	Disabled *bool                 `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSecurityLake `json:"connections,omitempty"`
	Pq          *PqSecurityLake          `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *InputAuthenticationMethodSecurityLake `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                                `json:"awsSecretKey,omitempty"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *InputSignatureVersionSecurityLake `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `default:"300" json:"socketTimeout"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Attach SQS notification metadata to a __sqsMetadata field on each event
	IncludeSqsMetadata *bool `default:"false" json:"includeSqsMetadata"`
	// Use Assume Role credentials to access Amazon S3
	EnableAssumeRole *bool `default:"true" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Use Assume Role credentials when accessing Amazon SQS
	EnableSQSAssumeRole *bool                   `default:"false" json:"enableSQSAssumeRole"`
	Preprocess          *PreprocessSecurityLake `json:"preprocess,omitempty"`
	// Fields to add to events from this input
	Metadata []MetadatumSecurityLake `json:"metadata,omitempty"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `default:"5" json:"parquetChunkSizeMB"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64                   `default:"600" json:"parquetChunkDownloadTimeout"`
	Checkpointing               *CheckpointingSecurityLake `json:"checkpointing,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding    *string `json:"encoding,omitempty"`
	Description *string `json:"description,omitempty"`
	AwsAPIKey   *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret          *string                         `json:"awsSecret,omitempty"`
	TagAfterProcessing *TagAfterProcessingSecurityLake `json:"tagAfterProcessing,omitempty"`
	// The key for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagKey *string `json:"processedTagKey,omitempty"`
	// The value for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagValue    *string        `json:"processedTagValue,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "queueName"}); err != nil {
		return err
	}
	return nil
}

func (i *InputSecurityLake) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputSecurityLake) GetType() InputTypeSecurityLake {
	if i == nil {
		return InputTypeSecurityLake("")
	}
	return i.Type
}

func (i *InputSecurityLake) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSecurityLake) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSecurityLake) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputSecurityLake) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputSecurityLake) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputSecurityLake) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputSecurityLake) GetConnections() []ConnectionSecurityLake {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputSecurityLake) GetPq() *PqSecurityLake {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputSecurityLake) GetQueueName() string {
	if i == nil {
		return ""
	}
	return i.QueueName
}

func (i *InputSecurityLake) GetFileFilter() *string {
	if i == nil {
		return nil
	}
	return i.FileFilter
}

func (i *InputSecurityLake) GetAwsAccountID() *string {
	if i == nil {
		return nil
	}
	return i.AwsAccountID
}

func (i *InputSecurityLake) GetAwsAuthenticationMethod() *InputAuthenticationMethodSecurityLake {
	if i == nil {
		return nil
	}
	return i.AwsAuthenticationMethod
}

func (i *InputSecurityLake) GetAwsSecretKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecretKey
}

func (i *InputSecurityLake) GetRegion() *string {
	if i == nil {
		return nil
	}
	return i.Region
}

func (i *InputSecurityLake) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputSecurityLake) GetSignatureVersion() *InputSignatureVersionSecurityLake {
	if i == nil {
		return nil
	}
	return i.SignatureVersion
}

func (i *InputSecurityLake) GetReuseConnections() *bool {
	if i == nil {
		return nil
	}
	return i.ReuseConnections
}

func (i *InputSecurityLake) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputSecurityLake) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputSecurityLake) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputSecurityLake) GetMaxMessages() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMessages
}

func (i *InputSecurityLake) GetVisibilityTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.VisibilityTimeout
}

func (i *InputSecurityLake) GetNumReceivers() *float64 {
	if i == nil {
		return nil
	}
	return i.NumReceivers
}

func (i *InputSecurityLake) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputSecurityLake) GetSkipOnError() *bool {
	if i == nil {
		return nil
	}
	return i.SkipOnError
}

func (i *InputSecurityLake) GetIncludeSqsMetadata() *bool {
	if i == nil {
		return nil
	}
	return i.IncludeSqsMetadata
}

func (i *InputSecurityLake) GetEnableAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableAssumeRole
}

func (i *InputSecurityLake) GetAssumeRoleArn() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleArn
}

func (i *InputSecurityLake) GetAssumeRoleExternalID() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleExternalID
}

func (i *InputSecurityLake) GetDurationSeconds() *float64 {
	if i == nil {
		return nil
	}
	return i.DurationSeconds
}

func (i *InputSecurityLake) GetEnableSQSAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableSQSAssumeRole
}

func (i *InputSecurityLake) GetPreprocess() *PreprocessSecurityLake {
	if i == nil {
		return nil
	}
	return i.Preprocess
}

func (i *InputSecurityLake) GetMetadata() []MetadatumSecurityLake {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputSecurityLake) GetParquetChunkSizeMB() *float64 {
	if i == nil {
		return nil
	}
	return i.ParquetChunkSizeMB
}

func (i *InputSecurityLake) GetParquetChunkDownloadTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.ParquetChunkDownloadTimeout
}

func (i *InputSecurityLake) GetCheckpointing() *CheckpointingSecurityLake {
	if i == nil {
		return nil
	}
	return i.Checkpointing
}

func (i *InputSecurityLake) GetPollTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.PollTimeout
}

func (i *InputSecurityLake) GetEncoding() *string {
	if i == nil {
		return nil
	}
	return i.Encoding
}

func (i *InputSecurityLake) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputSecurityLake) GetAwsAPIKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsAPIKey
}

func (i *InputSecurityLake) GetAwsSecret() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecret
}

func (i *InputSecurityLake) GetTagAfterProcessing() *TagAfterProcessingSecurityLake {
	if i == nil {
		return nil
	}
	return i.TagAfterProcessing
}

func (i *InputSecurityLake) GetProcessedTagKey() *string {
	if i == nil {
		return nil
	}
	return i.ProcessedTagKey
}

func (i *InputSecurityLake) GetProcessedTagValue() *string {
	if i == nil {
		return nil
	}
	return i.ProcessedTagValue
}

func (i *InputSecurityLake) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputTypeNetflow string

const (
	InputTypeNetflowNetflow InputTypeNetflow = "netflow"
)

func (e InputTypeNetflow) ToPointer() *InputTypeNetflow {
	return &e
}
func (e *InputTypeNetflow) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "netflow":
		*e = InputTypeNetflow(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeNetflow: %v", v)
	}
}

type ConnectionNetflow struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionNetflow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionNetflow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionNetflow) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionNetflow) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeNetflow - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeNetflow string

const (
	// ModeNetflowSmart Smart
	ModeNetflowSmart ModeNetflow = "smart"
	// ModeNetflowAlways Always On
	ModeNetflowAlways ModeNetflow = "always"
)

func (e ModeNetflow) ToPointer() *ModeNetflow {
	return &e
}

// CompressionNetflow - Codec to use to compress the persisted data
type CompressionNetflow string

const (
	// CompressionNetflowNone None
	CompressionNetflowNone CompressionNetflow = "none"
	// CompressionNetflowGzip Gzip
	CompressionNetflowGzip CompressionNetflow = "gzip"
)

func (e CompressionNetflow) ToPointer() *CompressionNetflow {
	return &e
}

type PqControlsNetflow struct {
}

func (p PqControlsNetflow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsNetflow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqNetflow struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeNetflow `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionNetflow `default:"none" json:"compress"`
	PqControls *PqControlsNetflow  `json:"pqControls,omitempty"`
}

func (p PqNetflow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqNetflow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqNetflow) GetMode() *ModeNetflow {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqNetflow) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqNetflow) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqNetflow) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqNetflow) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqNetflow) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqNetflow) GetCompress() *CompressionNetflow {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqNetflow) GetPqControls() *PqControlsNetflow {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MetadatumNetflow struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumNetflow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumNetflow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumNetflow) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumNetflow) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputNetflow struct {
	// Unique ID for this input
	ID       *string          `json:"id,omitempty"`
	Type     InputTypeNetflow `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionNetflow `json:"connections,omitempty"`
	Pq          *PqNetflow          `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port *float64 `default:"2055" json:"port"`
	// Allow forwarding of events to a NetFlow destination. Enabling this feature will generate an extra event containing __netflowRaw which can be routed to a NetFlow destination. Note that these events will not count against ingest quota.
	EnablePassThrough *bool `default:"false" json:"enablePassThrough"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist.
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// Specifies how many minutes NetFlow v9 templates are cached before being discarded if not refreshed. Adjust based on your network's template update frequency to optimize performance and memory usage.
	TemplateCacheMinutes *float64 `default:"30" json:"templateCacheMinutes"`
	// Accept messages in Netflow V5 format.
	V5Enabled *bool `default:"true" json:"v5Enabled"`
	// Accept messages in Netflow V9 format.
	V9Enabled *bool `default:"true" json:"v9Enabled"`
	// Accept messages in IPFIX format.
	IpfixEnabled *bool `default:"false" json:"ipfixEnabled"`
	// Fields to add to events from this input
	Metadata             []MetadatumNetflow `json:"metadata,omitempty"`
	Description          *string            `json:"description,omitempty"`
	AdditionalProperties map[string]any     `additionalProperties:"true" json:"-"`
}

func (i InputNetflow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputNetflow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputNetflow) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputNetflow) GetType() InputTypeNetflow {
	if i == nil {
		return InputTypeNetflow("")
	}
	return i.Type
}

func (i *InputNetflow) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputNetflow) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputNetflow) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputNetflow) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputNetflow) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputNetflow) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputNetflow) GetConnections() []ConnectionNetflow {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputNetflow) GetPq() *PqNetflow {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputNetflow) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputNetflow) GetPort() *float64 {
	if i == nil {
		return nil
	}
	return i.Port
}

func (i *InputNetflow) GetEnablePassThrough() *bool {
	if i == nil {
		return nil
	}
	return i.EnablePassThrough
}

func (i *InputNetflow) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputNetflow) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputNetflow) GetUDPSocketRxBufSize() *float64 {
	if i == nil {
		return nil
	}
	return i.UDPSocketRxBufSize
}

func (i *InputNetflow) GetTemplateCacheMinutes() *float64 {
	if i == nil {
		return nil
	}
	return i.TemplateCacheMinutes
}

func (i *InputNetflow) GetV5Enabled() *bool {
	if i == nil {
		return nil
	}
	return i.V5Enabled
}

func (i *InputNetflow) GetV9Enabled() *bool {
	if i == nil {
		return nil
	}
	return i.V9Enabled
}

func (i *InputNetflow) GetIpfixEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.IpfixEnabled
}

func (i *InputNetflow) GetMetadata() []MetadatumNetflow {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputNetflow) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputNetflow) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeWizWebhook string

const (
	TypeWizWebhookWizWebhook TypeWizWebhook = "wiz_webhook"
)

func (e TypeWizWebhook) ToPointer() *TypeWizWebhook {
	return &e
}
func (e *TypeWizWebhook) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "wiz_webhook":
		*e = TypeWizWebhook(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeWizWebhook: %v", v)
	}
}

type ConnectionWizWebhook struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionWizWebhook) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionWizWebhook) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionWizWebhook) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionWizWebhook) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeWizWebhook - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeWizWebhook string

const (
	// ModeWizWebhookSmart Smart
	ModeWizWebhookSmart ModeWizWebhook = "smart"
	// ModeWizWebhookAlways Always On
	ModeWizWebhookAlways ModeWizWebhook = "always"
)

func (e ModeWizWebhook) ToPointer() *ModeWizWebhook {
	return &e
}

// CompressionWizWebhook - Codec to use to compress the persisted data
type CompressionWizWebhook string

const (
	// CompressionWizWebhookNone None
	CompressionWizWebhookNone CompressionWizWebhook = "none"
	// CompressionWizWebhookGzip Gzip
	CompressionWizWebhookGzip CompressionWizWebhook = "gzip"
)

func (e CompressionWizWebhook) ToPointer() *CompressionWizWebhook {
	return &e
}

type PqControlsWizWebhook struct {
}

func (p PqControlsWizWebhook) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsWizWebhook) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqWizWebhook struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeWizWebhook `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionWizWebhook `default:"none" json:"compress"`
	PqControls *PqControlsWizWebhook  `json:"pqControls,omitempty"`
}

func (p PqWizWebhook) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqWizWebhook) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqWizWebhook) GetMode() *ModeWizWebhook {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqWizWebhook) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqWizWebhook) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqWizWebhook) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqWizWebhook) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqWizWebhook) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqWizWebhook) GetCompress() *CompressionWizWebhook {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqWizWebhook) GetPqControls() *PqControlsWizWebhook {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MinimumTLSVersionWizWebhook string

const (
	MinimumTLSVersionWizWebhookTlSv1  MinimumTLSVersionWizWebhook = "TLSv1"
	MinimumTLSVersionWizWebhookTlSv11 MinimumTLSVersionWizWebhook = "TLSv1.1"
	MinimumTLSVersionWizWebhookTlSv12 MinimumTLSVersionWizWebhook = "TLSv1.2"
	MinimumTLSVersionWizWebhookTlSv13 MinimumTLSVersionWizWebhook = "TLSv1.3"
)

func (e MinimumTLSVersionWizWebhook) ToPointer() *MinimumTLSVersionWizWebhook {
	return &e
}

type MaximumTLSVersionWizWebhook string

const (
	MaximumTLSVersionWizWebhookTlSv1  MaximumTLSVersionWizWebhook = "TLSv1"
	MaximumTLSVersionWizWebhookTlSv11 MaximumTLSVersionWizWebhook = "TLSv1.1"
	MaximumTLSVersionWizWebhookTlSv12 MaximumTLSVersionWizWebhook = "TLSv1.2"
	MaximumTLSVersionWizWebhookTlSv13 MaximumTLSVersionWizWebhook = "TLSv1.3"
)

func (e MaximumTLSVersionWizWebhook) ToPointer() *MaximumTLSVersionWizWebhook {
	return &e
}

type TLSSettingsServerSideWizWebhook struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                      `json:"caPath,omitempty"`
	MinVersion *MinimumTLSVersionWizWebhook `json:"minVersion,omitempty"`
	MaxVersion *MaximumTLSVersionWizWebhook `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideWizWebhook) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideWizWebhook) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideWizWebhook) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideWizWebhook) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideWizWebhook) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideWizWebhook) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideWizWebhook) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideWizWebhook) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideWizWebhook) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideWizWebhook) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideWizWebhook) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideWizWebhook) GetMinVersion() *MinimumTLSVersionWizWebhook {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideWizWebhook) GetMaxVersion() *MaximumTLSVersionWizWebhook {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

type MetadatumWizWebhook struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumWizWebhook) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumWizWebhook) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumWizWebhook) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumWizWebhook) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type AuthTokensExtMetadatumWizWebhook struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (a AuthTokensExtMetadatumWizWebhook) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokensExtMetadatumWizWebhook) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokensExtMetadatumWizWebhook) GetName() string {
	if a == nil {
		return ""
	}
	return a.Name
}

func (a *AuthTokensExtMetadatumWizWebhook) GetValue() string {
	if a == nil {
		return ""
	}
	return a.Value
}

type AuthTokensExtWizWebhook struct {
	// Shared secret to be provided by any client (Authorization: <token>)
	Token       string  `json:"token"`
	Description *string `json:"description,omitempty"`
	// Fields to add to events referencing this token
	Metadata []AuthTokensExtMetadatumWizWebhook `json:"metadata,omitempty"`
}

func (a AuthTokensExtWizWebhook) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokensExtWizWebhook) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, []string{"token"}); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokensExtWizWebhook) GetToken() string {
	if a == nil {
		return ""
	}
	return a.Token
}

func (a *AuthTokensExtWizWebhook) GetDescription() *string {
	if a == nil {
		return nil
	}
	return a.Description
}

func (a *AuthTokensExtWizWebhook) GetMetadata() []AuthTokensExtMetadatumWizWebhook {
	if a == nil {
		return nil
	}
	return a.Metadata
}

type InputWizWebhook struct {
	// Unique ID for this input
	ID       *string        `json:"id,omitempty"`
	Type     TypeWizWebhook `json:"type"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionWizWebhook `json:"connections,omitempty"`
	Pq          *PqWizWebhook          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                         `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideWizWebhook `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Fields to add to events from this input
	Metadata []MetadatumWizWebhook `json:"metadata,omitempty"`
	// List of URI paths accepted by this input. Wildcards are supported (such as /api/v*/hook). Defaults to allow all.
	AllowedPaths []string `json:"allowedPaths,omitempty"`
	// List of HTTP methods accepted by this input. Wildcards are supported (such as P*, GET). Defaults to allow all.
	AllowedMethods []string `json:"allowedMethods,omitempty"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokensExt        []AuthTokensExtWizWebhook `json:"authTokensExt,omitempty"`
	Description          *string                   `json:"description,omitempty"`
	AdditionalProperties map[string]any            `additionalProperties:"true" json:"-"`
}

func (i InputWizWebhook) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWizWebhook) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port"}); err != nil {
		return err
	}
	return nil
}

func (i *InputWizWebhook) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputWizWebhook) GetType() TypeWizWebhook {
	if i == nil {
		return TypeWizWebhook("")
	}
	return i.Type
}

func (i *InputWizWebhook) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputWizWebhook) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputWizWebhook) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputWizWebhook) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputWizWebhook) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputWizWebhook) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputWizWebhook) GetConnections() []ConnectionWizWebhook {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputWizWebhook) GetPq() *PqWizWebhook {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputWizWebhook) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputWizWebhook) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputWizWebhook) GetAuthTokens() []string {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputWizWebhook) GetTLS() *TLSSettingsServerSideWizWebhook {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputWizWebhook) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputWizWebhook) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputWizWebhook) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputWizWebhook) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputWizWebhook) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputWizWebhook) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputWizWebhook) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputWizWebhook) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputWizWebhook) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputWizWebhook) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputWizWebhook) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputWizWebhook) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputWizWebhook) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputWizWebhook) GetMetadata() []MetadatumWizWebhook {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputWizWebhook) GetAllowedPaths() []string {
	if i == nil {
		return nil
	}
	return i.AllowedPaths
}

func (i *InputWizWebhook) GetAllowedMethods() []string {
	if i == nil {
		return nil
	}
	return i.AllowedMethods
}

func (i *InputWizWebhook) GetAuthTokensExt() []AuthTokensExtWizWebhook {
	if i == nil {
		return nil
	}
	return i.AuthTokensExt
}

func (i *InputWizWebhook) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputWizWebhook) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeWiz string

const (
	TypeWizWiz TypeWiz = "wiz"
)

func (e TypeWiz) ToPointer() *TypeWiz {
	return &e
}
func (e *TypeWiz) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "wiz":
		*e = TypeWiz(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeWiz: %v", v)
	}
}

type ConnectionWiz struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionWiz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionWiz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionWiz) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionWiz) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeWiz - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeWiz string

const (
	// ModeWizSmart Smart
	ModeWizSmart ModeWiz = "smart"
	// ModeWizAlways Always On
	ModeWizAlways ModeWiz = "always"
)

func (e ModeWiz) ToPointer() *ModeWiz {
	return &e
}

// CompressionWiz - Codec to use to compress the persisted data
type CompressionWiz string

const (
	// CompressionWizNone None
	CompressionWizNone CompressionWiz = "none"
	// CompressionWizGzip Gzip
	CompressionWizGzip CompressionWiz = "gzip"
)

func (e CompressionWiz) ToPointer() *CompressionWiz {
	return &e
}

type PqControlsWiz struct {
}

func (p PqControlsWiz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsWiz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqWiz struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeWiz `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionWiz `default:"none" json:"compress"`
	PqControls *PqControlsWiz  `json:"pqControls,omitempty"`
}

func (p PqWiz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqWiz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqWiz) GetMode() *ModeWiz {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqWiz) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqWiz) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqWiz) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqWiz) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqWiz) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqWiz) GetCompress() *CompressionWiz {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqWiz) GetPqControls() *PqControlsWiz {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type ContentConfigWiz struct {
	// The name of the Wiz query
	ContentType        string  `json:"contentType"`
	ContentDescription *string `json:"contentDescription,omitempty"`
	Enabled            *bool   `default:"false" json:"enabled"`
}

func (c ContentConfigWiz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ContentConfigWiz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"contentType"}); err != nil {
		return err
	}
	return nil
}

func (c *ContentConfigWiz) GetContentType() string {
	if c == nil {
		return ""
	}
	return c.ContentType
}

func (c *ContentConfigWiz) GetContentDescription() *string {
	if c == nil {
		return nil
	}
	return c.ContentDescription
}

func (c *ContentConfigWiz) GetEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.Enabled
}

type MetadatumWiz struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumWiz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumWiz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumWiz) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumWiz) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

// RetryTypeWiz - The algorithm to use when performing HTTP retries
type RetryTypeWiz string

const (
	// RetryTypeWizNone Disabled
	RetryTypeWizNone RetryTypeWiz = "none"
	// RetryTypeWizBackoff Backoff
	RetryTypeWizBackoff RetryTypeWiz = "backoff"
	// RetryTypeWizStatic Static
	RetryTypeWizStatic RetryTypeWiz = "static"
)

func (e RetryTypeWiz) ToPointer() *RetryTypeWiz {
	return &e
}

type RetryRulesWiz struct {
	// The algorithm to use when performing HTTP retries
	Type *RetryTypeWiz `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of HTTP codes that trigger a retry. Leave empty to use the default list of 429 and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (r RetryRulesWiz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RetryRulesWiz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (r *RetryRulesWiz) GetType() *RetryTypeWiz {
	if r == nil {
		return nil
	}
	return r.Type
}

func (r *RetryRulesWiz) GetInterval() *float64 {
	if r == nil {
		return nil
	}
	return r.Interval
}

func (r *RetryRulesWiz) GetLimit() *float64 {
	if r == nil {
		return nil
	}
	return r.Limit
}

func (r *RetryRulesWiz) GetMultiplier() *float64 {
	if r == nil {
		return nil
	}
	return r.Multiplier
}

func (r *RetryRulesWiz) GetCodes() []float64 {
	if r == nil {
		return nil
	}
	return r.Codes
}

func (r *RetryRulesWiz) GetEnableHeader() *bool {
	if r == nil {
		return nil
	}
	return r.EnableHeader
}

func (r *RetryRulesWiz) GetRetryConnectTimeout() *bool {
	if r == nil {
		return nil
	}
	return r.RetryConnectTimeout
}

func (r *RetryRulesWiz) GetRetryConnectReset() *bool {
	if r == nil {
		return nil
	}
	return r.RetryConnectReset
}

// AuthenticationMethodWiz - Enter client secret directly, or select a stored secret
type AuthenticationMethodWiz string

const (
	AuthenticationMethodWizManual AuthenticationMethodWiz = "manual"
	AuthenticationMethodWizSecret AuthenticationMethodWiz = "secret"
)

func (e AuthenticationMethodWiz) ToPointer() *AuthenticationMethodWiz {
	return &e
}

type InputWiz struct {
	// Unique ID for this input
	ID       *string `json:"id,omitempty"`
	Type     TypeWiz `json:"type"`
	Disabled *bool   `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionWiz `json:"connections,omitempty"`
	Pq          *PqWiz          `json:"pq,omitempty"`
	// The Wiz GraphQL API endpoint. Example: https://api.us1.app.wiz.io/graphql
	Endpoint *string `default:"https://api.<region>.app.wiz.io/graphql" json:"endpoint"`
	// The authentication URL to generate an OAuth token
	AuthURL string `json:"authUrl"`
	// The audience to use when requesting an OAuth token for a custom auth URL. When not specified, `wiz-api` will be used.
	AuthAudienceOverride *string `json:"authAudienceOverride,omitempty"`
	// The client ID of the Wiz application
	ClientID      string             `json:"clientId"`
	ContentConfig []ContentConfigWiz `json:"contentConfig"`
	// HTTP request inactivity timeout. Use 0 to disable.
	RequestTimeout *float64 `default:"300" json:"requestTimeout"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
	IgnoreGroupJobsLimit *bool `default:"false" json:"ignoreGroupJobsLimit"`
	// Fields to add to events from this input
	Metadata   []MetadatumWiz `json:"metadata,omitempty"`
	RetryRules *RetryRulesWiz `json:"retryRules,omitempty"`
	// Enter client secret directly, or select a stored secret
	AuthType    *AuthenticationMethodWiz `default:"manual" json:"authType"`
	Description *string                  `json:"description,omitempty"`
	// The client secret of the Wiz application
	ClientSecret *string `json:"clientSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret           *string        `json:"textSecret,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputWiz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWiz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "authUrl", "clientId", "contentConfig"}); err != nil {
		return err
	}
	return nil
}

func (i *InputWiz) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputWiz) GetType() TypeWiz {
	if i == nil {
		return TypeWiz("")
	}
	return i.Type
}

func (i *InputWiz) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputWiz) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputWiz) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputWiz) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputWiz) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputWiz) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputWiz) GetConnections() []ConnectionWiz {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputWiz) GetPq() *PqWiz {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputWiz) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputWiz) GetAuthURL() string {
	if i == nil {
		return ""
	}
	return i.AuthURL
}

func (i *InputWiz) GetAuthAudienceOverride() *string {
	if i == nil {
		return nil
	}
	return i.AuthAudienceOverride
}

func (i *InputWiz) GetClientID() string {
	if i == nil {
		return ""
	}
	return i.ClientID
}

func (i *InputWiz) GetContentConfig() []ContentConfigWiz {
	if i == nil {
		return []ContentConfigWiz{}
	}
	return i.ContentConfig
}

func (i *InputWiz) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputWiz) GetKeepAliveTime() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTime
}

func (i *InputWiz) GetMaxMissedKeepAlives() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMissedKeepAlives
}

func (i *InputWiz) GetTTL() *string {
	if i == nil {
		return nil
	}
	return i.TTL
}

func (i *InputWiz) GetIgnoreGroupJobsLimit() *bool {
	if i == nil {
		return nil
	}
	return i.IgnoreGroupJobsLimit
}

func (i *InputWiz) GetMetadata() []MetadatumWiz {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputWiz) GetRetryRules() *RetryRulesWiz {
	if i == nil {
		return nil
	}
	return i.RetryRules
}

func (i *InputWiz) GetAuthType() *AuthenticationMethodWiz {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputWiz) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputWiz) GetClientSecret() *string {
	if i == nil {
		return nil
	}
	return i.ClientSecret
}

func (i *InputWiz) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputWiz) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputJournalFilesType string

const (
	InputJournalFilesTypeJournalFiles InputJournalFilesType = "journal_files"
)

func (e InputJournalFilesType) ToPointer() *InputJournalFilesType {
	return &e
}
func (e *InputJournalFilesType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "journal_files":
		*e = InputJournalFilesType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputJournalFilesType: %v", v)
	}
}

type InputJournalFilesConnection struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (i InputJournalFilesConnection) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputJournalFilesConnection) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (i *InputJournalFilesConnection) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputJournalFilesConnection) GetOutput() string {
	if i == nil {
		return ""
	}
	return i.Output
}

// InputJournalFilesMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputJournalFilesMode string

const (
	// InputJournalFilesModeSmart Smart
	InputJournalFilesModeSmart InputJournalFilesMode = "smart"
	// InputJournalFilesModeAlways Always On
	InputJournalFilesModeAlways InputJournalFilesMode = "always"
)

func (e InputJournalFilesMode) ToPointer() *InputJournalFilesMode {
	return &e
}

// InputJournalFilesCompression - Codec to use to compress the persisted data
type InputJournalFilesCompression string

const (
	// InputJournalFilesCompressionNone None
	InputJournalFilesCompressionNone InputJournalFilesCompression = "none"
	// InputJournalFilesCompressionGzip Gzip
	InputJournalFilesCompressionGzip InputJournalFilesCompression = "gzip"
)

func (e InputJournalFilesCompression) ToPointer() *InputJournalFilesCompression {
	return &e
}

type InputJournalFilesPqControls struct {
}

func (i InputJournalFilesPqControls) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputJournalFilesPqControls) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type InputJournalFilesPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputJournalFilesMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *InputJournalFilesCompression `default:"none" json:"compress"`
	PqControls *InputJournalFilesPqControls  `json:"pqControls,omitempty"`
}

func (i InputJournalFilesPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputJournalFilesPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputJournalFilesPq) GetMode() *InputJournalFilesMode {
	if i == nil {
		return nil
	}
	return i.Mode
}

func (i *InputJournalFilesPq) GetMaxBufferSize() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBufferSize
}

func (i *InputJournalFilesPq) GetCommitFrequency() *float64 {
	if i == nil {
		return nil
	}
	return i.CommitFrequency
}

func (i *InputJournalFilesPq) GetMaxFileSize() *string {
	if i == nil {
		return nil
	}
	return i.MaxFileSize
}

func (i *InputJournalFilesPq) GetMaxSize() *string {
	if i == nil {
		return nil
	}
	return i.MaxSize
}

func (i *InputJournalFilesPq) GetPath() *string {
	if i == nil {
		return nil
	}
	return i.Path
}

func (i *InputJournalFilesPq) GetCompress() *InputJournalFilesCompression {
	if i == nil {
		return nil
	}
	return i.Compress
}

func (i *InputJournalFilesPq) GetPqControls() *InputJournalFilesPqControls {
	if i == nil {
		return nil
	}
	return i.PqControls
}

type InputJournalFilesRule struct {
	// JavaScript expression applied to Journal objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitempty"`
}

func (i InputJournalFilesRule) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputJournalFilesRule) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"filter"}); err != nil {
		return err
	}
	return nil
}

func (i *InputJournalFilesRule) GetFilter() string {
	if i == nil {
		return ""
	}
	return i.Filter
}

func (i *InputJournalFilesRule) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type InputJournalFilesMetadatum struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (i InputJournalFilesMetadatum) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputJournalFilesMetadatum) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (i *InputJournalFilesMetadatum) GetName() string {
	if i == nil {
		return ""
	}
	return i.Name
}

func (i *InputJournalFilesMetadatum) GetValue() string {
	if i == nil {
		return ""
	}
	return i.Value
}

type InputJournalFiles struct {
	// Unique ID for this input
	ID       *string               `json:"id,omitempty"`
	Type     InputJournalFilesType `json:"type"`
	Disabled *bool                 `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputJournalFilesConnection `json:"connections,omitempty"`
	Pq          *InputJournalFilesPq          `json:"pq,omitempty"`
	// Directory path to search for journals. Environment variables will be resolved, e.g. $CRIBL_EDGE_FS_ROOT/var/log/journal/$MACHINE_ID.
	Path string `json:"path"`
	// Time, in seconds, between scanning for journals.
	Interval *float64 `default:"10" json:"interval"`
	// The full path of discovered journals are matched against this wildcard list.
	Journals []string `json:"journals"`
	// Add rules to decide which journal objects to allow. Events are generated if no rules are given or if all the rules' expressions evaluate to true.
	Rules []InputJournalFilesRule `json:"rules,omitempty"`
	// Skip log messages that are not part of the current boot session.
	CurrentBoot *bool `default:"false" json:"currentBoot"`
	// The maximum log message age, in duration form (e.g,: 60s, 4h, 3d, 1w).  Default of no value will apply no max age filters.
	MaxAgeDur *string `json:"maxAgeDur,omitempty"`
	// Fields to add to events from this input
	Metadata             []InputJournalFilesMetadatum `json:"metadata,omitempty"`
	Description          *string                      `json:"description,omitempty"`
	AdditionalProperties map[string]any               `additionalProperties:"true" json:"-"`
}

func (i InputJournalFiles) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputJournalFiles) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "path", "journals"}); err != nil {
		return err
	}
	return nil
}

func (i *InputJournalFiles) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputJournalFiles) GetType() InputJournalFilesType {
	if i == nil {
		return InputJournalFilesType("")
	}
	return i.Type
}

func (i *InputJournalFiles) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputJournalFiles) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputJournalFiles) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputJournalFiles) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputJournalFiles) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputJournalFiles) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputJournalFiles) GetConnections() []InputJournalFilesConnection {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputJournalFiles) GetPq() *InputJournalFilesPq {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputJournalFiles) GetPath() string {
	if i == nil {
		return ""
	}
	return i.Path
}

func (i *InputJournalFiles) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputJournalFiles) GetJournals() []string {
	if i == nil {
		return []string{}
	}
	return i.Journals
}

func (i *InputJournalFiles) GetRules() []InputJournalFilesRule {
	if i == nil {
		return nil
	}
	return i.Rules
}

func (i *InputJournalFiles) GetCurrentBoot() *bool {
	if i == nil {
		return nil
	}
	return i.CurrentBoot
}

func (i *InputJournalFiles) GetMaxAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MaxAgeDur
}

func (i *InputJournalFiles) GetMetadata() []InputJournalFilesMetadatum {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputJournalFiles) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputJournalFiles) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeRawUDP string

const (
	TypeRawUDPRawUDP TypeRawUDP = "raw_udp"
)

func (e TypeRawUDP) ToPointer() *TypeRawUDP {
	return &e
}
func (e *TypeRawUDP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "raw_udp":
		*e = TypeRawUDP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeRawUDP: %v", v)
	}
}

type ConnectionRawUDP struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionRawUDP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionRawUDP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionRawUDP) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionRawUDP) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeRawUDP - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeRawUDP string

const (
	// ModeRawUDPSmart Smart
	ModeRawUDPSmart ModeRawUDP = "smart"
	// ModeRawUDPAlways Always On
	ModeRawUDPAlways ModeRawUDP = "always"
)

func (e ModeRawUDP) ToPointer() *ModeRawUDP {
	return &e
}

// CompressionRawUDP - Codec to use to compress the persisted data
type CompressionRawUDP string

const (
	// CompressionRawUDPNone None
	CompressionRawUDPNone CompressionRawUDP = "none"
	// CompressionRawUDPGzip Gzip
	CompressionRawUDPGzip CompressionRawUDP = "gzip"
)

func (e CompressionRawUDP) ToPointer() *CompressionRawUDP {
	return &e
}

type PqControlsRawUDP struct {
}

func (p PqControlsRawUDP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsRawUDP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqRawUDP struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeRawUDP `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionRawUDP `default:"none" json:"compress"`
	PqControls *PqControlsRawUDP  `json:"pqControls,omitempty"`
}

func (p PqRawUDP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqRawUDP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqRawUDP) GetMode() *ModeRawUDP {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqRawUDP) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqRawUDP) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqRawUDP) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqRawUDP) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqRawUDP) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqRawUDP) GetCompress() *CompressionRawUDP {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqRawUDP) GetPqControls() *PqControlsRawUDP {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MetadatumRawUDP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumRawUDP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumRawUDP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumRawUDP) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumRawUDP) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputRawUDP struct {
	// Unique ID for this input
	ID       *string    `json:"id,omitempty"`
	Type     TypeRawUDP `json:"type"`
	Disabled *bool      `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionRawUDP `json:"connections,omitempty"`
	Pq          *PqRawUDP          `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Maximum number of events to buffer when downstream is blocking.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// If true, each UDP packet is assumed to contain a single message. If false, each UDP packet is assumed to contain multiple messages, separated by newlines.
	SingleMsgUDPPackets *bool `default:"false" json:"singleMsgUdpPackets"`
	// If true, a __rawBytes field will be added to each event containing the raw bytes of the datagram.
	IngestRawBytes *bool `default:"false" json:"ingestRawBytes"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// Fields to add to events from this input
	Metadata             []MetadatumRawUDP `json:"metadata,omitempty"`
	Description          *string           `json:"description,omitempty"`
	AdditionalProperties map[string]any    `additionalProperties:"true" json:"-"`
}

func (i InputRawUDP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputRawUDP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port"}); err != nil {
		return err
	}
	return nil
}

func (i *InputRawUDP) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputRawUDP) GetType() TypeRawUDP {
	if i == nil {
		return TypeRawUDP("")
	}
	return i.Type
}

func (i *InputRawUDP) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputRawUDP) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputRawUDP) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputRawUDP) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputRawUDP) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputRawUDP) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputRawUDP) GetConnections() []ConnectionRawUDP {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputRawUDP) GetPq() *PqRawUDP {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputRawUDP) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputRawUDP) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputRawUDP) GetMaxBufferSize() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBufferSize
}

func (i *InputRawUDP) GetIPWhitelistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPWhitelistRegex
}

func (i *InputRawUDP) GetSingleMsgUDPPackets() *bool {
	if i == nil {
		return nil
	}
	return i.SingleMsgUDPPackets
}

func (i *InputRawUDP) GetIngestRawBytes() *bool {
	if i == nil {
		return nil
	}
	return i.IngestRawBytes
}

func (i *InputRawUDP) GetUDPSocketRxBufSize() *float64 {
	if i == nil {
		return nil
	}
	return i.UDPSocketRxBufSize
}

func (i *InputRawUDP) GetMetadata() []MetadatumRawUDP {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputRawUDP) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputRawUDP) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeWinEventLogs string

const (
	TypeWinEventLogsWinEventLogs TypeWinEventLogs = "win_event_logs"
)

func (e TypeWinEventLogs) ToPointer() *TypeWinEventLogs {
	return &e
}
func (e *TypeWinEventLogs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "win_event_logs":
		*e = TypeWinEventLogs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeWinEventLogs: %v", v)
	}
}

type ConnectionWinEventLogs struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionWinEventLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionWinEventLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionWinEventLogs) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionWinEventLogs) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeWinEventLogs - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeWinEventLogs string

const (
	// ModeWinEventLogsSmart Smart
	ModeWinEventLogsSmart ModeWinEventLogs = "smart"
	// ModeWinEventLogsAlways Always On
	ModeWinEventLogsAlways ModeWinEventLogs = "always"
)

func (e ModeWinEventLogs) ToPointer() *ModeWinEventLogs {
	return &e
}

// CompressionWinEventLogs - Codec to use to compress the persisted data
type CompressionWinEventLogs string

const (
	// CompressionWinEventLogsNone None
	CompressionWinEventLogsNone CompressionWinEventLogs = "none"
	// CompressionWinEventLogsGzip Gzip
	CompressionWinEventLogsGzip CompressionWinEventLogs = "gzip"
)

func (e CompressionWinEventLogs) ToPointer() *CompressionWinEventLogs {
	return &e
}

type PqControlsWinEventLogs struct {
}

func (p PqControlsWinEventLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsWinEventLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqWinEventLogs struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeWinEventLogs `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionWinEventLogs `default:"none" json:"compress"`
	PqControls *PqControlsWinEventLogs  `json:"pqControls,omitempty"`
}

func (p PqWinEventLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqWinEventLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqWinEventLogs) GetMode() *ModeWinEventLogs {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqWinEventLogs) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqWinEventLogs) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqWinEventLogs) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqWinEventLogs) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqWinEventLogs) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqWinEventLogs) GetCompress() *CompressionWinEventLogs {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqWinEventLogs) GetPqControls() *PqControlsWinEventLogs {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// ReadMode - Read all stored and future event logs, or only future events
type ReadMode string

const (
	// ReadModeOldest Entire log
	ReadModeOldest ReadMode = "oldest"
	// ReadModeNewest From last entry
	ReadModeNewest ReadMode = "newest"
)

func (e ReadMode) ToPointer() *ReadMode {
	return &e
}

// EventFormat - Format of individual events
type EventFormat string

const (
	// EventFormatJSON JSON
	EventFormatJSON EventFormat = "json"
	// EventFormatXML XML
	EventFormatXML EventFormat = "xml"
)

func (e EventFormat) ToPointer() *EventFormat {
	return &e
}

type MetadatumWinEventLogs struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumWinEventLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumWinEventLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumWinEventLogs) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumWinEventLogs) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputWinEventLogs struct {
	// Unique ID for this input
	ID       *string          `json:"id,omitempty"`
	Type     TypeWinEventLogs `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionWinEventLogs `json:"connections,omitempty"`
	Pq          *PqWinEventLogs          `json:"pq,omitempty"`
	// Enter the event logs to collect. Run "Get-WinEvent -ListLog *" in PowerShell to see the available logs.
	LogNames []string `json:"logNames"`
	// Read all stored and future event logs, or only future events
	ReadMode *ReadMode `default:"newest" json:"readMode"`
	// Format of individual events
	EventFormat *EventFormat `default:"json" json:"eventFormat"`
	// Enable to use built-in tools (PowerShell for JSON, wevtutil for XML) to collect event logs instead of native API (default) [Learn more](https://docs.cribl.io/edge/sources-windows-event-logs/#advanced-settings)
	DisableNativeModule *bool `default:"false" json:"disableNativeModule"`
	// Time, in seconds, between checking for new entries (Applicable for pre-4.8.0 nodes that use Windows Tools)
	Interval *float64 `default:"10" json:"interval"`
	// The maximum number of events to read in one polling interval. A batch size higher than 500 can cause delays when pulling from multiple event logs. (Applicable for pre-4.8.0 nodes that use Windows Tools)
	BatchSize *float64 `default:"500" json:"batchSize"`
	// Fields to add to events from this input
	Metadata []MetadatumWinEventLogs `json:"metadata,omitempty"`
	// The maximum number of bytes in an event before it is flushed to the pipelines
	MaxEventBytes *float64 `default:"51200" json:"maxEventBytes"`
	Description   *string  `json:"description,omitempty"`
	// Enable/disable the rendering of localized event message strings (Applicable for 4.8.0 nodes and newer that use the Native API)
	DisableJSONRendering *bool `default:"false" json:"disableJsonRendering"`
	// Enable/disable the rendering of localized event message strings (Applicable for 4.8.0 nodes and newer that use the Native API)
	DisableXMLRendering  *bool          `default:"true" json:"disableXmlRendering"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputWinEventLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWinEventLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "logNames"}); err != nil {
		return err
	}
	return nil
}

func (i *InputWinEventLogs) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputWinEventLogs) GetType() TypeWinEventLogs {
	if i == nil {
		return TypeWinEventLogs("")
	}
	return i.Type
}

func (i *InputWinEventLogs) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputWinEventLogs) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputWinEventLogs) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputWinEventLogs) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputWinEventLogs) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputWinEventLogs) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputWinEventLogs) GetConnections() []ConnectionWinEventLogs {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputWinEventLogs) GetPq() *PqWinEventLogs {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputWinEventLogs) GetLogNames() []string {
	if i == nil {
		return []string{}
	}
	return i.LogNames
}

func (i *InputWinEventLogs) GetReadMode() *ReadMode {
	if i == nil {
		return nil
	}
	return i.ReadMode
}

func (i *InputWinEventLogs) GetEventFormat() *EventFormat {
	if i == nil {
		return nil
	}
	return i.EventFormat
}

func (i *InputWinEventLogs) GetDisableNativeModule() *bool {
	if i == nil {
		return nil
	}
	return i.DisableNativeModule
}

func (i *InputWinEventLogs) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputWinEventLogs) GetBatchSize() *float64 {
	if i == nil {
		return nil
	}
	return i.BatchSize
}

func (i *InputWinEventLogs) GetMetadata() []MetadatumWinEventLogs {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputWinEventLogs) GetMaxEventBytes() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxEventBytes
}

func (i *InputWinEventLogs) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputWinEventLogs) GetDisableJSONRendering() *bool {
	if i == nil {
		return nil
	}
	return i.DisableJSONRendering
}

func (i *InputWinEventLogs) GetDisableXMLRendering() *bool {
	if i == nil {
		return nil
	}
	return i.DisableXMLRendering
}

func (i *InputWinEventLogs) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeWef string

const (
	TypeWefWef TypeWef = "wef"
)

func (e TypeWef) ToPointer() *TypeWef {
	return &e
}
func (e *TypeWef) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "wef":
		*e = TypeWef(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeWef: %v", v)
	}
}

type ConnectionWef struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionWef) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionWef) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionWef) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionWef) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeWef - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeWef string

const (
	// ModeWefSmart Smart
	ModeWefSmart ModeWef = "smart"
	// ModeWefAlways Always On
	ModeWefAlways ModeWef = "always"
)

func (e ModeWef) ToPointer() *ModeWef {
	return &e
}

// CompressionWef - Codec to use to compress the persisted data
type CompressionWef string

const (
	// CompressionWefNone None
	CompressionWefNone CompressionWef = "none"
	// CompressionWefGzip Gzip
	CompressionWefGzip CompressionWef = "gzip"
)

func (e CompressionWef) ToPointer() *CompressionWef {
	return &e
}

type PqControlsWef struct {
}

func (p PqControlsWef) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsWef) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqWef struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeWef `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionWef `default:"none" json:"compress"`
	PqControls *PqControlsWef  `json:"pqControls,omitempty"`
}

func (p PqWef) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqWef) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqWef) GetMode() *ModeWef {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqWef) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqWef) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqWef) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqWef) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqWef) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqWef) GetCompress() *CompressionWef {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqWef) GetPqControls() *PqControlsWef {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// AuthMethodAuthenticationMethod - How to authenticate incoming client connections
type AuthMethodAuthenticationMethod string

const (
	// AuthMethodAuthenticationMethodClientCert Client certificate
	AuthMethodAuthenticationMethodClientCert AuthMethodAuthenticationMethod = "clientCert"
	// AuthMethodAuthenticationMethodKerberos Kerberos
	AuthMethodAuthenticationMethodKerberos AuthMethodAuthenticationMethod = "kerberos"
)

func (e AuthMethodAuthenticationMethod) ToPointer() *AuthMethodAuthenticationMethod {
	return &e
}

type MinimumTLSVersionWef string

const (
	MinimumTLSVersionWefTlSv1  MinimumTLSVersionWef = "TLSv1"
	MinimumTLSVersionWefTlSv11 MinimumTLSVersionWef = "TLSv1.1"
	MinimumTLSVersionWefTlSv12 MinimumTLSVersionWef = "TLSv1.2"
	MinimumTLSVersionWefTlSv13 MinimumTLSVersionWef = "TLSv1.3"
)

func (e MinimumTLSVersionWef) ToPointer() *MinimumTLSVersionWef {
	return &e
}

type MaximumTLSVersionWef string

const (
	MaximumTLSVersionWefTlSv1  MaximumTLSVersionWef = "TLSv1"
	MaximumTLSVersionWefTlSv11 MaximumTLSVersionWef = "TLSv1.1"
	MaximumTLSVersionWefTlSv12 MaximumTLSVersionWef = "TLSv1.2"
	MaximumTLSVersionWefTlSv13 MaximumTLSVersionWef = "TLSv1.3"
)

func (e MaximumTLSVersionWef) ToPointer() *MaximumTLSVersionWef {
	return &e
}

type MTLSSettings struct {
	// Enable TLS
	Disabled *bool `default:"false" json:"disabled"`
	// Required for WEF certificate authentication
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Required for WEF certificate authentication
	RequestCert *bool `default:"true" json:"requestCert"`
	// Name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath string `json:"privKeyPath"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath string `json:"certPath"`
	// Server path containing CA certificates (in PEM format) to use. Can reference $ENV_VARS. If multiple certificates are present in a .pem, each must directly certify the one preceding it.
	CaPath string `json:"caPath"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string               `default:"/.*/" json:"commonNameRegex"`
	MinVersion      *MinimumTLSVersionWef `json:"minVersion,omitempty"`
	MaxVersion      *MaximumTLSVersionWef `json:"maxVersion,omitempty"`
	// Enable OCSP check of certificate
	OcspCheck *bool `default:"false" json:"ocspCheck"`
	Keytab    any   `json:"keytab,omitempty"`
	Principal any   `json:"principal,omitempty"`
	// If enabled, checks will fail on any OCSP error. Otherwise, checks will fail only when a certificate is revoked, ignoring other errors.
	OcspCheckFailClose *bool `default:"false" json:"ocspCheckFailClose"`
}

func (m MTLSSettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MTLSSettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"privKeyPath", "certPath", "caPath"}); err != nil {
		return err
	}
	return nil
}

func (m *MTLSSettings) GetDisabled() *bool {
	if m == nil {
		return nil
	}
	return m.Disabled
}

func (m *MTLSSettings) GetRejectUnauthorized() *bool {
	if m == nil {
		return nil
	}
	return m.RejectUnauthorized
}

func (m *MTLSSettings) GetRequestCert() *bool {
	if m == nil {
		return nil
	}
	return m.RequestCert
}

func (m *MTLSSettings) GetCertificateName() *string {
	if m == nil {
		return nil
	}
	return m.CertificateName
}

func (m *MTLSSettings) GetPrivKeyPath() string {
	if m == nil {
		return ""
	}
	return m.PrivKeyPath
}

func (m *MTLSSettings) GetPassphrase() *string {
	if m == nil {
		return nil
	}
	return m.Passphrase
}

func (m *MTLSSettings) GetCertPath() string {
	if m == nil {
		return ""
	}
	return m.CertPath
}

func (m *MTLSSettings) GetCaPath() string {
	if m == nil {
		return ""
	}
	return m.CaPath
}

func (m *MTLSSettings) GetCommonNameRegex() *string {
	if m == nil {
		return nil
	}
	return m.CommonNameRegex
}

func (m *MTLSSettings) GetMinVersion() *MinimumTLSVersionWef {
	if m == nil {
		return nil
	}
	return m.MinVersion
}

func (m *MTLSSettings) GetMaxVersion() *MaximumTLSVersionWef {
	if m == nil {
		return nil
	}
	return m.MaxVersion
}

func (m *MTLSSettings) GetOcspCheck() *bool {
	if m == nil {
		return nil
	}
	return m.OcspCheck
}

func (m *MTLSSettings) GetKeytab() any {
	if m == nil {
		return nil
	}
	return m.Keytab
}

func (m *MTLSSettings) GetPrincipal() any {
	if m == nil {
		return nil
	}
	return m.Principal
}

func (m *MTLSSettings) GetOcspCheckFailClose() *bool {
	if m == nil {
		return nil
	}
	return m.OcspCheckFailClose
}

// InputFormat - Content format in which the endpoint should deliver events
type InputFormat string

const (
	InputFormatRaw          InputFormat = "Raw"
	InputFormatRenderedText InputFormat = "RenderedText"
)

func (e InputFormat) ToPointer() *InputFormat {
	return &e
}

type QueryBuilderMode string

const (
	QueryBuilderModeSimple QueryBuilderMode = "simple"
	QueryBuilderModeXML    QueryBuilderMode = "xml"
)

func (e QueryBuilderMode) ToPointer() *QueryBuilderMode {
	return &e
}

type SubscriptionMetadatum struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (s SubscriptionMetadatum) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SubscriptionMetadatum) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (s *SubscriptionMetadatum) GetName() string {
	if s == nil {
		return ""
	}
	return s.Name
}

func (s *SubscriptionMetadatum) GetValue() string {
	if s == nil {
		return ""
	}
	return s.Value
}

type Subscription struct {
	SubscriptionName string `json:"subscriptionName"`
	// Version UUID for this subscription. If any subscription parameters are modified, this value will change.
	Version *string `json:"version,omitempty"`
	// Content format in which the endpoint should deliver events
	ContentFormat *InputFormat `default:"Raw" json:"contentFormat"`
	// Maximum time (in seconds) between endpoint checkins before considering it unavailable
	HeartbeatInterval *float64 `default:"60" json:"heartbeatInterval"`
	// Interval (in seconds) over which the endpoint should collect events before sending them to Stream
	BatchTimeout *float64 `default:"60" json:"batchTimeout"`
	// Newly subscribed endpoints will send previously existing events. Disable to receive new events only.
	ReadExistingEvents *bool `default:"false" json:"readExistingEvents"`
	// Keep track of which events have been received, resuming from that point after a re-subscription. This setting takes precedence over 'Read existing events'. See [Cribl Docs](https://docs.cribl.io/stream/sources-wef/#subscriptions) for more details.
	SendBookmarks *bool `default:"true" json:"sendBookmarks"`
	// Receive compressed events from the source
	Compress *bool `default:"true" json:"compress"`
	// The DNS names of the endpoints that should forward these events. You may use wildcards, such as *.mydomain.com
	Targets []string `json:"targets"`
	// The RFC-3066 locale the Windows clients should use when sending events. Defaults to "en-US".
	Locale        *string           `default:"en-US" json:"locale"`
	QuerySelector *QueryBuilderMode `default:"simple" json:"querySelector"`
	// Fields to add to events ingested under this subscription
	Metadata []SubscriptionMetadatum `json:"metadata,omitempty"`
}

func (s Subscription) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *Subscription) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, []string{"subscriptionName", "targets"}); err != nil {
		return err
	}
	return nil
}

func (s *Subscription) GetSubscriptionName() string {
	if s == nil {
		return ""
	}
	return s.SubscriptionName
}

func (s *Subscription) GetVersion() *string {
	if s == nil {
		return nil
	}
	return s.Version
}

func (s *Subscription) GetContentFormat() *InputFormat {
	if s == nil {
		return nil
	}
	return s.ContentFormat
}

func (s *Subscription) GetHeartbeatInterval() *float64 {
	if s == nil {
		return nil
	}
	return s.HeartbeatInterval
}

func (s *Subscription) GetBatchTimeout() *float64 {
	if s == nil {
		return nil
	}
	return s.BatchTimeout
}

func (s *Subscription) GetReadExistingEvents() *bool {
	if s == nil {
		return nil
	}
	return s.ReadExistingEvents
}

func (s *Subscription) GetSendBookmarks() *bool {
	if s == nil {
		return nil
	}
	return s.SendBookmarks
}

func (s *Subscription) GetCompress() *bool {
	if s == nil {
		return nil
	}
	return s.Compress
}

func (s *Subscription) GetTargets() []string {
	if s == nil {
		return []string{}
	}
	return s.Targets
}

func (s *Subscription) GetLocale() *string {
	if s == nil {
		return nil
	}
	return s.Locale
}

func (s *Subscription) GetQuerySelector() *QueryBuilderMode {
	if s == nil {
		return nil
	}
	return s.QuerySelector
}

func (s *Subscription) GetMetadata() []SubscriptionMetadatum {
	if s == nil {
		return nil
	}
	return s.Metadata
}

type MetadatumWef struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumWef) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumWef) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumWef) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumWef) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputWef struct {
	// Unique ID for this input
	ID       *string `json:"id,omitempty"`
	Type     TypeWef `json:"type"`
	Disabled *bool   `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionWef `json:"connections,omitempty"`
	Pq          *PqWef          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port *float64 `default:"5986" json:"port"`
	// How to authenticate incoming client connections
	AuthMethod *AuthMethodAuthenticationMethod `default:"clientCert" json:"authMethod"`
	TLS        *MTLSSettings                   `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Preserve the client’s original IP address in the __srcIpPort field when connecting through an HTTP proxy that supports the X-Forwarded-For header. This does not apply to TCP-layer Proxy Protocol v1/v2.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"90" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// SHA1 fingerprint expected by the client, if it does not match the first certificate in the configured CA chain
	CaFingerprint *string `json:"caFingerprint,omitempty"`
	// Path to the keytab file containing the service principal credentials. @{product} will use `/etc/krb5.keytab` if not provided.
	Keytab *string `json:"keytab,omitempty"`
	// Kerberos principal used for authentication, typically in the form HTTP/<hostname>@<REALM>
	Principal *string `json:"principal,omitempty"`
	// Allow events to be ingested even if their MachineID does not match the client certificate CN
	AllowMachineIDMismatch *bool `default:"false" json:"allowMachineIdMismatch"`
	// Subscriptions to events on forwarding endpoints
	Subscriptions []Subscription `json:"subscriptions"`
	// Fields to add to events from this input
	Metadata    []MetadatumWef `json:"metadata,omitempty"`
	Description *string        `json:"description,omitempty"`
	// Log a warning if the client certificate authority (CA) fingerprint does not match the expected value. A mismatch prevents Cribl from receiving events from the Windows Event Forwarder.
	LogFingerprintMismatch *bool          `default:"false" json:"logFingerprintMismatch"`
	AdditionalProperties   map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputWef) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWef) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "subscriptions"}); err != nil {
		return err
	}
	return nil
}

func (i *InputWef) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputWef) GetType() TypeWef {
	if i == nil {
		return TypeWef("")
	}
	return i.Type
}

func (i *InputWef) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputWef) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputWef) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputWef) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputWef) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputWef) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputWef) GetConnections() []ConnectionWef {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputWef) GetPq() *PqWef {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputWef) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputWef) GetPort() *float64 {
	if i == nil {
		return nil
	}
	return i.Port
}

func (i *InputWef) GetAuthMethod() *AuthMethodAuthenticationMethod {
	if i == nil {
		return nil
	}
	return i.AuthMethod
}

func (i *InputWef) GetTLS() *MTLSSettings {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputWef) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputWef) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputWef) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputWef) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputWef) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputWef) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputWef) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputWef) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputWef) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputWef) GetCaFingerprint() *string {
	if i == nil {
		return nil
	}
	return i.CaFingerprint
}

func (i *InputWef) GetKeytab() *string {
	if i == nil {
		return nil
	}
	return i.Keytab
}

func (i *InputWef) GetPrincipal() *string {
	if i == nil {
		return nil
	}
	return i.Principal
}

func (i *InputWef) GetAllowMachineIDMismatch() *bool {
	if i == nil {
		return nil
	}
	return i.AllowMachineIDMismatch
}

func (i *InputWef) GetSubscriptions() []Subscription {
	if i == nil {
		return []Subscription{}
	}
	return i.Subscriptions
}

func (i *InputWef) GetMetadata() []MetadatumWef {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputWef) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputWef) GetLogFingerprintMismatch() *bool {
	if i == nil {
		return nil
	}
	return i.LogFingerprintMismatch
}

func (i *InputWef) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeAppscope string

const (
	TypeAppscopeAppscope TypeAppscope = "appscope"
)

func (e TypeAppscope) ToPointer() *TypeAppscope {
	return &e
}
func (e *TypeAppscope) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "appscope":
		*e = TypeAppscope(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeAppscope: %v", v)
	}
}

type ConnectionAppscope struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionAppscope) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionAppscope) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionAppscope) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionAppscope) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeAppscope - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeAppscope string

const (
	// ModeAppscopeSmart Smart
	ModeAppscopeSmart ModeAppscope = "smart"
	// ModeAppscopeAlways Always On
	ModeAppscopeAlways ModeAppscope = "always"
)

func (e ModeAppscope) ToPointer() *ModeAppscope {
	return &e
}

// CompressionAppscope - Codec to use to compress the persisted data
type CompressionAppscope string

const (
	// CompressionAppscopeNone None
	CompressionAppscopeNone CompressionAppscope = "none"
	// CompressionAppscopeGzip Gzip
	CompressionAppscopeGzip CompressionAppscope = "gzip"
)

func (e CompressionAppscope) ToPointer() *CompressionAppscope {
	return &e
}

type PqControlsAppscope struct {
}

func (p PqControlsAppscope) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsAppscope) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqAppscope struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeAppscope `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionAppscope `default:"none" json:"compress"`
	PqControls *PqControlsAppscope  `json:"pqControls,omitempty"`
}

func (p PqAppscope) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqAppscope) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqAppscope) GetMode() *ModeAppscope {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqAppscope) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqAppscope) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqAppscope) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqAppscope) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqAppscope) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqAppscope) GetCompress() *CompressionAppscope {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqAppscope) GetPqControls() *PqControlsAppscope {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MetadatumAppscope struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumAppscope) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumAppscope) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumAppscope) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumAppscope) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type Allow struct {
	// Specify the name of a process or family of processes.
	Procname string `json:"procname"`
	// Specify a string to substring-match against process command-line.
	Arg *string `json:"arg,omitempty"`
	// Choose a config to apply to processes that match the process name and/or argument.
	Config string `json:"config"`
}

func (a Allow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *Allow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, []string{"procname", "config"}); err != nil {
		return err
	}
	return nil
}

func (a *Allow) GetProcname() string {
	if a == nil {
		return ""
	}
	return a.Procname
}

func (a *Allow) GetArg() *string {
	if a == nil {
		return nil
	}
	return a.Arg
}

func (a *Allow) GetConfig() string {
	if a == nil {
		return ""
	}
	return a.Config
}

type FilterAppscope struct {
	// Specify processes that AppScope should be loaded into, and the config to use.
	Allow []Allow `json:"allow,omitempty"`
	// To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL.
	TransportURL *string `json:"transportURL,omitempty"`
}

func (f FilterAppscope) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(f, "", false)
}

func (f *FilterAppscope) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &f, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (f *FilterAppscope) GetAllow() []Allow {
	if f == nil {
		return nil
	}
	return f.Allow
}

func (f *FilterAppscope) GetTransportURL() *string {
	if f == nil {
		return nil
	}
	return f.TransportURL
}

type DataCompressionFormatAppscope string

const (
	DataCompressionFormatAppscopeNone DataCompressionFormatAppscope = "none"
	DataCompressionFormatAppscopeGzip DataCompressionFormatAppscope = "gzip"
)

func (e DataCompressionFormatAppscope) ToPointer() *DataCompressionFormatAppscope {
	return &e
}

type PersistenceAppscope struct {
	// Spool events and metrics on disk for Cribl Edge and Search
	Enable *bool `default:"false" json:"enable"`
	// Time span for each file bucket
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                        `default:"24h" json:"maxDataTime"`
	Compress    *DataCompressionFormatAppscope `default:"gzip" json:"compress"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/appscope
	DestPath *string `default:"$CRIBL_HOME/state/appscope" json:"destPath"`
}

func (p PersistenceAppscope) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PersistenceAppscope) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PersistenceAppscope) GetEnable() *bool {
	if p == nil {
		return nil
	}
	return p.Enable
}

func (p *PersistenceAppscope) GetTimeWindow() *string {
	if p == nil {
		return nil
	}
	return p.TimeWindow
}

func (p *PersistenceAppscope) GetMaxDataSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataSize
}

func (p *PersistenceAppscope) GetMaxDataTime() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataTime
}

func (p *PersistenceAppscope) GetCompress() *DataCompressionFormatAppscope {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PersistenceAppscope) GetDestPath() *string {
	if p == nil {
		return nil
	}
	return p.DestPath
}

// AuthenticationMethodAppscope - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type AuthenticationMethodAppscope string

const (
	AuthenticationMethodAppscopeManual AuthenticationMethodAppscope = "manual"
	AuthenticationMethodAppscopeSecret AuthenticationMethodAppscope = "secret"
)

func (e AuthenticationMethodAppscope) ToPointer() *AuthenticationMethodAppscope {
	return &e
}

type MinimumTLSVersionAppscope string

const (
	MinimumTLSVersionAppscopeTlSv1  MinimumTLSVersionAppscope = "TLSv1"
	MinimumTLSVersionAppscopeTlSv11 MinimumTLSVersionAppscope = "TLSv1.1"
	MinimumTLSVersionAppscopeTlSv12 MinimumTLSVersionAppscope = "TLSv1.2"
	MinimumTLSVersionAppscopeTlSv13 MinimumTLSVersionAppscope = "TLSv1.3"
)

func (e MinimumTLSVersionAppscope) ToPointer() *MinimumTLSVersionAppscope {
	return &e
}

type MaximumTLSVersionAppscope string

const (
	MaximumTLSVersionAppscopeTlSv1  MaximumTLSVersionAppscope = "TLSv1"
	MaximumTLSVersionAppscopeTlSv11 MaximumTLSVersionAppscope = "TLSv1.1"
	MaximumTLSVersionAppscopeTlSv12 MaximumTLSVersionAppscope = "TLSv1.2"
	MaximumTLSVersionAppscopeTlSv13 MaximumTLSVersionAppscope = "TLSv1.3"
)

func (e MaximumTLSVersionAppscope) ToPointer() *MaximumTLSVersionAppscope {
	return &e
}

type TLSSettingsServerSideAppscope struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                    `json:"caPath,omitempty"`
	MinVersion *MinimumTLSVersionAppscope `json:"minVersion,omitempty"`
	MaxVersion *MaximumTLSVersionAppscope `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideAppscope) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideAppscope) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideAppscope) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideAppscope) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideAppscope) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideAppscope) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideAppscope) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideAppscope) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideAppscope) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideAppscope) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideAppscope) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideAppscope) GetMinVersion() *MinimumTLSVersionAppscope {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideAppscope) GetMaxVersion() *MaximumTLSVersionAppscope {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

type InputAppscope struct {
	// Unique ID for this input
	ID       *string      `json:"id,omitempty"`
	Type     TypeAppscope `json:"type"`
	Disabled *bool        `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionAppscope `json:"connections,omitempty"`
	Pq          *PqAppscope          `json:"pq,omitempty"`
	// Regex matching IP addresses that are allowed to establish a connection
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `default:"0" json:"socketMaxLifespan"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Fields to add to events from this input
	Metadata []MetadatumAppscope `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port.
	EnableUnixPath *bool                `default:"false" json:"enableUnixPath"`
	Filter         *FilterAppscope      `json:"filter,omitempty"`
	Persistence    *PersistenceAppscope `json:"persistence,omitempty"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *AuthenticationMethodAppscope `default:"manual" json:"authType"`
	Description *string                       `json:"description,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `json:"host,omitempty"`
	// Port to listen on
	Port *float64                       `json:"port,omitempty"`
	TLS  *TLSSettingsServerSideAppscope `json:"tls,omitempty"`
	// Path to the UNIX domain socket to listen on.
	UnixSocketPath *string `default:"$CRIBL_HOME/state/appscope.sock" json:"unixSocketPath"`
	// Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions.
	UnixSocketPerms *string `json:"unixSocketPerms,omitempty"`
	// Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
	AuthToken *string `default:"" json:"authToken"`
	// Select or create a stored text secret
	TextSecret           *string        `json:"textSecret,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputAppscope) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAppscope) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputAppscope) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputAppscope) GetType() TypeAppscope {
	if i == nil {
		return TypeAppscope("")
	}
	return i.Type
}

func (i *InputAppscope) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputAppscope) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputAppscope) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputAppscope) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputAppscope) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputAppscope) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputAppscope) GetConnections() []ConnectionAppscope {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputAppscope) GetPq() *PqAppscope {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputAppscope) GetIPWhitelistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPWhitelistRegex
}

func (i *InputAppscope) GetMaxActiveCxn() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveCxn
}

func (i *InputAppscope) GetSocketIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketIdleTimeout
}

func (i *InputAppscope) GetSocketEndingMaxWait() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketEndingMaxWait
}

func (i *InputAppscope) GetSocketMaxLifespan() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketMaxLifespan
}

func (i *InputAppscope) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputAppscope) GetMetadata() []MetadatumAppscope {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputAppscope) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputAppscope) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputAppscope) GetEnableUnixPath() *bool {
	if i == nil {
		return nil
	}
	return i.EnableUnixPath
}

func (i *InputAppscope) GetFilter() *FilterAppscope {
	if i == nil {
		return nil
	}
	return i.Filter
}

func (i *InputAppscope) GetPersistence() *PersistenceAppscope {
	if i == nil {
		return nil
	}
	return i.Persistence
}

func (i *InputAppscope) GetAuthType() *AuthenticationMethodAppscope {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputAppscope) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputAppscope) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputAppscope) GetPort() *float64 {
	if i == nil {
		return nil
	}
	return i.Port
}

func (i *InputAppscope) GetTLS() *TLSSettingsServerSideAppscope {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputAppscope) GetUnixSocketPath() *string {
	if i == nil {
		return nil
	}
	return i.UnixSocketPath
}

func (i *InputAppscope) GetUnixSocketPerms() *string {
	if i == nil {
		return nil
	}
	return i.UnixSocketPerms
}

func (i *InputAppscope) GetAuthToken() *string {
	if i == nil {
		return nil
	}
	return i.AuthToken
}

func (i *InputAppscope) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputAppscope) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeTCP string

const (
	TypeTCPTCP TypeTCP = "tcp"
)

func (e TypeTCP) ToPointer() *TypeTCP {
	return &e
}
func (e *TypeTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "tcp":
		*e = TypeTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeTCP: %v", v)
	}
}

type ConnectionTCP struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionTCP) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionTCP) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeTCP - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeTCP string

const (
	// ModeTCPSmart Smart
	ModeTCPSmart ModeTCP = "smart"
	// ModeTCPAlways Always On
	ModeTCPAlways ModeTCP = "always"
)

func (e ModeTCP) ToPointer() *ModeTCP {
	return &e
}

// CompressionTCP - Codec to use to compress the persisted data
type CompressionTCP string

const (
	// CompressionTCPNone None
	CompressionTCPNone CompressionTCP = "none"
	// CompressionTCPGzip Gzip
	CompressionTCPGzip CompressionTCP = "gzip"
)

func (e CompressionTCP) ToPointer() *CompressionTCP {
	return &e
}

type PqControlsTCP struct {
}

func (p PqControlsTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqTCP struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeTCP `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionTCP `default:"none" json:"compress"`
	PqControls *PqControlsTCP  `json:"pqControls,omitempty"`
}

func (p PqTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqTCP) GetMode() *ModeTCP {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqTCP) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqTCP) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqTCP) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqTCP) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqTCP) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqTCP) GetCompress() *CompressionTCP {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqTCP) GetPqControls() *PqControlsTCP {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MinimumTLSVersionTCP string

const (
	MinimumTLSVersionTCPTlSv1  MinimumTLSVersionTCP = "TLSv1"
	MinimumTLSVersionTCPTlSv11 MinimumTLSVersionTCP = "TLSv1.1"
	MinimumTLSVersionTCPTlSv12 MinimumTLSVersionTCP = "TLSv1.2"
	MinimumTLSVersionTCPTlSv13 MinimumTLSVersionTCP = "TLSv1.3"
)

func (e MinimumTLSVersionTCP) ToPointer() *MinimumTLSVersionTCP {
	return &e
}

type MaximumTLSVersionTCP string

const (
	MaximumTLSVersionTCPTlSv1  MaximumTLSVersionTCP = "TLSv1"
	MaximumTLSVersionTCPTlSv11 MaximumTLSVersionTCP = "TLSv1.1"
	MaximumTLSVersionTCPTlSv12 MaximumTLSVersionTCP = "TLSv1.2"
	MaximumTLSVersionTCPTlSv13 MaximumTLSVersionTCP = "TLSv1.3"
)

func (e MaximumTLSVersionTCP) ToPointer() *MaximumTLSVersionTCP {
	return &e
}

type TLSSettingsServerSideTCP struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string               `json:"caPath,omitempty"`
	MinVersion *MinimumTLSVersionTCP `json:"minVersion,omitempty"`
	MaxVersion *MaximumTLSVersionTCP `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideTCP) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideTCP) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideTCP) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideTCP) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideTCP) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideTCP) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideTCP) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideTCP) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideTCP) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideTCP) GetMinVersion() *MinimumTLSVersionTCP {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideTCP) GetMaxVersion() *MaximumTLSVersionTCP {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

type MetadatumTCP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumTCP) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumTCP) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type PreprocessTCP struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (p PreprocessTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PreprocessTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PreprocessTCP) GetDisabled() *bool {
	if p == nil {
		return nil
	}
	return p.Disabled
}

func (p *PreprocessTCP) GetCommand() *string {
	if p == nil {
		return nil
	}
	return p.Command
}

func (p *PreprocessTCP) GetArgs() []string {
	if p == nil {
		return nil
	}
	return p.Args
}

// AuthenticationMethodTCP - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type AuthenticationMethodTCP string

const (
	AuthenticationMethodTCPManual AuthenticationMethodTCP = "manual"
	AuthenticationMethodTCPSecret AuthenticationMethodTCP = "secret"
)

func (e AuthenticationMethodTCP) ToPointer() *AuthenticationMethodTCP {
	return &e
}

type InputTCP struct {
	// Unique ID for this input
	ID       *string `json:"id,omitempty"`
	Type     TypeTCP `json:"type"`
	Disabled *bool   `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionTCP `json:"connections,omitempty"`
	Pq          *PqTCP          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                   `json:"port"`
	TLS  *TLSSettingsServerSideTCP `json:"tls,omitempty"`
	// Regex matching IP addresses that are allowed to establish a connection
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `default:"0" json:"socketMaxLifespan"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Fields to add to events from this input
	Metadata []MetadatumTCP `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Client will pass the header record with every new connection. The header can contain an authToken, and an object with a list of fields and values to add to every event. These fields can be used to simplify Event Breaker selection, routing, etc. Header has this format, and must be followed by a newline: { "authToken" : "myToken", "fields": { "field1": "value1", "field2": "value2" } }
	EnableHeader *bool          `default:"false" json:"enableHeader"`
	Preprocess   *PreprocessTCP `json:"preprocess,omitempty"`
	Description  *string        `json:"description,omitempty"`
	// Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
	AuthToken *string `default:"" json:"authToken"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *AuthenticationMethodTCP `default:"manual" json:"authType"`
	// Select or create a stored text secret
	TextSecret           *string        `json:"textSecret,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port"}); err != nil {
		return err
	}
	return nil
}

func (i *InputTCP) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputTCP) GetType() TypeTCP {
	if i == nil {
		return TypeTCP("")
	}
	return i.Type
}

func (i *InputTCP) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputTCP) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputTCP) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputTCP) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputTCP) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputTCP) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputTCP) GetConnections() []ConnectionTCP {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputTCP) GetPq() *PqTCP {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputTCP) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputTCP) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputTCP) GetTLS() *TLSSettingsServerSideTCP {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputTCP) GetIPWhitelistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPWhitelistRegex
}

func (i *InputTCP) GetMaxActiveCxn() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveCxn
}

func (i *InputTCP) GetSocketIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketIdleTimeout
}

func (i *InputTCP) GetSocketEndingMaxWait() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketEndingMaxWait
}

func (i *InputTCP) GetSocketMaxLifespan() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketMaxLifespan
}

func (i *InputTCP) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputTCP) GetMetadata() []MetadatumTCP {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputTCP) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputTCP) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputTCP) GetEnableHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHeader
}

func (i *InputTCP) GetPreprocess() *PreprocessTCP {
	if i == nil {
		return nil
	}
	return i.Preprocess
}

func (i *InputTCP) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputTCP) GetAuthToken() *string {
	if i == nil {
		return nil
	}
	return i.AuthToken
}

func (i *InputTCP) GetAuthType() *AuthenticationMethodTCP {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputTCP) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputTCP) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputFileType string

const (
	InputFileTypeFile InputFileType = "file"
)

func (e InputFileType) ToPointer() *InputFileType {
	return &e
}
func (e *InputFileType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "file":
		*e = InputFileType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFileType: %v", v)
	}
}

type InputFileConnection struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (i InputFileConnection) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFileConnection) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (i *InputFileConnection) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputFileConnection) GetOutput() string {
	if i == nil {
		return ""
	}
	return i.Output
}

// InputFilePqMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputFilePqMode string

const (
	// InputFilePqModeSmart Smart
	InputFilePqModeSmart InputFilePqMode = "smart"
	// InputFilePqModeAlways Always On
	InputFilePqModeAlways InputFilePqMode = "always"
)

func (e InputFilePqMode) ToPointer() *InputFilePqMode {
	return &e
}

// InputFileCompression - Codec to use to compress the persisted data
type InputFileCompression string

const (
	// InputFileCompressionNone None
	InputFileCompressionNone InputFileCompression = "none"
	// InputFileCompressionGzip Gzip
	InputFileCompressionGzip InputFileCompression = "gzip"
)

func (e InputFileCompression) ToPointer() *InputFileCompression {
	return &e
}

type InputFilePqControls struct {
}

func (i InputFilePqControls) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFilePqControls) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type InputFilePq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputFilePqMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *InputFileCompression `default:"none" json:"compress"`
	PqControls *InputFilePqControls  `json:"pqControls,omitempty"`
}

func (i InputFilePq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFilePq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputFilePq) GetMode() *InputFilePqMode {
	if i == nil {
		return nil
	}
	return i.Mode
}

func (i *InputFilePq) GetMaxBufferSize() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBufferSize
}

func (i *InputFilePq) GetCommitFrequency() *float64 {
	if i == nil {
		return nil
	}
	return i.CommitFrequency
}

func (i *InputFilePq) GetMaxFileSize() *string {
	if i == nil {
		return nil
	}
	return i.MaxFileSize
}

func (i *InputFilePq) GetMaxSize() *string {
	if i == nil {
		return nil
	}
	return i.MaxSize
}

func (i *InputFilePq) GetPath() *string {
	if i == nil {
		return nil
	}
	return i.Path
}

func (i *InputFilePq) GetCompress() *InputFileCompression {
	if i == nil {
		return nil
	}
	return i.Compress
}

func (i *InputFilePq) GetPqControls() *InputFilePqControls {
	if i == nil {
		return nil
	}
	return i.PqControls
}

// InputFileMode - Choose how to discover files to monitor
type InputFileMode string

const (
	// InputFileModeManual Manual
	InputFileModeManual InputFileMode = "manual"
	// InputFileModeAuto Auto
	InputFileModeAuto InputFileMode = "auto"
)

func (e InputFileMode) ToPointer() *InputFileMode {
	return &e
}

type InputFileMetadatum struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (i InputFileMetadatum) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFileMetadatum) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (i *InputFileMetadatum) GetName() string {
	if i == nil {
		return ""
	}
	return i.Name
}

func (i *InputFileMetadatum) GetValue() string {
	if i == nil {
		return ""
	}
	return i.Value
}

type InputFile struct {
	// Unique ID for this input
	ID       *string       `json:"id,omitempty"`
	Type     InputFileType `json:"type"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputFileConnection `json:"connections,omitempty"`
	Pq          *InputFilePq          `json:"pq,omitempty"`
	// Choose how to discover files to monitor
	Mode *InputFileMode `default:"manual" json:"mode"`
	// Time, in seconds, between scanning for files
	Interval *float64 `default:"10" json:"interval"`
	// The full path of discovered files are matched against this wildcard list
	Filenames []string `json:"filenames,omitempty"`
	// Apply filename allowlist to file entries in archive file types, like tar or zip.
	FilterArchivedFiles *bool `default:"false" json:"filterArchivedFiles"`
	// Read only new entries at the end of all files discovered at next startup. @{product} will then read newly discovered files from the head. Disable this to resume reading all files from head.
	TailOnly *bool `default:"true" json:"tailOnly"`
	// Time, in seconds, before an idle file is closed
	IdleTimeout *float64 `default:"300" json:"idleTimeout"`
	// The minimum age of files to monitor. Format examples: 30s, 15m, 1h. Age is relative to file modification time. Leave empty to apply no age filters.
	MinAgeDur *string `json:"minAgeDur,omitempty"`
	// The maximum age of event timestamps to collect. Format examples: 60s, 4h, 3d, 1w. Can be used in conjuction with "Check file modification times". Leave empty to apply no age filters.
	MaxAgeDur *string `json:"maxAgeDur,omitempty"`
	// Skip files with modification times earlier than the maximum age duration
	CheckFileModTime *bool `default:"false" json:"checkFileModTime"`
	// Forces files containing binary data to be streamed as text
	ForceText *bool `default:"false" json:"forceText"`
	// Length of file header bytes to use in hash for unique file identification
	HashLen *float64 `default:"256" json:"hashLen"`
	// Fields to add to events from this input
	Metadata []InputFileMetadatum `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	Description         *string  `json:"description,omitempty"`
	// Directory path to search for files. Environment variables will be resolved, e.g. $CRIBL_HOME/log/.
	Path *string `json:"path,omitempty"`
	// Set how many subdirectories deep to search. Use 0 to search only files in the given path, 1 to also look in its immediate subdirectories, etc. Leave it empty for unlimited depth.
	Depth                     *float64 `json:"depth,omitempty"`
	SuppressMissingPathErrors *bool    `default:"false" json:"suppressMissingPathErrors"`
	// Delete files after they have been collected
	DeleteFiles *bool `default:"false" json:"deleteFiles"`
	// Stream binary files as Base64-encoded chunks.
	IncludeUnidentifiableBinary *bool          `default:"false" json:"includeUnidentifiableBinary"`
	AdditionalProperties        map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputFile) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFile) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputFile) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputFile) GetType() InputFileType {
	if i == nil {
		return InputFileType("")
	}
	return i.Type
}

func (i *InputFile) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputFile) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputFile) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputFile) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputFile) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputFile) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputFile) GetConnections() []InputFileConnection {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputFile) GetPq() *InputFilePq {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputFile) GetMode() *InputFileMode {
	if i == nil {
		return nil
	}
	return i.Mode
}

func (i *InputFile) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputFile) GetFilenames() []string {
	if i == nil {
		return nil
	}
	return i.Filenames
}

func (i *InputFile) GetFilterArchivedFiles() *bool {
	if i == nil {
		return nil
	}
	return i.FilterArchivedFiles
}

func (i *InputFile) GetTailOnly() *bool {
	if i == nil {
		return nil
	}
	return i.TailOnly
}

func (i *InputFile) GetIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.IdleTimeout
}

func (i *InputFile) GetMinAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MinAgeDur
}

func (i *InputFile) GetMaxAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MaxAgeDur
}

func (i *InputFile) GetCheckFileModTime() *bool {
	if i == nil {
		return nil
	}
	return i.CheckFileModTime
}

func (i *InputFile) GetForceText() *bool {
	if i == nil {
		return nil
	}
	return i.ForceText
}

func (i *InputFile) GetHashLen() *float64 {
	if i == nil {
		return nil
	}
	return i.HashLen
}

func (i *InputFile) GetMetadata() []InputFileMetadatum {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputFile) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputFile) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputFile) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputFile) GetPath() *string {
	if i == nil {
		return nil
	}
	return i.Path
}

func (i *InputFile) GetDepth() *float64 {
	if i == nil {
		return nil
	}
	return i.Depth
}

func (i *InputFile) GetSuppressMissingPathErrors() *bool {
	if i == nil {
		return nil
	}
	return i.SuppressMissingPathErrors
}

func (i *InputFile) GetDeleteFiles() *bool {
	if i == nil {
		return nil
	}
	return i.DeleteFiles
}

func (i *InputFile) GetIncludeUnidentifiableBinary() *bool {
	if i == nil {
		return nil
	}
	return i.IncludeUnidentifiableBinary
}

func (i *InputFile) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputSyslogType2 string

const (
	InputSyslogType2Syslog InputSyslogType2 = "syslog"
)

func (e InputSyslogType2) ToPointer() *InputSyslogType2 {
	return &e
}
func (e *InputSyslogType2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "syslog":
		*e = InputSyslogType2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogType2: %v", v)
	}
}

type InputSyslogConnection2 struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (i InputSyslogConnection2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogConnection2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (i *InputSyslogConnection2) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSyslogConnection2) GetOutput() string {
	if i == nil {
		return ""
	}
	return i.Output
}

// InputSyslogMode2 - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputSyslogMode2 string

const (
	// InputSyslogMode2Smart Smart
	InputSyslogMode2Smart InputSyslogMode2 = "smart"
	// InputSyslogMode2Always Always On
	InputSyslogMode2Always InputSyslogMode2 = "always"
)

func (e InputSyslogMode2) ToPointer() *InputSyslogMode2 {
	return &e
}

// InputSyslogCompression2 - Codec to use to compress the persisted data
type InputSyslogCompression2 string

const (
	// InputSyslogCompression2None None
	InputSyslogCompression2None InputSyslogCompression2 = "none"
	// InputSyslogCompression2Gzip Gzip
	InputSyslogCompression2Gzip InputSyslogCompression2 = "gzip"
)

func (e InputSyslogCompression2) ToPointer() *InputSyslogCompression2 {
	return &e
}

type InputSyslogPqControls2 struct {
}

func (i InputSyslogPqControls2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogPqControls2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type InputSyslogPq2 struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputSyslogMode2 `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *InputSyslogCompression2 `default:"none" json:"compress"`
	PqControls *InputSyslogPqControls2  `json:"pqControls,omitempty"`
}

func (i InputSyslogPq2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogPq2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputSyslogPq2) GetMode() *InputSyslogMode2 {
	if i == nil {
		return nil
	}
	return i.Mode
}

func (i *InputSyslogPq2) GetMaxBufferSize() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBufferSize
}

func (i *InputSyslogPq2) GetCommitFrequency() *float64 {
	if i == nil {
		return nil
	}
	return i.CommitFrequency
}

func (i *InputSyslogPq2) GetMaxFileSize() *string {
	if i == nil {
		return nil
	}
	return i.MaxFileSize
}

func (i *InputSyslogPq2) GetMaxSize() *string {
	if i == nil {
		return nil
	}
	return i.MaxSize
}

func (i *InputSyslogPq2) GetPath() *string {
	if i == nil {
		return nil
	}
	return i.Path
}

func (i *InputSyslogPq2) GetCompress() *InputSyslogCompression2 {
	if i == nil {
		return nil
	}
	return i.Compress
}

func (i *InputSyslogPq2) GetPqControls() *InputSyslogPqControls2 {
	if i == nil {
		return nil
	}
	return i.PqControls
}

type InputSyslogMinimumTLSVersion2 string

const (
	InputSyslogMinimumTLSVersion2TlSv1  InputSyslogMinimumTLSVersion2 = "TLSv1"
	InputSyslogMinimumTLSVersion2TlSv11 InputSyslogMinimumTLSVersion2 = "TLSv1.1"
	InputSyslogMinimumTLSVersion2TlSv12 InputSyslogMinimumTLSVersion2 = "TLSv1.2"
	InputSyslogMinimumTLSVersion2TlSv13 InputSyslogMinimumTLSVersion2 = "TLSv1.3"
)

func (e InputSyslogMinimumTLSVersion2) ToPointer() *InputSyslogMinimumTLSVersion2 {
	return &e
}

type InputSyslogMaximumTLSVersion2 string

const (
	InputSyslogMaximumTLSVersion2TlSv1  InputSyslogMaximumTLSVersion2 = "TLSv1"
	InputSyslogMaximumTLSVersion2TlSv11 InputSyslogMaximumTLSVersion2 = "TLSv1.1"
	InputSyslogMaximumTLSVersion2TlSv12 InputSyslogMaximumTLSVersion2 = "TLSv1.2"
	InputSyslogMaximumTLSVersion2TlSv13 InputSyslogMaximumTLSVersion2 = "TLSv1.3"
)

func (e InputSyslogMaximumTLSVersion2) ToPointer() *InputSyslogMaximumTLSVersion2 {
	return &e
}

type InputSyslogTLSSettingsServerSide2 struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                        `json:"caPath,omitempty"`
	MinVersion *InputSyslogMinimumTLSVersion2 `json:"minVersion,omitempty"`
	MaxVersion *InputSyslogMaximumTLSVersion2 `json:"maxVersion,omitempty"`
}

func (i InputSyslogTLSSettingsServerSide2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogTLSSettingsServerSide2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputSyslogTLSSettingsServerSide2) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSyslogTLSSettingsServerSide2) GetRequestCert() *bool {
	if i == nil {
		return nil
	}
	return i.RequestCert
}

func (i *InputSyslogTLSSettingsServerSide2) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputSyslogTLSSettingsServerSide2) GetCommonNameRegex() *string {
	if i == nil {
		return nil
	}
	return i.CommonNameRegex
}

func (i *InputSyslogTLSSettingsServerSide2) GetCertificateName() *string {
	if i == nil {
		return nil
	}
	return i.CertificateName
}

func (i *InputSyslogTLSSettingsServerSide2) GetPrivKeyPath() *string {
	if i == nil {
		return nil
	}
	return i.PrivKeyPath
}

func (i *InputSyslogTLSSettingsServerSide2) GetPassphrase() *string {
	if i == nil {
		return nil
	}
	return i.Passphrase
}

func (i *InputSyslogTLSSettingsServerSide2) GetCertPath() *string {
	if i == nil {
		return nil
	}
	return i.CertPath
}

func (i *InputSyslogTLSSettingsServerSide2) GetCaPath() *string {
	if i == nil {
		return nil
	}
	return i.CaPath
}

func (i *InputSyslogTLSSettingsServerSide2) GetMinVersion() *InputSyslogMinimumTLSVersion2 {
	if i == nil {
		return nil
	}
	return i.MinVersion
}

func (i *InputSyslogTLSSettingsServerSide2) GetMaxVersion() *InputSyslogMaximumTLSVersion2 {
	if i == nil {
		return nil
	}
	return i.MaxVersion
}

type InputSyslogMetadatum2 struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (i InputSyslogMetadatum2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogMetadatum2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (i *InputSyslogMetadatum2) GetName() string {
	if i == nil {
		return ""
	}
	return i.Name
}

func (i *InputSyslogMetadatum2) GetValue() string {
	if i == nil {
		return ""
	}
	return i.Value
}

type InputSyslogSyslog2 struct {
	// Unique ID for this input
	ID       *string          `json:"id,omitempty"`
	Type     InputSyslogType2 `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputSyslogConnection2 `json:"connections,omitempty"`
	Pq          *InputSyslogPq2          `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Enter UDP port number to listen on. Not required if listening on TCP.
	UDPPort *float64 `json:"udpPort,omitempty"`
	// Enter TCP port number to listen on. Not required if listening on UDP.
	TCPPort float64 `json:"tcpPort"`
	// Maximum number of events to buffer when downstream is blocking. Only applies to UDP.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Timezone to assign to timestamps without timezone info
	TimestampTimezone *string `default:"local" json:"timestampTimezone"`
	// Treat UDP packet data received as full syslog message
	SingleMsgUDPPackets *bool `default:"false" json:"singleMsgUdpPackets"`
	// Enable if the connection is proxied by a device that supports Proxy Protocol V1 or V2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Wildcard list of fields to keep from source data; * = ALL (default)
	KeepFieldsList []string `json:"keepFieldsList,omitempty"`
	// Enable if incoming messages use octet counting per RFC 6587.
	OctetCounting *bool `default:"false" json:"octetCounting"`
	// Enable if we should infer the syslog framing of the incoming messages.
	InferFraming *bool `default:"true" json:"inferFraming"`
	// Enable if we should infer octet counting only if the messages comply with RFC 5424.
	StrictlyInferOctetCounting *bool `default:"true" json:"strictlyInferOctetCounting"`
	// Enable if RFC 3164-formatted messages have hyphens in the app name portion of the TAG section. If disabled, only alphanumeric characters and underscores are allowed. Ignored for RFC 5424-formatted messages.
	AllowNonStandardAppName *bool `default:"false" json:"allowNonStandardAppName"`
	// Maximum number of active connections allowed per Worker Process for TCP connections. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64                           `default:"0" json:"socketMaxLifespan"`
	TLS               *InputSyslogTLSSettingsServerSide2 `json:"tls,omitempty"`
	// Fields to add to events from this input
	Metadata []InputSyslogMetadatum2 `json:"metadata,omitempty"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool   `default:"false" json:"enableLoadBalancing"`
	Description         *string `json:"description,omitempty"`
	// When enabled, parses PROXY protocol headers during the TLS handshake. Disable if compatibility issues arise.
	EnableEnhancedProxyHeaderParsing *bool          `json:"enableEnhancedProxyHeaderParsing,omitempty"`
	AdditionalProperties             map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputSyslogSyslog2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogSyslog2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "tcpPort"}); err != nil {
		return err
	}
	return nil
}

func (i *InputSyslogSyslog2) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputSyslogSyslog2) GetType() InputSyslogType2 {
	if i == nil {
		return InputSyslogType2("")
	}
	return i.Type
}

func (i *InputSyslogSyslog2) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSyslogSyslog2) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSyslogSyslog2) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputSyslogSyslog2) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputSyslogSyslog2) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputSyslogSyslog2) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputSyslogSyslog2) GetConnections() []InputSyslogConnection2 {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputSyslogSyslog2) GetPq() *InputSyslogPq2 {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputSyslogSyslog2) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputSyslogSyslog2) GetUDPPort() *float64 {
	if i == nil {
		return nil
	}
	return i.UDPPort
}

func (i *InputSyslogSyslog2) GetTCPPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.TCPPort
}

func (i *InputSyslogSyslog2) GetMaxBufferSize() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBufferSize
}

func (i *InputSyslogSyslog2) GetIPWhitelistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPWhitelistRegex
}

func (i *InputSyslogSyslog2) GetTimestampTimezone() *string {
	if i == nil {
		return nil
	}
	return i.TimestampTimezone
}

func (i *InputSyslogSyslog2) GetSingleMsgUDPPackets() *bool {
	if i == nil {
		return nil
	}
	return i.SingleMsgUDPPackets
}

func (i *InputSyslogSyslog2) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputSyslogSyslog2) GetKeepFieldsList() []string {
	if i == nil {
		return nil
	}
	return i.KeepFieldsList
}

func (i *InputSyslogSyslog2) GetOctetCounting() *bool {
	if i == nil {
		return nil
	}
	return i.OctetCounting
}

func (i *InputSyslogSyslog2) GetInferFraming() *bool {
	if i == nil {
		return nil
	}
	return i.InferFraming
}

func (i *InputSyslogSyslog2) GetStrictlyInferOctetCounting() *bool {
	if i == nil {
		return nil
	}
	return i.StrictlyInferOctetCounting
}

func (i *InputSyslogSyslog2) GetAllowNonStandardAppName() *bool {
	if i == nil {
		return nil
	}
	return i.AllowNonStandardAppName
}

func (i *InputSyslogSyslog2) GetMaxActiveCxn() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveCxn
}

func (i *InputSyslogSyslog2) GetSocketIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketIdleTimeout
}

func (i *InputSyslogSyslog2) GetSocketEndingMaxWait() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketEndingMaxWait
}

func (i *InputSyslogSyslog2) GetSocketMaxLifespan() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketMaxLifespan
}

func (i *InputSyslogSyslog2) GetTLS() *InputSyslogTLSSettingsServerSide2 {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputSyslogSyslog2) GetMetadata() []InputSyslogMetadatum2 {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputSyslogSyslog2) GetUDPSocketRxBufSize() *float64 {
	if i == nil {
		return nil
	}
	return i.UDPSocketRxBufSize
}

func (i *InputSyslogSyslog2) GetEnableLoadBalancing() *bool {
	if i == nil {
		return nil
	}
	return i.EnableLoadBalancing
}

func (i *InputSyslogSyslog2) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputSyslogSyslog2) GetEnableEnhancedProxyHeaderParsing() *bool {
	if i == nil {
		return nil
	}
	return i.EnableEnhancedProxyHeaderParsing
}

func (i *InputSyslogSyslog2) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputSyslogType1 string

const (
	InputSyslogType1Syslog InputSyslogType1 = "syslog"
)

func (e InputSyslogType1) ToPointer() *InputSyslogType1 {
	return &e
}
func (e *InputSyslogType1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "syslog":
		*e = InputSyslogType1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogType1: %v", v)
	}
}

type InputSyslogConnection1 struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (i InputSyslogConnection1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogConnection1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (i *InputSyslogConnection1) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSyslogConnection1) GetOutput() string {
	if i == nil {
		return ""
	}
	return i.Output
}

// InputSyslogMode1 - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputSyslogMode1 string

const (
	// InputSyslogMode1Smart Smart
	InputSyslogMode1Smart InputSyslogMode1 = "smart"
	// InputSyslogMode1Always Always On
	InputSyslogMode1Always InputSyslogMode1 = "always"
)

func (e InputSyslogMode1) ToPointer() *InputSyslogMode1 {
	return &e
}

// InputSyslogCompression1 - Codec to use to compress the persisted data
type InputSyslogCompression1 string

const (
	// InputSyslogCompression1None None
	InputSyslogCompression1None InputSyslogCompression1 = "none"
	// InputSyslogCompression1Gzip Gzip
	InputSyslogCompression1Gzip InputSyslogCompression1 = "gzip"
)

func (e InputSyslogCompression1) ToPointer() *InputSyslogCompression1 {
	return &e
}

type InputSyslogPqControls1 struct {
}

func (i InputSyslogPqControls1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogPqControls1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type InputSyslogPq1 struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputSyslogMode1 `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *InputSyslogCompression1 `default:"none" json:"compress"`
	PqControls *InputSyslogPqControls1  `json:"pqControls,omitempty"`
}

func (i InputSyslogPq1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogPq1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputSyslogPq1) GetMode() *InputSyslogMode1 {
	if i == nil {
		return nil
	}
	return i.Mode
}

func (i *InputSyslogPq1) GetMaxBufferSize() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBufferSize
}

func (i *InputSyslogPq1) GetCommitFrequency() *float64 {
	if i == nil {
		return nil
	}
	return i.CommitFrequency
}

func (i *InputSyslogPq1) GetMaxFileSize() *string {
	if i == nil {
		return nil
	}
	return i.MaxFileSize
}

func (i *InputSyslogPq1) GetMaxSize() *string {
	if i == nil {
		return nil
	}
	return i.MaxSize
}

func (i *InputSyslogPq1) GetPath() *string {
	if i == nil {
		return nil
	}
	return i.Path
}

func (i *InputSyslogPq1) GetCompress() *InputSyslogCompression1 {
	if i == nil {
		return nil
	}
	return i.Compress
}

func (i *InputSyslogPq1) GetPqControls() *InputSyslogPqControls1 {
	if i == nil {
		return nil
	}
	return i.PqControls
}

type InputSyslogMinimumTLSVersion1 string

const (
	InputSyslogMinimumTLSVersion1TlSv1  InputSyslogMinimumTLSVersion1 = "TLSv1"
	InputSyslogMinimumTLSVersion1TlSv11 InputSyslogMinimumTLSVersion1 = "TLSv1.1"
	InputSyslogMinimumTLSVersion1TlSv12 InputSyslogMinimumTLSVersion1 = "TLSv1.2"
	InputSyslogMinimumTLSVersion1TlSv13 InputSyslogMinimumTLSVersion1 = "TLSv1.3"
)

func (e InputSyslogMinimumTLSVersion1) ToPointer() *InputSyslogMinimumTLSVersion1 {
	return &e
}

type InputSyslogMaximumTLSVersion1 string

const (
	InputSyslogMaximumTLSVersion1TlSv1  InputSyslogMaximumTLSVersion1 = "TLSv1"
	InputSyslogMaximumTLSVersion1TlSv11 InputSyslogMaximumTLSVersion1 = "TLSv1.1"
	InputSyslogMaximumTLSVersion1TlSv12 InputSyslogMaximumTLSVersion1 = "TLSv1.2"
	InputSyslogMaximumTLSVersion1TlSv13 InputSyslogMaximumTLSVersion1 = "TLSv1.3"
)

func (e InputSyslogMaximumTLSVersion1) ToPointer() *InputSyslogMaximumTLSVersion1 {
	return &e
}

type InputSyslogTLSSettingsServerSide1 struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                        `json:"caPath,omitempty"`
	MinVersion *InputSyslogMinimumTLSVersion1 `json:"minVersion,omitempty"`
	MaxVersion *InputSyslogMaximumTLSVersion1 `json:"maxVersion,omitempty"`
}

func (i InputSyslogTLSSettingsServerSide1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogTLSSettingsServerSide1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputSyslogTLSSettingsServerSide1) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSyslogTLSSettingsServerSide1) GetRequestCert() *bool {
	if i == nil {
		return nil
	}
	return i.RequestCert
}

func (i *InputSyslogTLSSettingsServerSide1) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputSyslogTLSSettingsServerSide1) GetCommonNameRegex() *string {
	if i == nil {
		return nil
	}
	return i.CommonNameRegex
}

func (i *InputSyslogTLSSettingsServerSide1) GetCertificateName() *string {
	if i == nil {
		return nil
	}
	return i.CertificateName
}

func (i *InputSyslogTLSSettingsServerSide1) GetPrivKeyPath() *string {
	if i == nil {
		return nil
	}
	return i.PrivKeyPath
}

func (i *InputSyslogTLSSettingsServerSide1) GetPassphrase() *string {
	if i == nil {
		return nil
	}
	return i.Passphrase
}

func (i *InputSyslogTLSSettingsServerSide1) GetCertPath() *string {
	if i == nil {
		return nil
	}
	return i.CertPath
}

func (i *InputSyslogTLSSettingsServerSide1) GetCaPath() *string {
	if i == nil {
		return nil
	}
	return i.CaPath
}

func (i *InputSyslogTLSSettingsServerSide1) GetMinVersion() *InputSyslogMinimumTLSVersion1 {
	if i == nil {
		return nil
	}
	return i.MinVersion
}

func (i *InputSyslogTLSSettingsServerSide1) GetMaxVersion() *InputSyslogMaximumTLSVersion1 {
	if i == nil {
		return nil
	}
	return i.MaxVersion
}

type InputSyslogMetadatum1 struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (i InputSyslogMetadatum1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogMetadatum1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (i *InputSyslogMetadatum1) GetName() string {
	if i == nil {
		return ""
	}
	return i.Name
}

func (i *InputSyslogMetadatum1) GetValue() string {
	if i == nil {
		return ""
	}
	return i.Value
}

type InputSyslogSyslog1 struct {
	// Unique ID for this input
	ID       *string          `json:"id,omitempty"`
	Type     InputSyslogType1 `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputSyslogConnection1 `json:"connections,omitempty"`
	Pq          *InputSyslogPq1          `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Enter UDP port number to listen on. Not required if listening on TCP.
	UDPPort float64 `json:"udpPort"`
	// Enter TCP port number to listen on. Not required if listening on UDP.
	TCPPort *float64 `json:"tcpPort,omitempty"`
	// Maximum number of events to buffer when downstream is blocking. Only applies to UDP.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Timezone to assign to timestamps without timezone info
	TimestampTimezone *string `default:"local" json:"timestampTimezone"`
	// Treat UDP packet data received as full syslog message
	SingleMsgUDPPackets *bool `default:"false" json:"singleMsgUdpPackets"`
	// Enable if the connection is proxied by a device that supports Proxy Protocol V1 or V2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Wildcard list of fields to keep from source data; * = ALL (default)
	KeepFieldsList []string `json:"keepFieldsList,omitempty"`
	// Enable if incoming messages use octet counting per RFC 6587.
	OctetCounting *bool `default:"false" json:"octetCounting"`
	// Enable if we should infer the syslog framing of the incoming messages.
	InferFraming *bool `default:"true" json:"inferFraming"`
	// Enable if we should infer octet counting only if the messages comply with RFC 5424.
	StrictlyInferOctetCounting *bool `default:"true" json:"strictlyInferOctetCounting"`
	// Enable if RFC 3164-formatted messages have hyphens in the app name portion of the TAG section. If disabled, only alphanumeric characters and underscores are allowed. Ignored for RFC 5424-formatted messages.
	AllowNonStandardAppName *bool `default:"false" json:"allowNonStandardAppName"`
	// Maximum number of active connections allowed per Worker Process for TCP connections. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64                           `default:"0" json:"socketMaxLifespan"`
	TLS               *InputSyslogTLSSettingsServerSide1 `json:"tls,omitempty"`
	// Fields to add to events from this input
	Metadata []InputSyslogMetadatum1 `json:"metadata,omitempty"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool   `default:"false" json:"enableLoadBalancing"`
	Description         *string `json:"description,omitempty"`
	// When enabled, parses PROXY protocol headers during the TLS handshake. Disable if compatibility issues arise.
	EnableEnhancedProxyHeaderParsing *bool          `json:"enableEnhancedProxyHeaderParsing,omitempty"`
	AdditionalProperties             map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputSyslogSyslog1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogSyslog1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "udpPort"}); err != nil {
		return err
	}
	return nil
}

func (i *InputSyslogSyslog1) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputSyslogSyslog1) GetType() InputSyslogType1 {
	if i == nil {
		return InputSyslogType1("")
	}
	return i.Type
}

func (i *InputSyslogSyslog1) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSyslogSyslog1) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSyslogSyslog1) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputSyslogSyslog1) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputSyslogSyslog1) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputSyslogSyslog1) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputSyslogSyslog1) GetConnections() []InputSyslogConnection1 {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputSyslogSyslog1) GetPq() *InputSyslogPq1 {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputSyslogSyslog1) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputSyslogSyslog1) GetUDPPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.UDPPort
}

func (i *InputSyslogSyslog1) GetTCPPort() *float64 {
	if i == nil {
		return nil
	}
	return i.TCPPort
}

func (i *InputSyslogSyslog1) GetMaxBufferSize() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBufferSize
}

func (i *InputSyslogSyslog1) GetIPWhitelistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPWhitelistRegex
}

func (i *InputSyslogSyslog1) GetTimestampTimezone() *string {
	if i == nil {
		return nil
	}
	return i.TimestampTimezone
}

func (i *InputSyslogSyslog1) GetSingleMsgUDPPackets() *bool {
	if i == nil {
		return nil
	}
	return i.SingleMsgUDPPackets
}

func (i *InputSyslogSyslog1) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputSyslogSyslog1) GetKeepFieldsList() []string {
	if i == nil {
		return nil
	}
	return i.KeepFieldsList
}

func (i *InputSyslogSyslog1) GetOctetCounting() *bool {
	if i == nil {
		return nil
	}
	return i.OctetCounting
}

func (i *InputSyslogSyslog1) GetInferFraming() *bool {
	if i == nil {
		return nil
	}
	return i.InferFraming
}

func (i *InputSyslogSyslog1) GetStrictlyInferOctetCounting() *bool {
	if i == nil {
		return nil
	}
	return i.StrictlyInferOctetCounting
}

func (i *InputSyslogSyslog1) GetAllowNonStandardAppName() *bool {
	if i == nil {
		return nil
	}
	return i.AllowNonStandardAppName
}

func (i *InputSyslogSyslog1) GetMaxActiveCxn() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveCxn
}

func (i *InputSyslogSyslog1) GetSocketIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketIdleTimeout
}

func (i *InputSyslogSyslog1) GetSocketEndingMaxWait() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketEndingMaxWait
}

func (i *InputSyslogSyslog1) GetSocketMaxLifespan() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketMaxLifespan
}

func (i *InputSyslogSyslog1) GetTLS() *InputSyslogTLSSettingsServerSide1 {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputSyslogSyslog1) GetMetadata() []InputSyslogMetadatum1 {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputSyslogSyslog1) GetUDPSocketRxBufSize() *float64 {
	if i == nil {
		return nil
	}
	return i.UDPSocketRxBufSize
}

func (i *InputSyslogSyslog1) GetEnableLoadBalancing() *bool {
	if i == nil {
		return nil
	}
	return i.EnableLoadBalancing
}

func (i *InputSyslogSyslog1) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputSyslogSyslog1) GetEnableEnhancedProxyHeaderParsing() *bool {
	if i == nil {
		return nil
	}
	return i.EnableEnhancedProxyHeaderParsing
}

func (i *InputSyslogSyslog1) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputSyslogType string

const (
	InputSyslogTypeInputSyslogSyslog1 InputSyslogType = "InputSyslog_Syslog_1"
	InputSyslogTypeInputSyslogSyslog2 InputSyslogType = "InputSyslog_Syslog_2"
)

type InputSyslog struct {
	InputSyslogSyslog1 *InputSyslogSyslog1 `queryParam:"inline,name=InputSyslog"`
	InputSyslogSyslog2 *InputSyslogSyslog2 `queryParam:"inline,name=InputSyslog"`

	Type InputSyslogType
}

func CreateInputSyslogInputSyslogSyslog1(inputSyslogSyslog1 InputSyslogSyslog1) InputSyslog {
	typ := InputSyslogTypeInputSyslogSyslog1

	return InputSyslog{
		InputSyslogSyslog1: &inputSyslogSyslog1,
		Type:               typ,
	}
}

func CreateInputSyslogInputSyslogSyslog2(inputSyslogSyslog2 InputSyslogSyslog2) InputSyslog {
	typ := InputSyslogTypeInputSyslogSyslog2

	return InputSyslog{
		InputSyslogSyslog2: &inputSyslogSyslog2,
		Type:               typ,
	}
}

func (u *InputSyslog) UnmarshalJSON(data []byte) error {

	var inputSyslogSyslog1 InputSyslogSyslog1 = InputSyslogSyslog1{}
	if err := utils.UnmarshalJSON(data, &inputSyslogSyslog1, "", true, nil); err == nil {
		u.InputSyslogSyslog1 = &inputSyslogSyslog1
		u.Type = InputSyslogTypeInputSyslogSyslog1
		return nil
	}

	var inputSyslogSyslog2 InputSyslogSyslog2 = InputSyslogSyslog2{}
	if err := utils.UnmarshalJSON(data, &inputSyslogSyslog2, "", true, nil); err == nil {
		u.InputSyslogSyslog2 = &inputSyslogSyslog2
		u.Type = InputSyslogTypeInputSyslogSyslog2
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for InputSyslog", string(data))
}

func (u InputSyslog) MarshalJSON() ([]byte, error) {
	if u.InputSyslogSyslog1 != nil {
		return utils.MarshalJSON(u.InputSyslogSyslog1, "", true)
	}

	if u.InputSyslogSyslog2 != nil {
		return utils.MarshalJSON(u.InputSyslogSyslog2, "", true)
	}

	return nil, errors.New("could not marshal union type InputSyslog: all fields are null")
}

type InputTypeSqs string

const (
	InputTypeSqsSqs InputTypeSqs = "sqs"
)

func (e InputTypeSqs) ToPointer() *InputTypeSqs {
	return &e
}
func (e *InputTypeSqs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sqs":
		*e = InputTypeSqs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeSqs: %v", v)
	}
}

type ConnectionSqs struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionSqs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionSqs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionSqs) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionSqs) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// PqModeSqs - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeSqs string

const (
	// PqModeSqsSmart Smart
	PqModeSqsSmart PqModeSqs = "smart"
	// PqModeSqsAlways Always On
	PqModeSqsAlways PqModeSqs = "always"
)

func (e PqModeSqs) ToPointer() *PqModeSqs {
	return &e
}

// PqCompressionSqs - Codec to use to compress the persisted data
type PqCompressionSqs string

const (
	// PqCompressionSqsNone None
	PqCompressionSqsNone PqCompressionSqs = "none"
	// PqCompressionSqsGzip Gzip
	PqCompressionSqsGzip PqCompressionSqs = "gzip"
)

func (e PqCompressionSqs) ToPointer() *PqCompressionSqs {
	return &e
}

type InputPqControlsSqs struct {
}

func (i InputPqControlsSqs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPqControlsSqs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqSqs struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeSqs `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *PqCompressionSqs   `default:"none" json:"compress"`
	PqControls *InputPqControlsSqs `json:"pqControls,omitempty"`
}

func (p PqSqs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSqs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqSqs) GetMode() *PqModeSqs {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqSqs) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqSqs) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqSqs) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqSqs) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqSqs) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqSqs) GetCompress() *PqCompressionSqs {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqSqs) GetPqControls() *InputPqControlsSqs {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// InputQueueType - The queue type used (or created)
type InputQueueType string

const (
	// InputQueueTypeStandard Standard
	InputQueueTypeStandard InputQueueType = "standard"
	// InputQueueTypeFifo FIFO
	InputQueueTypeFifo InputQueueType = "fifo"
)

func (e InputQueueType) ToPointer() *InputQueueType {
	return &e
}

// InputAuthenticationMethodSqs - AWS authentication method. Choose Auto to use IAM roles.
type InputAuthenticationMethodSqs string

const (
	// InputAuthenticationMethodSqsAuto Auto
	InputAuthenticationMethodSqsAuto InputAuthenticationMethodSqs = "auto"
	// InputAuthenticationMethodSqsManual Manual
	InputAuthenticationMethodSqsManual InputAuthenticationMethodSqs = "manual"
	// InputAuthenticationMethodSqsSecret Secret Key pair
	InputAuthenticationMethodSqsSecret InputAuthenticationMethodSqs = "secret"
)

func (e InputAuthenticationMethodSqs) ToPointer() *InputAuthenticationMethodSqs {
	return &e
}

// InputSignatureVersionSqs - Signature version to use for signing SQS requests
type InputSignatureVersionSqs string

const (
	InputSignatureVersionSqsV2 InputSignatureVersionSqs = "v2"
	InputSignatureVersionSqsV4 InputSignatureVersionSqs = "v4"
)

func (e InputSignatureVersionSqs) ToPointer() *InputSignatureVersionSqs {
	return &e
}

type MetadatumSqs struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumSqs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumSqs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumSqs) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumSqs) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputSqs struct {
	// Unique ID for this input
	ID       *string      `json:"id,omitempty"`
	Type     InputTypeSqs `json:"type"`
	Disabled *bool        `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSqs `json:"connections,omitempty"`
	Pq          *PqSqs          `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read events from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can only be evaluated at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// The queue type used (or created)
	QueueType InputQueueType `json:"queueType"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// Create queue if it does not exist
	CreateQueue *bool `default:"false" json:"createQueue"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *InputAuthenticationMethodSqs `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                       `json:"awsSecretKey,omitempty"`
	// AWS Region where the SQS queue is located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// SQS service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to SQS-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing SQS requests
	SignatureVersion *InputSignatureVersionSqs `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access SQS
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"10" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// Fields to add to events from this input
	Metadata []MetadatumSqs `json:"metadata,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	Description *string  `json:"description,omitempty"`
	AwsAPIKey   *string  `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers         *float64       `default:"3" json:"numReceivers"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputSqs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSqs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "queueName", "queueType"}); err != nil {
		return err
	}
	return nil
}

func (i *InputSqs) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputSqs) GetType() InputTypeSqs {
	if i == nil {
		return InputTypeSqs("")
	}
	return i.Type
}

func (i *InputSqs) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSqs) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSqs) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputSqs) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputSqs) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputSqs) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputSqs) GetConnections() []ConnectionSqs {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputSqs) GetPq() *PqSqs {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputSqs) GetQueueName() string {
	if i == nil {
		return ""
	}
	return i.QueueName
}

func (i *InputSqs) GetQueueType() InputQueueType {
	if i == nil {
		return InputQueueType("")
	}
	return i.QueueType
}

func (i *InputSqs) GetAwsAccountID() *string {
	if i == nil {
		return nil
	}
	return i.AwsAccountID
}

func (i *InputSqs) GetCreateQueue() *bool {
	if i == nil {
		return nil
	}
	return i.CreateQueue
}

func (i *InputSqs) GetAwsAuthenticationMethod() *InputAuthenticationMethodSqs {
	if i == nil {
		return nil
	}
	return i.AwsAuthenticationMethod
}

func (i *InputSqs) GetAwsSecretKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecretKey
}

func (i *InputSqs) GetRegion() *string {
	if i == nil {
		return nil
	}
	return i.Region
}

func (i *InputSqs) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputSqs) GetSignatureVersion() *InputSignatureVersionSqs {
	if i == nil {
		return nil
	}
	return i.SignatureVersion
}

func (i *InputSqs) GetReuseConnections() *bool {
	if i == nil {
		return nil
	}
	return i.ReuseConnections
}

func (i *InputSqs) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputSqs) GetEnableAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableAssumeRole
}

func (i *InputSqs) GetAssumeRoleArn() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleArn
}

func (i *InputSqs) GetAssumeRoleExternalID() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleExternalID
}

func (i *InputSqs) GetDurationSeconds() *float64 {
	if i == nil {
		return nil
	}
	return i.DurationSeconds
}

func (i *InputSqs) GetMaxMessages() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMessages
}

func (i *InputSqs) GetVisibilityTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.VisibilityTimeout
}

func (i *InputSqs) GetMetadata() []MetadatumSqs {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputSqs) GetPollTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.PollTimeout
}

func (i *InputSqs) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputSqs) GetAwsAPIKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsAPIKey
}

func (i *InputSqs) GetAwsSecret() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecret
}

func (i *InputSqs) GetNumReceivers() *float64 {
	if i == nil {
		return nil
	}
	return i.NumReceivers
}

func (i *InputSqs) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeModelDrivenTelemetry string

const (
	TypeModelDrivenTelemetryModelDrivenTelemetry TypeModelDrivenTelemetry = "model_driven_telemetry"
)

func (e TypeModelDrivenTelemetry) ToPointer() *TypeModelDrivenTelemetry {
	return &e
}
func (e *TypeModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "model_driven_telemetry":
		*e = TypeModelDrivenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeModelDrivenTelemetry: %v", v)
	}
}

type ConnectionModelDrivenTelemetry struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionModelDrivenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionModelDrivenTelemetry) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionModelDrivenTelemetry) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeModelDrivenTelemetry - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeModelDrivenTelemetry string

const (
	// ModeModelDrivenTelemetrySmart Smart
	ModeModelDrivenTelemetrySmart ModeModelDrivenTelemetry = "smart"
	// ModeModelDrivenTelemetryAlways Always On
	ModeModelDrivenTelemetryAlways ModeModelDrivenTelemetry = "always"
)

func (e ModeModelDrivenTelemetry) ToPointer() *ModeModelDrivenTelemetry {
	return &e
}

// CompressionModelDrivenTelemetry - Codec to use to compress the persisted data
type CompressionModelDrivenTelemetry string

const (
	// CompressionModelDrivenTelemetryNone None
	CompressionModelDrivenTelemetryNone CompressionModelDrivenTelemetry = "none"
	// CompressionModelDrivenTelemetryGzip Gzip
	CompressionModelDrivenTelemetryGzip CompressionModelDrivenTelemetry = "gzip"
)

func (e CompressionModelDrivenTelemetry) ToPointer() *CompressionModelDrivenTelemetry {
	return &e
}

type PqControlsModelDrivenTelemetry struct {
}

func (p PqControlsModelDrivenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqModelDrivenTelemetry struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeModelDrivenTelemetry `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionModelDrivenTelemetry `default:"none" json:"compress"`
	PqControls *PqControlsModelDrivenTelemetry  `json:"pqControls,omitempty"`
}

func (p PqModelDrivenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqModelDrivenTelemetry) GetMode() *ModeModelDrivenTelemetry {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqModelDrivenTelemetry) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqModelDrivenTelemetry) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqModelDrivenTelemetry) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqModelDrivenTelemetry) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqModelDrivenTelemetry) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqModelDrivenTelemetry) GetCompress() *CompressionModelDrivenTelemetry {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqModelDrivenTelemetry) GetPqControls() *PqControlsModelDrivenTelemetry {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MinimumTLSVersionModelDrivenTelemetry string

const (
	MinimumTLSVersionModelDrivenTelemetryTlSv1  MinimumTLSVersionModelDrivenTelemetry = "TLSv1"
	MinimumTLSVersionModelDrivenTelemetryTlSv11 MinimumTLSVersionModelDrivenTelemetry = "TLSv1.1"
	MinimumTLSVersionModelDrivenTelemetryTlSv12 MinimumTLSVersionModelDrivenTelemetry = "TLSv1.2"
	MinimumTLSVersionModelDrivenTelemetryTlSv13 MinimumTLSVersionModelDrivenTelemetry = "TLSv1.3"
)

func (e MinimumTLSVersionModelDrivenTelemetry) ToPointer() *MinimumTLSVersionModelDrivenTelemetry {
	return &e
}

type MaximumTLSVersionModelDrivenTelemetry string

const (
	MaximumTLSVersionModelDrivenTelemetryTlSv1  MaximumTLSVersionModelDrivenTelemetry = "TLSv1"
	MaximumTLSVersionModelDrivenTelemetryTlSv11 MaximumTLSVersionModelDrivenTelemetry = "TLSv1.1"
	MaximumTLSVersionModelDrivenTelemetryTlSv12 MaximumTLSVersionModelDrivenTelemetry = "TLSv1.2"
	MaximumTLSVersionModelDrivenTelemetryTlSv13 MaximumTLSVersionModelDrivenTelemetry = "TLSv1.3"
)

func (e MaximumTLSVersionModelDrivenTelemetry) ToPointer() *MaximumTLSVersionModelDrivenTelemetry {
	return &e
}

type TLSSettingsServerSideModelDrivenTelemetry struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                                `json:"caPath,omitempty"`
	MinVersion *MinimumTLSVersionModelDrivenTelemetry `json:"minVersion,omitempty"`
	MaxVersion *MaximumTLSVersionModelDrivenTelemetry `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideModelDrivenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideModelDrivenTelemetry) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideModelDrivenTelemetry) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideModelDrivenTelemetry) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideModelDrivenTelemetry) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideModelDrivenTelemetry) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideModelDrivenTelemetry) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideModelDrivenTelemetry) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideModelDrivenTelemetry) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideModelDrivenTelemetry) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideModelDrivenTelemetry) GetMinVersion() *MinimumTLSVersionModelDrivenTelemetry {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideModelDrivenTelemetry) GetMaxVersion() *MaximumTLSVersionModelDrivenTelemetry {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

type MetadatumModelDrivenTelemetry struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumModelDrivenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumModelDrivenTelemetry) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumModelDrivenTelemetry) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputModelDrivenTelemetry struct {
	// Unique ID for this input
	ID       *string                  `json:"id,omitempty"`
	Type     TypeModelDrivenTelemetry `json:"type"`
	Disabled *bool                    `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionModelDrivenTelemetry `json:"connections,omitempty"`
	Pq          *PqModelDrivenTelemetry          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port *float64                                   `default:"57000" json:"port"`
	TLS  *TLSSettingsServerSideModelDrivenTelemetry `json:"tls,omitempty"`
	// Fields to add to events from this input
	Metadata []MetadatumModelDrivenTelemetry `json:"metadata,omitempty"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// Time in milliseconds to allow the server to shutdown gracefully before forcing shutdown. Defaults to 5000.
	ShutdownTimeoutMs    *float64       `default:"5000" json:"shutdownTimeoutMs"`
	Description          *string        `json:"description,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputModelDrivenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputModelDrivenTelemetry) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputModelDrivenTelemetry) GetType() TypeModelDrivenTelemetry {
	if i == nil {
		return TypeModelDrivenTelemetry("")
	}
	return i.Type
}

func (i *InputModelDrivenTelemetry) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputModelDrivenTelemetry) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputModelDrivenTelemetry) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputModelDrivenTelemetry) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputModelDrivenTelemetry) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputModelDrivenTelemetry) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputModelDrivenTelemetry) GetConnections() []ConnectionModelDrivenTelemetry {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputModelDrivenTelemetry) GetPq() *PqModelDrivenTelemetry {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputModelDrivenTelemetry) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputModelDrivenTelemetry) GetPort() *float64 {
	if i == nil {
		return nil
	}
	return i.Port
}

func (i *InputModelDrivenTelemetry) GetTLS() *TLSSettingsServerSideModelDrivenTelemetry {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputModelDrivenTelemetry) GetMetadata() []MetadatumModelDrivenTelemetry {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputModelDrivenTelemetry) GetMaxActiveCxn() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveCxn
}

func (i *InputModelDrivenTelemetry) GetShutdownTimeoutMs() *float64 {
	if i == nil {
		return nil
	}
	return i.ShutdownTimeoutMs
}

func (i *InputModelDrivenTelemetry) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputModelDrivenTelemetry) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputTypeOpenTelemetry string

const (
	InputTypeOpenTelemetryOpenTelemetry InputTypeOpenTelemetry = "open_telemetry"
)

func (e InputTypeOpenTelemetry) ToPointer() *InputTypeOpenTelemetry {
	return &e
}
func (e *InputTypeOpenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "open_telemetry":
		*e = InputTypeOpenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeOpenTelemetry: %v", v)
	}
}

type ConnectionOpenTelemetry struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionOpenTelemetry) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionOpenTelemetry) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// PqModeOpenTelemetry - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeOpenTelemetry string

const (
	// PqModeOpenTelemetrySmart Smart
	PqModeOpenTelemetrySmart PqModeOpenTelemetry = "smart"
	// PqModeOpenTelemetryAlways Always On
	PqModeOpenTelemetryAlways PqModeOpenTelemetry = "always"
)

func (e PqModeOpenTelemetry) ToPointer() *PqModeOpenTelemetry {
	return &e
}

// PqCompressionOpenTelemetry - Codec to use to compress the persisted data
type PqCompressionOpenTelemetry string

const (
	// PqCompressionOpenTelemetryNone None
	PqCompressionOpenTelemetryNone PqCompressionOpenTelemetry = "none"
	// PqCompressionOpenTelemetryGzip Gzip
	PqCompressionOpenTelemetryGzip PqCompressionOpenTelemetry = "gzip"
)

func (e PqCompressionOpenTelemetry) ToPointer() *PqCompressionOpenTelemetry {
	return &e
}

type InputPqControlsOpenTelemetry struct {
}

func (i InputPqControlsOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPqControlsOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqOpenTelemetry struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeOpenTelemetry `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *PqCompressionOpenTelemetry   `default:"none" json:"compress"`
	PqControls *InputPqControlsOpenTelemetry `json:"pqControls,omitempty"`
}

func (p PqOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqOpenTelemetry) GetMode() *PqModeOpenTelemetry {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqOpenTelemetry) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqOpenTelemetry) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqOpenTelemetry) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqOpenTelemetry) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqOpenTelemetry) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqOpenTelemetry) GetCompress() *PqCompressionOpenTelemetry {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqOpenTelemetry) GetPqControls() *InputPqControlsOpenTelemetry {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type InputMinimumTLSVersionOpenTelemetry string

const (
	InputMinimumTLSVersionOpenTelemetryTlSv1  InputMinimumTLSVersionOpenTelemetry = "TLSv1"
	InputMinimumTLSVersionOpenTelemetryTlSv11 InputMinimumTLSVersionOpenTelemetry = "TLSv1.1"
	InputMinimumTLSVersionOpenTelemetryTlSv12 InputMinimumTLSVersionOpenTelemetry = "TLSv1.2"
	InputMinimumTLSVersionOpenTelemetryTlSv13 InputMinimumTLSVersionOpenTelemetry = "TLSv1.3"
)

func (e InputMinimumTLSVersionOpenTelemetry) ToPointer() *InputMinimumTLSVersionOpenTelemetry {
	return &e
}

type InputMaximumTLSVersionOpenTelemetry string

const (
	InputMaximumTLSVersionOpenTelemetryTlSv1  InputMaximumTLSVersionOpenTelemetry = "TLSv1"
	InputMaximumTLSVersionOpenTelemetryTlSv11 InputMaximumTLSVersionOpenTelemetry = "TLSv1.1"
	InputMaximumTLSVersionOpenTelemetryTlSv12 InputMaximumTLSVersionOpenTelemetry = "TLSv1.2"
	InputMaximumTLSVersionOpenTelemetryTlSv13 InputMaximumTLSVersionOpenTelemetry = "TLSv1.3"
)

func (e InputMaximumTLSVersionOpenTelemetry) ToPointer() *InputMaximumTLSVersionOpenTelemetry {
	return &e
}

type TLSSettingsServerSideOpenTelemetry struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                              `json:"caPath,omitempty"`
	MinVersion *InputMinimumTLSVersionOpenTelemetry `json:"minVersion,omitempty"`
	MaxVersion *InputMaximumTLSVersionOpenTelemetry `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideOpenTelemetry) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideOpenTelemetry) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideOpenTelemetry) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideOpenTelemetry) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideOpenTelemetry) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideOpenTelemetry) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideOpenTelemetry) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideOpenTelemetry) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideOpenTelemetry) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideOpenTelemetry) GetMinVersion() *InputMinimumTLSVersionOpenTelemetry {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideOpenTelemetry) GetMaxVersion() *InputMaximumTLSVersionOpenTelemetry {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

// InputProtocolOpenTelemetry - Select whether to leverage gRPC or HTTP for OpenTelemetry
type InputProtocolOpenTelemetry string

const (
	// InputProtocolOpenTelemetryGrpc gRPC
	InputProtocolOpenTelemetryGrpc InputProtocolOpenTelemetry = "grpc"
	// InputProtocolOpenTelemetryHTTP HTTP
	InputProtocolOpenTelemetryHTTP InputProtocolOpenTelemetry = "http"
)

func (e InputProtocolOpenTelemetry) ToPointer() *InputProtocolOpenTelemetry {
	return &e
}

// InputOTLPVersion - The version of OTLP Protobuf definitions to use when interpreting received data
type InputOTLPVersion string

const (
	// InputOTLPVersionZeroDot10Dot0 0.10.0
	InputOTLPVersionZeroDot10Dot0 InputOTLPVersion = "0.10.0"
	// InputOTLPVersionOneDot3Dot1 1.3.1
	InputOTLPVersionOneDot3Dot1 InputOTLPVersion = "1.3.1"
)

func (e InputOTLPVersion) ToPointer() *InputOTLPVersion {
	return &e
}

// InputAuthenticationTypeOpenTelemetry - OpenTelemetry authentication type
type InputAuthenticationTypeOpenTelemetry string

const (
	InputAuthenticationTypeOpenTelemetryNone              InputAuthenticationTypeOpenTelemetry = "none"
	InputAuthenticationTypeOpenTelemetryBasic             InputAuthenticationTypeOpenTelemetry = "basic"
	InputAuthenticationTypeOpenTelemetryCredentialsSecret InputAuthenticationTypeOpenTelemetry = "credentialsSecret"
	InputAuthenticationTypeOpenTelemetryToken             InputAuthenticationTypeOpenTelemetry = "token"
	InputAuthenticationTypeOpenTelemetryTextSecret        InputAuthenticationTypeOpenTelemetry = "textSecret"
	InputAuthenticationTypeOpenTelemetryOauth             InputAuthenticationTypeOpenTelemetry = "oauth"
)

func (e InputAuthenticationTypeOpenTelemetry) ToPointer() *InputAuthenticationTypeOpenTelemetry {
	return &e
}

type InputMetadatumOpenTelemetry struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (i InputMetadatumOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputMetadatumOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (i *InputMetadatumOpenTelemetry) GetName() string {
	if i == nil {
		return ""
	}
	return i.Name
}

func (i *InputMetadatumOpenTelemetry) GetValue() string {
	if i == nil {
		return ""
	}
	return i.Value
}

type InputOauthParamOpenTelemetry struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (i InputOauthParamOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOauthParamOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (i *InputOauthParamOpenTelemetry) GetName() string {
	if i == nil {
		return ""
	}
	return i.Name
}

func (i *InputOauthParamOpenTelemetry) GetValue() string {
	if i == nil {
		return ""
	}
	return i.Value
}

type InputOauthHeaderOpenTelemetry struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (i InputOauthHeaderOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOauthHeaderOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (i *InputOauthHeaderOpenTelemetry) GetName() string {
	if i == nil {
		return ""
	}
	return i.Name
}

func (i *InputOauthHeaderOpenTelemetry) GetValue() string {
	if i == nil {
		return ""
	}
	return i.Value
}

type InputOpenTelemetry struct {
	// Unique ID for this input
	ID       *string                `json:"id,omitempty"`
	Type     InputTypeOpenTelemetry `json:"type"`
	Disabled *bool                  `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionOpenTelemetry `json:"connections,omitempty"`
	Pq          *PqOpenTelemetry          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port *float64                            `default:"4317" json:"port"`
	TLS  *TLSSettingsServerSideOpenTelemetry `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket  *int64 `default:"0" json:"maxRequestsPerSocket"`
	EnableProxyHeader     any    `json:"enableProxyHeader,omitempty"`
	CaptureHeaders        any    `json:"captureHeaders,omitempty"`
	ActivityLogSampleRate any    `json:"activityLogSampleRate,omitempty"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"15" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist.
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Select whether to leverage gRPC or HTTP for OpenTelemetry
	Protocol *InputProtocolOpenTelemetry `default:"grpc" json:"protocol"`
	// Enable to extract each incoming span to a separate event
	ExtractSpans *bool `default:"false" json:"extractSpans"`
	// Enable to extract each incoming Gauge or IntGauge metric to multiple events, one per data point
	ExtractMetrics *bool `default:"false" json:"extractMetrics"`
	// The version of OTLP Protobuf definitions to use when interpreting received data
	OtlpVersion *InputOTLPVersion `default:"0.10.0" json:"otlpVersion"`
	// OpenTelemetry authentication type
	AuthType *InputAuthenticationTypeOpenTelemetry `default:"none" json:"authType"`
	// Fields to add to events from this input
	Metadata []InputMetadatumOpenTelemetry `json:"metadata,omitempty"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	Description  *string  `json:"description,omitempty"`
	Username     *string  `json:"username,omitempty"`
	Password     *string  `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []InputOauthParamOpenTelemetry `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []InputOauthHeaderOpenTelemetry `json:"oauthHeaders,omitempty"`
	// Enable to extract each incoming log record to a separate event
	ExtractLogs          *bool          `default:"false" json:"extractLogs"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputOpenTelemetry) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputOpenTelemetry) GetType() InputTypeOpenTelemetry {
	if i == nil {
		return InputTypeOpenTelemetry("")
	}
	return i.Type
}

func (i *InputOpenTelemetry) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputOpenTelemetry) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputOpenTelemetry) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputOpenTelemetry) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputOpenTelemetry) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputOpenTelemetry) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputOpenTelemetry) GetConnections() []ConnectionOpenTelemetry {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputOpenTelemetry) GetPq() *PqOpenTelemetry {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputOpenTelemetry) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputOpenTelemetry) GetPort() *float64 {
	if i == nil {
		return nil
	}
	return i.Port
}

func (i *InputOpenTelemetry) GetTLS() *TLSSettingsServerSideOpenTelemetry {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputOpenTelemetry) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputOpenTelemetry) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputOpenTelemetry) GetEnableProxyHeader() any {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputOpenTelemetry) GetCaptureHeaders() any {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputOpenTelemetry) GetActivityLogSampleRate() any {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputOpenTelemetry) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputOpenTelemetry) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputOpenTelemetry) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputOpenTelemetry) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputOpenTelemetry) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputOpenTelemetry) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputOpenTelemetry) GetProtocol() *InputProtocolOpenTelemetry {
	if i == nil {
		return nil
	}
	return i.Protocol
}

func (i *InputOpenTelemetry) GetExtractSpans() *bool {
	if i == nil {
		return nil
	}
	return i.ExtractSpans
}

func (i *InputOpenTelemetry) GetExtractMetrics() *bool {
	if i == nil {
		return nil
	}
	return i.ExtractMetrics
}

func (i *InputOpenTelemetry) GetOtlpVersion() *InputOTLPVersion {
	if i == nil {
		return nil
	}
	return i.OtlpVersion
}

func (i *InputOpenTelemetry) GetAuthType() *InputAuthenticationTypeOpenTelemetry {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputOpenTelemetry) GetMetadata() []InputMetadatumOpenTelemetry {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputOpenTelemetry) GetMaxActiveCxn() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveCxn
}

func (i *InputOpenTelemetry) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputOpenTelemetry) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputOpenTelemetry) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputOpenTelemetry) GetToken() *string {
	if i == nil {
		return nil
	}
	return i.Token
}

func (i *InputOpenTelemetry) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputOpenTelemetry) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputOpenTelemetry) GetLoginURL() *string {
	if i == nil {
		return nil
	}
	return i.LoginURL
}

func (i *InputOpenTelemetry) GetSecretParamName() *string {
	if i == nil {
		return nil
	}
	return i.SecretParamName
}

func (i *InputOpenTelemetry) GetSecret() *string {
	if i == nil {
		return nil
	}
	return i.Secret
}

func (i *InputOpenTelemetry) GetTokenAttributeName() *string {
	if i == nil {
		return nil
	}
	return i.TokenAttributeName
}

func (i *InputOpenTelemetry) GetAuthHeaderExpr() *string {
	if i == nil {
		return nil
	}
	return i.AuthHeaderExpr
}

func (i *InputOpenTelemetry) GetTokenTimeoutSecs() *float64 {
	if i == nil {
		return nil
	}
	return i.TokenTimeoutSecs
}

func (i *InputOpenTelemetry) GetOauthParams() []InputOauthParamOpenTelemetry {
	if i == nil {
		return nil
	}
	return i.OauthParams
}

func (i *InputOpenTelemetry) GetOauthHeaders() []InputOauthHeaderOpenTelemetry {
	if i == nil {
		return nil
	}
	return i.OauthHeaders
}

func (i *InputOpenTelemetry) GetExtractLogs() *bool {
	if i == nil {
		return nil
	}
	return i.ExtractLogs
}

func (i *InputOpenTelemetry) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputTypeSnmp string

const (
	InputTypeSnmpSnmp InputTypeSnmp = "snmp"
)

func (e InputTypeSnmp) ToPointer() *InputTypeSnmp {
	return &e
}
func (e *InputTypeSnmp) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "snmp":
		*e = InputTypeSnmp(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeSnmp: %v", v)
	}
}

type ConnectionSnmp struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionSnmp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionSnmp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionSnmp) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionSnmp) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeSnmp - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeSnmp string

const (
	// ModeSnmpSmart Smart
	ModeSnmpSmart ModeSnmp = "smart"
	// ModeSnmpAlways Always On
	ModeSnmpAlways ModeSnmp = "always"
)

func (e ModeSnmp) ToPointer() *ModeSnmp {
	return &e
}

// CompressionSnmp - Codec to use to compress the persisted data
type CompressionSnmp string

const (
	// CompressionSnmpNone None
	CompressionSnmpNone CompressionSnmp = "none"
	// CompressionSnmpGzip Gzip
	CompressionSnmpGzip CompressionSnmp = "gzip"
)

func (e CompressionSnmp) ToPointer() *CompressionSnmp {
	return &e
}

type PqControlsSnmp struct {
}

func (p PqControlsSnmp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsSnmp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqSnmp struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeSnmp `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionSnmp `default:"none" json:"compress"`
	PqControls *PqControlsSnmp  `json:"pqControls,omitempty"`
}

func (p PqSnmp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSnmp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqSnmp) GetMode() *ModeSnmp {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqSnmp) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqSnmp) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqSnmp) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqSnmp) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqSnmp) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqSnmp) GetCompress() *CompressionSnmp {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqSnmp) GetPqControls() *PqControlsSnmp {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type AuthenticationProtocol string

const (
	// AuthenticationProtocolNone None
	AuthenticationProtocolNone AuthenticationProtocol = "none"
	// AuthenticationProtocolMd5 MD5
	AuthenticationProtocolMd5 AuthenticationProtocol = "md5"
	// AuthenticationProtocolSha SHA1
	AuthenticationProtocolSha AuthenticationProtocol = "sha"
	// AuthenticationProtocolSha224 SHA224
	AuthenticationProtocolSha224 AuthenticationProtocol = "sha224"
	// AuthenticationProtocolSha256 SHA256
	AuthenticationProtocolSha256 AuthenticationProtocol = "sha256"
	// AuthenticationProtocolSha384 SHA384
	AuthenticationProtocolSha384 AuthenticationProtocol = "sha384"
	// AuthenticationProtocolSha512 SHA512
	AuthenticationProtocolSha512 AuthenticationProtocol = "sha512"
)

func (e AuthenticationProtocol) ToPointer() *AuthenticationProtocol {
	return &e
}

type V3User struct {
	Name         string                  `json:"name"`
	AuthProtocol *AuthenticationProtocol `default:"none" json:"authProtocol"`
	AuthKey      any                     `json:"authKey,omitempty"`
	PrivProtocol *string                 `default:"none" json:"privProtocol"`
}

func (v V3User) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(v, "", false)
}

func (v *V3User) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &v, "", false, []string{"name"}); err != nil {
		return err
	}
	return nil
}

func (v *V3User) GetName() string {
	if v == nil {
		return ""
	}
	return v.Name
}

func (v *V3User) GetAuthProtocol() *AuthenticationProtocol {
	if v == nil {
		return nil
	}
	return v.AuthProtocol
}

func (v *V3User) GetAuthKey() any {
	if v == nil {
		return nil
	}
	return v.AuthKey
}

func (v *V3User) GetPrivProtocol() *string {
	if v == nil {
		return nil
	}
	return v.PrivProtocol
}

// SNMPv3Authentication - Authentication parameters for SNMPv3 trap. Set the log level to debug if you are experiencing authentication or decryption issues.
type SNMPv3Authentication struct {
	V3AuthEnabled *bool `default:"false" json:"v3AuthEnabled"`
	// Pass through traps that don't match any of the configured users. @{product} will not attempt to decrypt these traps.
	AllowUnmatchedTrap *bool `default:"false" json:"allowUnmatchedTrap"`
	// User credentials for receiving v3 traps
	V3Users []V3User `json:"v3Users,omitempty"`
}

func (s SNMPv3Authentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SNMPv3Authentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (s *SNMPv3Authentication) GetV3AuthEnabled() *bool {
	if s == nil {
		return nil
	}
	return s.V3AuthEnabled
}

func (s *SNMPv3Authentication) GetAllowUnmatchedTrap() *bool {
	if s == nil {
		return nil
	}
	return s.AllowUnmatchedTrap
}

func (s *SNMPv3Authentication) GetV3Users() []V3User {
	if s == nil {
		return nil
	}
	return s.V3Users
}

type MetadatumSnmp struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumSnmp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumSnmp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumSnmp) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumSnmp) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputSnmp struct {
	// Unique ID for this input
	ID       *string       `json:"id,omitempty"`
	Type     InputTypeSnmp `json:"type"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSnmp `json:"connections,omitempty"`
	Pq          *PqSnmp          `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// UDP port to receive SNMP traps on. Defaults to 162.
	Port *float64 `default:"162" json:"port"`
	// Authentication parameters for SNMPv3 trap. Set the log level to debug if you are experiencing authentication or decryption issues.
	SnmpV3Auth *SNMPv3Authentication `json:"snmpV3Auth,omitempty"`
	// Maximum number of events to buffer when downstream is blocking.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Fields to add to events from this input
	Metadata []MetadatumSnmp `json:"metadata,omitempty"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// If enabled, parses varbinds as an array of objects that include OID, value, and type
	VarbindsWithTypes *bool `default:"false" json:"varbindsWithTypes"`
	// If enabled, the parser will attempt to parse varbind octet strings as UTF-8, first, otherwise will fallback to other methods
	BestEffortParsing    *bool          `default:"false" json:"bestEffortParsing"`
	Description          *string        `json:"description,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputSnmp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSnmp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputSnmp) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputSnmp) GetType() InputTypeSnmp {
	if i == nil {
		return InputTypeSnmp("")
	}
	return i.Type
}

func (i *InputSnmp) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSnmp) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSnmp) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputSnmp) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputSnmp) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputSnmp) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputSnmp) GetConnections() []ConnectionSnmp {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputSnmp) GetPq() *PqSnmp {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputSnmp) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputSnmp) GetPort() *float64 {
	if i == nil {
		return nil
	}
	return i.Port
}

func (i *InputSnmp) GetSnmpV3Auth() *SNMPv3Authentication {
	if i == nil {
		return nil
	}
	return i.SnmpV3Auth
}

func (i *InputSnmp) GetMaxBufferSize() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBufferSize
}

func (i *InputSnmp) GetIPWhitelistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPWhitelistRegex
}

func (i *InputSnmp) GetMetadata() []MetadatumSnmp {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputSnmp) GetUDPSocketRxBufSize() *float64 {
	if i == nil {
		return nil
	}
	return i.UDPSocketRxBufSize
}

func (i *InputSnmp) GetVarbindsWithTypes() *bool {
	if i == nil {
		return nil
	}
	return i.VarbindsWithTypes
}

func (i *InputSnmp) GetBestEffortParsing() *bool {
	if i == nil {
		return nil
	}
	return i.BestEffortParsing
}

func (i *InputSnmp) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputSnmp) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeS3Inventory string

const (
	TypeS3InventoryS3Inventory TypeS3Inventory = "s3_inventory"
)

func (e TypeS3Inventory) ToPointer() *TypeS3Inventory {
	return &e
}
func (e *TypeS3Inventory) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "s3_inventory":
		*e = TypeS3Inventory(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeS3Inventory: %v", v)
	}
}

type ConnectionS3Inventory struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionS3Inventory) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionS3Inventory) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionS3Inventory) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionS3Inventory) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeS3Inventory - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeS3Inventory string

const (
	// ModeS3InventorySmart Smart
	ModeS3InventorySmart ModeS3Inventory = "smart"
	// ModeS3InventoryAlways Always On
	ModeS3InventoryAlways ModeS3Inventory = "always"
)

func (e ModeS3Inventory) ToPointer() *ModeS3Inventory {
	return &e
}

// CompressionS3Inventory - Codec to use to compress the persisted data
type CompressionS3Inventory string

const (
	// CompressionS3InventoryNone None
	CompressionS3InventoryNone CompressionS3Inventory = "none"
	// CompressionS3InventoryGzip Gzip
	CompressionS3InventoryGzip CompressionS3Inventory = "gzip"
)

func (e CompressionS3Inventory) ToPointer() *CompressionS3Inventory {
	return &e
}

type PqControlsS3Inventory struct {
}

func (p PqControlsS3Inventory) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsS3Inventory) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqS3Inventory struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeS3Inventory `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionS3Inventory `default:"none" json:"compress"`
	PqControls *PqControlsS3Inventory  `json:"pqControls,omitempty"`
}

func (p PqS3Inventory) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqS3Inventory) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqS3Inventory) GetMode() *ModeS3Inventory {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqS3Inventory) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqS3Inventory) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqS3Inventory) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqS3Inventory) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqS3Inventory) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqS3Inventory) GetCompress() *CompressionS3Inventory {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqS3Inventory) GetPqControls() *PqControlsS3Inventory {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// AuthenticationMethodS3Inventory - AWS authentication method. Choose Auto to use IAM roles.
type AuthenticationMethodS3Inventory string

const (
	// AuthenticationMethodS3InventoryAuto Auto
	AuthenticationMethodS3InventoryAuto AuthenticationMethodS3Inventory = "auto"
	// AuthenticationMethodS3InventoryManual Manual
	AuthenticationMethodS3InventoryManual AuthenticationMethodS3Inventory = "manual"
	// AuthenticationMethodS3InventorySecret Secret Key pair
	AuthenticationMethodS3InventorySecret AuthenticationMethodS3Inventory = "secret"
)

func (e AuthenticationMethodS3Inventory) ToPointer() *AuthenticationMethodS3Inventory {
	return &e
}

// SignatureVersionS3Inventory - Signature version to use for signing S3 requests
type SignatureVersionS3Inventory string

const (
	SignatureVersionS3InventoryV2 SignatureVersionS3Inventory = "v2"
	SignatureVersionS3InventoryV4 SignatureVersionS3Inventory = "v4"
)

func (e SignatureVersionS3Inventory) ToPointer() *SignatureVersionS3Inventory {
	return &e
}

type PreprocessS3Inventory struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (p PreprocessS3Inventory) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PreprocessS3Inventory) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PreprocessS3Inventory) GetDisabled() *bool {
	if p == nil {
		return nil
	}
	return p.Disabled
}

func (p *PreprocessS3Inventory) GetCommand() *string {
	if p == nil {
		return nil
	}
	return p.Command
}

func (p *PreprocessS3Inventory) GetArgs() []string {
	if p == nil {
		return nil
	}
	return p.Args
}

type MetadatumS3Inventory struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumS3Inventory) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumS3Inventory) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumS3Inventory) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumS3Inventory) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type CheckpointingS3Inventory struct {
	// Resume processing files after an interruption
	Enabled *bool `default:"false" json:"enabled"`
	// The number of times to retry processing when a processing error occurs. If Skip file on error is enabled, this setting is ignored.
	Retries *float64 `default:"5" json:"retries"`
}

func (c CheckpointingS3Inventory) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CheckpointingS3Inventory) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *CheckpointingS3Inventory) GetEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.Enabled
}

func (c *CheckpointingS3Inventory) GetRetries() *float64 {
	if c == nil {
		return nil
	}
	return c.Retries
}

type TagAfterProcessingS3Inventory string

const (
	TagAfterProcessingS3InventoryFalse TagAfterProcessingS3Inventory = "false"
	TagAfterProcessingS3InventoryTrue  TagAfterProcessingS3Inventory = "true"
)

func (e TagAfterProcessingS3Inventory) ToPointer() *TagAfterProcessingS3Inventory {
	return &e
}

type InputS3Inventory struct {
	// Unique ID for this input
	ID       *string         `json:"id,omitempty"`
	Type     TypeS3Inventory `json:"type"`
	Disabled *bool           `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionS3Inventory `json:"connections,omitempty"`
	Pq          *PqS3Inventory          `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *AuthenticationMethodS3Inventory `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                          `json:"awsSecretKey,omitempty"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *SignatureVersionS3Inventory `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `default:"300" json:"socketTimeout"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Attach SQS notification metadata to a __sqsMetadata field on each event
	IncludeSqsMetadata *bool `default:"false" json:"includeSqsMetadata"`
	// Use Assume Role credentials to access Amazon S3
	EnableAssumeRole *bool `default:"true" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Use Assume Role credentials when accessing Amazon SQS
	EnableSQSAssumeRole *bool                  `default:"false" json:"enableSQSAssumeRole"`
	Preprocess          *PreprocessS3Inventory `json:"preprocess,omitempty"`
	// Fields to add to events from this input
	Metadata []MetadatumS3Inventory `json:"metadata,omitempty"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `default:"5" json:"parquetChunkSizeMB"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64                  `default:"600" json:"parquetChunkDownloadTimeout"`
	Checkpointing               *CheckpointingS3Inventory `json:"checkpointing,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	// Filename suffix of the manifest checksum file. If a filename matching this suffix is received        in the queue, the matching manifest file will be downloaded and validated against its value. Defaults to "checksum"
	ChecksumSuffix *string `default:"checksum" json:"checksumSuffix"`
	// Maximum download size (KB) of each manifest or checksum file. Manifest files larger than this size will not be read.        Defaults to 4096.
	MaxManifestSizeKB *int64 `default:"4096" json:"maxManifestSizeKB"`
	// If set to Yes, each inventory file in the manifest will be validated against its checksum. Defaults to false
	ValidateInventoryFiles *bool   `default:"false" json:"validateInventoryFiles"`
	Description            *string `json:"description,omitempty"`
	AwsAPIKey              *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret          *string                        `json:"awsSecret,omitempty"`
	TagAfterProcessing *TagAfterProcessingS3Inventory `json:"tagAfterProcessing,omitempty"`
	// The key for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagKey *string `json:"processedTagKey,omitempty"`
	// The value for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagValue    *string        `json:"processedTagValue,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputS3Inventory) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputS3Inventory) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "queueName"}); err != nil {
		return err
	}
	return nil
}

func (i *InputS3Inventory) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputS3Inventory) GetType() TypeS3Inventory {
	if i == nil {
		return TypeS3Inventory("")
	}
	return i.Type
}

func (i *InputS3Inventory) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputS3Inventory) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputS3Inventory) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputS3Inventory) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputS3Inventory) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputS3Inventory) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputS3Inventory) GetConnections() []ConnectionS3Inventory {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputS3Inventory) GetPq() *PqS3Inventory {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputS3Inventory) GetQueueName() string {
	if i == nil {
		return ""
	}
	return i.QueueName
}

func (i *InputS3Inventory) GetFileFilter() *string {
	if i == nil {
		return nil
	}
	return i.FileFilter
}

func (i *InputS3Inventory) GetAwsAccountID() *string {
	if i == nil {
		return nil
	}
	return i.AwsAccountID
}

func (i *InputS3Inventory) GetAwsAuthenticationMethod() *AuthenticationMethodS3Inventory {
	if i == nil {
		return nil
	}
	return i.AwsAuthenticationMethod
}

func (i *InputS3Inventory) GetAwsSecretKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecretKey
}

func (i *InputS3Inventory) GetRegion() *string {
	if i == nil {
		return nil
	}
	return i.Region
}

func (i *InputS3Inventory) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputS3Inventory) GetSignatureVersion() *SignatureVersionS3Inventory {
	if i == nil {
		return nil
	}
	return i.SignatureVersion
}

func (i *InputS3Inventory) GetReuseConnections() *bool {
	if i == nil {
		return nil
	}
	return i.ReuseConnections
}

func (i *InputS3Inventory) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputS3Inventory) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputS3Inventory) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputS3Inventory) GetMaxMessages() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMessages
}

func (i *InputS3Inventory) GetVisibilityTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.VisibilityTimeout
}

func (i *InputS3Inventory) GetNumReceivers() *float64 {
	if i == nil {
		return nil
	}
	return i.NumReceivers
}

func (i *InputS3Inventory) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputS3Inventory) GetSkipOnError() *bool {
	if i == nil {
		return nil
	}
	return i.SkipOnError
}

func (i *InputS3Inventory) GetIncludeSqsMetadata() *bool {
	if i == nil {
		return nil
	}
	return i.IncludeSqsMetadata
}

func (i *InputS3Inventory) GetEnableAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableAssumeRole
}

func (i *InputS3Inventory) GetAssumeRoleArn() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleArn
}

func (i *InputS3Inventory) GetAssumeRoleExternalID() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleExternalID
}

func (i *InputS3Inventory) GetDurationSeconds() *float64 {
	if i == nil {
		return nil
	}
	return i.DurationSeconds
}

func (i *InputS3Inventory) GetEnableSQSAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableSQSAssumeRole
}

func (i *InputS3Inventory) GetPreprocess() *PreprocessS3Inventory {
	if i == nil {
		return nil
	}
	return i.Preprocess
}

func (i *InputS3Inventory) GetMetadata() []MetadatumS3Inventory {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputS3Inventory) GetParquetChunkSizeMB() *float64 {
	if i == nil {
		return nil
	}
	return i.ParquetChunkSizeMB
}

func (i *InputS3Inventory) GetParquetChunkDownloadTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.ParquetChunkDownloadTimeout
}

func (i *InputS3Inventory) GetCheckpointing() *CheckpointingS3Inventory {
	if i == nil {
		return nil
	}
	return i.Checkpointing
}

func (i *InputS3Inventory) GetPollTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.PollTimeout
}

func (i *InputS3Inventory) GetChecksumSuffix() *string {
	if i == nil {
		return nil
	}
	return i.ChecksumSuffix
}

func (i *InputS3Inventory) GetMaxManifestSizeKB() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxManifestSizeKB
}

func (i *InputS3Inventory) GetValidateInventoryFiles() *bool {
	if i == nil {
		return nil
	}
	return i.ValidateInventoryFiles
}

func (i *InputS3Inventory) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputS3Inventory) GetAwsAPIKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsAPIKey
}

func (i *InputS3Inventory) GetAwsSecret() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecret
}

func (i *InputS3Inventory) GetTagAfterProcessing() *TagAfterProcessingS3Inventory {
	if i == nil {
		return nil
	}
	return i.TagAfterProcessing
}

func (i *InputS3Inventory) GetProcessedTagKey() *string {
	if i == nil {
		return nil
	}
	return i.ProcessedTagKey
}

func (i *InputS3Inventory) GetProcessedTagValue() *string {
	if i == nil {
		return nil
	}
	return i.ProcessedTagValue
}

func (i *InputS3Inventory) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputTypeS3 string

const (
	InputTypeS3S3 InputTypeS3 = "s3"
)

func (e InputTypeS3) ToPointer() *InputTypeS3 {
	return &e
}
func (e *InputTypeS3) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "s3":
		*e = InputTypeS3(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeS3: %v", v)
	}
}

type ConnectionS3 struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionS3) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionS3) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeS3 - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeS3 string

const (
	// ModeS3Smart Smart
	ModeS3Smart ModeS3 = "smart"
	// ModeS3Always Always On
	ModeS3Always ModeS3 = "always"
)

func (e ModeS3) ToPointer() *ModeS3 {
	return &e
}

// PqCompressionS3 - Codec to use to compress the persisted data
type PqCompressionS3 string

const (
	// PqCompressionS3None None
	PqCompressionS3None PqCompressionS3 = "none"
	// PqCompressionS3Gzip Gzip
	PqCompressionS3Gzip PqCompressionS3 = "gzip"
)

func (e PqCompressionS3) ToPointer() *PqCompressionS3 {
	return &e
}

type PqControlsS3 struct {
}

func (p PqControlsS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqS3 struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeS3 `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *PqCompressionS3 `default:"none" json:"compress"`
	PqControls *PqControlsS3    `json:"pqControls,omitempty"`
}

func (p PqS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqS3) GetMode() *ModeS3 {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqS3) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqS3) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqS3) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqS3) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqS3) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqS3) GetCompress() *PqCompressionS3 {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqS3) GetPqControls() *PqControlsS3 {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// InputAuthenticationMethodS3 - AWS authentication method. Choose Auto to use IAM roles.
type InputAuthenticationMethodS3 string

const (
	// InputAuthenticationMethodS3Auto Auto
	InputAuthenticationMethodS3Auto InputAuthenticationMethodS3 = "auto"
	// InputAuthenticationMethodS3Manual Manual
	InputAuthenticationMethodS3Manual InputAuthenticationMethodS3 = "manual"
	// InputAuthenticationMethodS3Secret Secret Key pair
	InputAuthenticationMethodS3Secret InputAuthenticationMethodS3 = "secret"
)

func (e InputAuthenticationMethodS3) ToPointer() *InputAuthenticationMethodS3 {
	return &e
}

// InputSignatureVersionS3 - Signature version to use for signing S3 requests
type InputSignatureVersionS3 string

const (
	InputSignatureVersionS3V2 InputSignatureVersionS3 = "v2"
	InputSignatureVersionS3V4 InputSignatureVersionS3 = "v4"
)

func (e InputSignatureVersionS3) ToPointer() *InputSignatureVersionS3 {
	return &e
}

type PreprocessS3 struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (p PreprocessS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PreprocessS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PreprocessS3) GetDisabled() *bool {
	if p == nil {
		return nil
	}
	return p.Disabled
}

func (p *PreprocessS3) GetCommand() *string {
	if p == nil {
		return nil
	}
	return p.Command
}

func (p *PreprocessS3) GetArgs() []string {
	if p == nil {
		return nil
	}
	return p.Args
}

type MetadatumS3 struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumS3) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumS3) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type CheckpointingS3 struct {
	// Resume processing files after an interruption
	Enabled *bool `default:"false" json:"enabled"`
	// The number of times to retry processing when a processing error occurs. If Skip file on error is enabled, this setting is ignored.
	Retries *float64 `default:"5" json:"retries"`
}

func (c CheckpointingS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CheckpointingS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *CheckpointingS3) GetEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.Enabled
}

func (c *CheckpointingS3) GetRetries() *float64 {
	if c == nil {
		return nil
	}
	return c.Retries
}

type InputS3 struct {
	// Unique ID for this input
	ID       *string     `json:"id,omitempty"`
	Type     InputTypeS3 `json:"type"`
	Disabled *bool       `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionS3 `json:"connections,omitempty"`
	Pq          *PqS3          `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *InputAuthenticationMethodS3 `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                      `json:"awsSecretKey,omitempty"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *InputSignatureVersionS3 `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `default:"300" json:"socketTimeout"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Attach SQS notification metadata to a __sqsMetadata field on each event
	IncludeSqsMetadata *bool `default:"false" json:"includeSqsMetadata"`
	// Use Assume Role credentials to access Amazon S3
	EnableAssumeRole *bool `default:"true" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Use Assume Role credentials when accessing Amazon SQS
	EnableSQSAssumeRole *bool         `default:"false" json:"enableSQSAssumeRole"`
	Preprocess          *PreprocessS3 `json:"preprocess,omitempty"`
	// Fields to add to events from this input
	Metadata []MetadatumS3 `json:"metadata,omitempty"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `default:"5" json:"parquetChunkSizeMB"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64         `default:"600" json:"parquetChunkDownloadTimeout"`
	Checkpointing               *CheckpointingS3 `json:"checkpointing,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding *string `json:"encoding,omitempty"`
	// Add a tag to processed S3 objects. Requires s3:GetObjectTagging and s3:PutObjectTagging AWS permissions.
	TagAfterProcessing *bool   `default:"false" json:"tagAfterProcessing"`
	Description        *string `json:"description,omitempty"`
	AwsAPIKey          *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// The key for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagKey *string `json:"processedTagKey,omitempty"`
	// The value for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagValue    *string        `json:"processedTagValue,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "queueName"}); err != nil {
		return err
	}
	return nil
}

func (i *InputS3) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputS3) GetType() InputTypeS3 {
	if i == nil {
		return InputTypeS3("")
	}
	return i.Type
}

func (i *InputS3) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputS3) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputS3) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputS3) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputS3) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputS3) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputS3) GetConnections() []ConnectionS3 {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputS3) GetPq() *PqS3 {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputS3) GetQueueName() string {
	if i == nil {
		return ""
	}
	return i.QueueName
}

func (i *InputS3) GetFileFilter() *string {
	if i == nil {
		return nil
	}
	return i.FileFilter
}

func (i *InputS3) GetAwsAccountID() *string {
	if i == nil {
		return nil
	}
	return i.AwsAccountID
}

func (i *InputS3) GetAwsAuthenticationMethod() *InputAuthenticationMethodS3 {
	if i == nil {
		return nil
	}
	return i.AwsAuthenticationMethod
}

func (i *InputS3) GetAwsSecretKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecretKey
}

func (i *InputS3) GetRegion() *string {
	if i == nil {
		return nil
	}
	return i.Region
}

func (i *InputS3) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputS3) GetSignatureVersion() *InputSignatureVersionS3 {
	if i == nil {
		return nil
	}
	return i.SignatureVersion
}

func (i *InputS3) GetReuseConnections() *bool {
	if i == nil {
		return nil
	}
	return i.ReuseConnections
}

func (i *InputS3) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputS3) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputS3) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputS3) GetMaxMessages() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMessages
}

func (i *InputS3) GetVisibilityTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.VisibilityTimeout
}

func (i *InputS3) GetNumReceivers() *float64 {
	if i == nil {
		return nil
	}
	return i.NumReceivers
}

func (i *InputS3) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputS3) GetSkipOnError() *bool {
	if i == nil {
		return nil
	}
	return i.SkipOnError
}

func (i *InputS3) GetIncludeSqsMetadata() *bool {
	if i == nil {
		return nil
	}
	return i.IncludeSqsMetadata
}

func (i *InputS3) GetEnableAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableAssumeRole
}

func (i *InputS3) GetAssumeRoleArn() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleArn
}

func (i *InputS3) GetAssumeRoleExternalID() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleExternalID
}

func (i *InputS3) GetDurationSeconds() *float64 {
	if i == nil {
		return nil
	}
	return i.DurationSeconds
}

func (i *InputS3) GetEnableSQSAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableSQSAssumeRole
}

func (i *InputS3) GetPreprocess() *PreprocessS3 {
	if i == nil {
		return nil
	}
	return i.Preprocess
}

func (i *InputS3) GetMetadata() []MetadatumS3 {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputS3) GetParquetChunkSizeMB() *float64 {
	if i == nil {
		return nil
	}
	return i.ParquetChunkSizeMB
}

func (i *InputS3) GetParquetChunkDownloadTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.ParquetChunkDownloadTimeout
}

func (i *InputS3) GetCheckpointing() *CheckpointingS3 {
	if i == nil {
		return nil
	}
	return i.Checkpointing
}

func (i *InputS3) GetPollTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.PollTimeout
}

func (i *InputS3) GetEncoding() *string {
	if i == nil {
		return nil
	}
	return i.Encoding
}

func (i *InputS3) GetTagAfterProcessing() *bool {
	if i == nil {
		return nil
	}
	return i.TagAfterProcessing
}

func (i *InputS3) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputS3) GetAwsAPIKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsAPIKey
}

func (i *InputS3) GetAwsSecret() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecret
}

func (i *InputS3) GetProcessedTagKey() *string {
	if i == nil {
		return nil
	}
	return i.ProcessedTagKey
}

func (i *InputS3) GetProcessedTagValue() *string {
	if i == nil {
		return nil
	}
	return i.ProcessedTagValue
}

func (i *InputS3) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeMetrics string

const (
	TypeMetricsMetrics TypeMetrics = "metrics"
)

func (e TypeMetrics) ToPointer() *TypeMetrics {
	return &e
}
func (e *TypeMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "metrics":
		*e = TypeMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeMetrics: %v", v)
	}
}

type ConnectionMetrics struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionMetrics) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionMetrics) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeMetrics - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeMetrics string

const (
	// ModeMetricsSmart Smart
	ModeMetricsSmart ModeMetrics = "smart"
	// ModeMetricsAlways Always On
	ModeMetricsAlways ModeMetrics = "always"
)

func (e ModeMetrics) ToPointer() *ModeMetrics {
	return &e
}

// CompressionMetrics - Codec to use to compress the persisted data
type CompressionMetrics string

const (
	// CompressionMetricsNone None
	CompressionMetricsNone CompressionMetrics = "none"
	// CompressionMetricsGzip Gzip
	CompressionMetricsGzip CompressionMetrics = "gzip"
)

func (e CompressionMetrics) ToPointer() *CompressionMetrics {
	return &e
}

type PqControlsMetrics struct {
}

func (p PqControlsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqMetrics struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeMetrics `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionMetrics `default:"none" json:"compress"`
	PqControls *PqControlsMetrics  `json:"pqControls,omitempty"`
}

func (p PqMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqMetrics) GetMode() *ModeMetrics {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqMetrics) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqMetrics) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqMetrics) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqMetrics) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqMetrics) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqMetrics) GetCompress() *CompressionMetrics {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqMetrics) GetPqControls() *PqControlsMetrics {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MinimumTLSVersionMetrics string

const (
	MinimumTLSVersionMetricsTlSv1  MinimumTLSVersionMetrics = "TLSv1"
	MinimumTLSVersionMetricsTlSv11 MinimumTLSVersionMetrics = "TLSv1.1"
	MinimumTLSVersionMetricsTlSv12 MinimumTLSVersionMetrics = "TLSv1.2"
	MinimumTLSVersionMetricsTlSv13 MinimumTLSVersionMetrics = "TLSv1.3"
)

func (e MinimumTLSVersionMetrics) ToPointer() *MinimumTLSVersionMetrics {
	return &e
}

type MaximumTLSVersionMetrics string

const (
	MaximumTLSVersionMetricsTlSv1  MaximumTLSVersionMetrics = "TLSv1"
	MaximumTLSVersionMetricsTlSv11 MaximumTLSVersionMetrics = "TLSv1.1"
	MaximumTLSVersionMetricsTlSv12 MaximumTLSVersionMetrics = "TLSv1.2"
	MaximumTLSVersionMetricsTlSv13 MaximumTLSVersionMetrics = "TLSv1.3"
)

func (e MaximumTLSVersionMetrics) ToPointer() *MaximumTLSVersionMetrics {
	return &e
}

type TLSSettingsServerSideMetrics struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                   `json:"caPath,omitempty"`
	MinVersion *MinimumTLSVersionMetrics `json:"minVersion,omitempty"`
	MaxVersion *MaximumTLSVersionMetrics `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideMetrics) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideMetrics) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideMetrics) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideMetrics) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideMetrics) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideMetrics) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideMetrics) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideMetrics) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideMetrics) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideMetrics) GetMinVersion() *MinimumTLSVersionMetrics {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideMetrics) GetMaxVersion() *MaximumTLSVersionMetrics {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

type MetadatumMetrics struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumMetrics) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumMetrics) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputMetrics struct {
	// Unique ID for this input
	ID       *string     `json:"id,omitempty"`
	Type     TypeMetrics `json:"type"`
	Disabled *bool       `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionMetrics `json:"connections,omitempty"`
	Pq          *PqMetrics          `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Enter UDP port number to listen on. Not required if listening on TCP.
	UDPPort *float64 `json:"udpPort,omitempty"`
	// Enter TCP port number to listen on. Not required if listening on UDP.
	TCPPort *float64 `json:"tcpPort,omitempty"`
	// Maximum number of events to buffer when downstream is blocking. Only applies to UDP.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Enable if the connection is proxied by a device that supports Proxy Protocol V1 or V2
	EnableProxyHeader *bool                         `default:"false" json:"enableProxyHeader"`
	TLS               *TLSSettingsServerSideMetrics `json:"tls,omitempty"`
	// Fields to add to events from this input
	Metadata []MetadatumMetrics `json:"metadata,omitempty"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize   *float64       `json:"udpSocketRxBufSize,omitempty"`
	Description          *string        `json:"description,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputMetrics) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputMetrics) GetType() TypeMetrics {
	if i == nil {
		return TypeMetrics("")
	}
	return i.Type
}

func (i *InputMetrics) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputMetrics) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputMetrics) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputMetrics) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputMetrics) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputMetrics) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputMetrics) GetConnections() []ConnectionMetrics {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputMetrics) GetPq() *PqMetrics {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputMetrics) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputMetrics) GetUDPPort() *float64 {
	if i == nil {
		return nil
	}
	return i.UDPPort
}

func (i *InputMetrics) GetTCPPort() *float64 {
	if i == nil {
		return nil
	}
	return i.TCPPort
}

func (i *InputMetrics) GetMaxBufferSize() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBufferSize
}

func (i *InputMetrics) GetIPWhitelistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPWhitelistRegex
}

func (i *InputMetrics) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputMetrics) GetTLS() *TLSSettingsServerSideMetrics {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputMetrics) GetMetadata() []MetadatumMetrics {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputMetrics) GetUDPSocketRxBufSize() *float64 {
	if i == nil {
		return nil
	}
	return i.UDPSocketRxBufSize
}

func (i *InputMetrics) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputMetrics) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeCriblmetrics string

const (
	TypeCriblmetricsCriblmetrics TypeCriblmetrics = "criblmetrics"
)

func (e TypeCriblmetrics) ToPointer() *TypeCriblmetrics {
	return &e
}
func (e *TypeCriblmetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "criblmetrics":
		*e = TypeCriblmetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCriblmetrics: %v", v)
	}
}

type ConnectionCriblmetrics struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionCriblmetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionCriblmetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionCriblmetrics) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionCriblmetrics) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeCriblmetrics - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeCriblmetrics string

const (
	// ModeCriblmetricsSmart Smart
	ModeCriblmetricsSmart ModeCriblmetrics = "smart"
	// ModeCriblmetricsAlways Always On
	ModeCriblmetricsAlways ModeCriblmetrics = "always"
)

func (e ModeCriblmetrics) ToPointer() *ModeCriblmetrics {
	return &e
}

// CompressionCriblmetrics - Codec to use to compress the persisted data
type CompressionCriblmetrics string

const (
	// CompressionCriblmetricsNone None
	CompressionCriblmetricsNone CompressionCriblmetrics = "none"
	// CompressionCriblmetricsGzip Gzip
	CompressionCriblmetricsGzip CompressionCriblmetrics = "gzip"
)

func (e CompressionCriblmetrics) ToPointer() *CompressionCriblmetrics {
	return &e
}

type PqControlsCriblmetrics struct {
}

func (p PqControlsCriblmetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsCriblmetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqCriblmetrics struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeCriblmetrics `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionCriblmetrics `default:"none" json:"compress"`
	PqControls *PqControlsCriblmetrics  `json:"pqControls,omitempty"`
}

func (p PqCriblmetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqCriblmetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqCriblmetrics) GetMode() *ModeCriblmetrics {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqCriblmetrics) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqCriblmetrics) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqCriblmetrics) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqCriblmetrics) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqCriblmetrics) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqCriblmetrics) GetCompress() *CompressionCriblmetrics {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqCriblmetrics) GetPqControls() *PqControlsCriblmetrics {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MetadatumCriblmetrics struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumCriblmetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumCriblmetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumCriblmetrics) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumCriblmetrics) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputCriblmetrics struct {
	// Unique ID for this input
	ID       *string          `json:"id,omitempty"`
	Type     TypeCriblmetrics `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionCriblmetrics `json:"connections,omitempty"`
	Pq          *PqCriblmetrics          `json:"pq,omitempty"`
	// A prefix that is applied to the metrics provided by Cribl Stream
	Prefix *string `default:"cribl.logstream." json:"prefix"`
	// Include granular metrics. Disabling this will drop the following metrics events: `cribl.logstream.host.(in_bytes,in_events,out_bytes,out_events)`, `cribl.logstream.index.(in_bytes,in_events,out_bytes,out_events)`, `cribl.logstream.source.(in_bytes,in_events,out_bytes,out_events)`, `cribl.logstream.sourcetype.(in_bytes,in_events,out_bytes,out_events)`.
	FullFidelity *bool `default:"true" json:"fullFidelity"`
	// Fields to add to events from this input
	Metadata             []MetadatumCriblmetrics `json:"metadata,omitempty"`
	Description          *string                 `json:"description,omitempty"`
	AdditionalProperties map[string]any          `additionalProperties:"true" json:"-"`
}

func (i InputCriblmetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblmetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputCriblmetrics) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputCriblmetrics) GetType() TypeCriblmetrics {
	if i == nil {
		return TypeCriblmetrics("")
	}
	return i.Type
}

func (i *InputCriblmetrics) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputCriblmetrics) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputCriblmetrics) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputCriblmetrics) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputCriblmetrics) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputCriblmetrics) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputCriblmetrics) GetConnections() []ConnectionCriblmetrics {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputCriblmetrics) GetPq() *PqCriblmetrics {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputCriblmetrics) GetPrefix() *string {
	if i == nil {
		return nil
	}
	return i.Prefix
}

func (i *InputCriblmetrics) GetFullFidelity() *bool {
	if i == nil {
		return nil
	}
	return i.FullFidelity
}

func (i *InputCriblmetrics) GetMetadata() []MetadatumCriblmetrics {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputCriblmetrics) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputCriblmetrics) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputTypeKinesis string

const (
	InputTypeKinesisKinesis InputTypeKinesis = "kinesis"
)

func (e InputTypeKinesis) ToPointer() *InputTypeKinesis {
	return &e
}
func (e *InputTypeKinesis) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kinesis":
		*e = InputTypeKinesis(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeKinesis: %v", v)
	}
}

type ConnectionKinesis struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionKinesis) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionKinesis) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionKinesis) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionKinesis) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// PqModeKinesis - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeKinesis string

const (
	// PqModeKinesisSmart Smart
	PqModeKinesisSmart PqModeKinesis = "smart"
	// PqModeKinesisAlways Always On
	PqModeKinesisAlways PqModeKinesis = "always"
)

func (e PqModeKinesis) ToPointer() *PqModeKinesis {
	return &e
}

// PqCompressionKinesis - Codec to use to compress the persisted data
type PqCompressionKinesis string

const (
	// PqCompressionKinesisNone None
	PqCompressionKinesisNone PqCompressionKinesis = "none"
	// PqCompressionKinesisGzip Gzip
	PqCompressionKinesisGzip PqCompressionKinesis = "gzip"
)

func (e PqCompressionKinesis) ToPointer() *PqCompressionKinesis {
	return &e
}

type InputPqControlsKinesis struct {
}

func (i InputPqControlsKinesis) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPqControlsKinesis) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqKinesis struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeKinesis `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *PqCompressionKinesis   `default:"none" json:"compress"`
	PqControls *InputPqControlsKinesis `json:"pqControls,omitempty"`
}

func (p PqKinesis) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqKinesis) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqKinesis) GetMode() *PqModeKinesis {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqKinesis) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqKinesis) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqKinesis) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqKinesis) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqKinesis) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqKinesis) GetCompress() *PqCompressionKinesis {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqKinesis) GetPqControls() *InputPqControlsKinesis {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// ShardIteratorStart - Location at which to start reading a shard for the first time
type ShardIteratorStart string

const (
	// ShardIteratorStartTrimHorizon Earliest record
	ShardIteratorStartTrimHorizon ShardIteratorStart = "TRIM_HORIZON"
	// ShardIteratorStartLatest Latest record
	ShardIteratorStartLatest ShardIteratorStart = "LATEST"
)

func (e ShardIteratorStart) ToPointer() *ShardIteratorStart {
	return &e
}

// InputRecordDataFormat - Format of data inside the Kinesis Stream records. Gzip compression is automatically detected.
type InputRecordDataFormat string

const (
	// InputRecordDataFormatCribl Cribl
	InputRecordDataFormatCribl InputRecordDataFormat = "cribl"
	// InputRecordDataFormatNdjson Newline JSON
	InputRecordDataFormatNdjson InputRecordDataFormat = "ndjson"
	// InputRecordDataFormatCloudwatch Cloudwatch Logs
	InputRecordDataFormatCloudwatch InputRecordDataFormat = "cloudwatch"
	// InputRecordDataFormatLine Event per line
	InputRecordDataFormatLine InputRecordDataFormat = "line"
)

func (e InputRecordDataFormat) ToPointer() *InputRecordDataFormat {
	return &e
}

// ShardLoadBalancing - The load-balancing algorithm to use for spreading out shards across Workers and Worker Processes
type ShardLoadBalancing string

const (
	// ShardLoadBalancingConsistentHashing Consistent Hashing
	ShardLoadBalancingConsistentHashing ShardLoadBalancing = "ConsistentHashing"
	// ShardLoadBalancingRoundRobin Round Robin
	ShardLoadBalancingRoundRobin ShardLoadBalancing = "RoundRobin"
)

func (e ShardLoadBalancing) ToPointer() *ShardLoadBalancing {
	return &e
}

// InputAuthenticationMethodKinesis - AWS authentication method. Choose Auto to use IAM roles.
type InputAuthenticationMethodKinesis string

const (
	// InputAuthenticationMethodKinesisAuto Auto
	InputAuthenticationMethodKinesisAuto InputAuthenticationMethodKinesis = "auto"
	// InputAuthenticationMethodKinesisManual Manual
	InputAuthenticationMethodKinesisManual InputAuthenticationMethodKinesis = "manual"
	// InputAuthenticationMethodKinesisSecret Secret Key pair
	InputAuthenticationMethodKinesisSecret InputAuthenticationMethodKinesis = "secret"
)

func (e InputAuthenticationMethodKinesis) ToPointer() *InputAuthenticationMethodKinesis {
	return &e
}

// InputSignatureVersionKinesis - Signature version to use for signing Kinesis stream requests
type InputSignatureVersionKinesis string

const (
	InputSignatureVersionKinesisV2 InputSignatureVersionKinesis = "v2"
	InputSignatureVersionKinesisV4 InputSignatureVersionKinesis = "v4"
)

func (e InputSignatureVersionKinesis) ToPointer() *InputSignatureVersionKinesis {
	return &e
}

type MetadatumKinesis struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumKinesis) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumKinesis) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumKinesis) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumKinesis) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputKinesis struct {
	// Unique ID for this input
	ID       *string          `json:"id,omitempty"`
	Type     InputTypeKinesis `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionKinesis `json:"connections,omitempty"`
	Pq          *PqKinesis          `json:"pq,omitempty"`
	// Kinesis Data Stream to read data from
	StreamName string `json:"streamName"`
	// Time interval in minutes between consecutive service calls
	ServiceInterval *float64 `default:"1" json:"serviceInterval"`
	// A JavaScript expression to be called with each shardId for the stream. If the expression evaluates to a truthy value, the shard will be processed.
	ShardExpr *string `default:"true" json:"shardExpr"`
	// Location at which to start reading a shard for the first time
	ShardIteratorType *ShardIteratorStart `default:"TRIM_HORIZON" json:"shardIteratorType"`
	// Format of data inside the Kinesis Stream records. Gzip compression is automatically detected.
	PayloadFormat *InputRecordDataFormat `default:"cribl" json:"payloadFormat"`
	// Maximum number of records per getRecords call
	GetRecordsLimit *float64 `default:"5000" json:"getRecordsLimit"`
	// Maximum number of records, across all shards, to pull down at once per Worker Process
	GetRecordsLimitTotal *float64 `default:"20000" json:"getRecordsLimitTotal"`
	// The load-balancing algorithm to use for spreading out shards across Workers and Worker Processes
	LoadBalancingAlgorithm *ShardLoadBalancing `default:"ConsistentHashing" json:"loadBalancingAlgorithm"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *InputAuthenticationMethodKinesis `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                           `json:"awsSecretKey,omitempty"`
	// Region where the Kinesis stream is located
	Region string `json:"region"`
	// Kinesis stream service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to Kinesis stream-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing Kinesis stream requests
	SignatureVersion *InputSignatureVersionKinesis `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access Kinesis stream
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Verify Kinesis Producer Library (KPL) event checksums
	VerifyKPLCheckSums *bool `default:"false" json:"verifyKPLCheckSums"`
	// When resuming streaming from a stored state, Stream will read the next available record, rather than rereading the last-read record. Enabling this setting can cause data loss after a Worker Node's unexpected shutdown or restart.
	AvoidDuplicates *bool `default:"false" json:"avoidDuplicates"`
	// Fields to add to events from this input
	Metadata    []MetadatumKinesis `json:"metadata,omitempty"`
	Description *string            `json:"description,omitempty"`
	AwsAPIKey   *string            `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret            *string        `json:"awsSecret,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputKinesis) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKinesis) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "streamName", "region"}); err != nil {
		return err
	}
	return nil
}

func (i *InputKinesis) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputKinesis) GetType() InputTypeKinesis {
	if i == nil {
		return InputTypeKinesis("")
	}
	return i.Type
}

func (i *InputKinesis) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKinesis) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputKinesis) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputKinesis) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputKinesis) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputKinesis) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputKinesis) GetConnections() []ConnectionKinesis {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputKinesis) GetPq() *PqKinesis {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputKinesis) GetStreamName() string {
	if i == nil {
		return ""
	}
	return i.StreamName
}

func (i *InputKinesis) GetServiceInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.ServiceInterval
}

func (i *InputKinesis) GetShardExpr() *string {
	if i == nil {
		return nil
	}
	return i.ShardExpr
}

func (i *InputKinesis) GetShardIteratorType() *ShardIteratorStart {
	if i == nil {
		return nil
	}
	return i.ShardIteratorType
}

func (i *InputKinesis) GetPayloadFormat() *InputRecordDataFormat {
	if i == nil {
		return nil
	}
	return i.PayloadFormat
}

func (i *InputKinesis) GetGetRecordsLimit() *float64 {
	if i == nil {
		return nil
	}
	return i.GetRecordsLimit
}

func (i *InputKinesis) GetGetRecordsLimitTotal() *float64 {
	if i == nil {
		return nil
	}
	return i.GetRecordsLimitTotal
}

func (i *InputKinesis) GetLoadBalancingAlgorithm() *ShardLoadBalancing {
	if i == nil {
		return nil
	}
	return i.LoadBalancingAlgorithm
}

func (i *InputKinesis) GetAwsAuthenticationMethod() *InputAuthenticationMethodKinesis {
	if i == nil {
		return nil
	}
	return i.AwsAuthenticationMethod
}

func (i *InputKinesis) GetAwsSecretKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecretKey
}

func (i *InputKinesis) GetRegion() string {
	if i == nil {
		return ""
	}
	return i.Region
}

func (i *InputKinesis) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputKinesis) GetSignatureVersion() *InputSignatureVersionKinesis {
	if i == nil {
		return nil
	}
	return i.SignatureVersion
}

func (i *InputKinesis) GetReuseConnections() *bool {
	if i == nil {
		return nil
	}
	return i.ReuseConnections
}

func (i *InputKinesis) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputKinesis) GetEnableAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableAssumeRole
}

func (i *InputKinesis) GetAssumeRoleArn() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleArn
}

func (i *InputKinesis) GetAssumeRoleExternalID() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleExternalID
}

func (i *InputKinesis) GetDurationSeconds() *float64 {
	if i == nil {
		return nil
	}
	return i.DurationSeconds
}

func (i *InputKinesis) GetVerifyKPLCheckSums() *bool {
	if i == nil {
		return nil
	}
	return i.VerifyKPLCheckSums
}

func (i *InputKinesis) GetAvoidDuplicates() *bool {
	if i == nil {
		return nil
	}
	return i.AvoidDuplicates
}

func (i *InputKinesis) GetMetadata() []MetadatumKinesis {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputKinesis) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputKinesis) GetAwsAPIKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsAPIKey
}

func (i *InputKinesis) GetAwsSecret() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecret
}

func (i *InputKinesis) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeHTTPRaw string

const (
	TypeHTTPRawHTTPRaw TypeHTTPRaw = "http_raw"
)

func (e TypeHTTPRaw) ToPointer() *TypeHTTPRaw {
	return &e
}
func (e *TypeHTTPRaw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http_raw":
		*e = TypeHTTPRaw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeHTTPRaw: %v", v)
	}
}

type ConnectionHTTPRaw struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionHTTPRaw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionHTTPRaw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionHTTPRaw) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionHTTPRaw) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeHTTPRaw - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeHTTPRaw string

const (
	// ModeHTTPRawSmart Smart
	ModeHTTPRawSmart ModeHTTPRaw = "smart"
	// ModeHTTPRawAlways Always On
	ModeHTTPRawAlways ModeHTTPRaw = "always"
)

func (e ModeHTTPRaw) ToPointer() *ModeHTTPRaw {
	return &e
}

// CompressionHTTPRaw - Codec to use to compress the persisted data
type CompressionHTTPRaw string

const (
	// CompressionHTTPRawNone None
	CompressionHTTPRawNone CompressionHTTPRaw = "none"
	// CompressionHTTPRawGzip Gzip
	CompressionHTTPRawGzip CompressionHTTPRaw = "gzip"
)

func (e CompressionHTTPRaw) ToPointer() *CompressionHTTPRaw {
	return &e
}

type PqControlsHTTPRaw struct {
}

func (p PqControlsHTTPRaw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsHTTPRaw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqHTTPRaw struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeHTTPRaw `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionHTTPRaw `default:"none" json:"compress"`
	PqControls *PqControlsHTTPRaw  `json:"pqControls,omitempty"`
}

func (p PqHTTPRaw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqHTTPRaw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqHTTPRaw) GetMode() *ModeHTTPRaw {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqHTTPRaw) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqHTTPRaw) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqHTTPRaw) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqHTTPRaw) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqHTTPRaw) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqHTTPRaw) GetCompress() *CompressionHTTPRaw {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqHTTPRaw) GetPqControls() *PqControlsHTTPRaw {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MinimumTLSVersionHTTPRaw string

const (
	MinimumTLSVersionHTTPRawTlSv1  MinimumTLSVersionHTTPRaw = "TLSv1"
	MinimumTLSVersionHTTPRawTlSv11 MinimumTLSVersionHTTPRaw = "TLSv1.1"
	MinimumTLSVersionHTTPRawTlSv12 MinimumTLSVersionHTTPRaw = "TLSv1.2"
	MinimumTLSVersionHTTPRawTlSv13 MinimumTLSVersionHTTPRaw = "TLSv1.3"
)

func (e MinimumTLSVersionHTTPRaw) ToPointer() *MinimumTLSVersionHTTPRaw {
	return &e
}

type MaximumTLSVersionHTTPRaw string

const (
	MaximumTLSVersionHTTPRawTlSv1  MaximumTLSVersionHTTPRaw = "TLSv1"
	MaximumTLSVersionHTTPRawTlSv11 MaximumTLSVersionHTTPRaw = "TLSv1.1"
	MaximumTLSVersionHTTPRawTlSv12 MaximumTLSVersionHTTPRaw = "TLSv1.2"
	MaximumTLSVersionHTTPRawTlSv13 MaximumTLSVersionHTTPRaw = "TLSv1.3"
)

func (e MaximumTLSVersionHTTPRaw) ToPointer() *MaximumTLSVersionHTTPRaw {
	return &e
}

type TLSSettingsServerSideHTTPRaw struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                   `json:"caPath,omitempty"`
	MinVersion *MinimumTLSVersionHTTPRaw `json:"minVersion,omitempty"`
	MaxVersion *MaximumTLSVersionHTTPRaw `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideHTTPRaw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideHTTPRaw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideHTTPRaw) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideHTTPRaw) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideHTTPRaw) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideHTTPRaw) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideHTTPRaw) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideHTTPRaw) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideHTTPRaw) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideHTTPRaw) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideHTTPRaw) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideHTTPRaw) GetMinVersion() *MinimumTLSVersionHTTPRaw {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideHTTPRaw) GetMaxVersion() *MaximumTLSVersionHTTPRaw {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

type MetadatumHTTPRaw struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumHTTPRaw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumHTTPRaw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumHTTPRaw) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumHTTPRaw) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type AuthTokensExtMetadatumHTTPRaw struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (a AuthTokensExtMetadatumHTTPRaw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokensExtMetadatumHTTPRaw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokensExtMetadatumHTTPRaw) GetName() string {
	if a == nil {
		return ""
	}
	return a.Name
}

func (a *AuthTokensExtMetadatumHTTPRaw) GetValue() string {
	if a == nil {
		return ""
	}
	return a.Value
}

type AuthTokensExtHTTPRaw struct {
	// Shared secret to be provided by any client (Authorization: <token>)
	Token       string  `json:"token"`
	Description *string `json:"description,omitempty"`
	// Fields to add to events referencing this token
	Metadata []AuthTokensExtMetadatumHTTPRaw `json:"metadata,omitempty"`
}

func (a AuthTokensExtHTTPRaw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokensExtHTTPRaw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, []string{"token"}); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokensExtHTTPRaw) GetToken() string {
	if a == nil {
		return ""
	}
	return a.Token
}

func (a *AuthTokensExtHTTPRaw) GetDescription() *string {
	if a == nil {
		return nil
	}
	return a.Description
}

func (a *AuthTokensExtHTTPRaw) GetMetadata() []AuthTokensExtMetadatumHTTPRaw {
	if a == nil {
		return nil
	}
	return a.Metadata
}

type InputHTTPRaw struct {
	// Unique ID for this input
	ID       *string     `json:"id,omitempty"`
	Type     TypeHTTPRaw `json:"type"`
	Disabled *bool       `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionHTTPRaw `json:"connections,omitempty"`
	Pq          *PqHTTPRaw          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                      `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideHTTPRaw `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Fields to add to events from this input
	Metadata []MetadatumHTTPRaw `json:"metadata,omitempty"`
	// List of URI paths accepted by this input, wildcards are supported, e.g /api/v*/hook. Defaults to allow all.
	AllowedPaths []string `json:"allowedPaths,omitempty"`
	// List of HTTP methods accepted by this input. Wildcards are supported (such as P*, GET). Defaults to allow all.
	AllowedMethods []string `json:"allowedMethods,omitempty"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokensExt        []AuthTokensExtHTTPRaw `json:"authTokensExt,omitempty"`
	Description          *string                `json:"description,omitempty"`
	AdditionalProperties map[string]any         `additionalProperties:"true" json:"-"`
}

func (i InputHTTPRaw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputHTTPRaw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port"}); err != nil {
		return err
	}
	return nil
}

func (i *InputHTTPRaw) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputHTTPRaw) GetType() TypeHTTPRaw {
	if i == nil {
		return TypeHTTPRaw("")
	}
	return i.Type
}

func (i *InputHTTPRaw) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputHTTPRaw) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputHTTPRaw) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputHTTPRaw) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputHTTPRaw) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputHTTPRaw) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputHTTPRaw) GetConnections() []ConnectionHTTPRaw {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputHTTPRaw) GetPq() *PqHTTPRaw {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputHTTPRaw) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputHTTPRaw) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputHTTPRaw) GetAuthTokens() []string {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputHTTPRaw) GetTLS() *TLSSettingsServerSideHTTPRaw {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputHTTPRaw) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputHTTPRaw) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputHTTPRaw) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputHTTPRaw) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputHTTPRaw) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputHTTPRaw) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputHTTPRaw) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputHTTPRaw) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputHTTPRaw) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputHTTPRaw) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputHTTPRaw) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputHTTPRaw) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputHTTPRaw) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputHTTPRaw) GetMetadata() []MetadatumHTTPRaw {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputHTTPRaw) GetAllowedPaths() []string {
	if i == nil {
		return nil
	}
	return i.AllowedPaths
}

func (i *InputHTTPRaw) GetAllowedMethods() []string {
	if i == nil {
		return nil
	}
	return i.AllowedMethods
}

func (i *InputHTTPRaw) GetAuthTokensExt() []AuthTokensExtHTTPRaw {
	if i == nil {
		return nil
	}
	return i.AuthTokensExt
}

func (i *InputHTTPRaw) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputHTTPRaw) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeDatagen string

const (
	TypeDatagenDatagen TypeDatagen = "datagen"
)

func (e TypeDatagen) ToPointer() *TypeDatagen {
	return &e
}
func (e *TypeDatagen) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "datagen":
		*e = TypeDatagen(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeDatagen: %v", v)
	}
}

type ConnectionDatagen struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionDatagen) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionDatagen) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionDatagen) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionDatagen) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeDatagen - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeDatagen string

const (
	// ModeDatagenSmart Smart
	ModeDatagenSmart ModeDatagen = "smart"
	// ModeDatagenAlways Always On
	ModeDatagenAlways ModeDatagen = "always"
)

func (e ModeDatagen) ToPointer() *ModeDatagen {
	return &e
}

// CompressionDatagen - Codec to use to compress the persisted data
type CompressionDatagen string

const (
	// CompressionDatagenNone None
	CompressionDatagenNone CompressionDatagen = "none"
	// CompressionDatagenGzip Gzip
	CompressionDatagenGzip CompressionDatagen = "gzip"
)

func (e CompressionDatagen) ToPointer() *CompressionDatagen {
	return &e
}

type PqControlsDatagen struct {
}

func (p PqControlsDatagen) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsDatagen) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqDatagen struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeDatagen `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionDatagen `default:"none" json:"compress"`
	PqControls *PqControlsDatagen  `json:"pqControls,omitempty"`
}

func (p PqDatagen) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqDatagen) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqDatagen) GetMode() *ModeDatagen {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqDatagen) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqDatagen) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqDatagen) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqDatagen) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqDatagen) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqDatagen) GetCompress() *CompressionDatagen {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqDatagen) GetPqControls() *PqControlsDatagen {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type Sample struct {
	Sample string `json:"sample"`
	// Maximum number of events to generate per second per Worker Node. Defaults to 10.
	EventsPerSec *float64 `default:"10" json:"eventsPerSec"`
}

func (s Sample) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *Sample) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, []string{"sample"}); err != nil {
		return err
	}
	return nil
}

func (s *Sample) GetSample() string {
	if s == nil {
		return ""
	}
	return s.Sample
}

func (s *Sample) GetEventsPerSec() *float64 {
	if s == nil {
		return nil
	}
	return s.EventsPerSec
}

type MetadatumDatagen struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumDatagen) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumDatagen) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumDatagen) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumDatagen) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputDatagen struct {
	// Unique ID for this input
	ID       *string     `json:"id,omitempty"`
	Type     TypeDatagen `json:"type"`
	Disabled *bool       `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionDatagen `json:"connections,omitempty"`
	Pq          *PqDatagen          `json:"pq,omitempty"`
	Samples     []Sample            `json:"samples"`
	// Fields to add to events from this input
	Metadata             []MetadatumDatagen `json:"metadata,omitempty"`
	Description          *string            `json:"description,omitempty"`
	AdditionalProperties map[string]any     `additionalProperties:"true" json:"-"`
}

func (i InputDatagen) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputDatagen) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "samples"}); err != nil {
		return err
	}
	return nil
}

func (i *InputDatagen) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputDatagen) GetType() TypeDatagen {
	if i == nil {
		return TypeDatagen("")
	}
	return i.Type
}

func (i *InputDatagen) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputDatagen) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputDatagen) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputDatagen) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputDatagen) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputDatagen) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputDatagen) GetConnections() []ConnectionDatagen {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputDatagen) GetPq() *PqDatagen {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputDatagen) GetSamples() []Sample {
	if i == nil {
		return []Sample{}
	}
	return i.Samples
}

func (i *InputDatagen) GetMetadata() []MetadatumDatagen {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputDatagen) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputDatagen) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeDatadogAgent string

const (
	TypeDatadogAgentDatadogAgent TypeDatadogAgent = "datadog_agent"
)

func (e TypeDatadogAgent) ToPointer() *TypeDatadogAgent {
	return &e
}
func (e *TypeDatadogAgent) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "datadog_agent":
		*e = TypeDatadogAgent(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeDatadogAgent: %v", v)
	}
}

type ConnectionDatadogAgent struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionDatadogAgent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionDatadogAgent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionDatadogAgent) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionDatadogAgent) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeDatadogAgent - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeDatadogAgent string

const (
	// ModeDatadogAgentSmart Smart
	ModeDatadogAgentSmart ModeDatadogAgent = "smart"
	// ModeDatadogAgentAlways Always On
	ModeDatadogAgentAlways ModeDatadogAgent = "always"
)

func (e ModeDatadogAgent) ToPointer() *ModeDatadogAgent {
	return &e
}

// CompressionDatadogAgent - Codec to use to compress the persisted data
type CompressionDatadogAgent string

const (
	// CompressionDatadogAgentNone None
	CompressionDatadogAgentNone CompressionDatadogAgent = "none"
	// CompressionDatadogAgentGzip Gzip
	CompressionDatadogAgentGzip CompressionDatadogAgent = "gzip"
)

func (e CompressionDatadogAgent) ToPointer() *CompressionDatadogAgent {
	return &e
}

type PqControlsDatadogAgent struct {
}

func (p PqControlsDatadogAgent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsDatadogAgent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqDatadogAgent struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeDatadogAgent `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionDatadogAgent `default:"none" json:"compress"`
	PqControls *PqControlsDatadogAgent  `json:"pqControls,omitempty"`
}

func (p PqDatadogAgent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqDatadogAgent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqDatadogAgent) GetMode() *ModeDatadogAgent {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqDatadogAgent) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqDatadogAgent) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqDatadogAgent) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqDatadogAgent) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqDatadogAgent) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqDatadogAgent) GetCompress() *CompressionDatadogAgent {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqDatadogAgent) GetPqControls() *PqControlsDatadogAgent {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MinimumTLSVersionDatadogAgent string

const (
	MinimumTLSVersionDatadogAgentTlSv1  MinimumTLSVersionDatadogAgent = "TLSv1"
	MinimumTLSVersionDatadogAgentTlSv11 MinimumTLSVersionDatadogAgent = "TLSv1.1"
	MinimumTLSVersionDatadogAgentTlSv12 MinimumTLSVersionDatadogAgent = "TLSv1.2"
	MinimumTLSVersionDatadogAgentTlSv13 MinimumTLSVersionDatadogAgent = "TLSv1.3"
)

func (e MinimumTLSVersionDatadogAgent) ToPointer() *MinimumTLSVersionDatadogAgent {
	return &e
}

type MaximumTLSVersionDatadogAgent string

const (
	MaximumTLSVersionDatadogAgentTlSv1  MaximumTLSVersionDatadogAgent = "TLSv1"
	MaximumTLSVersionDatadogAgentTlSv11 MaximumTLSVersionDatadogAgent = "TLSv1.1"
	MaximumTLSVersionDatadogAgentTlSv12 MaximumTLSVersionDatadogAgent = "TLSv1.2"
	MaximumTLSVersionDatadogAgentTlSv13 MaximumTLSVersionDatadogAgent = "TLSv1.3"
)

func (e MaximumTLSVersionDatadogAgent) ToPointer() *MaximumTLSVersionDatadogAgent {
	return &e
}

type TLSSettingsServerSideDatadogAgent struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                        `json:"caPath,omitempty"`
	MinVersion *MinimumTLSVersionDatadogAgent `json:"minVersion,omitempty"`
	MaxVersion *MaximumTLSVersionDatadogAgent `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideDatadogAgent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideDatadogAgent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideDatadogAgent) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideDatadogAgent) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideDatadogAgent) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideDatadogAgent) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideDatadogAgent) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideDatadogAgent) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideDatadogAgent) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideDatadogAgent) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideDatadogAgent) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideDatadogAgent) GetMinVersion() *MinimumTLSVersionDatadogAgent {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideDatadogAgent) GetMaxVersion() *MaximumTLSVersionDatadogAgent {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

type MetadatumDatadogAgent struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumDatadogAgent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumDatadogAgent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumDatadogAgent) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumDatadogAgent) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type ProxyModeDatadogAgent struct {
	// Toggle to Yes to send key validation requests from Datadog Agent to the Datadog API. If toggled to No (the default), Stream handles key validation requests by always responding that the key is valid.
	Enabled *bool `default:"false" json:"enabled"`
	// Whether to reject certificates that cannot be verified against a valid CA (e.g., self-signed certificates).
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
}

func (p ProxyModeDatadogAgent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *ProxyModeDatadogAgent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *ProxyModeDatadogAgent) GetEnabled() *bool {
	if p == nil {
		return nil
	}
	return p.Enabled
}

func (p *ProxyModeDatadogAgent) GetRejectUnauthorized() *bool {
	if p == nil {
		return nil
	}
	return p.RejectUnauthorized
}

type InputDatadogAgent struct {
	// Unique ID for this input
	ID       *string          `json:"id,omitempty"`
	Type     TypeDatadogAgent `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionDatadogAgent `json:"connections,omitempty"`
	Pq          *PqDatadogAgent          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                            `json:"port"`
	TLS  *TLSSettingsServerSideDatadogAgent `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Toggle to Yes to extract each incoming metric to multiple events, one per data point. This works well when sending metrics to a statsd-type output. If sending metrics to DatadogHQ or any destination that accepts arbitrary JSON, leave toggled to No (the default).
	ExtractMetrics *bool `default:"false" json:"extractMetrics"`
	// Fields to add to events from this input
	Metadata             []MetadatumDatadogAgent `json:"metadata,omitempty"`
	ProxyMode            *ProxyModeDatadogAgent  `json:"proxyMode,omitempty"`
	Description          *string                 `json:"description,omitempty"`
	AdditionalProperties map[string]any          `additionalProperties:"true" json:"-"`
}

func (i InputDatadogAgent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputDatadogAgent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port"}); err != nil {
		return err
	}
	return nil
}

func (i *InputDatadogAgent) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputDatadogAgent) GetType() TypeDatadogAgent {
	if i == nil {
		return TypeDatadogAgent("")
	}
	return i.Type
}

func (i *InputDatadogAgent) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputDatadogAgent) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputDatadogAgent) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputDatadogAgent) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputDatadogAgent) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputDatadogAgent) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputDatadogAgent) GetConnections() []ConnectionDatadogAgent {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputDatadogAgent) GetPq() *PqDatadogAgent {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputDatadogAgent) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputDatadogAgent) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputDatadogAgent) GetTLS() *TLSSettingsServerSideDatadogAgent {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputDatadogAgent) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputDatadogAgent) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputDatadogAgent) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputDatadogAgent) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputDatadogAgent) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputDatadogAgent) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputDatadogAgent) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputDatadogAgent) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputDatadogAgent) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputDatadogAgent) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputDatadogAgent) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputDatadogAgent) GetExtractMetrics() *bool {
	if i == nil {
		return nil
	}
	return i.ExtractMetrics
}

func (i *InputDatadogAgent) GetMetadata() []MetadatumDatadogAgent {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputDatadogAgent) GetProxyMode() *ProxyModeDatadogAgent {
	if i == nil {
		return nil
	}
	return i.ProxyMode
}

func (i *InputDatadogAgent) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputDatadogAgent) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeCrowdstrike string

const (
	TypeCrowdstrikeCrowdstrike TypeCrowdstrike = "crowdstrike"
)

func (e TypeCrowdstrike) ToPointer() *TypeCrowdstrike {
	return &e
}
func (e *TypeCrowdstrike) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "crowdstrike":
		*e = TypeCrowdstrike(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCrowdstrike: %v", v)
	}
}

type ConnectionCrowdstrike struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionCrowdstrike) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionCrowdstrike) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionCrowdstrike) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionCrowdstrike) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeCrowdstrike - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeCrowdstrike string

const (
	// ModeCrowdstrikeSmart Smart
	ModeCrowdstrikeSmart ModeCrowdstrike = "smart"
	// ModeCrowdstrikeAlways Always On
	ModeCrowdstrikeAlways ModeCrowdstrike = "always"
)

func (e ModeCrowdstrike) ToPointer() *ModeCrowdstrike {
	return &e
}

// CompressionCrowdstrike - Codec to use to compress the persisted data
type CompressionCrowdstrike string

const (
	// CompressionCrowdstrikeNone None
	CompressionCrowdstrikeNone CompressionCrowdstrike = "none"
	// CompressionCrowdstrikeGzip Gzip
	CompressionCrowdstrikeGzip CompressionCrowdstrike = "gzip"
)

func (e CompressionCrowdstrike) ToPointer() *CompressionCrowdstrike {
	return &e
}

type PqControlsCrowdstrike struct {
}

func (p PqControlsCrowdstrike) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsCrowdstrike) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqCrowdstrike struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeCrowdstrike `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionCrowdstrike `default:"none" json:"compress"`
	PqControls *PqControlsCrowdstrike  `json:"pqControls,omitempty"`
}

func (p PqCrowdstrike) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqCrowdstrike) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqCrowdstrike) GetMode() *ModeCrowdstrike {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqCrowdstrike) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqCrowdstrike) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqCrowdstrike) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqCrowdstrike) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqCrowdstrike) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqCrowdstrike) GetCompress() *CompressionCrowdstrike {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqCrowdstrike) GetPqControls() *PqControlsCrowdstrike {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// AuthenticationMethodCrowdstrike - AWS authentication method. Choose Auto to use IAM roles.
type AuthenticationMethodCrowdstrike string

const (
	// AuthenticationMethodCrowdstrikeAuto Auto
	AuthenticationMethodCrowdstrikeAuto AuthenticationMethodCrowdstrike = "auto"
	// AuthenticationMethodCrowdstrikeManual Manual
	AuthenticationMethodCrowdstrikeManual AuthenticationMethodCrowdstrike = "manual"
	// AuthenticationMethodCrowdstrikeSecret Secret Key pair
	AuthenticationMethodCrowdstrikeSecret AuthenticationMethodCrowdstrike = "secret"
)

func (e AuthenticationMethodCrowdstrike) ToPointer() *AuthenticationMethodCrowdstrike {
	return &e
}

// SignatureVersionCrowdstrike - Signature version to use for signing S3 requests
type SignatureVersionCrowdstrike string

const (
	SignatureVersionCrowdstrikeV2 SignatureVersionCrowdstrike = "v2"
	SignatureVersionCrowdstrikeV4 SignatureVersionCrowdstrike = "v4"
)

func (e SignatureVersionCrowdstrike) ToPointer() *SignatureVersionCrowdstrike {
	return &e
}

type PreprocessCrowdstrike struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (p PreprocessCrowdstrike) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PreprocessCrowdstrike) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PreprocessCrowdstrike) GetDisabled() *bool {
	if p == nil {
		return nil
	}
	return p.Disabled
}

func (p *PreprocessCrowdstrike) GetCommand() *string {
	if p == nil {
		return nil
	}
	return p.Command
}

func (p *PreprocessCrowdstrike) GetArgs() []string {
	if p == nil {
		return nil
	}
	return p.Args
}

type MetadatumCrowdstrike struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumCrowdstrike) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumCrowdstrike) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumCrowdstrike) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumCrowdstrike) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type CheckpointingCrowdstrike struct {
	// Resume processing files after an interruption
	Enabled *bool `default:"false" json:"enabled"`
	// The number of times to retry processing when a processing error occurs. If Skip file on error is enabled, this setting is ignored.
	Retries *float64 `default:"5" json:"retries"`
}

func (c CheckpointingCrowdstrike) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CheckpointingCrowdstrike) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *CheckpointingCrowdstrike) GetEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.Enabled
}

func (c *CheckpointingCrowdstrike) GetRetries() *float64 {
	if c == nil {
		return nil
	}
	return c.Retries
}

type TagAfterProcessingCrowdstrike string

const (
	TagAfterProcessingCrowdstrikeFalse TagAfterProcessingCrowdstrike = "false"
	TagAfterProcessingCrowdstrikeTrue  TagAfterProcessingCrowdstrike = "true"
)

func (e TagAfterProcessingCrowdstrike) ToPointer() *TagAfterProcessingCrowdstrike {
	return &e
}

type InputCrowdstrike struct {
	// Unique ID for this input
	ID       *string         `json:"id,omitempty"`
	Type     TypeCrowdstrike `json:"type"`
	Disabled *bool           `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionCrowdstrike `json:"connections,omitempty"`
	Pq          *PqCrowdstrike          `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *AuthenticationMethodCrowdstrike `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                          `json:"awsSecretKey,omitempty"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *SignatureVersionCrowdstrike `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"21600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `default:"300" json:"socketTimeout"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Attach SQS notification metadata to a __sqsMetadata field on each event
	IncludeSqsMetadata *bool `default:"false" json:"includeSqsMetadata"`
	// Use Assume Role credentials to access Amazon S3
	EnableAssumeRole *bool `default:"true" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Use Assume Role credentials when accessing Amazon SQS
	EnableSQSAssumeRole *bool                  `default:"false" json:"enableSQSAssumeRole"`
	Preprocess          *PreprocessCrowdstrike `json:"preprocess,omitempty"`
	// Fields to add to events from this input
	Metadata      []MetadatumCrowdstrike    `json:"metadata,omitempty"`
	Checkpointing *CheckpointingCrowdstrike `json:"checkpointing,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding    *string `json:"encoding,omitempty"`
	Description *string `json:"description,omitempty"`
	AwsAPIKey   *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret          *string                        `json:"awsSecret,omitempty"`
	TagAfterProcessing *TagAfterProcessingCrowdstrike `json:"tagAfterProcessing,omitempty"`
	// The key for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagKey *string `json:"processedTagKey,omitempty"`
	// The value for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagValue    *string        `json:"processedTagValue,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputCrowdstrike) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCrowdstrike) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "queueName"}); err != nil {
		return err
	}
	return nil
}

func (i *InputCrowdstrike) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputCrowdstrike) GetType() TypeCrowdstrike {
	if i == nil {
		return TypeCrowdstrike("")
	}
	return i.Type
}

func (i *InputCrowdstrike) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputCrowdstrike) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputCrowdstrike) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputCrowdstrike) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputCrowdstrike) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputCrowdstrike) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputCrowdstrike) GetConnections() []ConnectionCrowdstrike {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputCrowdstrike) GetPq() *PqCrowdstrike {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputCrowdstrike) GetQueueName() string {
	if i == nil {
		return ""
	}
	return i.QueueName
}

func (i *InputCrowdstrike) GetFileFilter() *string {
	if i == nil {
		return nil
	}
	return i.FileFilter
}

func (i *InputCrowdstrike) GetAwsAccountID() *string {
	if i == nil {
		return nil
	}
	return i.AwsAccountID
}

func (i *InputCrowdstrike) GetAwsAuthenticationMethod() *AuthenticationMethodCrowdstrike {
	if i == nil {
		return nil
	}
	return i.AwsAuthenticationMethod
}

func (i *InputCrowdstrike) GetAwsSecretKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecretKey
}

func (i *InputCrowdstrike) GetRegion() *string {
	if i == nil {
		return nil
	}
	return i.Region
}

func (i *InputCrowdstrike) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputCrowdstrike) GetSignatureVersion() *SignatureVersionCrowdstrike {
	if i == nil {
		return nil
	}
	return i.SignatureVersion
}

func (i *InputCrowdstrike) GetReuseConnections() *bool {
	if i == nil {
		return nil
	}
	return i.ReuseConnections
}

func (i *InputCrowdstrike) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputCrowdstrike) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputCrowdstrike) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputCrowdstrike) GetMaxMessages() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMessages
}

func (i *InputCrowdstrike) GetVisibilityTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.VisibilityTimeout
}

func (i *InputCrowdstrike) GetNumReceivers() *float64 {
	if i == nil {
		return nil
	}
	return i.NumReceivers
}

func (i *InputCrowdstrike) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputCrowdstrike) GetSkipOnError() *bool {
	if i == nil {
		return nil
	}
	return i.SkipOnError
}

func (i *InputCrowdstrike) GetIncludeSqsMetadata() *bool {
	if i == nil {
		return nil
	}
	return i.IncludeSqsMetadata
}

func (i *InputCrowdstrike) GetEnableAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableAssumeRole
}

func (i *InputCrowdstrike) GetAssumeRoleArn() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleArn
}

func (i *InputCrowdstrike) GetAssumeRoleExternalID() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleExternalID
}

func (i *InputCrowdstrike) GetDurationSeconds() *float64 {
	if i == nil {
		return nil
	}
	return i.DurationSeconds
}

func (i *InputCrowdstrike) GetEnableSQSAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableSQSAssumeRole
}

func (i *InputCrowdstrike) GetPreprocess() *PreprocessCrowdstrike {
	if i == nil {
		return nil
	}
	return i.Preprocess
}

func (i *InputCrowdstrike) GetMetadata() []MetadatumCrowdstrike {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputCrowdstrike) GetCheckpointing() *CheckpointingCrowdstrike {
	if i == nil {
		return nil
	}
	return i.Checkpointing
}

func (i *InputCrowdstrike) GetPollTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.PollTimeout
}

func (i *InputCrowdstrike) GetEncoding() *string {
	if i == nil {
		return nil
	}
	return i.Encoding
}

func (i *InputCrowdstrike) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputCrowdstrike) GetAwsAPIKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsAPIKey
}

func (i *InputCrowdstrike) GetAwsSecret() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecret
}

func (i *InputCrowdstrike) GetTagAfterProcessing() *TagAfterProcessingCrowdstrike {
	if i == nil {
		return nil
	}
	return i.TagAfterProcessing
}

func (i *InputCrowdstrike) GetProcessedTagKey() *string {
	if i == nil {
		return nil
	}
	return i.ProcessedTagKey
}

func (i *InputCrowdstrike) GetProcessedTagValue() *string {
	if i == nil {
		return nil
	}
	return i.ProcessedTagValue
}

func (i *InputCrowdstrike) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeWindowsMetrics string

const (
	TypeWindowsMetricsWindowsMetrics TypeWindowsMetrics = "windows_metrics"
)

func (e TypeWindowsMetrics) ToPointer() *TypeWindowsMetrics {
	return &e
}
func (e *TypeWindowsMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "windows_metrics":
		*e = TypeWindowsMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeWindowsMetrics: %v", v)
	}
}

type ConnectionWindowsMetrics struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionWindowsMetrics) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionWindowsMetrics) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// PqModeWindowsMetrics - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeWindowsMetrics string

const (
	// PqModeWindowsMetricsSmart Smart
	PqModeWindowsMetricsSmart PqModeWindowsMetrics = "smart"
	// PqModeWindowsMetricsAlways Always On
	PqModeWindowsMetricsAlways PqModeWindowsMetrics = "always"
)

func (e PqModeWindowsMetrics) ToPointer() *PqModeWindowsMetrics {
	return &e
}

// CompressionWindowsMetrics - Codec to use to compress the persisted data
type CompressionWindowsMetrics string

const (
	// CompressionWindowsMetricsNone None
	CompressionWindowsMetricsNone CompressionWindowsMetrics = "none"
	// CompressionWindowsMetricsGzip Gzip
	CompressionWindowsMetricsGzip CompressionWindowsMetrics = "gzip"
)

func (e CompressionWindowsMetrics) ToPointer() *CompressionWindowsMetrics {
	return &e
}

type PqControlsWindowsMetrics struct {
}

func (p PqControlsWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqWindowsMetrics struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeWindowsMetrics `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionWindowsMetrics `default:"none" json:"compress"`
	PqControls *PqControlsWindowsMetrics  `json:"pqControls,omitempty"`
}

func (p PqWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqWindowsMetrics) GetMode() *PqModeWindowsMetrics {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqWindowsMetrics) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqWindowsMetrics) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqWindowsMetrics) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqWindowsMetrics) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqWindowsMetrics) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqWindowsMetrics) GetCompress() *CompressionWindowsMetrics {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqWindowsMetrics) GetPqControls() *PqControlsWindowsMetrics {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// HostModeWindowsMetrics - Select level of detail for host metrics
type HostModeWindowsMetrics string

const (
	// HostModeWindowsMetricsBasic Basic
	HostModeWindowsMetricsBasic HostModeWindowsMetrics = "basic"
	// HostModeWindowsMetricsAll All
	HostModeWindowsMetricsAll HostModeWindowsMetrics = "all"
	// HostModeWindowsMetricsCustom Custom
	HostModeWindowsMetricsCustom HostModeWindowsMetrics = "custom"
	// HostModeWindowsMetricsDisabled Disabled
	HostModeWindowsMetricsDisabled HostModeWindowsMetrics = "disabled"
)

func (e HostModeWindowsMetrics) ToPointer() *HostModeWindowsMetrics {
	return &e
}

// SystemModeWindowsMetrics - Select the level of details for system metrics
type SystemModeWindowsMetrics string

const (
	// SystemModeWindowsMetricsBasic Basic
	SystemModeWindowsMetricsBasic SystemModeWindowsMetrics = "basic"
	// SystemModeWindowsMetricsAll All
	SystemModeWindowsMetricsAll SystemModeWindowsMetrics = "all"
	// SystemModeWindowsMetricsCustom Custom
	SystemModeWindowsMetricsCustom SystemModeWindowsMetrics = "custom"
	// SystemModeWindowsMetricsDisabled Disabled
	SystemModeWindowsMetricsDisabled SystemModeWindowsMetrics = "disabled"
)

func (e SystemModeWindowsMetrics) ToPointer() *SystemModeWindowsMetrics {
	return &e
}

type SystemWindowsMetrics struct {
	// Select the level of details for system metrics
	Mode *SystemModeWindowsMetrics `default:"basic" json:"mode"`
	// Generate metrics for all system information
	Detail *bool `default:"false" json:"detail"`
}

func (s SystemWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SystemWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (s *SystemWindowsMetrics) GetMode() *SystemModeWindowsMetrics {
	if s == nil {
		return nil
	}
	return s.Mode
}

func (s *SystemWindowsMetrics) GetDetail() *bool {
	if s == nil {
		return nil
	}
	return s.Detail
}

// CPUModeWindowsMetrics - Select the level of details for CPU metrics
type CPUModeWindowsMetrics string

const (
	// CPUModeWindowsMetricsBasic Basic
	CPUModeWindowsMetricsBasic CPUModeWindowsMetrics = "basic"
	// CPUModeWindowsMetricsAll All
	CPUModeWindowsMetricsAll CPUModeWindowsMetrics = "all"
	// CPUModeWindowsMetricsCustom Custom
	CPUModeWindowsMetricsCustom CPUModeWindowsMetrics = "custom"
	// CPUModeWindowsMetricsDisabled Disabled
	CPUModeWindowsMetricsDisabled CPUModeWindowsMetrics = "disabled"
)

func (e CPUModeWindowsMetrics) ToPointer() *CPUModeWindowsMetrics {
	return &e
}

type CPUWindowsMetrics struct {
	// Select the level of details for CPU metrics
	Mode *CPUModeWindowsMetrics `default:"basic" json:"mode"`
	// Generate metrics for each CPU
	PerCPU *bool `default:"false" json:"perCpu"`
	// Generate metrics for all CPU states
	Detail *bool `default:"false" json:"detail"`
	// Generate raw, monotonic CPU time counters
	Time *bool `default:"false" json:"time"`
}

func (c CPUWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CPUWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *CPUWindowsMetrics) GetMode() *CPUModeWindowsMetrics {
	if c == nil {
		return nil
	}
	return c.Mode
}

func (c *CPUWindowsMetrics) GetPerCPU() *bool {
	if c == nil {
		return nil
	}
	return c.PerCPU
}

func (c *CPUWindowsMetrics) GetDetail() *bool {
	if c == nil {
		return nil
	}
	return c.Detail
}

func (c *CPUWindowsMetrics) GetTime() *bool {
	if c == nil {
		return nil
	}
	return c.Time
}

// MemoryModeWindowsMetrics - Select the level of details for memory metrics
type MemoryModeWindowsMetrics string

const (
	// MemoryModeWindowsMetricsBasic Basic
	MemoryModeWindowsMetricsBasic MemoryModeWindowsMetrics = "basic"
	// MemoryModeWindowsMetricsAll All
	MemoryModeWindowsMetricsAll MemoryModeWindowsMetrics = "all"
	// MemoryModeWindowsMetricsCustom Custom
	MemoryModeWindowsMetricsCustom MemoryModeWindowsMetrics = "custom"
	// MemoryModeWindowsMetricsDisabled Disabled
	MemoryModeWindowsMetricsDisabled MemoryModeWindowsMetrics = "disabled"
)

func (e MemoryModeWindowsMetrics) ToPointer() *MemoryModeWindowsMetrics {
	return &e
}

type MemoryWindowsMetrics struct {
	// Select the level of details for memory metrics
	Mode *MemoryModeWindowsMetrics `default:"basic" json:"mode"`
	// Generate metrics for all memory states
	Detail *bool `default:"false" json:"detail"`
}

func (m MemoryWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MemoryWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (m *MemoryWindowsMetrics) GetMode() *MemoryModeWindowsMetrics {
	if m == nil {
		return nil
	}
	return m.Mode
}

func (m *MemoryWindowsMetrics) GetDetail() *bool {
	if m == nil {
		return nil
	}
	return m.Detail
}

// NetworkModeWindowsMetrics - Select the level of details for network metrics
type NetworkModeWindowsMetrics string

const (
	// NetworkModeWindowsMetricsBasic Basic
	NetworkModeWindowsMetricsBasic NetworkModeWindowsMetrics = "basic"
	// NetworkModeWindowsMetricsAll All
	NetworkModeWindowsMetricsAll NetworkModeWindowsMetrics = "all"
	// NetworkModeWindowsMetricsCustom Custom
	NetworkModeWindowsMetricsCustom NetworkModeWindowsMetrics = "custom"
	// NetworkModeWindowsMetricsDisabled Disabled
	NetworkModeWindowsMetricsDisabled NetworkModeWindowsMetrics = "disabled"
)

func (e NetworkModeWindowsMetrics) ToPointer() *NetworkModeWindowsMetrics {
	return &e
}

type NetworkWindowsMetrics struct {
	// Select the level of details for network metrics
	Mode *NetworkModeWindowsMetrics `default:"basic" json:"mode"`
	// Generate full network metrics
	Detail *bool `default:"false" json:"detail"`
	// Generate protocol metrics for ICMP, ICMPMsg, IP, TCP, UDP and UDPLite
	Protocols *bool `default:"false" json:"protocols"`
	// Network interfaces to include/exclude. All interfaces are included if this list is empty.
	Devices []string `json:"devices,omitempty"`
	// Generate separate metrics for each interface
	PerInterface *bool `default:"false" json:"perInterface"`
}

func (n NetworkWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(n, "", false)
}

func (n *NetworkWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &n, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (n *NetworkWindowsMetrics) GetMode() *NetworkModeWindowsMetrics {
	if n == nil {
		return nil
	}
	return n.Mode
}

func (n *NetworkWindowsMetrics) GetDetail() *bool {
	if n == nil {
		return nil
	}
	return n.Detail
}

func (n *NetworkWindowsMetrics) GetProtocols() *bool {
	if n == nil {
		return nil
	}
	return n.Protocols
}

func (n *NetworkWindowsMetrics) GetDevices() []string {
	if n == nil {
		return nil
	}
	return n.Devices
}

func (n *NetworkWindowsMetrics) GetPerInterface() *bool {
	if n == nil {
		return nil
	}
	return n.PerInterface
}

// DiskModeWindowsMetrics - Select the level of details for disk metrics
type DiskModeWindowsMetrics string

const (
	// DiskModeWindowsMetricsBasic Basic
	DiskModeWindowsMetricsBasic DiskModeWindowsMetrics = "basic"
	// DiskModeWindowsMetricsAll All
	DiskModeWindowsMetricsAll DiskModeWindowsMetrics = "all"
	// DiskModeWindowsMetricsCustom Custom
	DiskModeWindowsMetricsCustom DiskModeWindowsMetrics = "custom"
	// DiskModeWindowsMetricsDisabled Disabled
	DiskModeWindowsMetricsDisabled DiskModeWindowsMetrics = "disabled"
)

func (e DiskModeWindowsMetrics) ToPointer() *DiskModeWindowsMetrics {
	return &e
}

type DiskWindowsMetrics struct {
	// Select the level of details for disk metrics
	Mode *DiskModeWindowsMetrics `default:"basic" json:"mode"`
	// Generate separate metrics for each volume
	PerVolume *bool `default:"false" json:"perVolume"`
	// Generate full disk metrics
	Detail *bool `default:"false" json:"detail"`
	// Windows volumes to include/exclude. E.g.: C:, !E:, etc. Wildcards and ! (not) operators are supported. All volumes are included if this list is empty.
	Volumes []string `json:"volumes,omitempty"`
}

func (d DiskWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DiskWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DiskWindowsMetrics) GetMode() *DiskModeWindowsMetrics {
	if d == nil {
		return nil
	}
	return d.Mode
}

func (d *DiskWindowsMetrics) GetPerVolume() *bool {
	if d == nil {
		return nil
	}
	return d.PerVolume
}

func (d *DiskWindowsMetrics) GetDetail() *bool {
	if d == nil {
		return nil
	}
	return d.Detail
}

func (d *DiskWindowsMetrics) GetVolumes() []string {
	if d == nil {
		return nil
	}
	return d.Volumes
}

type CustomWindowsMetrics struct {
	System  *SystemWindowsMetrics  `json:"system,omitempty"`
	CPU     *CPUWindowsMetrics     `json:"cpu,omitempty"`
	Memory  *MemoryWindowsMetrics  `json:"memory,omitempty"`
	Network *NetworkWindowsMetrics `json:"network,omitempty"`
	Disk    *DiskWindowsMetrics    `json:"disk,omitempty"`
}

func (c CustomWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CustomWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *CustomWindowsMetrics) GetSystem() *SystemWindowsMetrics {
	if c == nil {
		return nil
	}
	return c.System
}

func (c *CustomWindowsMetrics) GetCPU() *CPUWindowsMetrics {
	if c == nil {
		return nil
	}
	return c.CPU
}

func (c *CustomWindowsMetrics) GetMemory() *MemoryWindowsMetrics {
	if c == nil {
		return nil
	}
	return c.Memory
}

func (c *CustomWindowsMetrics) GetNetwork() *NetworkWindowsMetrics {
	if c == nil {
		return nil
	}
	return c.Network
}

func (c *CustomWindowsMetrics) GetDisk() *DiskWindowsMetrics {
	if c == nil {
		return nil
	}
	return c.Disk
}

type HostWindowsMetrics struct {
	// Select level of detail for host metrics
	Mode   *HostModeWindowsMetrics `default:"basic" json:"mode"`
	Custom *CustomWindowsMetrics   `json:"custom,omitempty"`
}

func (h HostWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *HostWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (h *HostWindowsMetrics) GetMode() *HostModeWindowsMetrics {
	if h == nil {
		return nil
	}
	return h.Mode
}

func (h *HostWindowsMetrics) GetCustom() *CustomWindowsMetrics {
	if h == nil {
		return nil
	}
	return h.Custom
}

type SetWindowsMetrics struct {
	Name            string `json:"name"`
	Filter          string `json:"filter"`
	IncludeChildren *bool  `default:"false" json:"includeChildren"`
}

func (s SetWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SetWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, []string{"name", "filter"}); err != nil {
		return err
	}
	return nil
}

func (s *SetWindowsMetrics) GetName() string {
	if s == nil {
		return ""
	}
	return s.Name
}

func (s *SetWindowsMetrics) GetFilter() string {
	if s == nil {
		return ""
	}
	return s.Filter
}

func (s *SetWindowsMetrics) GetIncludeChildren() *bool {
	if s == nil {
		return nil
	}
	return s.IncludeChildren
}

type ProcessWindowsMetrics struct {
	// Configure sets to collect process metrics
	Sets []SetWindowsMetrics `json:"sets,omitempty"`
}

func (p ProcessWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *ProcessWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *ProcessWindowsMetrics) GetSets() []SetWindowsMetrics {
	if p == nil {
		return nil
	}
	return p.Sets
}

type MetadatumWindowsMetrics struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumWindowsMetrics) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumWindowsMetrics) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type DataCompressionFormatWindowsMetrics string

const (
	DataCompressionFormatWindowsMetricsNone DataCompressionFormatWindowsMetrics = "none"
	DataCompressionFormatWindowsMetricsGzip DataCompressionFormatWindowsMetrics = "gzip"
)

func (e DataCompressionFormatWindowsMetrics) ToPointer() *DataCompressionFormatWindowsMetrics {
	return &e
}

type PersistenceWindowsMetrics struct {
	// Spool metrics to disk for Cribl Edge and Search
	Enable *bool `default:"false" json:"enable"`
	// Time span for each file bucket
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                              `default:"24h" json:"maxDataTime"`
	Compress    *DataCompressionFormatWindowsMetrics `default:"gzip" json:"compress"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/windows_metrics
	DestPath *string `default:"$CRIBL_HOME/state/windows_metrics" json:"destPath"`
}

func (p PersistenceWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PersistenceWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PersistenceWindowsMetrics) GetEnable() *bool {
	if p == nil {
		return nil
	}
	return p.Enable
}

func (p *PersistenceWindowsMetrics) GetTimeWindow() *string {
	if p == nil {
		return nil
	}
	return p.TimeWindow
}

func (p *PersistenceWindowsMetrics) GetMaxDataSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataSize
}

func (p *PersistenceWindowsMetrics) GetMaxDataTime() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataTime
}

func (p *PersistenceWindowsMetrics) GetCompress() *DataCompressionFormatWindowsMetrics {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PersistenceWindowsMetrics) GetDestPath() *string {
	if p == nil {
		return nil
	}
	return p.DestPath
}

type InputWindowsMetrics struct {
	// Unique ID for this input
	ID       *string            `json:"id,omitempty"`
	Type     TypeWindowsMetrics `json:"type"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionWindowsMetrics `json:"connections,omitempty"`
	Pq          *PqWindowsMetrics          `json:"pq,omitempty"`
	// Time, in seconds, between consecutive metric collections. Default is 10 seconds.
	Interval *float64               `default:"10" json:"interval"`
	Host     *HostWindowsMetrics    `json:"host,omitempty"`
	Process  *ProcessWindowsMetrics `json:"process,omitempty"`
	// Fields to add to events from this input
	Metadata    []MetadatumWindowsMetrics  `json:"metadata,omitempty"`
	Persistence *PersistenceWindowsMetrics `json:"persistence,omitempty"`
	// Enable to use built-in tools (PowerShell) to collect metrics instead of native API (default) [Learn more](https://docs.cribl.io/edge/sources-windows-metrics/#advanced-tab)
	DisableNativeModule  *bool          `default:"false" json:"disableNativeModule"`
	Description          *string        `json:"description,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputWindowsMetrics) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputWindowsMetrics) GetType() TypeWindowsMetrics {
	if i == nil {
		return TypeWindowsMetrics("")
	}
	return i.Type
}

func (i *InputWindowsMetrics) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputWindowsMetrics) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputWindowsMetrics) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputWindowsMetrics) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputWindowsMetrics) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputWindowsMetrics) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputWindowsMetrics) GetConnections() []ConnectionWindowsMetrics {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputWindowsMetrics) GetPq() *PqWindowsMetrics {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputWindowsMetrics) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputWindowsMetrics) GetHost() *HostWindowsMetrics {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputWindowsMetrics) GetProcess() *ProcessWindowsMetrics {
	if i == nil {
		return nil
	}
	return i.Process
}

func (i *InputWindowsMetrics) GetMetadata() []MetadatumWindowsMetrics {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputWindowsMetrics) GetPersistence() *PersistenceWindowsMetrics {
	if i == nil {
		return nil
	}
	return i.Persistence
}

func (i *InputWindowsMetrics) GetDisableNativeModule() *bool {
	if i == nil {
		return nil
	}
	return i.DisableNativeModule
}

func (i *InputWindowsMetrics) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputWindowsMetrics) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeKubeEvents string

const (
	TypeKubeEventsKubeEvents TypeKubeEvents = "kube_events"
)

func (e TypeKubeEvents) ToPointer() *TypeKubeEvents {
	return &e
}
func (e *TypeKubeEvents) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kube_events":
		*e = TypeKubeEvents(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeKubeEvents: %v", v)
	}
}

type ConnectionKubeEvents struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionKubeEvents) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionKubeEvents) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionKubeEvents) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionKubeEvents) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeKubeEvents - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeKubeEvents string

const (
	// ModeKubeEventsSmart Smart
	ModeKubeEventsSmart ModeKubeEvents = "smart"
	// ModeKubeEventsAlways Always On
	ModeKubeEventsAlways ModeKubeEvents = "always"
)

func (e ModeKubeEvents) ToPointer() *ModeKubeEvents {
	return &e
}

// CompressionKubeEvents - Codec to use to compress the persisted data
type CompressionKubeEvents string

const (
	// CompressionKubeEventsNone None
	CompressionKubeEventsNone CompressionKubeEvents = "none"
	// CompressionKubeEventsGzip Gzip
	CompressionKubeEventsGzip CompressionKubeEvents = "gzip"
)

func (e CompressionKubeEvents) ToPointer() *CompressionKubeEvents {
	return &e
}

type PqControlsKubeEvents struct {
}

func (p PqControlsKubeEvents) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsKubeEvents) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqKubeEvents struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeKubeEvents `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionKubeEvents `default:"none" json:"compress"`
	PqControls *PqControlsKubeEvents  `json:"pqControls,omitempty"`
}

func (p PqKubeEvents) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqKubeEvents) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqKubeEvents) GetMode() *ModeKubeEvents {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqKubeEvents) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqKubeEvents) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqKubeEvents) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqKubeEvents) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqKubeEvents) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqKubeEvents) GetCompress() *CompressionKubeEvents {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqKubeEvents) GetPqControls() *PqControlsKubeEvents {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type RuleKubeEvents struct {
	// JavaScript expression applied to Kubernetes objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitempty"`
}

func (r RuleKubeEvents) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RuleKubeEvents) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, []string{"filter"}); err != nil {
		return err
	}
	return nil
}

func (r *RuleKubeEvents) GetFilter() string {
	if r == nil {
		return ""
	}
	return r.Filter
}

func (r *RuleKubeEvents) GetDescription() *string {
	if r == nil {
		return nil
	}
	return r.Description
}

type MetadatumKubeEvents struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumKubeEvents) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumKubeEvents) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumKubeEvents) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumKubeEvents) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputKubeEvents struct {
	// Unique ID for this input
	ID       *string        `json:"id,omitempty"`
	Type     TypeKubeEvents `json:"type"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionKubeEvents `json:"connections,omitempty"`
	Pq          *PqKubeEvents          `json:"pq,omitempty"`
	// Filtering on event fields
	Rules []RuleKubeEvents `json:"rules,omitempty"`
	// Fields to add to events from this input
	Metadata             []MetadatumKubeEvents `json:"metadata,omitempty"`
	Description          *string               `json:"description,omitempty"`
	AdditionalProperties map[string]any        `additionalProperties:"true" json:"-"`
}

func (i InputKubeEvents) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeEvents) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputKubeEvents) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputKubeEvents) GetType() TypeKubeEvents {
	if i == nil {
		return TypeKubeEvents("")
	}
	return i.Type
}

func (i *InputKubeEvents) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKubeEvents) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputKubeEvents) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputKubeEvents) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputKubeEvents) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputKubeEvents) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputKubeEvents) GetConnections() []ConnectionKubeEvents {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputKubeEvents) GetPq() *PqKubeEvents {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputKubeEvents) GetRules() []RuleKubeEvents {
	if i == nil {
		return nil
	}
	return i.Rules
}

func (i *InputKubeEvents) GetMetadata() []MetadatumKubeEvents {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputKubeEvents) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputKubeEvents) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeKubeLogs string

const (
	TypeKubeLogsKubeLogs TypeKubeLogs = "kube_logs"
)

func (e TypeKubeLogs) ToPointer() *TypeKubeLogs {
	return &e
}
func (e *TypeKubeLogs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kube_logs":
		*e = TypeKubeLogs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeKubeLogs: %v", v)
	}
}

type ConnectionKubeLogs struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionKubeLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionKubeLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionKubeLogs) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionKubeLogs) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeKubeLogs - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeKubeLogs string

const (
	// ModeKubeLogsSmart Smart
	ModeKubeLogsSmart ModeKubeLogs = "smart"
	// ModeKubeLogsAlways Always On
	ModeKubeLogsAlways ModeKubeLogs = "always"
)

func (e ModeKubeLogs) ToPointer() *ModeKubeLogs {
	return &e
}

// PqCompressionKubeLogs - Codec to use to compress the persisted data
type PqCompressionKubeLogs string

const (
	// PqCompressionKubeLogsNone None
	PqCompressionKubeLogsNone PqCompressionKubeLogs = "none"
	// PqCompressionKubeLogsGzip Gzip
	PqCompressionKubeLogsGzip PqCompressionKubeLogs = "gzip"
)

func (e PqCompressionKubeLogs) ToPointer() *PqCompressionKubeLogs {
	return &e
}

type PqControlsKubeLogs struct {
}

func (p PqControlsKubeLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsKubeLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqKubeLogs struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeKubeLogs `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *PqCompressionKubeLogs `default:"none" json:"compress"`
	PqControls *PqControlsKubeLogs    `json:"pqControls,omitempty"`
}

func (p PqKubeLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqKubeLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqKubeLogs) GetMode() *ModeKubeLogs {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqKubeLogs) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqKubeLogs) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqKubeLogs) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqKubeLogs) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqKubeLogs) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqKubeLogs) GetCompress() *PqCompressionKubeLogs {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqKubeLogs) GetPqControls() *PqControlsKubeLogs {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type RuleKubeLogs struct {
	// JavaScript expression applied to Pod objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitempty"`
}

func (r RuleKubeLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RuleKubeLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, []string{"filter"}); err != nil {
		return err
	}
	return nil
}

func (r *RuleKubeLogs) GetFilter() string {
	if r == nil {
		return ""
	}
	return r.Filter
}

func (r *RuleKubeLogs) GetDescription() *string {
	if r == nil {
		return nil
	}
	return r.Description
}

type MetadatumKubeLogs struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumKubeLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumKubeLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumKubeLogs) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumKubeLogs) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

// PersistenceCompressionKubeLogs - Data compression format. Default is gzip.
type PersistenceCompressionKubeLogs string

const (
	PersistenceCompressionKubeLogsNone PersistenceCompressionKubeLogs = "none"
	PersistenceCompressionKubeLogsGzip PersistenceCompressionKubeLogs = "gzip"
)

func (e PersistenceCompressionKubeLogs) ToPointer() *PersistenceCompressionKubeLogs {
	return &e
}

type DiskSpoolingKubeLogs struct {
	// Spool events on disk for Cribl Edge and Search. Default is disabled.
	Enable *bool `default:"false" json:"enable"`
	// Time period for grouping spooled events. Default is 10m.
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space that can be consumed before older buckets are deleted. Examples: 420MB, 4GB. Default is 1GB.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data before older buckets are deleted. Examples: 2h, 4d. Default is 24h.
	MaxDataTime *string `default:"24h" json:"maxDataTime"`
	// Data compression format. Default is gzip.
	Compress *PersistenceCompressionKubeLogs `default:"gzip" json:"compress"`
}

func (d DiskSpoolingKubeLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DiskSpoolingKubeLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DiskSpoolingKubeLogs) GetEnable() *bool {
	if d == nil {
		return nil
	}
	return d.Enable
}

func (d *DiskSpoolingKubeLogs) GetTimeWindow() *string {
	if d == nil {
		return nil
	}
	return d.TimeWindow
}

func (d *DiskSpoolingKubeLogs) GetMaxDataSize() *string {
	if d == nil {
		return nil
	}
	return d.MaxDataSize
}

func (d *DiskSpoolingKubeLogs) GetMaxDataTime() *string {
	if d == nil {
		return nil
	}
	return d.MaxDataTime
}

func (d *DiskSpoolingKubeLogs) GetCompress() *PersistenceCompressionKubeLogs {
	if d == nil {
		return nil
	}
	return d.Compress
}

type InputKubeLogs struct {
	// Unique ID for this input
	ID       *string      `json:"id,omitempty"`
	Type     TypeKubeLogs `json:"type"`
	Disabled *bool        `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionKubeLogs `json:"connections,omitempty"`
	Pq          *PqKubeLogs          `json:"pq,omitempty"`
	// Time, in seconds, between checks for new containers. Default is 15 secs.
	Interval *float64 `default:"15" json:"interval"`
	// Add rules to decide which Pods to collect logs from. Logs are collected if no rules are given or if all the rules' expressions evaluate to true.
	Rules []RuleKubeLogs `json:"rules,omitempty"`
	// For use when containers do not emit a timestamp, prefix each line of output with a timestamp. If you enable this setting, you can use the Kubernetes Logs Event Breaker and the kubernetes_logs Pre-processing Pipeline to remove them from the events after the timestamps are extracted.
	Timestamps *bool `default:"false" json:"timestamps"`
	// Fields to add to events from this input
	Metadata    []MetadatumKubeLogs   `json:"metadata,omitempty"`
	Persistence *DiskSpoolingKubeLogs `json:"persistence,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing  *bool          `default:"false" json:"enableLoadBalancing"`
	Description          *string        `json:"description,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputKubeLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputKubeLogs) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputKubeLogs) GetType() TypeKubeLogs {
	if i == nil {
		return TypeKubeLogs("")
	}
	return i.Type
}

func (i *InputKubeLogs) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKubeLogs) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputKubeLogs) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputKubeLogs) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputKubeLogs) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputKubeLogs) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputKubeLogs) GetConnections() []ConnectionKubeLogs {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputKubeLogs) GetPq() *PqKubeLogs {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputKubeLogs) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputKubeLogs) GetRules() []RuleKubeLogs {
	if i == nil {
		return nil
	}
	return i.Rules
}

func (i *InputKubeLogs) GetTimestamps() *bool {
	if i == nil {
		return nil
	}
	return i.Timestamps
}

func (i *InputKubeLogs) GetMetadata() []MetadatumKubeLogs {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputKubeLogs) GetPersistence() *DiskSpoolingKubeLogs {
	if i == nil {
		return nil
	}
	return i.Persistence
}

func (i *InputKubeLogs) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputKubeLogs) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputKubeLogs) GetEnableLoadBalancing() *bool {
	if i == nil {
		return nil
	}
	return i.EnableLoadBalancing
}

func (i *InputKubeLogs) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputKubeLogs) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeKubeMetrics string

const (
	TypeKubeMetricsKubeMetrics TypeKubeMetrics = "kube_metrics"
)

func (e TypeKubeMetrics) ToPointer() *TypeKubeMetrics {
	return &e
}
func (e *TypeKubeMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kube_metrics":
		*e = TypeKubeMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeKubeMetrics: %v", v)
	}
}

type ConnectionKubeMetrics struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionKubeMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionKubeMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionKubeMetrics) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionKubeMetrics) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeKubeMetrics - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeKubeMetrics string

const (
	// ModeKubeMetricsSmart Smart
	ModeKubeMetricsSmart ModeKubeMetrics = "smart"
	// ModeKubeMetricsAlways Always On
	ModeKubeMetricsAlways ModeKubeMetrics = "always"
)

func (e ModeKubeMetrics) ToPointer() *ModeKubeMetrics {
	return &e
}

// CompressionKubeMetrics - Codec to use to compress the persisted data
type CompressionKubeMetrics string

const (
	// CompressionKubeMetricsNone None
	CompressionKubeMetricsNone CompressionKubeMetrics = "none"
	// CompressionKubeMetricsGzip Gzip
	CompressionKubeMetricsGzip CompressionKubeMetrics = "gzip"
)

func (e CompressionKubeMetrics) ToPointer() *CompressionKubeMetrics {
	return &e
}

type PqControlsKubeMetrics struct {
}

func (p PqControlsKubeMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsKubeMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqKubeMetrics struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeKubeMetrics `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionKubeMetrics `default:"none" json:"compress"`
	PqControls *PqControlsKubeMetrics  `json:"pqControls,omitempty"`
}

func (p PqKubeMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqKubeMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqKubeMetrics) GetMode() *ModeKubeMetrics {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqKubeMetrics) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqKubeMetrics) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqKubeMetrics) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqKubeMetrics) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqKubeMetrics) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqKubeMetrics) GetCompress() *CompressionKubeMetrics {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqKubeMetrics) GetPqControls() *PqControlsKubeMetrics {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type RuleKubeMetrics struct {
	// JavaScript expression applied to Kubernetes objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitempty"`
}

func (r RuleKubeMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RuleKubeMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, []string{"filter"}); err != nil {
		return err
	}
	return nil
}

func (r *RuleKubeMetrics) GetFilter() string {
	if r == nil {
		return ""
	}
	return r.Filter
}

func (r *RuleKubeMetrics) GetDescription() *string {
	if r == nil {
		return nil
	}
	return r.Description
}

type MetadatumKubeMetrics struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumKubeMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumKubeMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumKubeMetrics) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumKubeMetrics) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type DataCompressionFormatKubeMetrics string

const (
	DataCompressionFormatKubeMetricsNone DataCompressionFormatKubeMetrics = "none"
	DataCompressionFormatKubeMetricsGzip DataCompressionFormatKubeMetrics = "gzip"
)

func (e DataCompressionFormatKubeMetrics) ToPointer() *DataCompressionFormatKubeMetrics {
	return &e
}

type PersistenceKubeMetrics struct {
	// Spool metrics on disk for Cribl Search
	Enable *bool `default:"false" json:"enable"`
	// Time span for each file bucket
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                           `default:"24h" json:"maxDataTime"`
	Compress    *DataCompressionFormatKubeMetrics `default:"gzip" json:"compress"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/<id>
	DestPath *string `default:"$CRIBL_HOME/state/kube_metrics" json:"destPath"`
}

func (p PersistenceKubeMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PersistenceKubeMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PersistenceKubeMetrics) GetEnable() *bool {
	if p == nil {
		return nil
	}
	return p.Enable
}

func (p *PersistenceKubeMetrics) GetTimeWindow() *string {
	if p == nil {
		return nil
	}
	return p.TimeWindow
}

func (p *PersistenceKubeMetrics) GetMaxDataSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataSize
}

func (p *PersistenceKubeMetrics) GetMaxDataTime() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataTime
}

func (p *PersistenceKubeMetrics) GetCompress() *DataCompressionFormatKubeMetrics {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PersistenceKubeMetrics) GetDestPath() *string {
	if p == nil {
		return nil
	}
	return p.DestPath
}

type InputKubeMetrics struct {
	// Unique ID for this input
	ID       *string         `json:"id,omitempty"`
	Type     TypeKubeMetrics `json:"type"`
	Disabled *bool           `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionKubeMetrics `json:"connections,omitempty"`
	Pq          *PqKubeMetrics          `json:"pq,omitempty"`
	// Time, in seconds, between consecutive metrics collections. Default is 15 secs.
	Interval *float64 `default:"15" json:"interval"`
	// Add rules to decide which Kubernetes objects to generate metrics for. Events are generated if no rules are given or of all the rules' expressions evaluate to true.
	Rules []RuleKubeMetrics `json:"rules,omitempty"`
	// Fields to add to events from this input
	Metadata             []MetadatumKubeMetrics  `json:"metadata,omitempty"`
	Persistence          *PersistenceKubeMetrics `json:"persistence,omitempty"`
	Description          *string                 `json:"description,omitempty"`
	AdditionalProperties map[string]any          `additionalProperties:"true" json:"-"`
}

func (i InputKubeMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputKubeMetrics) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputKubeMetrics) GetType() TypeKubeMetrics {
	if i == nil {
		return TypeKubeMetrics("")
	}
	return i.Type
}

func (i *InputKubeMetrics) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKubeMetrics) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputKubeMetrics) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputKubeMetrics) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputKubeMetrics) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputKubeMetrics) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputKubeMetrics) GetConnections() []ConnectionKubeMetrics {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputKubeMetrics) GetPq() *PqKubeMetrics {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputKubeMetrics) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputKubeMetrics) GetRules() []RuleKubeMetrics {
	if i == nil {
		return nil
	}
	return i.Rules
}

func (i *InputKubeMetrics) GetMetadata() []MetadatumKubeMetrics {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputKubeMetrics) GetPersistence() *PersistenceKubeMetrics {
	if i == nil {
		return nil
	}
	return i.Persistence
}

func (i *InputKubeMetrics) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputKubeMetrics) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeSystemState string

const (
	TypeSystemStateSystemState TypeSystemState = "system_state"
)

func (e TypeSystemState) ToPointer() *TypeSystemState {
	return &e
}
func (e *TypeSystemState) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "system_state":
		*e = TypeSystemState(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeSystemState: %v", v)
	}
}

type ConnectionSystemState struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionSystemState) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionSystemState) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionSystemState) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionSystemState) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeSystemState - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeSystemState string

const (
	// ModeSystemStateSmart Smart
	ModeSystemStateSmart ModeSystemState = "smart"
	// ModeSystemStateAlways Always On
	ModeSystemStateAlways ModeSystemState = "always"
)

func (e ModeSystemState) ToPointer() *ModeSystemState {
	return &e
}

// CompressionSystemState - Codec to use to compress the persisted data
type CompressionSystemState string

const (
	// CompressionSystemStateNone None
	CompressionSystemStateNone CompressionSystemState = "none"
	// CompressionSystemStateGzip Gzip
	CompressionSystemStateGzip CompressionSystemState = "gzip"
)

func (e CompressionSystemState) ToPointer() *CompressionSystemState {
	return &e
}

type PqControlsSystemState struct {
}

func (p PqControlsSystemState) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsSystemState) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqSystemState struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeSystemState `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionSystemState `default:"none" json:"compress"`
	PqControls *PqControlsSystemState  `json:"pqControls,omitempty"`
}

func (p PqSystemState) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSystemState) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqSystemState) GetMode() *ModeSystemState {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqSystemState) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqSystemState) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqSystemState) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqSystemState) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqSystemState) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqSystemState) GetCompress() *CompressionSystemState {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqSystemState) GetPqControls() *PqControlsSystemState {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MetadatumSystemState struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumSystemState) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumSystemState) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumSystemState) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumSystemState) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

// HostsFile - Creates events based on entries collected from the hosts file
type HostsFile struct {
	Enable *bool `default:"true" json:"enable"`
}

func (h HostsFile) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *HostsFile) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (h *HostsFile) GetEnable() *bool {
	if h == nil {
		return nil
	}
	return h.Enable
}

// Interfaces - Creates events for each of the host’s network interfaces
type Interfaces struct {
	Enable *bool `default:"true" json:"enable"`
}

func (i Interfaces) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *Interfaces) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *Interfaces) GetEnable() *bool {
	if i == nil {
		return nil
	}
	return i.Enable
}

// DisksAndFileSystems - Creates events for physical disks, partitions, and file systems
type DisksAndFileSystems struct {
	Enable *bool `default:"true" json:"enable"`
}

func (d DisksAndFileSystems) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DisksAndFileSystems) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DisksAndFileSystems) GetEnable() *bool {
	if d == nil {
		return nil
	}
	return d.Enable
}

// HostInfo - Creates events based on the host system’s current state
type HostInfo struct {
	Enable *bool `default:"true" json:"enable"`
}

func (h HostInfo) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *HostInfo) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (h *HostInfo) GetEnable() *bool {
	if h == nil {
		return nil
	}
	return h.Enable
}

// InputRoutes - Creates events based on entries collected from the host’s network routes
type InputRoutes struct {
	Enable *bool `default:"true" json:"enable"`
}

func (i InputRoutes) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputRoutes) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputRoutes) GetEnable() *bool {
	if i == nil {
		return nil
	}
	return i.Enable
}

// DNS - Creates events for DNS resolvers and search entries
type DNS struct {
	Enable *bool `default:"true" json:"enable"`
}

func (d DNS) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DNS) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DNS) GetEnable() *bool {
	if d == nil {
		return nil
	}
	return d.Enable
}

// UsersAndGroups - Creates events for local users and groups
type UsersAndGroups struct {
	Enable *bool `default:"true" json:"enable"`
}

func (u UsersAndGroups) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(u, "", false)
}

func (u *UsersAndGroups) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &u, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (u *UsersAndGroups) GetEnable() *bool {
	if u == nil {
		return nil
	}
	return u.Enable
}

// Firewall - Creates events for Firewall rules entries
type Firewall struct {
	Enable *bool `default:"true" json:"enable"`
}

func (f Firewall) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(f, "", false)
}

func (f *Firewall) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &f, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (f *Firewall) GetEnable() *bool {
	if f == nil {
		return nil
	}
	return f.Enable
}

// Services - Creates events from the list of services
type Services struct {
	Enable *bool `default:"true" json:"enable"`
}

func (s Services) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *Services) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (s *Services) GetEnable() *bool {
	if s == nil {
		return nil
	}
	return s.Enable
}

// ListeningPorts - Creates events from list of listening ports
type ListeningPorts struct {
	Enable *bool `default:"true" json:"enable"`
}

func (l ListeningPorts) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(l, "", false)
}

func (l *ListeningPorts) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &l, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (l *ListeningPorts) GetEnable() *bool {
	if l == nil {
		return nil
	}
	return l.Enable
}

// LoggedInUsers - Creates events from list of logged-in users
type LoggedInUsers struct {
	Enable *bool `default:"true" json:"enable"`
}

func (l LoggedInUsers) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(l, "", false)
}

func (l *LoggedInUsers) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &l, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (l *LoggedInUsers) GetEnable() *bool {
	if l == nil {
		return nil
	}
	return l.Enable
}

type Collectors struct {
	// Creates events based on entries collected from the hosts file
	Hostsfile *HostsFile `json:"hostsfile,omitempty"`
	// Creates events for each of the host’s network interfaces
	Interfaces *Interfaces `json:"interfaces,omitempty"`
	// Creates events for physical disks, partitions, and file systems
	Disk *DisksAndFileSystems `json:"disk,omitempty"`
	// Creates events based on the host system’s current state
	Metadata *HostInfo `json:"metadata,omitempty"`
	// Creates events based on entries collected from the host’s network routes
	Routes *InputRoutes `json:"routes,omitempty"`
	// Creates events for DNS resolvers and search entries
	DNS *DNS `json:"dns,omitempty"`
	// Creates events for local users and groups
	User *UsersAndGroups `json:"user,omitempty"`
	// Creates events for Firewall rules entries
	Firewall *Firewall `json:"firewall,omitempty"`
	// Creates events from the list of services
	Services *Services `json:"services,omitempty"`
	// Creates events from list of listening ports
	Ports *ListeningPorts `json:"ports,omitempty"`
	// Creates events from list of logged-in users
	LoginUsers *LoggedInUsers `json:"loginUsers,omitempty"`
}

func (c Collectors) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *Collectors) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *Collectors) GetHostsfile() *HostsFile {
	if c == nil {
		return nil
	}
	return c.Hostsfile
}

func (c *Collectors) GetInterfaces() *Interfaces {
	if c == nil {
		return nil
	}
	return c.Interfaces
}

func (c *Collectors) GetDisk() *DisksAndFileSystems {
	if c == nil {
		return nil
	}
	return c.Disk
}

func (c *Collectors) GetMetadata() *HostInfo {
	if c == nil {
		return nil
	}
	return c.Metadata
}

func (c *Collectors) GetRoutes() *InputRoutes {
	if c == nil {
		return nil
	}
	return c.Routes
}

func (c *Collectors) GetDNS() *DNS {
	if c == nil {
		return nil
	}
	return c.DNS
}

func (c *Collectors) GetUser() *UsersAndGroups {
	if c == nil {
		return nil
	}
	return c.User
}

func (c *Collectors) GetFirewall() *Firewall {
	if c == nil {
		return nil
	}
	return c.Firewall
}

func (c *Collectors) GetServices() *Services {
	if c == nil {
		return nil
	}
	return c.Services
}

func (c *Collectors) GetPorts() *ListeningPorts {
	if c == nil {
		return nil
	}
	return c.Ports
}

func (c *Collectors) GetLoginUsers() *LoggedInUsers {
	if c == nil {
		return nil
	}
	return c.LoginUsers
}

type DataCompressionFormatSystemState string

const (
	DataCompressionFormatSystemStateNone DataCompressionFormatSystemState = "none"
	DataCompressionFormatSystemStateGzip DataCompressionFormatSystemState = "gzip"
)

func (e DataCompressionFormatSystemState) ToPointer() *DataCompressionFormatSystemState {
	return &e
}

type PersistenceSystemState struct {
	// Spool metrics to disk for Cribl Edge and Search
	Enable *bool `default:"false" json:"enable"`
	// Time span for each file bucket
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                           `default:"24h" json:"maxDataTime"`
	Compress    *DataCompressionFormatSystemState `default:"none" json:"compress"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/system_state
	DestPath *string `default:"$CRIBL_HOME/state/system_state" json:"destPath"`
}

func (p PersistenceSystemState) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PersistenceSystemState) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PersistenceSystemState) GetEnable() *bool {
	if p == nil {
		return nil
	}
	return p.Enable
}

func (p *PersistenceSystemState) GetTimeWindow() *string {
	if p == nil {
		return nil
	}
	return p.TimeWindow
}

func (p *PersistenceSystemState) GetMaxDataSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataSize
}

func (p *PersistenceSystemState) GetMaxDataTime() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataTime
}

func (p *PersistenceSystemState) GetCompress() *DataCompressionFormatSystemState {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PersistenceSystemState) GetDestPath() *string {
	if p == nil {
		return nil
	}
	return p.DestPath
}

type InputSystemState struct {
	// Unique ID for this input
	ID       *string         `json:"id,omitempty"`
	Type     TypeSystemState `json:"type"`
	Disabled *bool           `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSystemState `json:"connections,omitempty"`
	Pq          *PqSystemState          `json:"pq,omitempty"`
	// Time, in seconds, between consecutive state collections. Default is 300 seconds (5 minutes).
	Interval *float64 `default:"300" json:"interval"`
	// Fields to add to events from this input
	Metadata    []MetadatumSystemState  `json:"metadata,omitempty"`
	Collectors  *Collectors             `json:"collectors,omitempty"`
	Persistence *PersistenceSystemState `json:"persistence,omitempty"`
	// Enable to use built-in tools (PowerShell) to collect events instead of native API (default) [Learn more](https://docs.cribl.io/edge/sources-system-state/#advanced-tab)
	DisableNativeModule  *bool          `default:"false" json:"disableNativeModule"`
	Description          *string        `json:"description,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputSystemState) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSystemState) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputSystemState) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputSystemState) GetType() TypeSystemState {
	if i == nil {
		return TypeSystemState("")
	}
	return i.Type
}

func (i *InputSystemState) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSystemState) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSystemState) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputSystemState) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputSystemState) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputSystemState) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputSystemState) GetConnections() []ConnectionSystemState {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputSystemState) GetPq() *PqSystemState {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputSystemState) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputSystemState) GetMetadata() []MetadatumSystemState {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputSystemState) GetCollectors() *Collectors {
	if i == nil {
		return nil
	}
	return i.Collectors
}

func (i *InputSystemState) GetPersistence() *PersistenceSystemState {
	if i == nil {
		return nil
	}
	return i.Persistence
}

func (i *InputSystemState) GetDisableNativeModule() *bool {
	if i == nil {
		return nil
	}
	return i.DisableNativeModule
}

func (i *InputSystemState) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputSystemState) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeSystemMetrics string

const (
	TypeSystemMetricsSystemMetrics TypeSystemMetrics = "system_metrics"
)

func (e TypeSystemMetrics) ToPointer() *TypeSystemMetrics {
	return &e
}
func (e *TypeSystemMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "system_metrics":
		*e = TypeSystemMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeSystemMetrics: %v", v)
	}
}

type ConnectionSystemMetrics struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionSystemMetrics) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionSystemMetrics) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// PqModeSystemMetrics - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeSystemMetrics string

const (
	// PqModeSystemMetricsSmart Smart
	PqModeSystemMetricsSmart PqModeSystemMetrics = "smart"
	// PqModeSystemMetricsAlways Always On
	PqModeSystemMetricsAlways PqModeSystemMetrics = "always"
)

func (e PqModeSystemMetrics) ToPointer() *PqModeSystemMetrics {
	return &e
}

// CompressionSystemMetrics - Codec to use to compress the persisted data
type CompressionSystemMetrics string

const (
	// CompressionSystemMetricsNone None
	CompressionSystemMetricsNone CompressionSystemMetrics = "none"
	// CompressionSystemMetricsGzip Gzip
	CompressionSystemMetricsGzip CompressionSystemMetrics = "gzip"
)

func (e CompressionSystemMetrics) ToPointer() *CompressionSystemMetrics {
	return &e
}

type PqControlsSystemMetrics struct {
}

func (p PqControlsSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqSystemMetrics struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeSystemMetrics `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionSystemMetrics `default:"none" json:"compress"`
	PqControls *PqControlsSystemMetrics  `json:"pqControls,omitempty"`
}

func (p PqSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqSystemMetrics) GetMode() *PqModeSystemMetrics {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqSystemMetrics) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqSystemMetrics) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqSystemMetrics) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqSystemMetrics) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqSystemMetrics) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqSystemMetrics) GetCompress() *CompressionSystemMetrics {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqSystemMetrics) GetPqControls() *PqControlsSystemMetrics {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// HostModeSystemMetrics - Select level of detail for host metrics
type HostModeSystemMetrics string

const (
	// HostModeSystemMetricsBasic Basic
	HostModeSystemMetricsBasic HostModeSystemMetrics = "basic"
	// HostModeSystemMetricsAll All
	HostModeSystemMetricsAll HostModeSystemMetrics = "all"
	// HostModeSystemMetricsCustom Custom
	HostModeSystemMetricsCustom HostModeSystemMetrics = "custom"
	// HostModeSystemMetricsDisabled Disabled
	HostModeSystemMetricsDisabled HostModeSystemMetrics = "disabled"
)

func (e HostModeSystemMetrics) ToPointer() *HostModeSystemMetrics {
	return &e
}

// SystemModeSystemMetrics - Select the level of detail for system metrics
type SystemModeSystemMetrics string

const (
	// SystemModeSystemMetricsBasic Basic
	SystemModeSystemMetricsBasic SystemModeSystemMetrics = "basic"
	// SystemModeSystemMetricsAll All
	SystemModeSystemMetricsAll SystemModeSystemMetrics = "all"
	// SystemModeSystemMetricsCustom Custom
	SystemModeSystemMetricsCustom SystemModeSystemMetrics = "custom"
	// SystemModeSystemMetricsDisabled Disabled
	SystemModeSystemMetricsDisabled SystemModeSystemMetrics = "disabled"
)

func (e SystemModeSystemMetrics) ToPointer() *SystemModeSystemMetrics {
	return &e
}

type SystemSystemMetrics struct {
	// Select the level of detail for system metrics
	Mode *SystemModeSystemMetrics `default:"basic" json:"mode"`
	// Generate metrics for the numbers of processes in various states
	Processes *bool `default:"false" json:"processes"`
}

func (s SystemSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SystemSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (s *SystemSystemMetrics) GetMode() *SystemModeSystemMetrics {
	if s == nil {
		return nil
	}
	return s.Mode
}

func (s *SystemSystemMetrics) GetProcesses() *bool {
	if s == nil {
		return nil
	}
	return s.Processes
}

// CPUModeSystemMetrics - Select the level of detail for CPU metrics
type CPUModeSystemMetrics string

const (
	// CPUModeSystemMetricsBasic Basic
	CPUModeSystemMetricsBasic CPUModeSystemMetrics = "basic"
	// CPUModeSystemMetricsAll All
	CPUModeSystemMetricsAll CPUModeSystemMetrics = "all"
	// CPUModeSystemMetricsCustom Custom
	CPUModeSystemMetricsCustom CPUModeSystemMetrics = "custom"
	// CPUModeSystemMetricsDisabled Disabled
	CPUModeSystemMetricsDisabled CPUModeSystemMetrics = "disabled"
)

func (e CPUModeSystemMetrics) ToPointer() *CPUModeSystemMetrics {
	return &e
}

type CPUSystemMetrics struct {
	// Select the level of detail for CPU metrics
	Mode *CPUModeSystemMetrics `default:"basic" json:"mode"`
	// Generate metrics for each CPU
	PerCPU *bool `default:"false" json:"perCpu"`
	// Generate metrics for all CPU states
	Detail *bool `default:"false" json:"detail"`
	// Generate raw, monotonic CPU time counters
	Time *bool `default:"false" json:"time"`
}

func (c CPUSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CPUSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *CPUSystemMetrics) GetMode() *CPUModeSystemMetrics {
	if c == nil {
		return nil
	}
	return c.Mode
}

func (c *CPUSystemMetrics) GetPerCPU() *bool {
	if c == nil {
		return nil
	}
	return c.PerCPU
}

func (c *CPUSystemMetrics) GetDetail() *bool {
	if c == nil {
		return nil
	}
	return c.Detail
}

func (c *CPUSystemMetrics) GetTime() *bool {
	if c == nil {
		return nil
	}
	return c.Time
}

// MemoryModeSystemMetrics - Select the level of detail for memory metrics
type MemoryModeSystemMetrics string

const (
	// MemoryModeSystemMetricsBasic Basic
	MemoryModeSystemMetricsBasic MemoryModeSystemMetrics = "basic"
	// MemoryModeSystemMetricsAll All
	MemoryModeSystemMetricsAll MemoryModeSystemMetrics = "all"
	// MemoryModeSystemMetricsCustom Custom
	MemoryModeSystemMetricsCustom MemoryModeSystemMetrics = "custom"
	// MemoryModeSystemMetricsDisabled Disabled
	MemoryModeSystemMetricsDisabled MemoryModeSystemMetrics = "disabled"
)

func (e MemoryModeSystemMetrics) ToPointer() *MemoryModeSystemMetrics {
	return &e
}

type MemorySystemMetrics struct {
	// Select the level of detail for memory metrics
	Mode *MemoryModeSystemMetrics `default:"basic" json:"mode"`
	// Generate metrics for all memory states
	Detail *bool `default:"false" json:"detail"`
}

func (m MemorySystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MemorySystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (m *MemorySystemMetrics) GetMode() *MemoryModeSystemMetrics {
	if m == nil {
		return nil
	}
	return m.Mode
}

func (m *MemorySystemMetrics) GetDetail() *bool {
	if m == nil {
		return nil
	}
	return m.Detail
}

// NetworkModeSystemMetrics - Select the level of detail for network metrics
type NetworkModeSystemMetrics string

const (
	// NetworkModeSystemMetricsBasic Basic
	NetworkModeSystemMetricsBasic NetworkModeSystemMetrics = "basic"
	// NetworkModeSystemMetricsAll All
	NetworkModeSystemMetricsAll NetworkModeSystemMetrics = "all"
	// NetworkModeSystemMetricsCustom Custom
	NetworkModeSystemMetricsCustom NetworkModeSystemMetrics = "custom"
	// NetworkModeSystemMetricsDisabled Disabled
	NetworkModeSystemMetricsDisabled NetworkModeSystemMetrics = "disabled"
)

func (e NetworkModeSystemMetrics) ToPointer() *NetworkModeSystemMetrics {
	return &e
}

type NetworkSystemMetrics struct {
	// Select the level of detail for network metrics
	Mode *NetworkModeSystemMetrics `default:"basic" json:"mode"`
	// Generate full network metrics
	Detail *bool `default:"false" json:"detail"`
	// Generate protocol metrics for ICMP, ICMPMsg, IP, TCP, UDP and UDPLite
	Protocols *bool `default:"false" json:"protocols"`
	// Network interfaces to include/exclude. Examples: eth0, !lo. All interfaces are included if this list is empty.
	Devices []string `json:"devices,omitempty"`
	// Generate separate metrics for each interface
	PerInterface *bool `default:"false" json:"perInterface"`
}

func (n NetworkSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(n, "", false)
}

func (n *NetworkSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &n, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (n *NetworkSystemMetrics) GetMode() *NetworkModeSystemMetrics {
	if n == nil {
		return nil
	}
	return n.Mode
}

func (n *NetworkSystemMetrics) GetDetail() *bool {
	if n == nil {
		return nil
	}
	return n.Detail
}

func (n *NetworkSystemMetrics) GetProtocols() *bool {
	if n == nil {
		return nil
	}
	return n.Protocols
}

func (n *NetworkSystemMetrics) GetDevices() []string {
	if n == nil {
		return nil
	}
	return n.Devices
}

func (n *NetworkSystemMetrics) GetPerInterface() *bool {
	if n == nil {
		return nil
	}
	return n.PerInterface
}

// DiskModeSystemMetrics - Select the level of detail for disk metrics
type DiskModeSystemMetrics string

const (
	// DiskModeSystemMetricsBasic Basic
	DiskModeSystemMetricsBasic DiskModeSystemMetrics = "basic"
	// DiskModeSystemMetricsAll All
	DiskModeSystemMetricsAll DiskModeSystemMetrics = "all"
	// DiskModeSystemMetricsCustom Custom
	DiskModeSystemMetricsCustom DiskModeSystemMetrics = "custom"
	// DiskModeSystemMetricsDisabled Disabled
	DiskModeSystemMetricsDisabled DiskModeSystemMetrics = "disabled"
)

func (e DiskModeSystemMetrics) ToPointer() *DiskModeSystemMetrics {
	return &e
}

type DiskSystemMetrics struct {
	// Select the level of detail for disk metrics
	Mode *DiskModeSystemMetrics `default:"basic" json:"mode"`
	// Generate full disk metrics
	Detail *bool `default:"false" json:"detail"`
	// Generate filesystem inode metrics
	Inodes *bool `default:"false" json:"inodes"`
	// Block devices to include/exclude. Examples: sda*, !loop*. Wildcards and ! (not) operators are supported. All devices are included if this list is empty.
	Devices []string `json:"devices,omitempty"`
	// Filesystem mountpoints to include/exclude. Examples: /, /home, !/proc*, !/tmp. Wildcards and ! (not) operators are supported. All mountpoints are included if this list is empty.
	Mountpoints []string `json:"mountpoints,omitempty"`
	// Filesystem types to include/exclude. Examples: ext4, !*tmpfs, !squashfs. Wildcards and ! (not) operators are supported. All types are included if this list is empty.
	Fstypes []string `json:"fstypes,omitempty"`
	// Generate separate metrics for each device
	PerDevice *bool `default:"false" json:"perDevice"`
}

func (d DiskSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DiskSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DiskSystemMetrics) GetMode() *DiskModeSystemMetrics {
	if d == nil {
		return nil
	}
	return d.Mode
}

func (d *DiskSystemMetrics) GetDetail() *bool {
	if d == nil {
		return nil
	}
	return d.Detail
}

func (d *DiskSystemMetrics) GetInodes() *bool {
	if d == nil {
		return nil
	}
	return d.Inodes
}

func (d *DiskSystemMetrics) GetDevices() []string {
	if d == nil {
		return nil
	}
	return d.Devices
}

func (d *DiskSystemMetrics) GetMountpoints() []string {
	if d == nil {
		return nil
	}
	return d.Mountpoints
}

func (d *DiskSystemMetrics) GetFstypes() []string {
	if d == nil {
		return nil
	}
	return d.Fstypes
}

func (d *DiskSystemMetrics) GetPerDevice() *bool {
	if d == nil {
		return nil
	}
	return d.PerDevice
}

type CustomSystemMetrics struct {
	System  *SystemSystemMetrics  `json:"system,omitempty"`
	CPU     *CPUSystemMetrics     `json:"cpu,omitempty"`
	Memory  *MemorySystemMetrics  `json:"memory,omitempty"`
	Network *NetworkSystemMetrics `json:"network,omitempty"`
	Disk    *DiskSystemMetrics    `json:"disk,omitempty"`
}

func (c CustomSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CustomSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *CustomSystemMetrics) GetSystem() *SystemSystemMetrics {
	if c == nil {
		return nil
	}
	return c.System
}

func (c *CustomSystemMetrics) GetCPU() *CPUSystemMetrics {
	if c == nil {
		return nil
	}
	return c.CPU
}

func (c *CustomSystemMetrics) GetMemory() *MemorySystemMetrics {
	if c == nil {
		return nil
	}
	return c.Memory
}

func (c *CustomSystemMetrics) GetNetwork() *NetworkSystemMetrics {
	if c == nil {
		return nil
	}
	return c.Network
}

func (c *CustomSystemMetrics) GetDisk() *DiskSystemMetrics {
	if c == nil {
		return nil
	}
	return c.Disk
}

type HostSystemMetrics struct {
	// Select level of detail for host metrics
	Mode   *HostModeSystemMetrics `default:"basic" json:"mode"`
	Custom *CustomSystemMetrics   `json:"custom,omitempty"`
}

func (h HostSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *HostSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (h *HostSystemMetrics) GetMode() *HostModeSystemMetrics {
	if h == nil {
		return nil
	}
	return h.Mode
}

func (h *HostSystemMetrics) GetCustom() *CustomSystemMetrics {
	if h == nil {
		return nil
	}
	return h.Custom
}

type SetSystemMetrics struct {
	Name            string `json:"name"`
	Filter          string `json:"filter"`
	IncludeChildren *bool  `default:"false" json:"includeChildren"`
}

func (s SetSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SetSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, []string{"name", "filter"}); err != nil {
		return err
	}
	return nil
}

func (s *SetSystemMetrics) GetName() string {
	if s == nil {
		return ""
	}
	return s.Name
}

func (s *SetSystemMetrics) GetFilter() string {
	if s == nil {
		return ""
	}
	return s.Filter
}

func (s *SetSystemMetrics) GetIncludeChildren() *bool {
	if s == nil {
		return nil
	}
	return s.IncludeChildren
}

type ProcessSystemMetrics struct {
	// Configure sets to collect process metrics
	Sets []SetSystemMetrics `json:"sets,omitempty"`
}

func (p ProcessSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *ProcessSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *ProcessSystemMetrics) GetSets() []SetSystemMetrics {
	if p == nil {
		return nil
	}
	return p.Sets
}

// ContainerMode - Select the level of detail for container metrics
type ContainerMode string

const (
	// ContainerModeBasic Basic
	ContainerModeBasic ContainerMode = "basic"
	// ContainerModeAll All
	ContainerModeAll ContainerMode = "all"
	// ContainerModeCustom Custom
	ContainerModeCustom ContainerMode = "custom"
	// ContainerModeDisabled Disabled
	ContainerModeDisabled ContainerMode = "disabled"
)

func (e ContainerMode) ToPointer() *ContainerMode {
	return &e
}

type ContainerFilter struct {
	Expr string `json:"expr"`
}

func (c ContainerFilter) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ContainerFilter) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"expr"}); err != nil {
		return err
	}
	return nil
}

func (c *ContainerFilter) GetExpr() string {
	if c == nil {
		return ""
	}
	return c.Expr
}

type Container struct {
	// Select the level of detail for container metrics
	Mode *ContainerMode `default:"basic" json:"mode"`
	// Full paths for Docker's UNIX-domain socket
	DockerSocket []string `json:"dockerSocket,omitempty"`
	// Timeout, in seconds, for the Docker API
	DockerTimeout *float64 `default:"5" json:"dockerTimeout"`
	// Containers matching any of these will be included. All are included if no filters are added.
	Filters []ContainerFilter `json:"filters,omitempty"`
	// Include stopped and paused containers
	AllContainers *bool `default:"false" json:"allContainers"`
	// Generate separate metrics for each device
	PerDevice *bool `default:"false" json:"perDevice"`
	// Generate full container metrics
	Detail *bool `default:"false" json:"detail"`
}

func (c Container) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *Container) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *Container) GetMode() *ContainerMode {
	if c == nil {
		return nil
	}
	return c.Mode
}

func (c *Container) GetDockerSocket() []string {
	if c == nil {
		return nil
	}
	return c.DockerSocket
}

func (c *Container) GetDockerTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.DockerTimeout
}

func (c *Container) GetFilters() []ContainerFilter {
	if c == nil {
		return nil
	}
	return c.Filters
}

func (c *Container) GetAllContainers() *bool {
	if c == nil {
		return nil
	}
	return c.AllContainers
}

func (c *Container) GetPerDevice() *bool {
	if c == nil {
		return nil
	}
	return c.PerDevice
}

func (c *Container) GetDetail() *bool {
	if c == nil {
		return nil
	}
	return c.Detail
}

type MetadatumSystemMetrics struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumSystemMetrics) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumSystemMetrics) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type DataCompressionFormatSystemMetrics string

const (
	DataCompressionFormatSystemMetricsNone DataCompressionFormatSystemMetrics = "none"
	DataCompressionFormatSystemMetricsGzip DataCompressionFormatSystemMetrics = "gzip"
)

func (e DataCompressionFormatSystemMetrics) ToPointer() *DataCompressionFormatSystemMetrics {
	return &e
}

type PersistenceSystemMetrics struct {
	// Spool metrics to disk for Cribl Edge and Search
	Enable *bool `default:"false" json:"enable"`
	// Time span for each file bucket
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                             `default:"24h" json:"maxDataTime"`
	Compress    *DataCompressionFormatSystemMetrics `default:"gzip" json:"compress"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/system_metrics
	DestPath *string `default:"$CRIBL_HOME/state/system_metrics" json:"destPath"`
}

func (p PersistenceSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PersistenceSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PersistenceSystemMetrics) GetEnable() *bool {
	if p == nil {
		return nil
	}
	return p.Enable
}

func (p *PersistenceSystemMetrics) GetTimeWindow() *string {
	if p == nil {
		return nil
	}
	return p.TimeWindow
}

func (p *PersistenceSystemMetrics) GetMaxDataSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataSize
}

func (p *PersistenceSystemMetrics) GetMaxDataTime() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataTime
}

func (p *PersistenceSystemMetrics) GetCompress() *DataCompressionFormatSystemMetrics {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PersistenceSystemMetrics) GetDestPath() *string {
	if p == nil {
		return nil
	}
	return p.DestPath
}

type InputSystemMetrics struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     TypeSystemMetrics `json:"type"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSystemMetrics `json:"connections,omitempty"`
	Pq          *PqSystemMetrics          `json:"pq,omitempty"`
	// Time, in seconds, between consecutive metric collections. Default is 10 seconds.
	Interval  *float64              `default:"10" json:"interval"`
	Host      *HostSystemMetrics    `json:"host,omitempty"`
	Process   *ProcessSystemMetrics `json:"process,omitempty"`
	Container *Container            `json:"container,omitempty"`
	// Fields to add to events from this input
	Metadata             []MetadatumSystemMetrics  `json:"metadata,omitempty"`
	Persistence          *PersistenceSystemMetrics `json:"persistence,omitempty"`
	Description          *string                   `json:"description,omitempty"`
	AdditionalProperties map[string]any            `additionalProperties:"true" json:"-"`
}

func (i InputSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputSystemMetrics) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputSystemMetrics) GetType() TypeSystemMetrics {
	if i == nil {
		return TypeSystemMetrics("")
	}
	return i.Type
}

func (i *InputSystemMetrics) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSystemMetrics) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSystemMetrics) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputSystemMetrics) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputSystemMetrics) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputSystemMetrics) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputSystemMetrics) GetConnections() []ConnectionSystemMetrics {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputSystemMetrics) GetPq() *PqSystemMetrics {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputSystemMetrics) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputSystemMetrics) GetHost() *HostSystemMetrics {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputSystemMetrics) GetProcess() *ProcessSystemMetrics {
	if i == nil {
		return nil
	}
	return i.Process
}

func (i *InputSystemMetrics) GetContainer() *Container {
	if i == nil {
		return nil
	}
	return i.Container
}

func (i *InputSystemMetrics) GetMetadata() []MetadatumSystemMetrics {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputSystemMetrics) GetPersistence() *PersistenceSystemMetrics {
	if i == nil {
		return nil
	}
	return i.Persistence
}

func (i *InputSystemMetrics) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputSystemMetrics) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputTypeTcpjson string

const (
	InputTypeTcpjsonTcpjson InputTypeTcpjson = "tcpjson"
)

func (e InputTypeTcpjson) ToPointer() *InputTypeTcpjson {
	return &e
}
func (e *InputTypeTcpjson) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "tcpjson":
		*e = InputTypeTcpjson(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeTcpjson: %v", v)
	}
}

type ConnectionTcpjson struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionTcpjson) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionTcpjson) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionTcpjson) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionTcpjson) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// PqModeTcpjson - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeTcpjson string

const (
	// PqModeTcpjsonSmart Smart
	PqModeTcpjsonSmart PqModeTcpjson = "smart"
	// PqModeTcpjsonAlways Always On
	PqModeTcpjsonAlways PqModeTcpjson = "always"
)

func (e PqModeTcpjson) ToPointer() *PqModeTcpjson {
	return &e
}

// PqCompressionTcpjson - Codec to use to compress the persisted data
type PqCompressionTcpjson string

const (
	// PqCompressionTcpjsonNone None
	PqCompressionTcpjsonNone PqCompressionTcpjson = "none"
	// PqCompressionTcpjsonGzip Gzip
	PqCompressionTcpjsonGzip PqCompressionTcpjson = "gzip"
)

func (e PqCompressionTcpjson) ToPointer() *PqCompressionTcpjson {
	return &e
}

type InputPqControlsTcpjson struct {
}

func (i InputPqControlsTcpjson) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPqControlsTcpjson) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqTcpjson struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeTcpjson `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *PqCompressionTcpjson   `default:"none" json:"compress"`
	PqControls *InputPqControlsTcpjson `json:"pqControls,omitempty"`
}

func (p PqTcpjson) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqTcpjson) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqTcpjson) GetMode() *PqModeTcpjson {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqTcpjson) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqTcpjson) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqTcpjson) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqTcpjson) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqTcpjson) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqTcpjson) GetCompress() *PqCompressionTcpjson {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqTcpjson) GetPqControls() *InputPqControlsTcpjson {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type InputMinimumTLSVersionTcpjson string

const (
	InputMinimumTLSVersionTcpjsonTlSv1  InputMinimumTLSVersionTcpjson = "TLSv1"
	InputMinimumTLSVersionTcpjsonTlSv11 InputMinimumTLSVersionTcpjson = "TLSv1.1"
	InputMinimumTLSVersionTcpjsonTlSv12 InputMinimumTLSVersionTcpjson = "TLSv1.2"
	InputMinimumTLSVersionTcpjsonTlSv13 InputMinimumTLSVersionTcpjson = "TLSv1.3"
)

func (e InputMinimumTLSVersionTcpjson) ToPointer() *InputMinimumTLSVersionTcpjson {
	return &e
}

type InputMaximumTLSVersionTcpjson string

const (
	InputMaximumTLSVersionTcpjsonTlSv1  InputMaximumTLSVersionTcpjson = "TLSv1"
	InputMaximumTLSVersionTcpjsonTlSv11 InputMaximumTLSVersionTcpjson = "TLSv1.1"
	InputMaximumTLSVersionTcpjsonTlSv12 InputMaximumTLSVersionTcpjson = "TLSv1.2"
	InputMaximumTLSVersionTcpjsonTlSv13 InputMaximumTLSVersionTcpjson = "TLSv1.3"
)

func (e InputMaximumTLSVersionTcpjson) ToPointer() *InputMaximumTLSVersionTcpjson {
	return &e
}

type TLSSettingsServerSideTcpjson struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                        `json:"caPath,omitempty"`
	MinVersion *InputMinimumTLSVersionTcpjson `json:"minVersion,omitempty"`
	MaxVersion *InputMaximumTLSVersionTcpjson `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideTcpjson) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideTcpjson) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideTcpjson) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideTcpjson) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideTcpjson) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideTcpjson) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideTcpjson) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideTcpjson) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideTcpjson) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideTcpjson) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideTcpjson) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideTcpjson) GetMinVersion() *InputMinimumTLSVersionTcpjson {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideTcpjson) GetMaxVersion() *InputMaximumTLSVersionTcpjson {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

type MetadatumTcpjson struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumTcpjson) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumTcpjson) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumTcpjson) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumTcpjson) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

// InputAuthenticationMethodTcpjson - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type InputAuthenticationMethodTcpjson string

const (
	InputAuthenticationMethodTcpjsonManual InputAuthenticationMethodTcpjson = "manual"
	InputAuthenticationMethodTcpjsonSecret InputAuthenticationMethodTcpjson = "secret"
)

func (e InputAuthenticationMethodTcpjson) ToPointer() *InputAuthenticationMethodTcpjson {
	return &e
}

type InputTcpjson struct {
	// Unique ID for this input
	ID       *string          `json:"id,omitempty"`
	Type     InputTypeTcpjson `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionTcpjson `json:"connections,omitempty"`
	Pq          *PqTcpjson          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                       `json:"port"`
	TLS  *TLSSettingsServerSideTcpjson `json:"tls,omitempty"`
	// Regex matching IP addresses that are allowed to establish a connection
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `default:"0" json:"socketMaxLifespan"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Fields to add to events from this input
	Metadata []MetadatumTcpjson `json:"metadata,omitempty"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool `default:"false" json:"enableLoadBalancing"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *InputAuthenticationMethodTcpjson `default:"manual" json:"authType"`
	Description *string                           `json:"description,omitempty"`
	// Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
	AuthToken *string `default:"" json:"authToken"`
	// Select or create a stored text secret
	TextSecret           *string        `json:"textSecret,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputTcpjson) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTcpjson) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port"}); err != nil {
		return err
	}
	return nil
}

func (i *InputTcpjson) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputTcpjson) GetType() InputTypeTcpjson {
	if i == nil {
		return InputTypeTcpjson("")
	}
	return i.Type
}

func (i *InputTcpjson) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputTcpjson) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputTcpjson) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputTcpjson) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputTcpjson) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputTcpjson) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputTcpjson) GetConnections() []ConnectionTcpjson {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputTcpjson) GetPq() *PqTcpjson {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputTcpjson) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputTcpjson) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputTcpjson) GetTLS() *TLSSettingsServerSideTcpjson {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputTcpjson) GetIPWhitelistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPWhitelistRegex
}

func (i *InputTcpjson) GetMaxActiveCxn() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveCxn
}

func (i *InputTcpjson) GetSocketIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketIdleTimeout
}

func (i *InputTcpjson) GetSocketEndingMaxWait() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketEndingMaxWait
}

func (i *InputTcpjson) GetSocketMaxLifespan() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketMaxLifespan
}

func (i *InputTcpjson) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputTcpjson) GetMetadata() []MetadatumTcpjson {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputTcpjson) GetEnableLoadBalancing() *bool {
	if i == nil {
		return nil
	}
	return i.EnableLoadBalancing
}

func (i *InputTcpjson) GetAuthType() *InputAuthenticationMethodTcpjson {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputTcpjson) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputTcpjson) GetAuthToken() *string {
	if i == nil {
		return nil
	}
	return i.AuthToken
}

func (i *InputTcpjson) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputTcpjson) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeCriblLakeHTTP string

const (
	TypeCriblLakeHTTPCriblLakeHTTP TypeCriblLakeHTTP = "cribl_lake_http"
)

func (e TypeCriblLakeHTTP) ToPointer() *TypeCriblLakeHTTP {
	return &e
}
func (e *TypeCriblLakeHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_lake_http":
		*e = TypeCriblLakeHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCriblLakeHTTP: %v", v)
	}
}

type ConnectionCriblLakeHTTP struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionCriblLakeHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionCriblLakeHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionCriblLakeHTTP) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionCriblLakeHTTP) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeCriblLakeHTTP - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeCriblLakeHTTP string

const (
	// ModeCriblLakeHTTPSmart Smart
	ModeCriblLakeHTTPSmart ModeCriblLakeHTTP = "smart"
	// ModeCriblLakeHTTPAlways Always On
	ModeCriblLakeHTTPAlways ModeCriblLakeHTTP = "always"
)

func (e ModeCriblLakeHTTP) ToPointer() *ModeCriblLakeHTTP {
	return &e
}

// CompressionCriblLakeHTTP - Codec to use to compress the persisted data
type CompressionCriblLakeHTTP string

const (
	// CompressionCriblLakeHTTPNone None
	CompressionCriblLakeHTTPNone CompressionCriblLakeHTTP = "none"
	// CompressionCriblLakeHTTPGzip Gzip
	CompressionCriblLakeHTTPGzip CompressionCriblLakeHTTP = "gzip"
)

func (e CompressionCriblLakeHTTP) ToPointer() *CompressionCriblLakeHTTP {
	return &e
}

type PqControlsCriblLakeHTTP struct {
}

func (p PqControlsCriblLakeHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsCriblLakeHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqCriblLakeHTTP struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeCriblLakeHTTP `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionCriblLakeHTTP `default:"none" json:"compress"`
	PqControls *PqControlsCriblLakeHTTP  `json:"pqControls,omitempty"`
}

func (p PqCriblLakeHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqCriblLakeHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqCriblLakeHTTP) GetMode() *ModeCriblLakeHTTP {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqCriblLakeHTTP) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqCriblLakeHTTP) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqCriblLakeHTTP) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqCriblLakeHTTP) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqCriblLakeHTTP) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqCriblLakeHTTP) GetCompress() *CompressionCriblLakeHTTP {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqCriblLakeHTTP) GetPqControls() *PqControlsCriblLakeHTTP {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MinimumTLSVersionCriblLakeHTTP string

const (
	MinimumTLSVersionCriblLakeHTTPTlSv1  MinimumTLSVersionCriblLakeHTTP = "TLSv1"
	MinimumTLSVersionCriblLakeHTTPTlSv11 MinimumTLSVersionCriblLakeHTTP = "TLSv1.1"
	MinimumTLSVersionCriblLakeHTTPTlSv12 MinimumTLSVersionCriblLakeHTTP = "TLSv1.2"
	MinimumTLSVersionCriblLakeHTTPTlSv13 MinimumTLSVersionCriblLakeHTTP = "TLSv1.3"
)

func (e MinimumTLSVersionCriblLakeHTTP) ToPointer() *MinimumTLSVersionCriblLakeHTTP {
	return &e
}

type MaximumTLSVersionCriblLakeHTTP string

const (
	MaximumTLSVersionCriblLakeHTTPTlSv1  MaximumTLSVersionCriblLakeHTTP = "TLSv1"
	MaximumTLSVersionCriblLakeHTTPTlSv11 MaximumTLSVersionCriblLakeHTTP = "TLSv1.1"
	MaximumTLSVersionCriblLakeHTTPTlSv12 MaximumTLSVersionCriblLakeHTTP = "TLSv1.2"
	MaximumTLSVersionCriblLakeHTTPTlSv13 MaximumTLSVersionCriblLakeHTTP = "TLSv1.3"
)

func (e MaximumTLSVersionCriblLakeHTTP) ToPointer() *MaximumTLSVersionCriblLakeHTTP {
	return &e
}

type TLSSettingsServerSideCriblLakeHTTP struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                         `json:"caPath,omitempty"`
	MinVersion *MinimumTLSVersionCriblLakeHTTP `json:"minVersion,omitempty"`
	MaxVersion *MaximumTLSVersionCriblLakeHTTP `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideCriblLakeHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideCriblLakeHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideCriblLakeHTTP) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideCriblLakeHTTP) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideCriblLakeHTTP) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideCriblLakeHTTP) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideCriblLakeHTTP) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideCriblLakeHTTP) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideCriblLakeHTTP) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideCriblLakeHTTP) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideCriblLakeHTTP) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideCriblLakeHTTP) GetMinVersion() *MinimumTLSVersionCriblLakeHTTP {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideCriblLakeHTTP) GetMaxVersion() *MaximumTLSVersionCriblLakeHTTP {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

type MetadatumCriblLakeHTTP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumCriblLakeHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumCriblLakeHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumCriblLakeHTTP) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumCriblLakeHTTP) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type AuthTokensExtMetadatumCriblLakeHTTP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (a AuthTokensExtMetadatumCriblLakeHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokensExtMetadatumCriblLakeHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokensExtMetadatumCriblLakeHTTP) GetName() string {
	if a == nil {
		return ""
	}
	return a.Name
}

func (a *AuthTokensExtMetadatumCriblLakeHTTP) GetValue() string {
	if a == nil {
		return ""
	}
	return a.Value
}

type SplunkHecMetadata struct {
	Enabled *bool `json:"enabled,omitempty"`
}

func (s SplunkHecMetadata) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SplunkHecMetadata) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (s *SplunkHecMetadata) GetEnabled() *bool {
	if s == nil {
		return nil
	}
	return s.Enabled
}

type ElasticsearchMetadata struct {
	Enabled *bool `json:"enabled,omitempty"`
}

func (e ElasticsearchMetadata) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(e, "", false)
}

func (e *ElasticsearchMetadata) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &e, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (e *ElasticsearchMetadata) GetEnabled() *bool {
	if e == nil {
		return nil
	}
	return e.Enabled
}

type AuthTokensExtCriblLakeHTTP struct {
	Token       string  `json:"token"`
	Description *string `json:"description,omitempty"`
	// Fields to add to events referencing this token
	Metadata              []AuthTokensExtMetadatumCriblLakeHTTP `json:"metadata,omitempty"`
	SplunkHecMetadata     *SplunkHecMetadata                    `json:"splunkHecMetadata,omitempty"`
	ElasticsearchMetadata *ElasticsearchMetadata                `json:"elasticsearchMetadata,omitempty"`
}

func (a AuthTokensExtCriblLakeHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokensExtCriblLakeHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, []string{"token"}); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokensExtCriblLakeHTTP) GetToken() string {
	if a == nil {
		return ""
	}
	return a.Token
}

func (a *AuthTokensExtCriblLakeHTTP) GetDescription() *string {
	if a == nil {
		return nil
	}
	return a.Description
}

func (a *AuthTokensExtCriblLakeHTTP) GetMetadata() []AuthTokensExtMetadatumCriblLakeHTTP {
	if a == nil {
		return nil
	}
	return a.Metadata
}

func (a *AuthTokensExtCriblLakeHTTP) GetSplunkHecMetadata() *SplunkHecMetadata {
	if a == nil {
		return nil
	}
	return a.SplunkHecMetadata
}

func (a *AuthTokensExtCriblLakeHTTP) GetElasticsearchMetadata() *ElasticsearchMetadata {
	if a == nil {
		return nil
	}
	return a.ElasticsearchMetadata
}

type InputCriblLakeHTTP struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     TypeCriblLakeHTTP `json:"type"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionCriblLakeHTTP `json:"connections,omitempty"`
	Pq          *PqCriblLakeHTTP          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                            `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideCriblLakeHTTP `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for the Cribl HTTP API requests. Only _bulk (default /cribl/_bulk) is available. Use empty string to disable.
	CriblAPI *string `default:"/cribl" json:"criblAPI"`
	// Absolute path on which to listen for the Elasticsearch API requests. Only _bulk (default /elastic/_bulk) is available. Use empty string to disable.
	ElasticAPI *string `default:"/elastic" json:"elasticAPI"`
	// Absolute path on which listen for the Splunk HTTP Event Collector API requests. Use empty string to disable.
	SplunkHecAPI  *string `default:"/services/collector" json:"splunkHecAPI"`
	SplunkHecAcks *bool   `default:"false" json:"splunkHecAcks"`
	// Fields to add to events from this input
	Metadata             []MetadatumCriblLakeHTTP     `json:"metadata,omitempty"`
	AuthTokensExt        []AuthTokensExtCriblLakeHTTP `json:"authTokensExt,omitempty"`
	Description          *string                      `json:"description,omitempty"`
	AdditionalProperties map[string]any               `additionalProperties:"true" json:"-"`
}

func (i InputCriblLakeHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblLakeHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port"}); err != nil {
		return err
	}
	return nil
}

func (i *InputCriblLakeHTTP) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputCriblLakeHTTP) GetType() TypeCriblLakeHTTP {
	if i == nil {
		return TypeCriblLakeHTTP("")
	}
	return i.Type
}

func (i *InputCriblLakeHTTP) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputCriblLakeHTTP) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputCriblLakeHTTP) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputCriblLakeHTTP) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputCriblLakeHTTP) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputCriblLakeHTTP) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputCriblLakeHTTP) GetConnections() []ConnectionCriblLakeHTTP {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputCriblLakeHTTP) GetPq() *PqCriblLakeHTTP {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputCriblLakeHTTP) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputCriblLakeHTTP) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputCriblLakeHTTP) GetAuthTokens() []string {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputCriblLakeHTTP) GetTLS() *TLSSettingsServerSideCriblLakeHTTP {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputCriblLakeHTTP) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputCriblLakeHTTP) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputCriblLakeHTTP) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputCriblLakeHTTP) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputCriblLakeHTTP) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputCriblLakeHTTP) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputCriblLakeHTTP) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputCriblLakeHTTP) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputCriblLakeHTTP) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputCriblLakeHTTP) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputCriblLakeHTTP) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputCriblLakeHTTP) GetCriblAPI() *string {
	if i == nil {
		return nil
	}
	return i.CriblAPI
}

func (i *InputCriblLakeHTTP) GetElasticAPI() *string {
	if i == nil {
		return nil
	}
	return i.ElasticAPI
}

func (i *InputCriblLakeHTTP) GetSplunkHecAPI() *string {
	if i == nil {
		return nil
	}
	return i.SplunkHecAPI
}

func (i *InputCriblLakeHTTP) GetSplunkHecAcks() *bool {
	if i == nil {
		return nil
	}
	return i.SplunkHecAcks
}

func (i *InputCriblLakeHTTP) GetMetadata() []MetadatumCriblLakeHTTP {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputCriblLakeHTTP) GetAuthTokensExt() []AuthTokensExtCriblLakeHTTP {
	if i == nil {
		return nil
	}
	return i.AuthTokensExt
}

func (i *InputCriblLakeHTTP) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputCriblLakeHTTP) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputTypeCriblHTTP string

const (
	InputTypeCriblHTTPCriblHTTP InputTypeCriblHTTP = "cribl_http"
)

func (e InputTypeCriblHTTP) ToPointer() *InputTypeCriblHTTP {
	return &e
}
func (e *InputTypeCriblHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_http":
		*e = InputTypeCriblHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeCriblHTTP: %v", v)
	}
}

type ConnectionCriblHTTP struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionCriblHTTP) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionCriblHTTP) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// PqModeCriblHTTP - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeCriblHTTP string

const (
	// PqModeCriblHTTPSmart Smart
	PqModeCriblHTTPSmart PqModeCriblHTTP = "smart"
	// PqModeCriblHTTPAlways Always On
	PqModeCriblHTTPAlways PqModeCriblHTTP = "always"
)

func (e PqModeCriblHTTP) ToPointer() *PqModeCriblHTTP {
	return &e
}

// PqCompressionCriblHTTP - Codec to use to compress the persisted data
type PqCompressionCriblHTTP string

const (
	// PqCompressionCriblHTTPNone None
	PqCompressionCriblHTTPNone PqCompressionCriblHTTP = "none"
	// PqCompressionCriblHTTPGzip Gzip
	PqCompressionCriblHTTPGzip PqCompressionCriblHTTP = "gzip"
)

func (e PqCompressionCriblHTTP) ToPointer() *PqCompressionCriblHTTP {
	return &e
}

type InputPqControlsCriblHTTP struct {
}

func (i InputPqControlsCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPqControlsCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqCriblHTTP struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeCriblHTTP `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *PqCompressionCriblHTTP   `default:"none" json:"compress"`
	PqControls *InputPqControlsCriblHTTP `json:"pqControls,omitempty"`
}

func (p PqCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqCriblHTTP) GetMode() *PqModeCriblHTTP {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqCriblHTTP) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqCriblHTTP) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqCriblHTTP) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqCriblHTTP) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqCriblHTTP) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqCriblHTTP) GetCompress() *PqCompressionCriblHTTP {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqCriblHTTP) GetPqControls() *InputPqControlsCriblHTTP {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type InputAuthTokenCriblHTTP struct {
	// Select or create a stored text secret
	TokenSecret string `json:"tokenSecret"`
	Enabled     *bool  `default:"true" json:"enabled"`
	// Optional token description
	Description *string `json:"description,omitempty"`
}

func (i InputAuthTokenCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAuthTokenCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"tokenSecret"}); err != nil {
		return err
	}
	return nil
}

func (i *InputAuthTokenCriblHTTP) GetTokenSecret() string {
	if i == nil {
		return ""
	}
	return i.TokenSecret
}

func (i *InputAuthTokenCriblHTTP) GetEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.Enabled
}

func (i *InputAuthTokenCriblHTTP) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type InputMinimumTLSVersionCriblHTTP string

const (
	InputMinimumTLSVersionCriblHTTPTlSv1  InputMinimumTLSVersionCriblHTTP = "TLSv1"
	InputMinimumTLSVersionCriblHTTPTlSv11 InputMinimumTLSVersionCriblHTTP = "TLSv1.1"
	InputMinimumTLSVersionCriblHTTPTlSv12 InputMinimumTLSVersionCriblHTTP = "TLSv1.2"
	InputMinimumTLSVersionCriblHTTPTlSv13 InputMinimumTLSVersionCriblHTTP = "TLSv1.3"
)

func (e InputMinimumTLSVersionCriblHTTP) ToPointer() *InputMinimumTLSVersionCriblHTTP {
	return &e
}

type InputMaximumTLSVersionCriblHTTP string

const (
	InputMaximumTLSVersionCriblHTTPTlSv1  InputMaximumTLSVersionCriblHTTP = "TLSv1"
	InputMaximumTLSVersionCriblHTTPTlSv11 InputMaximumTLSVersionCriblHTTP = "TLSv1.1"
	InputMaximumTLSVersionCriblHTTPTlSv12 InputMaximumTLSVersionCriblHTTP = "TLSv1.2"
	InputMaximumTLSVersionCriblHTTPTlSv13 InputMaximumTLSVersionCriblHTTP = "TLSv1.3"
)

func (e InputMaximumTLSVersionCriblHTTP) ToPointer() *InputMaximumTLSVersionCriblHTTP {
	return &e
}

type TLSSettingsServerSideCriblHTTP struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                          `json:"caPath,omitempty"`
	MinVersion *InputMinimumTLSVersionCriblHTTP `json:"minVersion,omitempty"`
	MaxVersion *InputMaximumTLSVersionCriblHTTP `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideCriblHTTP) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideCriblHTTP) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideCriblHTTP) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideCriblHTTP) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideCriblHTTP) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideCriblHTTP) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideCriblHTTP) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideCriblHTTP) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideCriblHTTP) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideCriblHTTP) GetMinVersion() *InputMinimumTLSVersionCriblHTTP {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideCriblHTTP) GetMaxVersion() *InputMaximumTLSVersionCriblHTTP {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

type MetadatumCriblHTTP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumCriblHTTP) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumCriblHTTP) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputCriblHTTP struct {
	// Unique ID for this input
	ID       *string            `json:"id,omitempty"`
	Type     InputTypeCriblHTTP `json:"type"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionCriblHTTP `json:"connections,omitempty"`
	Pq          *PqCriblHTTP          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be used by connected environments to authorize connections. These tokens should be installed in Cribl HTTP destinations in connected environments.
	AuthTokens []InputAuthTokenCriblHTTP       `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideCriblHTTP `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Fields to add to events from this input
	Metadata             []MetadatumCriblHTTP `json:"metadata,omitempty"`
	Description          *string              `json:"description,omitempty"`
	AdditionalProperties map[string]any       `additionalProperties:"true" json:"-"`
}

func (i InputCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port"}); err != nil {
		return err
	}
	return nil
}

func (i *InputCriblHTTP) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputCriblHTTP) GetType() InputTypeCriblHTTP {
	if i == nil {
		return InputTypeCriblHTTP("")
	}
	return i.Type
}

func (i *InputCriblHTTP) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputCriblHTTP) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputCriblHTTP) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputCriblHTTP) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputCriblHTTP) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputCriblHTTP) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputCriblHTTP) GetConnections() []ConnectionCriblHTTP {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputCriblHTTP) GetPq() *PqCriblHTTP {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputCriblHTTP) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputCriblHTTP) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputCriblHTTP) GetAuthTokens() []InputAuthTokenCriblHTTP {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputCriblHTTP) GetTLS() *TLSSettingsServerSideCriblHTTP {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputCriblHTTP) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputCriblHTTP) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputCriblHTTP) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputCriblHTTP) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputCriblHTTP) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputCriblHTTP) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputCriblHTTP) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputCriblHTTP) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputCriblHTTP) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputCriblHTTP) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputCriblHTTP) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputCriblHTTP) GetMetadata() []MetadatumCriblHTTP {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputCriblHTTP) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputCriblHTTP) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputTypeCriblTCP string

const (
	InputTypeCriblTCPCriblTCP InputTypeCriblTCP = "cribl_tcp"
)

func (e InputTypeCriblTCP) ToPointer() *InputTypeCriblTCP {
	return &e
}
func (e *InputTypeCriblTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_tcp":
		*e = InputTypeCriblTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeCriblTCP: %v", v)
	}
}

type ConnectionCriblTCP struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionCriblTCP) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionCriblTCP) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// PqModeCriblTCP - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeCriblTCP string

const (
	// PqModeCriblTCPSmart Smart
	PqModeCriblTCPSmart PqModeCriblTCP = "smart"
	// PqModeCriblTCPAlways Always On
	PqModeCriblTCPAlways PqModeCriblTCP = "always"
)

func (e PqModeCriblTCP) ToPointer() *PqModeCriblTCP {
	return &e
}

// PqCompressionCriblTCP - Codec to use to compress the persisted data
type PqCompressionCriblTCP string

const (
	// PqCompressionCriblTCPNone None
	PqCompressionCriblTCPNone PqCompressionCriblTCP = "none"
	// PqCompressionCriblTCPGzip Gzip
	PqCompressionCriblTCPGzip PqCompressionCriblTCP = "gzip"
)

func (e PqCompressionCriblTCP) ToPointer() *PqCompressionCriblTCP {
	return &e
}

type InputPqControlsCriblTCP struct {
}

func (i InputPqControlsCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPqControlsCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqCriblTCP struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeCriblTCP `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *PqCompressionCriblTCP   `default:"none" json:"compress"`
	PqControls *InputPqControlsCriblTCP `json:"pqControls,omitempty"`
}

func (p PqCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqCriblTCP) GetMode() *PqModeCriblTCP {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqCriblTCP) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqCriblTCP) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqCriblTCP) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqCriblTCP) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqCriblTCP) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqCriblTCP) GetCompress() *PqCompressionCriblTCP {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqCriblTCP) GetPqControls() *InputPqControlsCriblTCP {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type InputMinimumTLSVersionCriblTCP string

const (
	InputMinimumTLSVersionCriblTCPTlSv1  InputMinimumTLSVersionCriblTCP = "TLSv1"
	InputMinimumTLSVersionCriblTCPTlSv11 InputMinimumTLSVersionCriblTCP = "TLSv1.1"
	InputMinimumTLSVersionCriblTCPTlSv12 InputMinimumTLSVersionCriblTCP = "TLSv1.2"
	InputMinimumTLSVersionCriblTCPTlSv13 InputMinimumTLSVersionCriblTCP = "TLSv1.3"
)

func (e InputMinimumTLSVersionCriblTCP) ToPointer() *InputMinimumTLSVersionCriblTCP {
	return &e
}

type InputMaximumTLSVersionCriblTCP string

const (
	InputMaximumTLSVersionCriblTCPTlSv1  InputMaximumTLSVersionCriblTCP = "TLSv1"
	InputMaximumTLSVersionCriblTCPTlSv11 InputMaximumTLSVersionCriblTCP = "TLSv1.1"
	InputMaximumTLSVersionCriblTCPTlSv12 InputMaximumTLSVersionCriblTCP = "TLSv1.2"
	InputMaximumTLSVersionCriblTCPTlSv13 InputMaximumTLSVersionCriblTCP = "TLSv1.3"
)

func (e InputMaximumTLSVersionCriblTCP) ToPointer() *InputMaximumTLSVersionCriblTCP {
	return &e
}

type TLSSettingsServerSideCriblTCP struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                         `json:"caPath,omitempty"`
	MinVersion *InputMinimumTLSVersionCriblTCP `json:"minVersion,omitempty"`
	MaxVersion *InputMaximumTLSVersionCriblTCP `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideCriblTCP) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideCriblTCP) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideCriblTCP) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideCriblTCP) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideCriblTCP) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideCriblTCP) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideCriblTCP) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideCriblTCP) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideCriblTCP) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideCriblTCP) GetMinVersion() *InputMinimumTLSVersionCriblTCP {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideCriblTCP) GetMaxVersion() *InputMaximumTLSVersionCriblTCP {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

type MetadatumCriblTCP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumCriblTCP) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumCriblTCP) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputAuthTokenCriblTCP struct {
	// Select or create a stored text secret
	TokenSecret string `json:"tokenSecret"`
	Enabled     *bool  `default:"true" json:"enabled"`
	// Optional token description
	Description *string `json:"description,omitempty"`
}

func (i InputAuthTokenCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAuthTokenCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"tokenSecret"}); err != nil {
		return err
	}
	return nil
}

func (i *InputAuthTokenCriblTCP) GetTokenSecret() string {
	if i == nil {
		return ""
	}
	return i.TokenSecret
}

func (i *InputAuthTokenCriblTCP) GetEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.Enabled
}

func (i *InputAuthTokenCriblTCP) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type InputCriblTCP struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     InputTypeCriblTCP `json:"type"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionCriblTCP `json:"connections,omitempty"`
	Pq          *PqCriblTCP          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                        `json:"port"`
	TLS  *TLSSettingsServerSideCriblTCP `json:"tls,omitempty"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `default:"0" json:"socketMaxLifespan"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Fields to add to events from this input
	Metadata []MetadatumCriblTCP `json:"metadata,omitempty"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool `default:"false" json:"enableLoadBalancing"`
	// Shared secrets to be used by connected environments to authorize connections. These tokens should be installed in Cribl TCP destinations in connected environments.
	AuthTokens           []InputAuthTokenCriblTCP `json:"authTokens,omitempty"`
	Description          *string                  `json:"description,omitempty"`
	AdditionalProperties map[string]any           `additionalProperties:"true" json:"-"`
}

func (i InputCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port"}); err != nil {
		return err
	}
	return nil
}

func (i *InputCriblTCP) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputCriblTCP) GetType() InputTypeCriblTCP {
	if i == nil {
		return InputTypeCriblTCP("")
	}
	return i.Type
}

func (i *InputCriblTCP) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputCriblTCP) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputCriblTCP) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputCriblTCP) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputCriblTCP) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputCriblTCP) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputCriblTCP) GetConnections() []ConnectionCriblTCP {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputCriblTCP) GetPq() *PqCriblTCP {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputCriblTCP) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputCriblTCP) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputCriblTCP) GetTLS() *TLSSettingsServerSideCriblTCP {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputCriblTCP) GetMaxActiveCxn() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveCxn
}

func (i *InputCriblTCP) GetSocketIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketIdleTimeout
}

func (i *InputCriblTCP) GetSocketEndingMaxWait() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketEndingMaxWait
}

func (i *InputCriblTCP) GetSocketMaxLifespan() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketMaxLifespan
}

func (i *InputCriblTCP) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputCriblTCP) GetMetadata() []MetadatumCriblTCP {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputCriblTCP) GetEnableLoadBalancing() *bool {
	if i == nil {
		return nil
	}
	return i.EnableLoadBalancing
}

func (i *InputCriblTCP) GetAuthTokens() []InputAuthTokenCriblTCP {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputCriblTCP) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputCriblTCP) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeCribl string

const (
	TypeCriblCribl TypeCribl = "cribl"
)

func (e TypeCribl) ToPointer() *TypeCribl {
	return &e
}
func (e *TypeCribl) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl":
		*e = TypeCribl(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCribl: %v", v)
	}
}

type ConnectionCribl struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionCribl) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionCribl) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionCribl) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionCribl) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeCribl - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeCribl string

const (
	// ModeCriblSmart Smart
	ModeCriblSmart ModeCribl = "smart"
	// ModeCriblAlways Always On
	ModeCriblAlways ModeCribl = "always"
)

func (e ModeCribl) ToPointer() *ModeCribl {
	return &e
}

// CompressionCribl - Codec to use to compress the persisted data
type CompressionCribl string

const (
	// CompressionCriblNone None
	CompressionCriblNone CompressionCribl = "none"
	// CompressionCriblGzip Gzip
	CompressionCriblGzip CompressionCribl = "gzip"
)

func (e CompressionCribl) ToPointer() *CompressionCribl {
	return &e
}

type PqControlsCribl struct {
}

func (p PqControlsCribl) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsCribl) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqCribl struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeCribl `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionCribl `default:"none" json:"compress"`
	PqControls *PqControlsCribl  `json:"pqControls,omitempty"`
}

func (p PqCribl) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqCribl) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqCribl) GetMode() *ModeCribl {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqCribl) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqCribl) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqCribl) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqCribl) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqCribl) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqCribl) GetCompress() *CompressionCribl {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqCribl) GetPqControls() *PqControlsCribl {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MetadatumCribl struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumCribl) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumCribl) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumCribl) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumCribl) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputCribl struct {
	// Unique ID for this input
	ID       *string   `json:"id,omitempty"`
	Type     TypeCribl `json:"type"`
	Disabled *bool     `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionCribl `json:"connections,omitempty"`
	Pq          *PqCribl          `json:"pq,omitempty"`
	Filter      *string           `json:"filter,omitempty"`
	// Fields to add to events from this input
	Metadata             []MetadatumCribl `json:"metadata,omitempty"`
	Description          *string          `json:"description,omitempty"`
	AdditionalProperties map[string]any   `additionalProperties:"true" json:"-"`
}

func (i InputCribl) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCribl) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputCribl) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputCribl) GetType() TypeCribl {
	if i == nil {
		return TypeCribl("")
	}
	return i.Type
}

func (i *InputCribl) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputCribl) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputCribl) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputCribl) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputCribl) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputCribl) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputCribl) GetConnections() []ConnectionCribl {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputCribl) GetPq() *PqCribl {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputCribl) GetFilter() *string {
	if i == nil {
		return nil
	}
	return i.Filter
}

func (i *InputCribl) GetMetadata() []MetadatumCribl {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputCribl) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputCribl) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputTypeGooglePubsub string

const (
	InputTypeGooglePubsubGooglePubsub InputTypeGooglePubsub = "google_pubsub"
)

func (e InputTypeGooglePubsub) ToPointer() *InputTypeGooglePubsub {
	return &e
}
func (e *InputTypeGooglePubsub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "google_pubsub":
		*e = InputTypeGooglePubsub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeGooglePubsub: %v", v)
	}
}

type ConnectionGooglePubsub struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionGooglePubsub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionGooglePubsub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionGooglePubsub) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionGooglePubsub) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// PqModeGooglePubsub - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeGooglePubsub string

const (
	// PqModeGooglePubsubSmart Smart
	PqModeGooglePubsubSmart PqModeGooglePubsub = "smart"
	// PqModeGooglePubsubAlways Always On
	PqModeGooglePubsubAlways PqModeGooglePubsub = "always"
)

func (e PqModeGooglePubsub) ToPointer() *PqModeGooglePubsub {
	return &e
}

// PqCompressionGooglePubsub - Codec to use to compress the persisted data
type PqCompressionGooglePubsub string

const (
	// PqCompressionGooglePubsubNone None
	PqCompressionGooglePubsubNone PqCompressionGooglePubsub = "none"
	// PqCompressionGooglePubsubGzip Gzip
	PqCompressionGooglePubsubGzip PqCompressionGooglePubsub = "gzip"
)

func (e PqCompressionGooglePubsub) ToPointer() *PqCompressionGooglePubsub {
	return &e
}

type InputPqControlsGooglePubsub struct {
}

func (i InputPqControlsGooglePubsub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPqControlsGooglePubsub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqGooglePubsub struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeGooglePubsub `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *PqCompressionGooglePubsub   `default:"none" json:"compress"`
	PqControls *InputPqControlsGooglePubsub `json:"pqControls,omitempty"`
}

func (p PqGooglePubsub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqGooglePubsub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqGooglePubsub) GetMode() *PqModeGooglePubsub {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqGooglePubsub) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqGooglePubsub) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqGooglePubsub) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqGooglePubsub) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqGooglePubsub) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqGooglePubsub) GetCompress() *PqCompressionGooglePubsub {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqGooglePubsub) GetPqControls() *InputPqControlsGooglePubsub {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// InputGoogleAuthenticationMethod - Choose Auto to use Google Application Default Credentials (ADC), Manual to enter Google service account credentials directly, or Secret to select or create a stored secret that references Google service account credentials.
type InputGoogleAuthenticationMethod string

const (
	// InputGoogleAuthenticationMethodAuto Auto
	InputGoogleAuthenticationMethodAuto InputGoogleAuthenticationMethod = "auto"
	// InputGoogleAuthenticationMethodManual Manual
	InputGoogleAuthenticationMethodManual InputGoogleAuthenticationMethod = "manual"
	// InputGoogleAuthenticationMethodSecret Secret
	InputGoogleAuthenticationMethodSecret InputGoogleAuthenticationMethod = "secret"
)

func (e InputGoogleAuthenticationMethod) ToPointer() *InputGoogleAuthenticationMethod {
	return &e
}

type MetadatumGooglePubsub struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumGooglePubsub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumGooglePubsub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumGooglePubsub) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumGooglePubsub) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputGooglePubsub struct {
	// Unique ID for this input
	ID       *string               `json:"id,omitempty"`
	Type     InputTypeGooglePubsub `json:"type"`
	Disabled *bool                 `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionGooglePubsub `json:"connections,omitempty"`
	Pq          *PqGooglePubsub          `json:"pq,omitempty"`
	// ID of the topic to receive events from. When Monitor subscription is enabled, any value may be entered.
	TopicName *string `default:"cribl" json:"topicName"`
	// ID of the subscription to use when receiving events. When Monitor subscription is enabled, the fully qualified subscription name must be entered. Example: projects/myProject/subscriptions/mySubscription
	SubscriptionName string `json:"subscriptionName"`
	// Use when the subscription is not created by this Source and topic is not known
	MonitorSubscription *bool `default:"false" json:"monitorSubscription"`
	// Create topic if it does not exist
	CreateTopic *bool `default:"false" json:"createTopic"`
	// Create subscription if it does not exist
	CreateSubscription *bool `default:"true" json:"createSubscription"`
	// Region to retrieve messages from. Select 'default' to allow Google to auto-select the nearest region. When using ordered delivery, the selected region must be allowed by message storage policy.
	Region *string `json:"region,omitempty"`
	// Choose Auto to use Google Application Default Credentials (ADC), Manual to enter Google service account credentials directly, or Secret to select or create a stored secret that references Google service account credentials.
	GoogleAuthMethod *InputGoogleAuthenticationMethod `default:"manual" json:"googleAuthMethod"`
	// Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
	ServiceAccountCredentials *string `json:"serviceAccountCredentials,omitempty"`
	// Select or create a stored text secret
	Secret *string `json:"secret,omitempty"`
	// If Destination exerts backpressure, this setting limits how many inbound events Stream will queue for processing before it stops retrieving events
	MaxBacklog *float64 `default:"1000" json:"maxBacklog"`
	// How many streams to pull messages from at one time. Doubling the value doubles the number of messages this Source pulls from the topic (if available), while consuming more CPU and memory. Defaults to 5.
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Pull request timeout, in milliseconds
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// Fields to add to events from this input
	Metadata    []MetadatumGooglePubsub `json:"metadata,omitempty"`
	Description *string                 `json:"description,omitempty"`
	// Receive events in the order they were added to the queue. The process sending events must have ordering enabled.
	OrderedDelivery      *bool          `default:"false" json:"orderedDelivery"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputGooglePubsub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGooglePubsub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "subscriptionName"}); err != nil {
		return err
	}
	return nil
}

func (i *InputGooglePubsub) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputGooglePubsub) GetType() InputTypeGooglePubsub {
	if i == nil {
		return InputTypeGooglePubsub("")
	}
	return i.Type
}

func (i *InputGooglePubsub) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputGooglePubsub) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputGooglePubsub) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputGooglePubsub) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputGooglePubsub) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputGooglePubsub) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputGooglePubsub) GetConnections() []ConnectionGooglePubsub {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputGooglePubsub) GetPq() *PqGooglePubsub {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputGooglePubsub) GetTopicName() *string {
	if i == nil {
		return nil
	}
	return i.TopicName
}

func (i *InputGooglePubsub) GetSubscriptionName() string {
	if i == nil {
		return ""
	}
	return i.SubscriptionName
}

func (i *InputGooglePubsub) GetMonitorSubscription() *bool {
	if i == nil {
		return nil
	}
	return i.MonitorSubscription
}

func (i *InputGooglePubsub) GetCreateTopic() *bool {
	if i == nil {
		return nil
	}
	return i.CreateTopic
}

func (i *InputGooglePubsub) GetCreateSubscription() *bool {
	if i == nil {
		return nil
	}
	return i.CreateSubscription
}

func (i *InputGooglePubsub) GetRegion() *string {
	if i == nil {
		return nil
	}
	return i.Region
}

func (i *InputGooglePubsub) GetGoogleAuthMethod() *InputGoogleAuthenticationMethod {
	if i == nil {
		return nil
	}
	return i.GoogleAuthMethod
}

func (i *InputGooglePubsub) GetServiceAccountCredentials() *string {
	if i == nil {
		return nil
	}
	return i.ServiceAccountCredentials
}

func (i *InputGooglePubsub) GetSecret() *string {
	if i == nil {
		return nil
	}
	return i.Secret
}

func (i *InputGooglePubsub) GetMaxBacklog() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBacklog
}

func (i *InputGooglePubsub) GetConcurrency() *float64 {
	if i == nil {
		return nil
	}
	return i.Concurrency
}

func (i *InputGooglePubsub) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputGooglePubsub) GetMetadata() []MetadatumGooglePubsub {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputGooglePubsub) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputGooglePubsub) GetOrderedDelivery() *bool {
	if i == nil {
		return nil
	}
	return i.OrderedDelivery
}

func (i *InputGooglePubsub) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeFirehose string

const (
	TypeFirehoseFirehose TypeFirehose = "firehose"
)

func (e TypeFirehose) ToPointer() *TypeFirehose {
	return &e
}
func (e *TypeFirehose) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "firehose":
		*e = TypeFirehose(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeFirehose: %v", v)
	}
}

type ConnectionFirehose struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionFirehose) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionFirehose) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionFirehose) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionFirehose) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeFirehose - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeFirehose string

const (
	// ModeFirehoseSmart Smart
	ModeFirehoseSmart ModeFirehose = "smart"
	// ModeFirehoseAlways Always On
	ModeFirehoseAlways ModeFirehose = "always"
)

func (e ModeFirehose) ToPointer() *ModeFirehose {
	return &e
}

// CompressionFirehose - Codec to use to compress the persisted data
type CompressionFirehose string

const (
	// CompressionFirehoseNone None
	CompressionFirehoseNone CompressionFirehose = "none"
	// CompressionFirehoseGzip Gzip
	CompressionFirehoseGzip CompressionFirehose = "gzip"
)

func (e CompressionFirehose) ToPointer() *CompressionFirehose {
	return &e
}

type PqControlsFirehose struct {
}

func (p PqControlsFirehose) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsFirehose) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqFirehose struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeFirehose `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionFirehose `default:"none" json:"compress"`
	PqControls *PqControlsFirehose  `json:"pqControls,omitempty"`
}

func (p PqFirehose) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqFirehose) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqFirehose) GetMode() *ModeFirehose {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqFirehose) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqFirehose) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqFirehose) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqFirehose) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqFirehose) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqFirehose) GetCompress() *CompressionFirehose {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqFirehose) GetPqControls() *PqControlsFirehose {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MinimumTLSVersionFirehose string

const (
	MinimumTLSVersionFirehoseTlSv1  MinimumTLSVersionFirehose = "TLSv1"
	MinimumTLSVersionFirehoseTlSv11 MinimumTLSVersionFirehose = "TLSv1.1"
	MinimumTLSVersionFirehoseTlSv12 MinimumTLSVersionFirehose = "TLSv1.2"
	MinimumTLSVersionFirehoseTlSv13 MinimumTLSVersionFirehose = "TLSv1.3"
)

func (e MinimumTLSVersionFirehose) ToPointer() *MinimumTLSVersionFirehose {
	return &e
}

type MaximumTLSVersionFirehose string

const (
	MaximumTLSVersionFirehoseTlSv1  MaximumTLSVersionFirehose = "TLSv1"
	MaximumTLSVersionFirehoseTlSv11 MaximumTLSVersionFirehose = "TLSv1.1"
	MaximumTLSVersionFirehoseTlSv12 MaximumTLSVersionFirehose = "TLSv1.2"
	MaximumTLSVersionFirehoseTlSv13 MaximumTLSVersionFirehose = "TLSv1.3"
)

func (e MaximumTLSVersionFirehose) ToPointer() *MaximumTLSVersionFirehose {
	return &e
}

type TLSSettingsServerSideFirehose struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                    `json:"caPath,omitempty"`
	MinVersion *MinimumTLSVersionFirehose `json:"minVersion,omitempty"`
	MaxVersion *MaximumTLSVersionFirehose `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideFirehose) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideFirehose) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideFirehose) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideFirehose) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideFirehose) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideFirehose) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideFirehose) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideFirehose) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideFirehose) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideFirehose) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideFirehose) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideFirehose) GetMinVersion() *MinimumTLSVersionFirehose {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideFirehose) GetMaxVersion() *MaximumTLSVersionFirehose {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

type MetadatumFirehose struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumFirehose) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumFirehose) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumFirehose) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumFirehose) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputFirehose struct {
	// Unique ID for this input
	ID       *string      `json:"id,omitempty"`
	Type     TypeFirehose `json:"type"`
	Disabled *bool        `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionFirehose `json:"connections,omitempty"`
	Pq          *PqFirehose          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                       `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideFirehose `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Fields to add to events from this input
	Metadata             []MetadatumFirehose `json:"metadata,omitempty"`
	Description          *string             `json:"description,omitempty"`
	AdditionalProperties map[string]any      `additionalProperties:"true" json:"-"`
}

func (i InputFirehose) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFirehose) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port"}); err != nil {
		return err
	}
	return nil
}

func (i *InputFirehose) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputFirehose) GetType() TypeFirehose {
	if i == nil {
		return TypeFirehose("")
	}
	return i.Type
}

func (i *InputFirehose) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputFirehose) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputFirehose) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputFirehose) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputFirehose) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputFirehose) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputFirehose) GetConnections() []ConnectionFirehose {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputFirehose) GetPq() *PqFirehose {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputFirehose) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputFirehose) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputFirehose) GetAuthTokens() []string {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputFirehose) GetTLS() *TLSSettingsServerSideFirehose {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputFirehose) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputFirehose) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputFirehose) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputFirehose) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputFirehose) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputFirehose) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputFirehose) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputFirehose) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputFirehose) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputFirehose) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputFirehose) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputFirehose) GetMetadata() []MetadatumFirehose {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputFirehose) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputFirehose) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputExecType string

const (
	InputExecTypeExec InputExecType = "exec"
)

func (e InputExecType) ToPointer() *InputExecType {
	return &e
}
func (e *InputExecType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "exec":
		*e = InputExecType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputExecType: %v", v)
	}
}

type InputExecConnection struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (i InputExecConnection) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputExecConnection) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (i *InputExecConnection) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputExecConnection) GetOutput() string {
	if i == nil {
		return ""
	}
	return i.Output
}

// InputExecMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputExecMode string

const (
	// InputExecModeSmart Smart
	InputExecModeSmart InputExecMode = "smart"
	// InputExecModeAlways Always On
	InputExecModeAlways InputExecMode = "always"
)

func (e InputExecMode) ToPointer() *InputExecMode {
	return &e
}

// InputExecCompression - Codec to use to compress the persisted data
type InputExecCompression string

const (
	// InputExecCompressionNone None
	InputExecCompressionNone InputExecCompression = "none"
	// InputExecCompressionGzip Gzip
	InputExecCompressionGzip InputExecCompression = "gzip"
)

func (e InputExecCompression) ToPointer() *InputExecCompression {
	return &e
}

type InputExecPqControls struct {
}

func (i InputExecPqControls) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputExecPqControls) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type InputExecPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputExecMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *InputExecCompression `default:"none" json:"compress"`
	PqControls *InputExecPqControls  `json:"pqControls,omitempty"`
}

func (i InputExecPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputExecPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputExecPq) GetMode() *InputExecMode {
	if i == nil {
		return nil
	}
	return i.Mode
}

func (i *InputExecPq) GetMaxBufferSize() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBufferSize
}

func (i *InputExecPq) GetCommitFrequency() *float64 {
	if i == nil {
		return nil
	}
	return i.CommitFrequency
}

func (i *InputExecPq) GetMaxFileSize() *string {
	if i == nil {
		return nil
	}
	return i.MaxFileSize
}

func (i *InputExecPq) GetMaxSize() *string {
	if i == nil {
		return nil
	}
	return i.MaxSize
}

func (i *InputExecPq) GetPath() *string {
	if i == nil {
		return nil
	}
	return i.Path
}

func (i *InputExecPq) GetCompress() *InputExecCompression {
	if i == nil {
		return nil
	}
	return i.Compress
}

func (i *InputExecPq) GetPqControls() *InputExecPqControls {
	if i == nil {
		return nil
	}
	return i.PqControls
}

// ScheduleType - Select a schedule type; either an interval (in seconds) or a cron-style schedule.
type ScheduleType string

const (
	ScheduleTypeInterval     ScheduleType = "interval"
	ScheduleTypeCronSchedule ScheduleType = "cronSchedule"
)

func (e ScheduleType) ToPointer() *ScheduleType {
	return &e
}

type InputExecMetadatum struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (i InputExecMetadatum) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputExecMetadatum) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (i *InputExecMetadatum) GetName() string {
	if i == nil {
		return ""
	}
	return i.Name
}

func (i *InputExecMetadatum) GetValue() string {
	if i == nil {
		return ""
	}
	return i.Value
}

type InputExec struct {
	// Unique ID for this input
	ID       *string       `json:"id,omitempty"`
	Type     InputExecType `json:"type"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputExecConnection `json:"connections,omitempty"`
	Pq          *InputExecPq          `json:"pq,omitempty"`
	// Command to execute; supports Bourne shell (or CMD on Windows) syntax
	Command string `json:"command"`
	// Maximum number of retry attempts in the event that the command fails
	Retries *float64 `default:"10" json:"retries"`
	// Select a schedule type; either an interval (in seconds) or a cron-style schedule.
	ScheduleType *ScheduleType `default:"interval" json:"scheduleType"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Fields to add to events from this input
	Metadata    []InputExecMetadatum `json:"metadata,omitempty"`
	Description *string              `json:"description,omitempty"`
	// Interval between command executions in seconds.
	Interval *float64 `default:"60" json:"interval"`
	// Cron schedule to execute the command on.
	CronSchedule         *string        `default:"* * * * *" json:"cronSchedule"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputExec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputExec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "command"}); err != nil {
		return err
	}
	return nil
}

func (i *InputExec) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputExec) GetType() InputExecType {
	if i == nil {
		return InputExecType("")
	}
	return i.Type
}

func (i *InputExec) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputExec) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputExec) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputExec) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputExec) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputExec) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputExec) GetConnections() []InputExecConnection {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputExec) GetPq() *InputExecPq {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputExec) GetCommand() string {
	if i == nil {
		return ""
	}
	return i.Command
}

func (i *InputExec) GetRetries() *float64 {
	if i == nil {
		return nil
	}
	return i.Retries
}

func (i *InputExec) GetScheduleType() *ScheduleType {
	if i == nil {
		return nil
	}
	return i.ScheduleType
}

func (i *InputExec) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputExec) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputExec) GetMetadata() []InputExecMetadatum {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputExec) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputExec) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputExec) GetCronSchedule() *string {
	if i == nil {
		return nil
	}
	return i.CronSchedule
}

func (i *InputExec) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeEventhub string

const (
	TypeEventhubEventhub TypeEventhub = "eventhub"
)

func (e TypeEventhub) ToPointer() *TypeEventhub {
	return &e
}
func (e *TypeEventhub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "eventhub":
		*e = TypeEventhub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeEventhub: %v", v)
	}
}

type ConnectionEventhub struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionEventhub) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionEventhub) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeEventhub - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeEventhub string

const (
	// ModeEventhubSmart Smart
	ModeEventhubSmart ModeEventhub = "smart"
	// ModeEventhubAlways Always On
	ModeEventhubAlways ModeEventhub = "always"
)

func (e ModeEventhub) ToPointer() *ModeEventhub {
	return &e
}

// CompressionEventhub - Codec to use to compress the persisted data
type CompressionEventhub string

const (
	// CompressionEventhubNone None
	CompressionEventhubNone CompressionEventhub = "none"
	// CompressionEventhubGzip Gzip
	CompressionEventhubGzip CompressionEventhub = "gzip"
)

func (e CompressionEventhub) ToPointer() *CompressionEventhub {
	return &e
}

type PqControlsEventhub struct {
}

func (p PqControlsEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqEventhub struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeEventhub `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionEventhub `default:"none" json:"compress"`
	PqControls *PqControlsEventhub  `json:"pqControls,omitempty"`
}

func (p PqEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqEventhub) GetMode() *ModeEventhub {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqEventhub) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqEventhub) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqEventhub) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqEventhub) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqEventhub) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqEventhub) GetCompress() *CompressionEventhub {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqEventhub) GetPqControls() *PqControlsEventhub {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// AuthTypeAuthenticationMethodEventhub - Enter password directly, or select a stored secret
type AuthTypeAuthenticationMethodEventhub string

const (
	AuthTypeAuthenticationMethodEventhubManual AuthTypeAuthenticationMethodEventhub = "manual"
	AuthTypeAuthenticationMethodEventhubSecret AuthTypeAuthenticationMethodEventhub = "secret"
)

func (e AuthTypeAuthenticationMethodEventhub) ToPointer() *AuthTypeAuthenticationMethodEventhub {
	return &e
}

type SASLMechanismEventhub string

const (
	// SASLMechanismEventhubPlain PLAIN
	SASLMechanismEventhubPlain SASLMechanismEventhub = "plain"
	// SASLMechanismEventhubOauthbearer OAUTHBEARER
	SASLMechanismEventhubOauthbearer SASLMechanismEventhub = "oauthbearer"
)

func (e SASLMechanismEventhub) ToPointer() *SASLMechanismEventhub {
	return &e
}

type ClientSecretAuthTypeAuthenticationMethodEventhub string

const (
	ClientSecretAuthTypeAuthenticationMethodEventhubManual      ClientSecretAuthTypeAuthenticationMethodEventhub = "manual"
	ClientSecretAuthTypeAuthenticationMethodEventhubSecret      ClientSecretAuthTypeAuthenticationMethodEventhub = "secret"
	ClientSecretAuthTypeAuthenticationMethodEventhubCertificate ClientSecretAuthTypeAuthenticationMethodEventhub = "certificate"
)

func (e ClientSecretAuthTypeAuthenticationMethodEventhub) ToPointer() *ClientSecretAuthTypeAuthenticationMethodEventhub {
	return &e
}

// InputMicrosoftEntraIDAuthenticationEndpoint - Endpoint used to acquire authentication tokens from Azure
type InputMicrosoftEntraIDAuthenticationEndpoint string

const (
	InputMicrosoftEntraIDAuthenticationEndpointHTTPSLoginMicrosoftonlineCom       InputMicrosoftEntraIDAuthenticationEndpoint = "https://login.microsoftonline.com"
	InputMicrosoftEntraIDAuthenticationEndpointHTTPSLoginMicrosoftonlineUs        InputMicrosoftEntraIDAuthenticationEndpoint = "https://login.microsoftonline.us"
	InputMicrosoftEntraIDAuthenticationEndpointHTTPSLoginPartnerMicrosoftonlineCn InputMicrosoftEntraIDAuthenticationEndpoint = "https://login.partner.microsoftonline.cn"
)

func (e InputMicrosoftEntraIDAuthenticationEndpoint) ToPointer() *InputMicrosoftEntraIDAuthenticationEndpoint {
	return &e
}

// AuthenticationEventhub - Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type AuthenticationEventhub struct {
	Disabled *bool `default:"false" json:"disabled"`
	// Enter password directly, or select a stored secret
	AuthType *AuthTypeAuthenticationMethodEventhub `default:"manual" json:"authType"`
	// Connection-string primary key, or connection-string secondary key, from the Event Hubs workspace
	Password *string `json:"password,omitempty"`
	// Select or create a stored text secret
	TextSecret *string                `json:"textSecret,omitempty"`
	Mechanism  *SASLMechanismEventhub `default:"plain" json:"mechanism"`
	// The username for authentication. For Event Hubs, this should always be $ConnectionString.
	Username             *string                                           `default:"$ConnectionString" json:"username"`
	ClientSecretAuthType *ClientSecretAuthTypeAuthenticationMethodEventhub `default:"manual" json:"clientSecretAuthType"`
	// client_secret to pass in the OAuth request parameter
	ClientSecret *string `json:"clientSecret,omitempty"`
	// Select or create a stored text secret
	ClientTextSecret *string `json:"clientTextSecret,omitempty"`
	// Select or create a stored certificate
	CertificateName *string `json:"certificateName,omitempty"`
	CertPath        *string `json:"certPath,omitempty"`
	PrivKeyPath     *string `json:"privKeyPath,omitempty"`
	Passphrase      *string `json:"passphrase,omitempty"`
	// Endpoint used to acquire authentication tokens from Azure
	OauthEndpoint *InputMicrosoftEntraIDAuthenticationEndpoint `default:"https://login.microsoftonline.com" json:"oauthEndpoint"`
	// client_id to pass in the OAuth request parameter
	ClientID *string `json:"clientId,omitempty"`
	// Directory ID (tenant identifier) in Azure Active Directory
	TenantID *string `json:"tenantId,omitempty"`
	// Scope to pass in the OAuth request parameter
	Scope *string `json:"scope,omitempty"`
}

func (a AuthenticationEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthenticationEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AuthenticationEventhub) GetDisabled() *bool {
	if a == nil {
		return nil
	}
	return a.Disabled
}

func (a *AuthenticationEventhub) GetAuthType() *AuthTypeAuthenticationMethodEventhub {
	if a == nil {
		return nil
	}
	return a.AuthType
}

func (a *AuthenticationEventhub) GetPassword() *string {
	if a == nil {
		return nil
	}
	return a.Password
}

func (a *AuthenticationEventhub) GetTextSecret() *string {
	if a == nil {
		return nil
	}
	return a.TextSecret
}

func (a *AuthenticationEventhub) GetMechanism() *SASLMechanismEventhub {
	if a == nil {
		return nil
	}
	return a.Mechanism
}

func (a *AuthenticationEventhub) GetUsername() *string {
	if a == nil {
		return nil
	}
	return a.Username
}

func (a *AuthenticationEventhub) GetClientSecretAuthType() *ClientSecretAuthTypeAuthenticationMethodEventhub {
	if a == nil {
		return nil
	}
	return a.ClientSecretAuthType
}

func (a *AuthenticationEventhub) GetClientSecret() *string {
	if a == nil {
		return nil
	}
	return a.ClientSecret
}

func (a *AuthenticationEventhub) GetClientTextSecret() *string {
	if a == nil {
		return nil
	}
	return a.ClientTextSecret
}

func (a *AuthenticationEventhub) GetCertificateName() *string {
	if a == nil {
		return nil
	}
	return a.CertificateName
}

func (a *AuthenticationEventhub) GetCertPath() *string {
	if a == nil {
		return nil
	}
	return a.CertPath
}

func (a *AuthenticationEventhub) GetPrivKeyPath() *string {
	if a == nil {
		return nil
	}
	return a.PrivKeyPath
}

func (a *AuthenticationEventhub) GetPassphrase() *string {
	if a == nil {
		return nil
	}
	return a.Passphrase
}

func (a *AuthenticationEventhub) GetOauthEndpoint() *InputMicrosoftEntraIDAuthenticationEndpoint {
	if a == nil {
		return nil
	}
	return a.OauthEndpoint
}

func (a *AuthenticationEventhub) GetClientID() *string {
	if a == nil {
		return nil
	}
	return a.ClientID
}

func (a *AuthenticationEventhub) GetTenantID() *string {
	if a == nil {
		return nil
	}
	return a.TenantID
}

func (a *AuthenticationEventhub) GetScope() *string {
	if a == nil {
		return nil
	}
	return a.Scope
}

type TLSSettingsClientSideEventhub struct {
	Disabled *bool `default:"false" json:"disabled"`
	// Reject certificates that are not authorized by a CA in the CA certificate path, or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
}

func (t TLSSettingsClientSideEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsClientSideEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsClientSideEventhub) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsClientSideEventhub) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

type MetadatumEventhub struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumEventhub) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumEventhub) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputEventhub struct {
	// Unique ID for this input
	ID       *string      `json:"id,omitempty"`
	Type     TypeEventhub `json:"type"`
	Disabled *bool        `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionEventhub `json:"connections,omitempty"`
	Pq          *PqEventhub          `json:"pq,omitempty"`
	// List of Event Hubs Kafka brokers to connect to (example: yourdomain.servicebus.windows.net:9093). The hostname can be found in the host portion of the primary or secondary connection string in Shared Access Policies.
	Brokers []string `json:"brokers"`
	// The name of the Event Hub (Kafka topic) to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Event Hubs Source to only a single topic.
	Topics []string `json:"topics"`
	// The consumer group this instance belongs to. Default is 'Cribl'.
	GroupID *string `default:"Cribl" json:"groupId"`
	// Start reading from earliest available data; relevant only during initial subscription
	FromBeginning *bool `default:"true" json:"fromBeginning"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *AuthenticationEventhub        `json:"sasl,omitempty"`
	TLS  *TLSSettingsClientSideEventhub `json:"tls,omitempty"`
	//       Timeout (session.timeout.ms in Kafka domain) used to detect client failures when using Kafka's group-management facilities.
	//       If the client sends no heartbeats to the broker before the timeout expires, the broker will remove the client from the group and initiate a rebalance.
	//       Value must be lower than rebalanceTimeout.
	//       See details [here](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
	SessionTimeout *float64 `default:"30000" json:"sessionTimeout"`
	//       Maximum allowed time (rebalance.timeout.ms in Kafka domain) for each worker to join the group after a rebalance begins.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See [Recommended configurations](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
	RebalanceTimeout *float64 `default:"60000" json:"rebalanceTimeout"`
	//       Expected time (heartbeat.interval.ms in Kafka domain) between heartbeats to the consumer coordinator when using Kafka's group-management facilities.
	//       Value must be lower than sessionTimeout and typically should not exceed 1/3 of the sessionTimeout value.
	//       See [Recommended configurations](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
	HeartbeatInterval *float64 `default:"3000" json:"heartbeatInterval"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitempty"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitempty"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `default:"1048576" json:"maxBytesPerPartition"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `default:"10485760" json:"maxBytes"`
	// Maximum number of network errors before the consumer re-creates a socket
	MaxSocketErrors *float64 `default:"0" json:"maxSocketErrors"`
	// Minimize duplicate events by starting only one consumer for each topic partition
	MinimizeDuplicates *bool `default:"false" json:"minimizeDuplicates"`
	// Fields to add to events from this input
	Metadata             []MetadatumEventhub `json:"metadata,omitempty"`
	Description          *string             `json:"description,omitempty"`
	AdditionalProperties map[string]any      `additionalProperties:"true" json:"-"`
}

func (i InputEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "brokers", "topics"}); err != nil {
		return err
	}
	return nil
}

func (i *InputEventhub) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputEventhub) GetType() TypeEventhub {
	if i == nil {
		return TypeEventhub("")
	}
	return i.Type
}

func (i *InputEventhub) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputEventhub) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputEventhub) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputEventhub) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputEventhub) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputEventhub) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputEventhub) GetConnections() []ConnectionEventhub {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputEventhub) GetPq() *PqEventhub {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputEventhub) GetBrokers() []string {
	if i == nil {
		return []string{}
	}
	return i.Brokers
}

func (i *InputEventhub) GetTopics() []string {
	if i == nil {
		return []string{}
	}
	return i.Topics
}

func (i *InputEventhub) GetGroupID() *string {
	if i == nil {
		return nil
	}
	return i.GroupID
}

func (i *InputEventhub) GetFromBeginning() *bool {
	if i == nil {
		return nil
	}
	return i.FromBeginning
}

func (i *InputEventhub) GetConnectionTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.ConnectionTimeout
}

func (i *InputEventhub) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputEventhub) GetMaxRetries() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxRetries
}

func (i *InputEventhub) GetMaxBackOff() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBackOff
}

func (i *InputEventhub) GetInitialBackoff() *float64 {
	if i == nil {
		return nil
	}
	return i.InitialBackoff
}

func (i *InputEventhub) GetBackoffRate() *float64 {
	if i == nil {
		return nil
	}
	return i.BackoffRate
}

func (i *InputEventhub) GetAuthenticationTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.AuthenticationTimeout
}

func (i *InputEventhub) GetReauthenticationThreshold() *float64 {
	if i == nil {
		return nil
	}
	return i.ReauthenticationThreshold
}

func (i *InputEventhub) GetSasl() *AuthenticationEventhub {
	if i == nil {
		return nil
	}
	return i.Sasl
}

func (i *InputEventhub) GetTLS() *TLSSettingsClientSideEventhub {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputEventhub) GetSessionTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SessionTimeout
}

func (i *InputEventhub) GetRebalanceTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RebalanceTimeout
}

func (i *InputEventhub) GetHeartbeatInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.HeartbeatInterval
}

func (i *InputEventhub) GetAutoCommitInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.AutoCommitInterval
}

func (i *InputEventhub) GetAutoCommitThreshold() *float64 {
	if i == nil {
		return nil
	}
	return i.AutoCommitThreshold
}

func (i *InputEventhub) GetMaxBytesPerPartition() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBytesPerPartition
}

func (i *InputEventhub) GetMaxBytes() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBytes
}

func (i *InputEventhub) GetMaxSocketErrors() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxSocketErrors
}

func (i *InputEventhub) GetMinimizeDuplicates() *bool {
	if i == nil {
		return nil
	}
	return i.MinimizeDuplicates
}

func (i *InputEventhub) GetMetadata() []MetadatumEventhub {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputEventhub) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputEventhub) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeOffice365MsgTrace string

const (
	TypeOffice365MsgTraceOffice365MsgTrace TypeOffice365MsgTrace = "office365_msg_trace"
)

func (e TypeOffice365MsgTrace) ToPointer() *TypeOffice365MsgTrace {
	return &e
}
func (e *TypeOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "office365_msg_trace":
		*e = TypeOffice365MsgTrace(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeOffice365MsgTrace: %v", v)
	}
}

type ConnectionOffice365MsgTrace struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionOffice365MsgTrace) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionOffice365MsgTrace) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionOffice365MsgTrace) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeOffice365MsgTrace - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeOffice365MsgTrace string

const (
	// ModeOffice365MsgTraceSmart Smart
	ModeOffice365MsgTraceSmart ModeOffice365MsgTrace = "smart"
	// ModeOffice365MsgTraceAlways Always On
	ModeOffice365MsgTraceAlways ModeOffice365MsgTrace = "always"
)

func (e ModeOffice365MsgTrace) ToPointer() *ModeOffice365MsgTrace {
	return &e
}

// CompressionOffice365MsgTrace - Codec to use to compress the persisted data
type CompressionOffice365MsgTrace string

const (
	// CompressionOffice365MsgTraceNone None
	CompressionOffice365MsgTraceNone CompressionOffice365MsgTrace = "none"
	// CompressionOffice365MsgTraceGzip Gzip
	CompressionOffice365MsgTraceGzip CompressionOffice365MsgTrace = "gzip"
)

func (e CompressionOffice365MsgTrace) ToPointer() *CompressionOffice365MsgTrace {
	return &e
}

type PqControlsOffice365MsgTrace struct {
}

func (p PqControlsOffice365MsgTrace) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqOffice365MsgTrace struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeOffice365MsgTrace `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionOffice365MsgTrace `default:"none" json:"compress"`
	PqControls *PqControlsOffice365MsgTrace  `json:"pqControls,omitempty"`
}

func (p PqOffice365MsgTrace) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqOffice365MsgTrace) GetMode() *ModeOffice365MsgTrace {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqOffice365MsgTrace) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqOffice365MsgTrace) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqOffice365MsgTrace) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqOffice365MsgTrace) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqOffice365MsgTrace) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqOffice365MsgTrace) GetCompress() *CompressionOffice365MsgTrace {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqOffice365MsgTrace) GetPqControls() *PqControlsOffice365MsgTrace {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// AuthenticationMethodOffice365MsgTrace - Select authentication method.
type AuthenticationMethodOffice365MsgTrace string

const (
	AuthenticationMethodOffice365MsgTraceManual      AuthenticationMethodOffice365MsgTrace = "manual"
	AuthenticationMethodOffice365MsgTraceSecret      AuthenticationMethodOffice365MsgTrace = "secret"
	AuthenticationMethodOffice365MsgTraceOauth       AuthenticationMethodOffice365MsgTrace = "oauth"
	AuthenticationMethodOffice365MsgTraceOauthSecret AuthenticationMethodOffice365MsgTrace = "oauthSecret"
	AuthenticationMethodOffice365MsgTraceOauthCert   AuthenticationMethodOffice365MsgTrace = "oauthCert"
)

func (e AuthenticationMethodOffice365MsgTrace) ToPointer() *AuthenticationMethodOffice365MsgTrace {
	return &e
}

// LogLevelOffice365MsgTrace - Log Level (verbosity) for collection runtime behavior.
type LogLevelOffice365MsgTrace string

const (
	LogLevelOffice365MsgTraceError LogLevelOffice365MsgTrace = "error"
	LogLevelOffice365MsgTraceWarn  LogLevelOffice365MsgTrace = "warn"
	LogLevelOffice365MsgTraceInfo  LogLevelOffice365MsgTrace = "info"
	LogLevelOffice365MsgTraceDebug LogLevelOffice365MsgTrace = "debug"
	LogLevelOffice365MsgTraceSilly LogLevelOffice365MsgTrace = "silly"
)

func (e LogLevelOffice365MsgTrace) ToPointer() *LogLevelOffice365MsgTrace {
	return &e
}

type MetadatumOffice365MsgTrace struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumOffice365MsgTrace) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumOffice365MsgTrace) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumOffice365MsgTrace) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

// RetryTypeOffice365MsgTrace - The algorithm to use when performing HTTP retries
type RetryTypeOffice365MsgTrace string

const (
	// RetryTypeOffice365MsgTraceNone Disabled
	RetryTypeOffice365MsgTraceNone RetryTypeOffice365MsgTrace = "none"
	// RetryTypeOffice365MsgTraceBackoff Backoff
	RetryTypeOffice365MsgTraceBackoff RetryTypeOffice365MsgTrace = "backoff"
	// RetryTypeOffice365MsgTraceStatic Static
	RetryTypeOffice365MsgTraceStatic RetryTypeOffice365MsgTrace = "static"
)

func (e RetryTypeOffice365MsgTrace) ToPointer() *RetryTypeOffice365MsgTrace {
	return &e
}

type RetryRulesOffice365MsgTrace struct {
	// The algorithm to use when performing HTTP retries
	Type *RetryTypeOffice365MsgTrace `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of http codes that trigger a retry. Leave empty to use the default list of 429, 500, and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (r RetryRulesOffice365MsgTrace) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RetryRulesOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (r *RetryRulesOffice365MsgTrace) GetType() *RetryTypeOffice365MsgTrace {
	if r == nil {
		return nil
	}
	return r.Type
}

func (r *RetryRulesOffice365MsgTrace) GetInterval() *float64 {
	if r == nil {
		return nil
	}
	return r.Interval
}

func (r *RetryRulesOffice365MsgTrace) GetLimit() *float64 {
	if r == nil {
		return nil
	}
	return r.Limit
}

func (r *RetryRulesOffice365MsgTrace) GetMultiplier() *float64 {
	if r == nil {
		return nil
	}
	return r.Multiplier
}

func (r *RetryRulesOffice365MsgTrace) GetCodes() []float64 {
	if r == nil {
		return nil
	}
	return r.Codes
}

func (r *RetryRulesOffice365MsgTrace) GetEnableHeader() *bool {
	if r == nil {
		return nil
	}
	return r.EnableHeader
}

func (r *RetryRulesOffice365MsgTrace) GetRetryConnectTimeout() *bool {
	if r == nil {
		return nil
	}
	return r.RetryConnectTimeout
}

func (r *RetryRulesOffice365MsgTrace) GetRetryConnectReset() *bool {
	if r == nil {
		return nil
	}
	return r.RetryConnectReset
}

// SubscriptionPlanOffice365MsgTrace - Office 365 subscription plan for your organization, typically Office 365 Enterprise
type SubscriptionPlanOffice365MsgTrace string

const (
	// SubscriptionPlanOffice365MsgTraceEnterpriseGcc Office 365 Enterprise
	SubscriptionPlanOffice365MsgTraceEnterpriseGcc SubscriptionPlanOffice365MsgTrace = "enterprise_gcc"
	// SubscriptionPlanOffice365MsgTraceGcc Office 365 GCC
	SubscriptionPlanOffice365MsgTraceGcc SubscriptionPlanOffice365MsgTrace = "gcc"
	// SubscriptionPlanOffice365MsgTraceGccHigh Office 365 GCC High
	SubscriptionPlanOffice365MsgTraceGccHigh SubscriptionPlanOffice365MsgTrace = "gcc_high"
	// SubscriptionPlanOffice365MsgTraceDod Office 365 DoD
	SubscriptionPlanOffice365MsgTraceDod SubscriptionPlanOffice365MsgTrace = "dod"
)

func (e SubscriptionPlanOffice365MsgTrace) ToPointer() *SubscriptionPlanOffice365MsgTrace {
	return &e
}

type CertOptions struct {
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path to the private key to use. Key should be in PEM format. Can reference $ENV_VARS.
	PrivKeyPath string `json:"privKeyPath"`
	// Passphrase to use to decrypt the private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Path to the certificate to use. Certificate should be in PEM format. Can reference $ENV_VARS.
	CertPath string `json:"certPath"`
}

func (c CertOptions) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CertOptions) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"privKeyPath", "certPath"}); err != nil {
		return err
	}
	return nil
}

func (c *CertOptions) GetCertificateName() *string {
	if c == nil {
		return nil
	}
	return c.CertificateName
}

func (c *CertOptions) GetPrivKeyPath() string {
	if c == nil {
		return ""
	}
	return c.PrivKeyPath
}

func (c *CertOptions) GetPassphrase() *string {
	if c == nil {
		return nil
	}
	return c.Passphrase
}

func (c *CertOptions) GetCertPath() string {
	if c == nil {
		return ""
	}
	return c.CertPath
}

type InputOffice365MsgTrace struct {
	// Unique ID for this input
	ID       *string               `json:"id,omitempty"`
	Type     TypeOffice365MsgTrace `json:"type"`
	Disabled *bool                 `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionOffice365MsgTrace `json:"connections,omitempty"`
	Pq          *PqOffice365MsgTrace          `json:"pq,omitempty"`
	// URL to use when retrieving report data.
	URL *string `default:"https://reports.office365.com/ecp/reportingwebservice/reporting.svc/MessageTrace" json:"url"`
	// How often (in minutes) to run the report. Must divide evenly into 60 minutes to create a predictable schedule, or Save will fail.
	Interval *float64 `default:"60" json:"interval"`
	// Backward offset for the search range's head. (E.g.: -3h@h) Message Trace data is delayed; this parameter (with Date range end) compensates for delay and gaps.
	StartDate *string `json:"startDate,omitempty"`
	// Backward offset for the search range's tail. (E.g.: -2h@h) Message Trace data is delayed; this parameter (with Date range start) compensates for delay and gaps.
	EndDate *string `json:"endDate,omitempty"`
	// HTTP request inactivity timeout. Maximum is 2400 (40 minutes); enter 0 to wait indefinitely.
	Timeout *float64 `default:"300" json:"timeout"`
	// Disables time filtering of events when a date range is specified.
	DisableTimeFilter *bool `default:"true" json:"disableTimeFilter"`
	// Select authentication method.
	AuthType *AuthenticationMethodOffice365MsgTrace `default:"oauth" json:"authType"`
	// Reschedule tasks that failed with non-fatal errors
	RescheduleDroppedTasks *bool `default:"true" json:"rescheduleDroppedTasks"`
	// Maximum number of times a task can be rescheduled
	MaxTaskReschedule *float64 `default:"1" json:"maxTaskReschedule"`
	// Log Level (verbosity) for collection runtime behavior.
	LogLevel *LogLevelOffice365MsgTrace `default:"info" json:"logLevel"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
	IgnoreGroupJobsLimit *bool `default:"false" json:"ignoreGroupJobsLimit"`
	// Fields to add to events from this input
	Metadata    []MetadatumOffice365MsgTrace `json:"metadata,omitempty"`
	RetryRules  *RetryRulesOffice365MsgTrace `json:"retryRules,omitempty"`
	Description *string                      `json:"description,omitempty"`
	// Username to run Message Trace API call.
	Username *string `json:"username,omitempty"`
	// Password to run Message Trace API call.
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials.
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// client_secret to pass in the OAuth request parameter.
	ClientSecret *string `json:"clientSecret,omitempty"`
	// Directory ID (tenant identifier) in Azure Active Directory.
	TenantID *string `json:"tenantId,omitempty"`
	// client_id to pass in the OAuth request parameter.
	ClientID *string `json:"clientId,omitempty"`
	// Resource to pass in the OAuth request parameter.
	Resource *string `default:"https://outlook.office365.com" json:"resource"`
	// Office 365 subscription plan for your organization, typically Office 365 Enterprise
	PlanType *SubscriptionPlanOffice365MsgTrace `default:"enterprise_gcc" json:"planType"`
	// Select or create a secret that references your client_secret to pass in the OAuth request parameter.
	TextSecret           *string        `json:"textSecret,omitempty"`
	CertOptions          *CertOptions   `json:"certOptions,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputOffice365MsgTrace) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputOffice365MsgTrace) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputOffice365MsgTrace) GetType() TypeOffice365MsgTrace {
	if i == nil {
		return TypeOffice365MsgTrace("")
	}
	return i.Type
}

func (i *InputOffice365MsgTrace) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputOffice365MsgTrace) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputOffice365MsgTrace) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputOffice365MsgTrace) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputOffice365MsgTrace) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputOffice365MsgTrace) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputOffice365MsgTrace) GetConnections() []ConnectionOffice365MsgTrace {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputOffice365MsgTrace) GetPq() *PqOffice365MsgTrace {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputOffice365MsgTrace) GetURL() *string {
	if i == nil {
		return nil
	}
	return i.URL
}

func (i *InputOffice365MsgTrace) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputOffice365MsgTrace) GetStartDate() *string {
	if i == nil {
		return nil
	}
	return i.StartDate
}

func (i *InputOffice365MsgTrace) GetEndDate() *string {
	if i == nil {
		return nil
	}
	return i.EndDate
}

func (i *InputOffice365MsgTrace) GetTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.Timeout
}

func (i *InputOffice365MsgTrace) GetDisableTimeFilter() *bool {
	if i == nil {
		return nil
	}
	return i.DisableTimeFilter
}

func (i *InputOffice365MsgTrace) GetAuthType() *AuthenticationMethodOffice365MsgTrace {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputOffice365MsgTrace) GetRescheduleDroppedTasks() *bool {
	if i == nil {
		return nil
	}
	return i.RescheduleDroppedTasks
}

func (i *InputOffice365MsgTrace) GetMaxTaskReschedule() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxTaskReschedule
}

func (i *InputOffice365MsgTrace) GetLogLevel() *LogLevelOffice365MsgTrace {
	if i == nil {
		return nil
	}
	return i.LogLevel
}

func (i *InputOffice365MsgTrace) GetJobTimeout() *string {
	if i == nil {
		return nil
	}
	return i.JobTimeout
}

func (i *InputOffice365MsgTrace) GetKeepAliveTime() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTime
}

func (i *InputOffice365MsgTrace) GetMaxMissedKeepAlives() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMissedKeepAlives
}

func (i *InputOffice365MsgTrace) GetTTL() *string {
	if i == nil {
		return nil
	}
	return i.TTL
}

func (i *InputOffice365MsgTrace) GetIgnoreGroupJobsLimit() *bool {
	if i == nil {
		return nil
	}
	return i.IgnoreGroupJobsLimit
}

func (i *InputOffice365MsgTrace) GetMetadata() []MetadatumOffice365MsgTrace {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputOffice365MsgTrace) GetRetryRules() *RetryRulesOffice365MsgTrace {
	if i == nil {
		return nil
	}
	return i.RetryRules
}

func (i *InputOffice365MsgTrace) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputOffice365MsgTrace) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputOffice365MsgTrace) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputOffice365MsgTrace) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputOffice365MsgTrace) GetClientSecret() *string {
	if i == nil {
		return nil
	}
	return i.ClientSecret
}

func (i *InputOffice365MsgTrace) GetTenantID() *string {
	if i == nil {
		return nil
	}
	return i.TenantID
}

func (i *InputOffice365MsgTrace) GetClientID() *string {
	if i == nil {
		return nil
	}
	return i.ClientID
}

func (i *InputOffice365MsgTrace) GetResource() *string {
	if i == nil {
		return nil
	}
	return i.Resource
}

func (i *InputOffice365MsgTrace) GetPlanType() *SubscriptionPlanOffice365MsgTrace {
	if i == nil {
		return nil
	}
	return i.PlanType
}

func (i *InputOffice365MsgTrace) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputOffice365MsgTrace) GetCertOptions() *CertOptions {
	if i == nil {
		return nil
	}
	return i.CertOptions
}

func (i *InputOffice365MsgTrace) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeOffice365Service string

const (
	TypeOffice365ServiceOffice365Service TypeOffice365Service = "office365_service"
)

func (e TypeOffice365Service) ToPointer() *TypeOffice365Service {
	return &e
}
func (e *TypeOffice365Service) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "office365_service":
		*e = TypeOffice365Service(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeOffice365Service: %v", v)
	}
}

type ConnectionOffice365Service struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionOffice365Service) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionOffice365Service) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionOffice365Service) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionOffice365Service) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeOffice365Service - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeOffice365Service string

const (
	// ModeOffice365ServiceSmart Smart
	ModeOffice365ServiceSmart ModeOffice365Service = "smart"
	// ModeOffice365ServiceAlways Always On
	ModeOffice365ServiceAlways ModeOffice365Service = "always"
)

func (e ModeOffice365Service) ToPointer() *ModeOffice365Service {
	return &e
}

// CompressionOffice365Service - Codec to use to compress the persisted data
type CompressionOffice365Service string

const (
	// CompressionOffice365ServiceNone None
	CompressionOffice365ServiceNone CompressionOffice365Service = "none"
	// CompressionOffice365ServiceGzip Gzip
	CompressionOffice365ServiceGzip CompressionOffice365Service = "gzip"
)

func (e CompressionOffice365Service) ToPointer() *CompressionOffice365Service {
	return &e
}

type PqControlsOffice365Service struct {
}

func (p PqControlsOffice365Service) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsOffice365Service) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqOffice365Service struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeOffice365Service `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionOffice365Service `default:"none" json:"compress"`
	PqControls *PqControlsOffice365Service  `json:"pqControls,omitempty"`
}

func (p PqOffice365Service) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqOffice365Service) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqOffice365Service) GetMode() *ModeOffice365Service {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqOffice365Service) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqOffice365Service) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqOffice365Service) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqOffice365Service) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqOffice365Service) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqOffice365Service) GetCompress() *CompressionOffice365Service {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqOffice365Service) GetPqControls() *PqControlsOffice365Service {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// SubscriptionPlanOffice365Service - Office 365 subscription plan for your organization, typically Office 365 Enterprise
type SubscriptionPlanOffice365Service string

const (
	// SubscriptionPlanOffice365ServiceEnterpriseGcc Office 365 Enterprise
	SubscriptionPlanOffice365ServiceEnterpriseGcc SubscriptionPlanOffice365Service = "enterprise_gcc"
	// SubscriptionPlanOffice365ServiceGcc Office 365 GCC
	SubscriptionPlanOffice365ServiceGcc SubscriptionPlanOffice365Service = "gcc"
	// SubscriptionPlanOffice365ServiceGccHigh Office 365 GCC High
	SubscriptionPlanOffice365ServiceGccHigh SubscriptionPlanOffice365Service = "gcc_high"
	// SubscriptionPlanOffice365ServiceDod Office 365 DoD
	SubscriptionPlanOffice365ServiceDod SubscriptionPlanOffice365Service = "dod"
)

func (e SubscriptionPlanOffice365Service) ToPointer() *SubscriptionPlanOffice365Service {
	return &e
}

type MetadatumOffice365Service struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumOffice365Service) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumOffice365Service) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumOffice365Service) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumOffice365Service) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

// LogLevelOffice365Service - Collector runtime Log Level
type LogLevelOffice365Service string

const (
	LogLevelOffice365ServiceError LogLevelOffice365Service = "error"
	LogLevelOffice365ServiceWarn  LogLevelOffice365Service = "warn"
	LogLevelOffice365ServiceInfo  LogLevelOffice365Service = "info"
	LogLevelOffice365ServiceDebug LogLevelOffice365Service = "debug"
)

func (e LogLevelOffice365Service) ToPointer() *LogLevelOffice365Service {
	return &e
}

type ContentConfigOffice365Service struct {
	// Office 365 Services API Content Type
	ContentType *string `json:"contentType,omitempty"`
	// If interval type is minutes the value entered must evenly divisible by 60 or save will fail
	Description *string  `json:"description,omitempty"`
	Interval    *float64 `json:"interval,omitempty"`
	// Collector runtime Log Level
	LogLevel *LogLevelOffice365Service `json:"logLevel,omitempty"`
	Enabled  *bool                     `json:"enabled,omitempty"`
}

func (c ContentConfigOffice365Service) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ContentConfigOffice365Service) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *ContentConfigOffice365Service) GetContentType() *string {
	if c == nil {
		return nil
	}
	return c.ContentType
}

func (c *ContentConfigOffice365Service) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *ContentConfigOffice365Service) GetInterval() *float64 {
	if c == nil {
		return nil
	}
	return c.Interval
}

func (c *ContentConfigOffice365Service) GetLogLevel() *LogLevelOffice365Service {
	if c == nil {
		return nil
	}
	return c.LogLevel
}

func (c *ContentConfigOffice365Service) GetEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.Enabled
}

// RetryTypeOffice365Service - The algorithm to use when performing HTTP retries
type RetryTypeOffice365Service string

const (
	// RetryTypeOffice365ServiceNone Disabled
	RetryTypeOffice365ServiceNone RetryTypeOffice365Service = "none"
	// RetryTypeOffice365ServiceBackoff Backoff
	RetryTypeOffice365ServiceBackoff RetryTypeOffice365Service = "backoff"
	// RetryTypeOffice365ServiceStatic Static
	RetryTypeOffice365ServiceStatic RetryTypeOffice365Service = "static"
)

func (e RetryTypeOffice365Service) ToPointer() *RetryTypeOffice365Service {
	return &e
}

type RetryRulesOffice365Service struct {
	// The algorithm to use when performing HTTP retries
	Type *RetryTypeOffice365Service `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of http codes that trigger a retry. Leave empty to use the default list of 429, 500, and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (r RetryRulesOffice365Service) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RetryRulesOffice365Service) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (r *RetryRulesOffice365Service) GetType() *RetryTypeOffice365Service {
	if r == nil {
		return nil
	}
	return r.Type
}

func (r *RetryRulesOffice365Service) GetInterval() *float64 {
	if r == nil {
		return nil
	}
	return r.Interval
}

func (r *RetryRulesOffice365Service) GetLimit() *float64 {
	if r == nil {
		return nil
	}
	return r.Limit
}

func (r *RetryRulesOffice365Service) GetMultiplier() *float64 {
	if r == nil {
		return nil
	}
	return r.Multiplier
}

func (r *RetryRulesOffice365Service) GetCodes() []float64 {
	if r == nil {
		return nil
	}
	return r.Codes
}

func (r *RetryRulesOffice365Service) GetEnableHeader() *bool {
	if r == nil {
		return nil
	}
	return r.EnableHeader
}

func (r *RetryRulesOffice365Service) GetRetryConnectTimeout() *bool {
	if r == nil {
		return nil
	}
	return r.RetryConnectTimeout
}

func (r *RetryRulesOffice365Service) GetRetryConnectReset() *bool {
	if r == nil {
		return nil
	}
	return r.RetryConnectReset
}

// AuthenticationMethodOffice365Service - Enter client secret directly, or select a stored secret
type AuthenticationMethodOffice365Service string

const (
	AuthenticationMethodOffice365ServiceManual AuthenticationMethodOffice365Service = "manual"
	AuthenticationMethodOffice365ServiceSecret AuthenticationMethodOffice365Service = "secret"
)

func (e AuthenticationMethodOffice365Service) ToPointer() *AuthenticationMethodOffice365Service {
	return &e
}

type InputOffice365Service struct {
	// Unique ID for this input
	ID       *string              `json:"id,omitempty"`
	Type     TypeOffice365Service `json:"type"`
	Disabled *bool                `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionOffice365Service `json:"connections,omitempty"`
	Pq          *PqOffice365Service          `json:"pq,omitempty"`
	// Office 365 subscription plan for your organization, typically Office 365 Enterprise
	PlanType *SubscriptionPlanOffice365Service `default:"enterprise_gcc" json:"planType"`
	// Office 365 Azure Tenant ID
	TenantID string `json:"tenantId"`
	// Office 365 Azure Application ID
	AppID string `json:"appId"`
	// HTTP request inactivity timeout, use 0 to disable
	Timeout *float64 `default:"300" json:"timeout"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
	IgnoreGroupJobsLimit *bool `default:"false" json:"ignoreGroupJobsLimit"`
	// Fields to add to events from this input
	Metadata []MetadatumOffice365Service `json:"metadata,omitempty"`
	// Enable Office 365 Service Communication API content types and polling intervals. Polling intervals are used to set up search date range and cron schedule, e.g.: */${interval} * * * *. Because of this, intervals entered for current and historical status must be evenly divisible by 60 to give a predictable schedule.
	ContentConfig []ContentConfigOffice365Service `json:"contentConfig,omitempty"`
	RetryRules    *RetryRulesOffice365Service     `json:"retryRules,omitempty"`
	// Enter client secret directly, or select a stored secret
	AuthType    *AuthenticationMethodOffice365Service `default:"manual" json:"authType"`
	Description *string                               `json:"description,omitempty"`
	// Office 365 Azure client secret
	ClientSecret *string `json:"clientSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret           *string        `json:"textSecret,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputOffice365Service) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365Service) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "tenantId", "appId"}); err != nil {
		return err
	}
	return nil
}

func (i *InputOffice365Service) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputOffice365Service) GetType() TypeOffice365Service {
	if i == nil {
		return TypeOffice365Service("")
	}
	return i.Type
}

func (i *InputOffice365Service) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputOffice365Service) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputOffice365Service) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputOffice365Service) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputOffice365Service) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputOffice365Service) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputOffice365Service) GetConnections() []ConnectionOffice365Service {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputOffice365Service) GetPq() *PqOffice365Service {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputOffice365Service) GetPlanType() *SubscriptionPlanOffice365Service {
	if i == nil {
		return nil
	}
	return i.PlanType
}

func (i *InputOffice365Service) GetTenantID() string {
	if i == nil {
		return ""
	}
	return i.TenantID
}

func (i *InputOffice365Service) GetAppID() string {
	if i == nil {
		return ""
	}
	return i.AppID
}

func (i *InputOffice365Service) GetTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.Timeout
}

func (i *InputOffice365Service) GetKeepAliveTime() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTime
}

func (i *InputOffice365Service) GetJobTimeout() *string {
	if i == nil {
		return nil
	}
	return i.JobTimeout
}

func (i *InputOffice365Service) GetMaxMissedKeepAlives() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMissedKeepAlives
}

func (i *InputOffice365Service) GetTTL() *string {
	if i == nil {
		return nil
	}
	return i.TTL
}

func (i *InputOffice365Service) GetIgnoreGroupJobsLimit() *bool {
	if i == nil {
		return nil
	}
	return i.IgnoreGroupJobsLimit
}

func (i *InputOffice365Service) GetMetadata() []MetadatumOffice365Service {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputOffice365Service) GetContentConfig() []ContentConfigOffice365Service {
	if i == nil {
		return nil
	}
	return i.ContentConfig
}

func (i *InputOffice365Service) GetRetryRules() *RetryRulesOffice365Service {
	if i == nil {
		return nil
	}
	return i.RetryRules
}

func (i *InputOffice365Service) GetAuthType() *AuthenticationMethodOffice365Service {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputOffice365Service) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputOffice365Service) GetClientSecret() *string {
	if i == nil {
		return nil
	}
	return i.ClientSecret
}

func (i *InputOffice365Service) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputOffice365Service) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeOffice365Mgmt string

const (
	TypeOffice365MgmtOffice365Mgmt TypeOffice365Mgmt = "office365_mgmt"
)

func (e TypeOffice365Mgmt) ToPointer() *TypeOffice365Mgmt {
	return &e
}
func (e *TypeOffice365Mgmt) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "office365_mgmt":
		*e = TypeOffice365Mgmt(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeOffice365Mgmt: %v", v)
	}
}

type ConnectionOffice365Mgmt struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionOffice365Mgmt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionOffice365Mgmt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionOffice365Mgmt) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionOffice365Mgmt) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeOffice365Mgmt - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeOffice365Mgmt string

const (
	// ModeOffice365MgmtSmart Smart
	ModeOffice365MgmtSmart ModeOffice365Mgmt = "smart"
	// ModeOffice365MgmtAlways Always On
	ModeOffice365MgmtAlways ModeOffice365Mgmt = "always"
)

func (e ModeOffice365Mgmt) ToPointer() *ModeOffice365Mgmt {
	return &e
}

// CompressionOffice365Mgmt - Codec to use to compress the persisted data
type CompressionOffice365Mgmt string

const (
	// CompressionOffice365MgmtNone None
	CompressionOffice365MgmtNone CompressionOffice365Mgmt = "none"
	// CompressionOffice365MgmtGzip Gzip
	CompressionOffice365MgmtGzip CompressionOffice365Mgmt = "gzip"
)

func (e CompressionOffice365Mgmt) ToPointer() *CompressionOffice365Mgmt {
	return &e
}

type PqControlsOffice365Mgmt struct {
}

func (p PqControlsOffice365Mgmt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsOffice365Mgmt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqOffice365Mgmt struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeOffice365Mgmt `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionOffice365Mgmt `default:"none" json:"compress"`
	PqControls *PqControlsOffice365Mgmt  `json:"pqControls,omitempty"`
}

func (p PqOffice365Mgmt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqOffice365Mgmt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqOffice365Mgmt) GetMode() *ModeOffice365Mgmt {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqOffice365Mgmt) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqOffice365Mgmt) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqOffice365Mgmt) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqOffice365Mgmt) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqOffice365Mgmt) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqOffice365Mgmt) GetCompress() *CompressionOffice365Mgmt {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqOffice365Mgmt) GetPqControls() *PqControlsOffice365Mgmt {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// SubscriptionPlanOffice365Mgmt - Office 365 subscription plan for your organization, typically Office 365 Enterprise
type SubscriptionPlanOffice365Mgmt string

const (
	// SubscriptionPlanOffice365MgmtEnterpriseGcc Office 365 Enterprise
	SubscriptionPlanOffice365MgmtEnterpriseGcc SubscriptionPlanOffice365Mgmt = "enterprise_gcc"
	// SubscriptionPlanOffice365MgmtGcc Office 365 GCC
	SubscriptionPlanOffice365MgmtGcc SubscriptionPlanOffice365Mgmt = "gcc"
	// SubscriptionPlanOffice365MgmtGccHigh Office 365 GCC High
	SubscriptionPlanOffice365MgmtGccHigh SubscriptionPlanOffice365Mgmt = "gcc_high"
	// SubscriptionPlanOffice365MgmtDod Office 365 DoD
	SubscriptionPlanOffice365MgmtDod SubscriptionPlanOffice365Mgmt = "dod"
)

func (e SubscriptionPlanOffice365Mgmt) ToPointer() *SubscriptionPlanOffice365Mgmt {
	return &e
}

type MetadatumOffice365Mgmt struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumOffice365Mgmt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumOffice365Mgmt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumOffice365Mgmt) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumOffice365Mgmt) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

// LogLevelOffice365Mgmt - Collector runtime Log Level
type LogLevelOffice365Mgmt string

const (
	LogLevelOffice365MgmtError LogLevelOffice365Mgmt = "error"
	LogLevelOffice365MgmtWarn  LogLevelOffice365Mgmt = "warn"
	LogLevelOffice365MgmtInfo  LogLevelOffice365Mgmt = "info"
	LogLevelOffice365MgmtDebug LogLevelOffice365Mgmt = "debug"
)

func (e LogLevelOffice365Mgmt) ToPointer() *LogLevelOffice365Mgmt {
	return &e
}

type ContentConfigOffice365Mgmt struct {
	// Office 365 Management Activity API Content Type
	ContentType *string `json:"contentType,omitempty"`
	// If interval type is minutes the value entered must evenly divisible by 60 or save will fail
	Description *string  `json:"description,omitempty"`
	Interval    *float64 `json:"interval,omitempty"`
	// Collector runtime Log Level
	LogLevel *LogLevelOffice365Mgmt `json:"logLevel,omitempty"`
	Enabled  *bool                  `json:"enabled,omitempty"`
}

func (c ContentConfigOffice365Mgmt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ContentConfigOffice365Mgmt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *ContentConfigOffice365Mgmt) GetContentType() *string {
	if c == nil {
		return nil
	}
	return c.ContentType
}

func (c *ContentConfigOffice365Mgmt) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *ContentConfigOffice365Mgmt) GetInterval() *float64 {
	if c == nil {
		return nil
	}
	return c.Interval
}

func (c *ContentConfigOffice365Mgmt) GetLogLevel() *LogLevelOffice365Mgmt {
	if c == nil {
		return nil
	}
	return c.LogLevel
}

func (c *ContentConfigOffice365Mgmt) GetEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.Enabled
}

// RetryTypeOffice365Mgmt - The algorithm to use when performing HTTP retries
type RetryTypeOffice365Mgmt string

const (
	// RetryTypeOffice365MgmtNone Disabled
	RetryTypeOffice365MgmtNone RetryTypeOffice365Mgmt = "none"
	// RetryTypeOffice365MgmtBackoff Backoff
	RetryTypeOffice365MgmtBackoff RetryTypeOffice365Mgmt = "backoff"
	// RetryTypeOffice365MgmtStatic Static
	RetryTypeOffice365MgmtStatic RetryTypeOffice365Mgmt = "static"
)

func (e RetryTypeOffice365Mgmt) ToPointer() *RetryTypeOffice365Mgmt {
	return &e
}

type RetryRulesOffice365Mgmt struct {
	// The algorithm to use when performing HTTP retries
	Type *RetryTypeOffice365Mgmt `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of http codes that trigger a retry. Leave empty to use the default list of 429, 500, and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (r RetryRulesOffice365Mgmt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RetryRulesOffice365Mgmt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (r *RetryRulesOffice365Mgmt) GetType() *RetryTypeOffice365Mgmt {
	if r == nil {
		return nil
	}
	return r.Type
}

func (r *RetryRulesOffice365Mgmt) GetInterval() *float64 {
	if r == nil {
		return nil
	}
	return r.Interval
}

func (r *RetryRulesOffice365Mgmt) GetLimit() *float64 {
	if r == nil {
		return nil
	}
	return r.Limit
}

func (r *RetryRulesOffice365Mgmt) GetMultiplier() *float64 {
	if r == nil {
		return nil
	}
	return r.Multiplier
}

func (r *RetryRulesOffice365Mgmt) GetCodes() []float64 {
	if r == nil {
		return nil
	}
	return r.Codes
}

func (r *RetryRulesOffice365Mgmt) GetEnableHeader() *bool {
	if r == nil {
		return nil
	}
	return r.EnableHeader
}

func (r *RetryRulesOffice365Mgmt) GetRetryConnectTimeout() *bool {
	if r == nil {
		return nil
	}
	return r.RetryConnectTimeout
}

func (r *RetryRulesOffice365Mgmt) GetRetryConnectReset() *bool {
	if r == nil {
		return nil
	}
	return r.RetryConnectReset
}

// AuthenticationMethodOffice365Mgmt - Enter client secret directly, or select a stored secret
type AuthenticationMethodOffice365Mgmt string

const (
	AuthenticationMethodOffice365MgmtManual AuthenticationMethodOffice365Mgmt = "manual"
	AuthenticationMethodOffice365MgmtSecret AuthenticationMethodOffice365Mgmt = "secret"
)

func (e AuthenticationMethodOffice365Mgmt) ToPointer() *AuthenticationMethodOffice365Mgmt {
	return &e
}

type InputOffice365Mgmt struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     TypeOffice365Mgmt `json:"type"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionOffice365Mgmt `json:"connections,omitempty"`
	Pq          *PqOffice365Mgmt          `json:"pq,omitempty"`
	// Office 365 subscription plan for your organization, typically Office 365 Enterprise
	PlanType *SubscriptionPlanOffice365Mgmt `default:"enterprise_gcc" json:"planType"`
	// Office 365 Azure Tenant ID
	TenantID string `json:"tenantId"`
	// Office 365 Azure Application ID
	AppID string `json:"appId"`
	// HTTP request inactivity timeout, use 0 to disable
	Timeout *float64 `default:"300" json:"timeout"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
	IgnoreGroupJobsLimit *bool `default:"false" json:"ignoreGroupJobsLimit"`
	// Fields to add to events from this input
	Metadata []MetadatumOffice365Mgmt `json:"metadata,omitempty"`
	// Optional Publisher Identifier to use in API requests, defaults to tenant id if not defined. For more information see [here](https://docs.microsoft.com/en-us/office/office-365-management-api/office-365-management-activity-api-reference#start-a-subscription)
	PublisherIdentifier *string `json:"publisherIdentifier,omitempty"`
	// Enable Office 365 Management Activity API content types and polling intervals. Polling intervals are used to set up search date range and cron schedule, e.g.: */${interval} * * * *. Because of this, intervals entered must be evenly divisible by 60 to give a predictable schedule.
	ContentConfig []ContentConfigOffice365Mgmt `json:"contentConfig,omitempty"`
	// Use this setting to account for ingestion lag. This is necessary because there can be a lag of 60 - 90 minutes (or longer) before Office 365 events are available for retrieval.
	IngestionLag *float64                 `default:"0" json:"ingestionLag"`
	RetryRules   *RetryRulesOffice365Mgmt `json:"retryRules,omitempty"`
	// Enter client secret directly, or select a stored secret
	AuthType    *AuthenticationMethodOffice365Mgmt `default:"manual" json:"authType"`
	Description *string                            `json:"description,omitempty"`
	// Office 365 Azure client secret
	ClientSecret *string `json:"clientSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret           *string        `json:"textSecret,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputOffice365Mgmt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365Mgmt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "tenantId", "appId"}); err != nil {
		return err
	}
	return nil
}

func (i *InputOffice365Mgmt) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputOffice365Mgmt) GetType() TypeOffice365Mgmt {
	if i == nil {
		return TypeOffice365Mgmt("")
	}
	return i.Type
}

func (i *InputOffice365Mgmt) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputOffice365Mgmt) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputOffice365Mgmt) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputOffice365Mgmt) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputOffice365Mgmt) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputOffice365Mgmt) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputOffice365Mgmt) GetConnections() []ConnectionOffice365Mgmt {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputOffice365Mgmt) GetPq() *PqOffice365Mgmt {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputOffice365Mgmt) GetPlanType() *SubscriptionPlanOffice365Mgmt {
	if i == nil {
		return nil
	}
	return i.PlanType
}

func (i *InputOffice365Mgmt) GetTenantID() string {
	if i == nil {
		return ""
	}
	return i.TenantID
}

func (i *InputOffice365Mgmt) GetAppID() string {
	if i == nil {
		return ""
	}
	return i.AppID
}

func (i *InputOffice365Mgmt) GetTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.Timeout
}

func (i *InputOffice365Mgmt) GetKeepAliveTime() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTime
}

func (i *InputOffice365Mgmt) GetJobTimeout() *string {
	if i == nil {
		return nil
	}
	return i.JobTimeout
}

func (i *InputOffice365Mgmt) GetMaxMissedKeepAlives() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMissedKeepAlives
}

func (i *InputOffice365Mgmt) GetTTL() *string {
	if i == nil {
		return nil
	}
	return i.TTL
}

func (i *InputOffice365Mgmt) GetIgnoreGroupJobsLimit() *bool {
	if i == nil {
		return nil
	}
	return i.IgnoreGroupJobsLimit
}

func (i *InputOffice365Mgmt) GetMetadata() []MetadatumOffice365Mgmt {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputOffice365Mgmt) GetPublisherIdentifier() *string {
	if i == nil {
		return nil
	}
	return i.PublisherIdentifier
}

func (i *InputOffice365Mgmt) GetContentConfig() []ContentConfigOffice365Mgmt {
	if i == nil {
		return nil
	}
	return i.ContentConfig
}

func (i *InputOffice365Mgmt) GetIngestionLag() *float64 {
	if i == nil {
		return nil
	}
	return i.IngestionLag
}

func (i *InputOffice365Mgmt) GetRetryRules() *RetryRulesOffice365Mgmt {
	if i == nil {
		return nil
	}
	return i.RetryRules
}

func (i *InputOffice365Mgmt) GetAuthType() *AuthenticationMethodOffice365Mgmt {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputOffice365Mgmt) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputOffice365Mgmt) GetClientSecret() *string {
	if i == nil {
		return nil
	}
	return i.ClientSecret
}

func (i *InputOffice365Mgmt) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputOffice365Mgmt) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeEdgePrometheus string

const (
	TypeEdgePrometheusEdgePrometheus TypeEdgePrometheus = "edge_prometheus"
)

func (e TypeEdgePrometheus) ToPointer() *TypeEdgePrometheus {
	return &e
}
func (e *TypeEdgePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "edge_prometheus":
		*e = TypeEdgePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeEdgePrometheus: %v", v)
	}
}

type ConnectionEdgePrometheus struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionEdgePrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionEdgePrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionEdgePrometheus) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionEdgePrometheus) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeEdgePrometheus - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeEdgePrometheus string

const (
	// ModeEdgePrometheusSmart Smart
	ModeEdgePrometheusSmart ModeEdgePrometheus = "smart"
	// ModeEdgePrometheusAlways Always On
	ModeEdgePrometheusAlways ModeEdgePrometheus = "always"
)

func (e ModeEdgePrometheus) ToPointer() *ModeEdgePrometheus {
	return &e
}

// PqCompressionEdgePrometheus - Codec to use to compress the persisted data
type PqCompressionEdgePrometheus string

const (
	// PqCompressionEdgePrometheusNone None
	PqCompressionEdgePrometheusNone PqCompressionEdgePrometheus = "none"
	// PqCompressionEdgePrometheusGzip Gzip
	PqCompressionEdgePrometheusGzip PqCompressionEdgePrometheus = "gzip"
)

func (e PqCompressionEdgePrometheus) ToPointer() *PqCompressionEdgePrometheus {
	return &e
}

type PqControlsEdgePrometheus struct {
}

func (p PqControlsEdgePrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsEdgePrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqEdgePrometheus struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeEdgePrometheus `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *PqCompressionEdgePrometheus `default:"none" json:"compress"`
	PqControls *PqControlsEdgePrometheus    `json:"pqControls,omitempty"`
}

func (p PqEdgePrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqEdgePrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqEdgePrometheus) GetMode() *ModeEdgePrometheus {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqEdgePrometheus) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqEdgePrometheus) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqEdgePrometheus) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqEdgePrometheus) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqEdgePrometheus) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqEdgePrometheus) GetCompress() *PqCompressionEdgePrometheus {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqEdgePrometheus) GetPqControls() *PqControlsEdgePrometheus {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// DiscoveryTypeEdgePrometheus - Target discovery mechanism. Use static to manually enter a list of targets.
type DiscoveryTypeEdgePrometheus string

const (
	// DiscoveryTypeEdgePrometheusStatic Static
	DiscoveryTypeEdgePrometheusStatic DiscoveryTypeEdgePrometheus = "static"
	// DiscoveryTypeEdgePrometheusDNS DNS
	DiscoveryTypeEdgePrometheusDNS DiscoveryTypeEdgePrometheus = "dns"
	// DiscoveryTypeEdgePrometheusEc2 AWS EC2
	DiscoveryTypeEdgePrometheusEc2 DiscoveryTypeEdgePrometheus = "ec2"
	// DiscoveryTypeEdgePrometheusK8sNode Kubernetes Node
	DiscoveryTypeEdgePrometheusK8sNode DiscoveryTypeEdgePrometheus = "k8s-node"
	// DiscoveryTypeEdgePrometheusK8sPods Kubernetes Pods
	DiscoveryTypeEdgePrometheusK8sPods DiscoveryTypeEdgePrometheus = "k8s-pods"
)

func (e DiscoveryTypeEdgePrometheus) ToPointer() *DiscoveryTypeEdgePrometheus {
	return &e
}

// PersistenceCompressionEdgePrometheus - Data compression format. Default is gzip.
type PersistenceCompressionEdgePrometheus string

const (
	PersistenceCompressionEdgePrometheusNone PersistenceCompressionEdgePrometheus = "none"
	PersistenceCompressionEdgePrometheusGzip PersistenceCompressionEdgePrometheus = "gzip"
)

func (e PersistenceCompressionEdgePrometheus) ToPointer() *PersistenceCompressionEdgePrometheus {
	return &e
}

type DiskSpoolingEdgePrometheus struct {
	// Spool events on disk for Cribl Edge and Search. Default is disabled.
	Enable *bool `default:"false" json:"enable"`
	// Time period for grouping spooled events. Default is 10m.
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space that can be consumed before older buckets are deleted. Examples: 420MB, 4GB. Default is 1GB.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data before older buckets are deleted. Examples: 2h, 4d. Default is 24h.
	MaxDataTime *string `default:"24h" json:"maxDataTime"`
	// Data compression format. Default is gzip.
	Compress *PersistenceCompressionEdgePrometheus `default:"gzip" json:"compress"`
}

func (d DiskSpoolingEdgePrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DiskSpoolingEdgePrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DiskSpoolingEdgePrometheus) GetEnable() *bool {
	if d == nil {
		return nil
	}
	return d.Enable
}

func (d *DiskSpoolingEdgePrometheus) GetTimeWindow() *string {
	if d == nil {
		return nil
	}
	return d.TimeWindow
}

func (d *DiskSpoolingEdgePrometheus) GetMaxDataSize() *string {
	if d == nil {
		return nil
	}
	return d.MaxDataSize
}

func (d *DiskSpoolingEdgePrometheus) GetMaxDataTime() *string {
	if d == nil {
		return nil
	}
	return d.MaxDataTime
}

func (d *DiskSpoolingEdgePrometheus) GetCompress() *PersistenceCompressionEdgePrometheus {
	if d == nil {
		return nil
	}
	return d.Compress
}

type MetadatumEdgePrometheus struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumEdgePrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumEdgePrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumEdgePrometheus) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumEdgePrometheus) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

// AuthTypeAuthenticationMethodEdgePrometheus - Enter credentials directly, or select a stored secret
type AuthTypeAuthenticationMethodEdgePrometheus string

const (
	AuthTypeAuthenticationMethodEdgePrometheusManual     AuthTypeAuthenticationMethodEdgePrometheus = "manual"
	AuthTypeAuthenticationMethodEdgePrometheusSecret     AuthTypeAuthenticationMethodEdgePrometheus = "secret"
	AuthTypeAuthenticationMethodEdgePrometheusKubernetes AuthTypeAuthenticationMethodEdgePrometheus = "kubernetes"
)

func (e AuthTypeAuthenticationMethodEdgePrometheus) ToPointer() *AuthTypeAuthenticationMethodEdgePrometheus {
	return &e
}

// TargetProtocol - Protocol to use when collecting metrics
type TargetProtocol string

const (
	TargetProtocolHTTP  TargetProtocol = "http"
	TargetProtocolHTTPS TargetProtocol = "https"
)

func (e TargetProtocol) ToPointer() *TargetProtocol {
	return &e
}

type Target struct {
	// Protocol to use when collecting metrics
	Protocol *TargetProtocol `default:"http" json:"protocol"`
	// Name of host from which to pull metrics.
	Host string `json:"host"`
	// The port number in the metrics URL for discovered targets.
	Port *float64 `default:"9090" json:"port"`
	// Path to use when collecting metrics from discovered targets
	Path *string `default:"/metrics" json:"path"`
}

func (t Target) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *Target) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, []string{"host"}); err != nil {
		return err
	}
	return nil
}

func (t *Target) GetProtocol() *TargetProtocol {
	if t == nil {
		return nil
	}
	return t.Protocol
}

func (t *Target) GetHost() string {
	if t == nil {
		return ""
	}
	return t.Host
}

func (t *Target) GetPort() *float64 {
	if t == nil {
		return nil
	}
	return t.Port
}

func (t *Target) GetPath() *string {
	if t == nil {
		return nil
	}
	return t.Path
}

// RecordTypeEdgePrometheus - DNS Record type to resolve
type RecordTypeEdgePrometheus string

const (
	RecordTypeEdgePrometheusSrv  RecordTypeEdgePrometheus = "SRV"
	RecordTypeEdgePrometheusA    RecordTypeEdgePrometheus = "A"
	RecordTypeEdgePrometheusAaaa RecordTypeEdgePrometheus = "AAAA"
)

func (e RecordTypeEdgePrometheus) ToPointer() *RecordTypeEdgePrometheus {
	return &e
}

// ScrapeProtocolProtocol - Protocol to use when collecting metrics
type ScrapeProtocolProtocol string

const (
	ScrapeProtocolProtocolHTTP  ScrapeProtocolProtocol = "http"
	ScrapeProtocolProtocolHTTPS ScrapeProtocolProtocol = "https"
)

func (e ScrapeProtocolProtocol) ToPointer() *ScrapeProtocolProtocol {
	return &e
}

// AwsAuthenticationMethodAuthenticationMethodEdgePrometheus - AWS authentication method. Choose Auto to use IAM roles.
type AwsAuthenticationMethodAuthenticationMethodEdgePrometheus string

const (
	// AwsAuthenticationMethodAuthenticationMethodEdgePrometheusAuto Auto
	AwsAuthenticationMethodAuthenticationMethodEdgePrometheusAuto AwsAuthenticationMethodAuthenticationMethodEdgePrometheus = "auto"
	// AwsAuthenticationMethodAuthenticationMethodEdgePrometheusManual Manual
	AwsAuthenticationMethodAuthenticationMethodEdgePrometheusManual AwsAuthenticationMethodAuthenticationMethodEdgePrometheus = "manual"
	// AwsAuthenticationMethodAuthenticationMethodEdgePrometheusSecret Secret Key pair
	AwsAuthenticationMethodAuthenticationMethodEdgePrometheusSecret AwsAuthenticationMethodAuthenticationMethodEdgePrometheus = "secret"
)

func (e AwsAuthenticationMethodAuthenticationMethodEdgePrometheus) ToPointer() *AwsAuthenticationMethodAuthenticationMethodEdgePrometheus {
	return &e
}

type SearchFilterEdgePrometheus struct {
	// Search filter attribute name, see: https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstances.html for more information. Attributes can be manually entered if not present in the drop down list
	Name string `json:"Name"`
	// Search Filter Values, if empty only "running" EC2 instances will be returned
	Values []string `json:"Values"`
}

func (s SearchFilterEdgePrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SearchFilterEdgePrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, []string{"Name", "Values"}); err != nil {
		return err
	}
	return nil
}

func (s *SearchFilterEdgePrometheus) GetName() string {
	if s == nil {
		return ""
	}
	return s.Name
}

func (s *SearchFilterEdgePrometheus) GetValues() []string {
	if s == nil {
		return []string{}
	}
	return s.Values
}

// SignatureVersionEdgePrometheus - Signature version to use for signing EC2 requests
type SignatureVersionEdgePrometheus string

const (
	SignatureVersionEdgePrometheusV2 SignatureVersionEdgePrometheus = "v2"
	SignatureVersionEdgePrometheusV4 SignatureVersionEdgePrometheus = "v4"
)

func (e SignatureVersionEdgePrometheus) ToPointer() *SignatureVersionEdgePrometheus {
	return &e
}

type PodFilter struct {
	// JavaScript expression applied to pods objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitempty"`
}

func (p PodFilter) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PodFilter) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, []string{"filter"}); err != nil {
		return err
	}
	return nil
}

func (p *PodFilter) GetFilter() string {
	if p == nil {
		return ""
	}
	return p.Filter
}

func (p *PodFilter) GetDescription() *string {
	if p == nil {
		return nil
	}
	return p.Description
}

type InputEdgePrometheus struct {
	// Unique ID for this input
	ID       *string            `json:"id,omitempty"`
	Type     TypeEdgePrometheus `json:"type"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionEdgePrometheus `json:"connections,omitempty"`
	Pq          *PqEdgePrometheus          `json:"pq,omitempty"`
	// Other dimensions to include in events
	DimensionList []string `json:"dimensionList,omitempty"`
	// Target discovery mechanism. Use static to manually enter a list of targets.
	DiscoveryType *DiscoveryTypeEdgePrometheus `default:"static" json:"discoveryType"`
	// How often in seconds to scrape targets for metrics.
	Interval *float64 `default:"15" json:"interval"`
	// Timeout, in milliseconds, before aborting HTTP connection attempts; 1-60000 or 0 to disable
	Timeout     *float64                    `default:"5000" json:"timeout"`
	Persistence *DiskSpoolingEdgePrometheus `json:"persistence,omitempty"`
	// Fields to add to events from this input
	Metadata []MetadatumEdgePrometheus `json:"metadata,omitempty"`
	// Enter credentials directly, or select a stored secret
	AuthType    *AuthTypeAuthenticationMethodEdgePrometheus `default:"manual" json:"authType"`
	Description *string                                     `json:"description,omitempty"`
	Targets     []Target                                    `json:"targets,omitempty"`
	// DNS Record type to resolve
	RecordType *RecordTypeEdgePrometheus `default:"SRV" json:"recordType"`
	// The port number in the metrics URL for discovered targets.
	ScrapePort *float64 `default:"9090" json:"scrapePort"`
	// List of DNS names to resolve
	NameList []string `json:"nameList,omitempty"`
	// Protocol to use when collecting metrics
	ScrapeProtocol *ScrapeProtocolProtocol `default:"http" json:"scrapeProtocol"`
	// Path to use when collecting metrics from discovered targets
	ScrapePath *string `default:"/metrics" json:"scrapePath"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *AwsAuthenticationMethodAuthenticationMethodEdgePrometheus `default:"auto" json:"awsAuthenticationMethod"`
	AwsAPIKey               *string                                                    `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Use public IP address for discovered targets. Set to false if the private IP address should be used.
	UsePublicIP *bool `default:"true" json:"usePublicIp"`
	// EC2 Instance Search Filter
	SearchFilter []SearchFilterEdgePrometheus `json:"searchFilter,omitempty"`
	AwsSecretKey *string                      `json:"awsSecretKey,omitempty"`
	// Region where the EC2 is located
	Region *string `json:"region,omitempty"`
	// EC2 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to EC2-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing EC2 requests
	SignatureVersion *SignatureVersionEdgePrometheus `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access EC2
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Protocol to use when collecting metrics
	ScrapeProtocolExpr *string `default:"metadata.annotations['prometheus.io/scheme'] || 'http'" json:"scrapeProtocolExpr"`
	// The port number in the metrics URL for discovered targets.
	ScrapePortExpr *string `default:"metadata.annotations['prometheus.io/port'] || 9090" json:"scrapePortExpr"`
	// Path to use when collecting metrics from discovered targets
	ScrapePathExpr *string `default:"metadata.annotations['prometheus.io/path'] || '/metrics'" json:"scrapePathExpr"`
	//   Add rules to decide which pods to discover for metrics.
	//   Pods are searched if no rules are given or of all the rules'
	//   expressions evaluate to true.
	//
	PodFilter []PodFilter `json:"podFilter,omitempty"`
	// Username for Prometheus Basic authentication
	Username *string `json:"username,omitempty"`
	// Password for Prometheus Basic authentication
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret    *string        `json:"credentialsSecret,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputEdgePrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputEdgePrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputEdgePrometheus) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputEdgePrometheus) GetType() TypeEdgePrometheus {
	if i == nil {
		return TypeEdgePrometheus("")
	}
	return i.Type
}

func (i *InputEdgePrometheus) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputEdgePrometheus) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputEdgePrometheus) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputEdgePrometheus) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputEdgePrometheus) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputEdgePrometheus) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputEdgePrometheus) GetConnections() []ConnectionEdgePrometheus {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputEdgePrometheus) GetPq() *PqEdgePrometheus {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputEdgePrometheus) GetDimensionList() []string {
	if i == nil {
		return nil
	}
	return i.DimensionList
}

func (i *InputEdgePrometheus) GetDiscoveryType() *DiscoveryTypeEdgePrometheus {
	if i == nil {
		return nil
	}
	return i.DiscoveryType
}

func (i *InputEdgePrometheus) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputEdgePrometheus) GetTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.Timeout
}

func (i *InputEdgePrometheus) GetPersistence() *DiskSpoolingEdgePrometheus {
	if i == nil {
		return nil
	}
	return i.Persistence
}

func (i *InputEdgePrometheus) GetMetadata() []MetadatumEdgePrometheus {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputEdgePrometheus) GetAuthType() *AuthTypeAuthenticationMethodEdgePrometheus {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputEdgePrometheus) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputEdgePrometheus) GetTargets() []Target {
	if i == nil {
		return nil
	}
	return i.Targets
}

func (i *InputEdgePrometheus) GetRecordType() *RecordTypeEdgePrometheus {
	if i == nil {
		return nil
	}
	return i.RecordType
}

func (i *InputEdgePrometheus) GetScrapePort() *float64 {
	if i == nil {
		return nil
	}
	return i.ScrapePort
}

func (i *InputEdgePrometheus) GetNameList() []string {
	if i == nil {
		return nil
	}
	return i.NameList
}

func (i *InputEdgePrometheus) GetScrapeProtocol() *ScrapeProtocolProtocol {
	if i == nil {
		return nil
	}
	return i.ScrapeProtocol
}

func (i *InputEdgePrometheus) GetScrapePath() *string {
	if i == nil {
		return nil
	}
	return i.ScrapePath
}

func (i *InputEdgePrometheus) GetAwsAuthenticationMethod() *AwsAuthenticationMethodAuthenticationMethodEdgePrometheus {
	if i == nil {
		return nil
	}
	return i.AwsAuthenticationMethod
}

func (i *InputEdgePrometheus) GetAwsAPIKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsAPIKey
}

func (i *InputEdgePrometheus) GetAwsSecret() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecret
}

func (i *InputEdgePrometheus) GetUsePublicIP() *bool {
	if i == nil {
		return nil
	}
	return i.UsePublicIP
}

func (i *InputEdgePrometheus) GetSearchFilter() []SearchFilterEdgePrometheus {
	if i == nil {
		return nil
	}
	return i.SearchFilter
}

func (i *InputEdgePrometheus) GetAwsSecretKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecretKey
}

func (i *InputEdgePrometheus) GetRegion() *string {
	if i == nil {
		return nil
	}
	return i.Region
}

func (i *InputEdgePrometheus) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputEdgePrometheus) GetSignatureVersion() *SignatureVersionEdgePrometheus {
	if i == nil {
		return nil
	}
	return i.SignatureVersion
}

func (i *InputEdgePrometheus) GetReuseConnections() *bool {
	if i == nil {
		return nil
	}
	return i.ReuseConnections
}

func (i *InputEdgePrometheus) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputEdgePrometheus) GetEnableAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableAssumeRole
}

func (i *InputEdgePrometheus) GetAssumeRoleArn() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleArn
}

func (i *InputEdgePrometheus) GetAssumeRoleExternalID() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleExternalID
}

func (i *InputEdgePrometheus) GetDurationSeconds() *float64 {
	if i == nil {
		return nil
	}
	return i.DurationSeconds
}

func (i *InputEdgePrometheus) GetScrapeProtocolExpr() *string {
	if i == nil {
		return nil
	}
	return i.ScrapeProtocolExpr
}

func (i *InputEdgePrometheus) GetScrapePortExpr() *string {
	if i == nil {
		return nil
	}
	return i.ScrapePortExpr
}

func (i *InputEdgePrometheus) GetScrapePathExpr() *string {
	if i == nil {
		return nil
	}
	return i.ScrapePathExpr
}

func (i *InputEdgePrometheus) GetPodFilter() []PodFilter {
	if i == nil {
		return nil
	}
	return i.PodFilter
}

func (i *InputEdgePrometheus) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputEdgePrometheus) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputEdgePrometheus) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputEdgePrometheus) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputTypePrometheus string

const (
	InputTypePrometheusPrometheus InputTypePrometheus = "prometheus"
)

func (e InputTypePrometheus) ToPointer() *InputTypePrometheus {
	return &e
}
func (e *InputTypePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "prometheus":
		*e = InputTypePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypePrometheus: %v", v)
	}
}

type ConnectionPrometheus struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionPrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionPrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionPrometheus) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionPrometheus) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// PqModePrometheus - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModePrometheus string

const (
	// PqModePrometheusSmart Smart
	PqModePrometheusSmart PqModePrometheus = "smart"
	// PqModePrometheusAlways Always On
	PqModePrometheusAlways PqModePrometheus = "always"
)

func (e PqModePrometheus) ToPointer() *PqModePrometheus {
	return &e
}

// PqCompressionPrometheus - Codec to use to compress the persisted data
type PqCompressionPrometheus string

const (
	// PqCompressionPrometheusNone None
	PqCompressionPrometheusNone PqCompressionPrometheus = "none"
	// PqCompressionPrometheusGzip Gzip
	PqCompressionPrometheusGzip PqCompressionPrometheus = "gzip"
)

func (e PqCompressionPrometheus) ToPointer() *PqCompressionPrometheus {
	return &e
}

type InputPqControlsPrometheus struct {
}

func (i InputPqControlsPrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPqControlsPrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqPrometheus struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModePrometheus `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *PqCompressionPrometheus   `default:"none" json:"compress"`
	PqControls *InputPqControlsPrometheus `json:"pqControls,omitempty"`
}

func (p PqPrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqPrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqPrometheus) GetMode() *PqModePrometheus {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqPrometheus) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqPrometheus) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqPrometheus) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqPrometheus) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqPrometheus) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqPrometheus) GetCompress() *PqCompressionPrometheus {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqPrometheus) GetPqControls() *InputPqControlsPrometheus {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// DiscoveryTypePrometheus - Target discovery mechanism. Use static to manually enter a list of targets.
type DiscoveryTypePrometheus string

const (
	// DiscoveryTypePrometheusStatic Static
	DiscoveryTypePrometheusStatic DiscoveryTypePrometheus = "static"
	// DiscoveryTypePrometheusDNS DNS
	DiscoveryTypePrometheusDNS DiscoveryTypePrometheus = "dns"
	// DiscoveryTypePrometheusEc2 AWS EC2
	DiscoveryTypePrometheusEc2 DiscoveryTypePrometheus = "ec2"
)

func (e DiscoveryTypePrometheus) ToPointer() *DiscoveryTypePrometheus {
	return &e
}

// LogLevelPrometheus - Collector runtime Log Level
type LogLevelPrometheus string

const (
	LogLevelPrometheusError LogLevelPrometheus = "error"
	LogLevelPrometheusWarn  LogLevelPrometheus = "warn"
	LogLevelPrometheusInfo  LogLevelPrometheus = "info"
	LogLevelPrometheusDebug LogLevelPrometheus = "debug"
)

func (e LogLevelPrometheus) ToPointer() *LogLevelPrometheus {
	return &e
}

type MetadatumPrometheus struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumPrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumPrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumPrometheus) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumPrometheus) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

// AuthTypeAuthenticationMethodPrometheus - Enter credentials directly, or select a stored secret
type AuthTypeAuthenticationMethodPrometheus string

const (
	AuthTypeAuthenticationMethodPrometheusManual AuthTypeAuthenticationMethodPrometheus = "manual"
	AuthTypeAuthenticationMethodPrometheusSecret AuthTypeAuthenticationMethodPrometheus = "secret"
)

func (e AuthTypeAuthenticationMethodPrometheus) ToPointer() *AuthTypeAuthenticationMethodPrometheus {
	return &e
}

// RecordTypePrometheus - DNS Record type to resolve
type RecordTypePrometheus string

const (
	RecordTypePrometheusSrv  RecordTypePrometheus = "SRV"
	RecordTypePrometheusA    RecordTypePrometheus = "A"
	RecordTypePrometheusAaaa RecordTypePrometheus = "AAAA"
)

func (e RecordTypePrometheus) ToPointer() *RecordTypePrometheus {
	return &e
}

// MetricsProtocol - Protocol to use when collecting metrics
type MetricsProtocol string

const (
	MetricsProtocolHTTP  MetricsProtocol = "http"
	MetricsProtocolHTTPS MetricsProtocol = "https"
)

func (e MetricsProtocol) ToPointer() *MetricsProtocol {
	return &e
}

// AwsAuthenticationMethodAuthenticationMethodPrometheus - AWS authentication method. Choose Auto to use IAM roles.
type AwsAuthenticationMethodAuthenticationMethodPrometheus string

const (
	// AwsAuthenticationMethodAuthenticationMethodPrometheusAuto Auto
	AwsAuthenticationMethodAuthenticationMethodPrometheusAuto AwsAuthenticationMethodAuthenticationMethodPrometheus = "auto"
	// AwsAuthenticationMethodAuthenticationMethodPrometheusManual Manual
	AwsAuthenticationMethodAuthenticationMethodPrometheusManual AwsAuthenticationMethodAuthenticationMethodPrometheus = "manual"
	// AwsAuthenticationMethodAuthenticationMethodPrometheusSecret Secret Key pair
	AwsAuthenticationMethodAuthenticationMethodPrometheusSecret AwsAuthenticationMethodAuthenticationMethodPrometheus = "secret"
)

func (e AwsAuthenticationMethodAuthenticationMethodPrometheus) ToPointer() *AwsAuthenticationMethodAuthenticationMethodPrometheus {
	return &e
}

type SearchFilterPrometheus struct {
	// Search filter attribute name, see: https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstances.html for more information. Attributes can be manually entered if not present in the drop down list
	Name string `json:"Name"`
	// Search Filter Values, if empty only "running" EC2 instances will be returned
	Values []string `json:"Values"`
}

func (s SearchFilterPrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SearchFilterPrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, []string{"Name", "Values"}); err != nil {
		return err
	}
	return nil
}

func (s *SearchFilterPrometheus) GetName() string {
	if s == nil {
		return ""
	}
	return s.Name
}

func (s *SearchFilterPrometheus) GetValues() []string {
	if s == nil {
		return []string{}
	}
	return s.Values
}

// SignatureVersionPrometheus - Signature version to use for signing EC2 requests
type SignatureVersionPrometheus string

const (
	SignatureVersionPrometheusV2 SignatureVersionPrometheus = "v2"
	SignatureVersionPrometheusV4 SignatureVersionPrometheus = "v4"
)

func (e SignatureVersionPrometheus) ToPointer() *SignatureVersionPrometheus {
	return &e
}

type InputPrometheus struct {
	// Unique ID for this input
	ID       *string             `json:"id,omitempty"`
	Type     InputTypePrometheus `json:"type"`
	Disabled *bool               `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionPrometheus `json:"connections,omitempty"`
	Pq          *PqPrometheus          `json:"pq,omitempty"`
	// Other dimensions to include in events
	DimensionList []string `json:"dimensionList,omitempty"`
	// Target discovery mechanism. Use static to manually enter a list of targets.
	DiscoveryType *DiscoveryTypePrometheus `default:"static" json:"discoveryType"`
	// How often in minutes to scrape targets for metrics, 60 must be evenly divisible by the value or save will fail.
	Interval *float64 `default:"15" json:"interval"`
	// Collector runtime Log Level
	LogLevel *LogLevelPrometheus `default:"info" json:"logLevel"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
	IgnoreGroupJobsLimit *bool `default:"false" json:"ignoreGroupJobsLimit"`
	// Fields to add to events from this input
	Metadata []MetadatumPrometheus `json:"metadata,omitempty"`
	// Enter credentials directly, or select a stored secret
	AuthType    *AuthTypeAuthenticationMethodPrometheus `default:"manual" json:"authType"`
	Description *string                                 `json:"description,omitempty"`
	// List of Prometheus targets to pull metrics from. Values can be in URL or host[:port] format. For example: http://localhost:9090/metrics, localhost:9090, or localhost. In cases where just host[:port] is specified, the endpoint will resolve to 'http://host[:port]/metrics'.
	TargetList []string `json:"targetList,omitempty"`
	// DNS Record type to resolve
	RecordType *RecordTypePrometheus `default:"SRV" json:"recordType"`
	// The port number in the metrics URL for discovered targets.
	ScrapePort *float64 `default:"9090" json:"scrapePort"`
	// List of DNS names to resolve
	NameList []string `json:"nameList,omitempty"`
	// Protocol to use when collecting metrics
	ScrapeProtocol *MetricsProtocol `default:"http" json:"scrapeProtocol"`
	// Path to use when collecting metrics from discovered targets
	ScrapePath *string `default:"/metrics" json:"scrapePath"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *AwsAuthenticationMethodAuthenticationMethodPrometheus `default:"auto" json:"awsAuthenticationMethod"`
	AwsAPIKey               *string                                                `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Use public IP address for discovered targets. Set to false if the private IP address should be used.
	UsePublicIP *bool `default:"true" json:"usePublicIp"`
	// EC2 Instance Search Filter
	SearchFilter []SearchFilterPrometheus `json:"searchFilter,omitempty"`
	AwsSecretKey *string                  `json:"awsSecretKey,omitempty"`
	// Region where the EC2 is located
	Region *string `json:"region,omitempty"`
	// EC2 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to EC2-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing EC2 requests
	SignatureVersion *SignatureVersionPrometheus `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Use Assume Role credentials to access EC2
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Username for Prometheus Basic authentication
	Username *string `json:"username,omitempty"`
	// Password for Prometheus Basic authentication
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret    *string        `json:"credentialsSecret,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputPrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputPrometheus) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputPrometheus) GetType() InputTypePrometheus {
	if i == nil {
		return InputTypePrometheus("")
	}
	return i.Type
}

func (i *InputPrometheus) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputPrometheus) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputPrometheus) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputPrometheus) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputPrometheus) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputPrometheus) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputPrometheus) GetConnections() []ConnectionPrometheus {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputPrometheus) GetPq() *PqPrometheus {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputPrometheus) GetDimensionList() []string {
	if i == nil {
		return nil
	}
	return i.DimensionList
}

func (i *InputPrometheus) GetDiscoveryType() *DiscoveryTypePrometheus {
	if i == nil {
		return nil
	}
	return i.DiscoveryType
}

func (i *InputPrometheus) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputPrometheus) GetLogLevel() *LogLevelPrometheus {
	if i == nil {
		return nil
	}
	return i.LogLevel
}

func (i *InputPrometheus) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputPrometheus) GetKeepAliveTime() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTime
}

func (i *InputPrometheus) GetJobTimeout() *string {
	if i == nil {
		return nil
	}
	return i.JobTimeout
}

func (i *InputPrometheus) GetMaxMissedKeepAlives() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMissedKeepAlives
}

func (i *InputPrometheus) GetTTL() *string {
	if i == nil {
		return nil
	}
	return i.TTL
}

func (i *InputPrometheus) GetIgnoreGroupJobsLimit() *bool {
	if i == nil {
		return nil
	}
	return i.IgnoreGroupJobsLimit
}

func (i *InputPrometheus) GetMetadata() []MetadatumPrometheus {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputPrometheus) GetAuthType() *AuthTypeAuthenticationMethodPrometheus {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputPrometheus) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputPrometheus) GetTargetList() []string {
	if i == nil {
		return nil
	}
	return i.TargetList
}

func (i *InputPrometheus) GetRecordType() *RecordTypePrometheus {
	if i == nil {
		return nil
	}
	return i.RecordType
}

func (i *InputPrometheus) GetScrapePort() *float64 {
	if i == nil {
		return nil
	}
	return i.ScrapePort
}

func (i *InputPrometheus) GetNameList() []string {
	if i == nil {
		return nil
	}
	return i.NameList
}

func (i *InputPrometheus) GetScrapeProtocol() *MetricsProtocol {
	if i == nil {
		return nil
	}
	return i.ScrapeProtocol
}

func (i *InputPrometheus) GetScrapePath() *string {
	if i == nil {
		return nil
	}
	return i.ScrapePath
}

func (i *InputPrometheus) GetAwsAuthenticationMethod() *AwsAuthenticationMethodAuthenticationMethodPrometheus {
	if i == nil {
		return nil
	}
	return i.AwsAuthenticationMethod
}

func (i *InputPrometheus) GetAwsAPIKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsAPIKey
}

func (i *InputPrometheus) GetAwsSecret() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecret
}

func (i *InputPrometheus) GetUsePublicIP() *bool {
	if i == nil {
		return nil
	}
	return i.UsePublicIP
}

func (i *InputPrometheus) GetSearchFilter() []SearchFilterPrometheus {
	if i == nil {
		return nil
	}
	return i.SearchFilter
}

func (i *InputPrometheus) GetAwsSecretKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecretKey
}

func (i *InputPrometheus) GetRegion() *string {
	if i == nil {
		return nil
	}
	return i.Region
}

func (i *InputPrometheus) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputPrometheus) GetSignatureVersion() *SignatureVersionPrometheus {
	if i == nil {
		return nil
	}
	return i.SignatureVersion
}

func (i *InputPrometheus) GetReuseConnections() *bool {
	if i == nil {
		return nil
	}
	return i.ReuseConnections
}

func (i *InputPrometheus) GetEnableAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableAssumeRole
}

func (i *InputPrometheus) GetAssumeRoleArn() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleArn
}

func (i *InputPrometheus) GetAssumeRoleExternalID() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleExternalID
}

func (i *InputPrometheus) GetDurationSeconds() *float64 {
	if i == nil {
		return nil
	}
	return i.DurationSeconds
}

func (i *InputPrometheus) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputPrometheus) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputPrometheus) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputPrometheus) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypePrometheusRw string

const (
	TypePrometheusRwPrometheusRw TypePrometheusRw = "prometheus_rw"
)

func (e TypePrometheusRw) ToPointer() *TypePrometheusRw {
	return &e
}
func (e *TypePrometheusRw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "prometheus_rw":
		*e = TypePrometheusRw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypePrometheusRw: %v", v)
	}
}

type ConnectionPrometheusRw struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionPrometheusRw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionPrometheusRw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionPrometheusRw) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionPrometheusRw) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModePrometheusRw - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModePrometheusRw string

const (
	// ModePrometheusRwSmart Smart
	ModePrometheusRwSmart ModePrometheusRw = "smart"
	// ModePrometheusRwAlways Always On
	ModePrometheusRwAlways ModePrometheusRw = "always"
)

func (e ModePrometheusRw) ToPointer() *ModePrometheusRw {
	return &e
}

// CompressionPrometheusRw - Codec to use to compress the persisted data
type CompressionPrometheusRw string

const (
	// CompressionPrometheusRwNone None
	CompressionPrometheusRwNone CompressionPrometheusRw = "none"
	// CompressionPrometheusRwGzip Gzip
	CompressionPrometheusRwGzip CompressionPrometheusRw = "gzip"
)

func (e CompressionPrometheusRw) ToPointer() *CompressionPrometheusRw {
	return &e
}

type PqControlsPrometheusRw struct {
}

func (p PqControlsPrometheusRw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsPrometheusRw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqPrometheusRw struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModePrometheusRw `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionPrometheusRw `default:"none" json:"compress"`
	PqControls *PqControlsPrometheusRw  `json:"pqControls,omitempty"`
}

func (p PqPrometheusRw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqPrometheusRw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqPrometheusRw) GetMode() *ModePrometheusRw {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqPrometheusRw) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqPrometheusRw) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqPrometheusRw) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqPrometheusRw) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqPrometheusRw) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqPrometheusRw) GetCompress() *CompressionPrometheusRw {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqPrometheusRw) GetPqControls() *PqControlsPrometheusRw {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MinimumTLSVersionPrometheusRw string

const (
	MinimumTLSVersionPrometheusRwTlSv1  MinimumTLSVersionPrometheusRw = "TLSv1"
	MinimumTLSVersionPrometheusRwTlSv11 MinimumTLSVersionPrometheusRw = "TLSv1.1"
	MinimumTLSVersionPrometheusRwTlSv12 MinimumTLSVersionPrometheusRw = "TLSv1.2"
	MinimumTLSVersionPrometheusRwTlSv13 MinimumTLSVersionPrometheusRw = "TLSv1.3"
)

func (e MinimumTLSVersionPrometheusRw) ToPointer() *MinimumTLSVersionPrometheusRw {
	return &e
}

type MaximumTLSVersionPrometheusRw string

const (
	MaximumTLSVersionPrometheusRwTlSv1  MaximumTLSVersionPrometheusRw = "TLSv1"
	MaximumTLSVersionPrometheusRwTlSv11 MaximumTLSVersionPrometheusRw = "TLSv1.1"
	MaximumTLSVersionPrometheusRwTlSv12 MaximumTLSVersionPrometheusRw = "TLSv1.2"
	MaximumTLSVersionPrometheusRwTlSv13 MaximumTLSVersionPrometheusRw = "TLSv1.3"
)

func (e MaximumTLSVersionPrometheusRw) ToPointer() *MaximumTLSVersionPrometheusRw {
	return &e
}

type TLSSettingsServerSidePrometheusRw struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                        `json:"caPath,omitempty"`
	MinVersion *MinimumTLSVersionPrometheusRw `json:"minVersion,omitempty"`
	MaxVersion *MaximumTLSVersionPrometheusRw `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSidePrometheusRw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSidePrometheusRw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSidePrometheusRw) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSidePrometheusRw) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSidePrometheusRw) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSidePrometheusRw) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSidePrometheusRw) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSidePrometheusRw) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSidePrometheusRw) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSidePrometheusRw) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSidePrometheusRw) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSidePrometheusRw) GetMinVersion() *MinimumTLSVersionPrometheusRw {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSidePrometheusRw) GetMaxVersion() *MaximumTLSVersionPrometheusRw {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

// AuthenticationTypePrometheusRw - Remote Write authentication type
type AuthenticationTypePrometheusRw string

const (
	AuthenticationTypePrometheusRwNone              AuthenticationTypePrometheusRw = "none"
	AuthenticationTypePrometheusRwBasic             AuthenticationTypePrometheusRw = "basic"
	AuthenticationTypePrometheusRwCredentialsSecret AuthenticationTypePrometheusRw = "credentialsSecret"
	AuthenticationTypePrometheusRwToken             AuthenticationTypePrometheusRw = "token"
	AuthenticationTypePrometheusRwTextSecret        AuthenticationTypePrometheusRw = "textSecret"
	AuthenticationTypePrometheusRwOauth             AuthenticationTypePrometheusRw = "oauth"
)

func (e AuthenticationTypePrometheusRw) ToPointer() *AuthenticationTypePrometheusRw {
	return &e
}

type MetadatumPrometheusRw struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumPrometheusRw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumPrometheusRw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumPrometheusRw) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumPrometheusRw) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type OauthParamPrometheusRw struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o OauthParamPrometheusRw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OauthParamPrometheusRw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (o *OauthParamPrometheusRw) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthParamPrometheusRw) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OauthHeaderPrometheusRw struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o OauthHeaderPrometheusRw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OauthHeaderPrometheusRw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (o *OauthHeaderPrometheusRw) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthHeaderPrometheusRw) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputPrometheusRw struct {
	// Unique ID for this input
	ID       *string          `json:"id,omitempty"`
	Type     TypePrometheusRw `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionPrometheusRw `json:"connections,omitempty"`
	Pq          *PqPrometheusRw          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                            `json:"port"`
	TLS  *TLSSettingsServerSidePrometheusRw `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Prometheus requests. Defaults to /write, which will expand as: http://<your‑upstream‑URL>:<your‑port>/write.
	PrometheusAPI *string `default:"/write" json:"prometheusAPI"`
	// Remote Write authentication type
	AuthType *AuthenticationTypePrometheusRw `default:"none" json:"authType"`
	// Fields to add to events from this input
	Metadata    []MetadatumPrometheusRw `json:"metadata,omitempty"`
	Description *string                 `json:"description,omitempty"`
	Username    *string                 `json:"username,omitempty"`
	Password    *string                 `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []OauthParamPrometheusRw `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders         []OauthHeaderPrometheusRw `json:"oauthHeaders,omitempty"`
	AdditionalProperties map[string]any            `additionalProperties:"true" json:"-"`
}

func (i InputPrometheusRw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPrometheusRw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port"}); err != nil {
		return err
	}
	return nil
}

func (i *InputPrometheusRw) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputPrometheusRw) GetType() TypePrometheusRw {
	if i == nil {
		return TypePrometheusRw("")
	}
	return i.Type
}

func (i *InputPrometheusRw) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputPrometheusRw) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputPrometheusRw) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputPrometheusRw) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputPrometheusRw) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputPrometheusRw) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputPrometheusRw) GetConnections() []ConnectionPrometheusRw {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputPrometheusRw) GetPq() *PqPrometheusRw {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputPrometheusRw) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputPrometheusRw) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputPrometheusRw) GetTLS() *TLSSettingsServerSidePrometheusRw {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputPrometheusRw) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputPrometheusRw) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputPrometheusRw) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputPrometheusRw) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputPrometheusRw) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputPrometheusRw) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputPrometheusRw) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputPrometheusRw) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputPrometheusRw) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputPrometheusRw) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputPrometheusRw) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputPrometheusRw) GetPrometheusAPI() *string {
	if i == nil {
		return nil
	}
	return i.PrometheusAPI
}

func (i *InputPrometheusRw) GetAuthType() *AuthenticationTypePrometheusRw {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputPrometheusRw) GetMetadata() []MetadatumPrometheusRw {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputPrometheusRw) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputPrometheusRw) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputPrometheusRw) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputPrometheusRw) GetToken() *string {
	if i == nil {
		return nil
	}
	return i.Token
}

func (i *InputPrometheusRw) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputPrometheusRw) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputPrometheusRw) GetLoginURL() *string {
	if i == nil {
		return nil
	}
	return i.LoginURL
}

func (i *InputPrometheusRw) GetSecretParamName() *string {
	if i == nil {
		return nil
	}
	return i.SecretParamName
}

func (i *InputPrometheusRw) GetSecret() *string {
	if i == nil {
		return nil
	}
	return i.Secret
}

func (i *InputPrometheusRw) GetTokenAttributeName() *string {
	if i == nil {
		return nil
	}
	return i.TokenAttributeName
}

func (i *InputPrometheusRw) GetAuthHeaderExpr() *string {
	if i == nil {
		return nil
	}
	return i.AuthHeaderExpr
}

func (i *InputPrometheusRw) GetTokenTimeoutSecs() *float64 {
	if i == nil {
		return nil
	}
	return i.TokenTimeoutSecs
}

func (i *InputPrometheusRw) GetOauthParams() []OauthParamPrometheusRw {
	if i == nil {
		return nil
	}
	return i.OauthParams
}

func (i *InputPrometheusRw) GetOauthHeaders() []OauthHeaderPrometheusRw {
	if i == nil {
		return nil
	}
	return i.OauthHeaders
}

func (i *InputPrometheusRw) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputTypeLoki string

const (
	InputTypeLokiLoki InputTypeLoki = "loki"
)

func (e InputTypeLoki) ToPointer() *InputTypeLoki {
	return &e
}
func (e *InputTypeLoki) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "loki":
		*e = InputTypeLoki(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeLoki: %v", v)
	}
}

type ConnectionLoki struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionLoki) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionLoki) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// PqModeLoki - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeLoki string

const (
	// PqModeLokiSmart Smart
	PqModeLokiSmart PqModeLoki = "smart"
	// PqModeLokiAlways Always On
	PqModeLokiAlways PqModeLoki = "always"
)

func (e PqModeLoki) ToPointer() *PqModeLoki {
	return &e
}

// PqCompressionLoki - Codec to use to compress the persisted data
type PqCompressionLoki string

const (
	// PqCompressionLokiNone None
	PqCompressionLokiNone PqCompressionLoki = "none"
	// PqCompressionLokiGzip Gzip
	PqCompressionLokiGzip PqCompressionLoki = "gzip"
)

func (e PqCompressionLoki) ToPointer() *PqCompressionLoki {
	return &e
}

type InputPqControlsLoki struct {
}

func (i InputPqControlsLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPqControlsLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqLoki struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeLoki `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *PqCompressionLoki   `default:"none" json:"compress"`
	PqControls *InputPqControlsLoki `json:"pqControls,omitempty"`
}

func (p PqLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqLoki) GetMode() *PqModeLoki {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqLoki) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqLoki) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqLoki) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqLoki) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqLoki) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqLoki) GetCompress() *PqCompressionLoki {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqLoki) GetPqControls() *InputPqControlsLoki {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MinimumTLSVersionLoki string

const (
	MinimumTLSVersionLokiTlSv1  MinimumTLSVersionLoki = "TLSv1"
	MinimumTLSVersionLokiTlSv11 MinimumTLSVersionLoki = "TLSv1.1"
	MinimumTLSVersionLokiTlSv12 MinimumTLSVersionLoki = "TLSv1.2"
	MinimumTLSVersionLokiTlSv13 MinimumTLSVersionLoki = "TLSv1.3"
)

func (e MinimumTLSVersionLoki) ToPointer() *MinimumTLSVersionLoki {
	return &e
}

type MaximumTLSVersionLoki string

const (
	MaximumTLSVersionLokiTlSv1  MaximumTLSVersionLoki = "TLSv1"
	MaximumTLSVersionLokiTlSv11 MaximumTLSVersionLoki = "TLSv1.1"
	MaximumTLSVersionLokiTlSv12 MaximumTLSVersionLoki = "TLSv1.2"
	MaximumTLSVersionLokiTlSv13 MaximumTLSVersionLoki = "TLSv1.3"
)

func (e MaximumTLSVersionLoki) ToPointer() *MaximumTLSVersionLoki {
	return &e
}

type TLSSettingsServerSideLoki struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                `json:"caPath,omitempty"`
	MinVersion *MinimumTLSVersionLoki `json:"minVersion,omitempty"`
	MaxVersion *MaximumTLSVersionLoki `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideLoki) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideLoki) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideLoki) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideLoki) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideLoki) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideLoki) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideLoki) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideLoki) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideLoki) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideLoki) GetMinVersion() *MinimumTLSVersionLoki {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideLoki) GetMaxVersion() *MaximumTLSVersionLoki {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

// InputAuthenticationTypeLoki - Loki logs authentication type
type InputAuthenticationTypeLoki string

const (
	InputAuthenticationTypeLokiNone              InputAuthenticationTypeLoki = "none"
	InputAuthenticationTypeLokiBasic             InputAuthenticationTypeLoki = "basic"
	InputAuthenticationTypeLokiCredentialsSecret InputAuthenticationTypeLoki = "credentialsSecret"
	InputAuthenticationTypeLokiToken             InputAuthenticationTypeLoki = "token"
	InputAuthenticationTypeLokiTextSecret        InputAuthenticationTypeLoki = "textSecret"
	InputAuthenticationTypeLokiOauth             InputAuthenticationTypeLoki = "oauth"
)

func (e InputAuthenticationTypeLoki) ToPointer() *InputAuthenticationTypeLoki {
	return &e
}

type MetadatumLoki struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumLoki) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumLoki) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type OauthParamLoki struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o OauthParamLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OauthParamLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (o *OauthParamLoki) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthParamLoki) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OauthHeaderLoki struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o OauthHeaderLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OauthHeaderLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (o *OauthHeaderLoki) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthHeaderLoki) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputLoki struct {
	// Unique ID for this input
	ID       *string       `json:"id,omitempty"`
	Type     InputTypeLoki `json:"type"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionLoki `json:"connections,omitempty"`
	Pq          *PqLoki          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                    `json:"port"`
	TLS  *TLSSettingsServerSideLoki `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Loki logs requests. Defaults to /loki/api/v1/push, which will (in this example) expand as: 'http://<your‑upstream‑URL>:<your‑port>/loki/api/v1/push'.
	LokiAPI *string `default:"/loki/api/v1/push" json:"lokiAPI"`
	// Loki logs authentication type
	AuthType *InputAuthenticationTypeLoki `default:"none" json:"authType"`
	// Fields to add to events from this input
	Metadata    []MetadatumLoki `json:"metadata,omitempty"`
	Description *string         `json:"description,omitempty"`
	Username    *string         `json:"username,omitempty"`
	Password    *string         `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []OauthParamLoki `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders         []OauthHeaderLoki `json:"oauthHeaders,omitempty"`
	AdditionalProperties map[string]any    `additionalProperties:"true" json:"-"`
}

func (i InputLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port"}); err != nil {
		return err
	}
	return nil
}

func (i *InputLoki) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputLoki) GetType() InputTypeLoki {
	if i == nil {
		return InputTypeLoki("")
	}
	return i.Type
}

func (i *InputLoki) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputLoki) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputLoki) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputLoki) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputLoki) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputLoki) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputLoki) GetConnections() []ConnectionLoki {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputLoki) GetPq() *PqLoki {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputLoki) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputLoki) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputLoki) GetTLS() *TLSSettingsServerSideLoki {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputLoki) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputLoki) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputLoki) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputLoki) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputLoki) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputLoki) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputLoki) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputLoki) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputLoki) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputLoki) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputLoki) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputLoki) GetLokiAPI() *string {
	if i == nil {
		return nil
	}
	return i.LokiAPI
}

func (i *InputLoki) GetAuthType() *InputAuthenticationTypeLoki {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputLoki) GetMetadata() []MetadatumLoki {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputLoki) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputLoki) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputLoki) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputLoki) GetToken() *string {
	if i == nil {
		return nil
	}
	return i.Token
}

func (i *InputLoki) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputLoki) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputLoki) GetLoginURL() *string {
	if i == nil {
		return nil
	}
	return i.LoginURL
}

func (i *InputLoki) GetSecretParamName() *string {
	if i == nil {
		return nil
	}
	return i.SecretParamName
}

func (i *InputLoki) GetSecret() *string {
	if i == nil {
		return nil
	}
	return i.Secret
}

func (i *InputLoki) GetTokenAttributeName() *string {
	if i == nil {
		return nil
	}
	return i.TokenAttributeName
}

func (i *InputLoki) GetAuthHeaderExpr() *string {
	if i == nil {
		return nil
	}
	return i.AuthHeaderExpr
}

func (i *InputLoki) GetTokenTimeoutSecs() *float64 {
	if i == nil {
		return nil
	}
	return i.TokenTimeoutSecs
}

func (i *InputLoki) GetOauthParams() []OauthParamLoki {
	if i == nil {
		return nil
	}
	return i.OauthParams
}

func (i *InputLoki) GetOauthHeaders() []OauthHeaderLoki {
	if i == nil {
		return nil
	}
	return i.OauthHeaders
}

func (i *InputLoki) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputGrafanaType2 string

const (
	InputGrafanaType2Grafana InputGrafanaType2 = "grafana"
)

func (e InputGrafanaType2) ToPointer() *InputGrafanaType2 {
	return &e
}
func (e *InputGrafanaType2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grafana":
		*e = InputGrafanaType2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaType2: %v", v)
	}
}

type InputGrafanaConnection2 struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (i InputGrafanaConnection2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaConnection2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (i *InputGrafanaConnection2) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputGrafanaConnection2) GetOutput() string {
	if i == nil {
		return ""
	}
	return i.Output
}

// InputGrafanaMode2 - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputGrafanaMode2 string

const (
	// InputGrafanaMode2Smart Smart
	InputGrafanaMode2Smart InputGrafanaMode2 = "smart"
	// InputGrafanaMode2Always Always On
	InputGrafanaMode2Always InputGrafanaMode2 = "always"
)

func (e InputGrafanaMode2) ToPointer() *InputGrafanaMode2 {
	return &e
}

// InputGrafanaCompression2 - Codec to use to compress the persisted data
type InputGrafanaCompression2 string

const (
	// InputGrafanaCompression2None None
	InputGrafanaCompression2None InputGrafanaCompression2 = "none"
	// InputGrafanaCompression2Gzip Gzip
	InputGrafanaCompression2Gzip InputGrafanaCompression2 = "gzip"
)

func (e InputGrafanaCompression2) ToPointer() *InputGrafanaCompression2 {
	return &e
}

type InputGrafanaPqControls2 struct {
}

func (i InputGrafanaPqControls2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaPqControls2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type InputGrafanaPq2 struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputGrafanaMode2 `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *InputGrafanaCompression2 `default:"none" json:"compress"`
	PqControls *InputGrafanaPqControls2  `json:"pqControls,omitempty"`
}

func (i InputGrafanaPq2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaPq2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputGrafanaPq2) GetMode() *InputGrafanaMode2 {
	if i == nil {
		return nil
	}
	return i.Mode
}

func (i *InputGrafanaPq2) GetMaxBufferSize() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBufferSize
}

func (i *InputGrafanaPq2) GetCommitFrequency() *float64 {
	if i == nil {
		return nil
	}
	return i.CommitFrequency
}

func (i *InputGrafanaPq2) GetMaxFileSize() *string {
	if i == nil {
		return nil
	}
	return i.MaxFileSize
}

func (i *InputGrafanaPq2) GetMaxSize() *string {
	if i == nil {
		return nil
	}
	return i.MaxSize
}

func (i *InputGrafanaPq2) GetPath() *string {
	if i == nil {
		return nil
	}
	return i.Path
}

func (i *InputGrafanaPq2) GetCompress() *InputGrafanaCompression2 {
	if i == nil {
		return nil
	}
	return i.Compress
}

func (i *InputGrafanaPq2) GetPqControls() *InputGrafanaPqControls2 {
	if i == nil {
		return nil
	}
	return i.PqControls
}

type InputGrafanaMinimumTLSVersion2 string

const (
	InputGrafanaMinimumTLSVersion2TlSv1  InputGrafanaMinimumTLSVersion2 = "TLSv1"
	InputGrafanaMinimumTLSVersion2TlSv11 InputGrafanaMinimumTLSVersion2 = "TLSv1.1"
	InputGrafanaMinimumTLSVersion2TlSv12 InputGrafanaMinimumTLSVersion2 = "TLSv1.2"
	InputGrafanaMinimumTLSVersion2TlSv13 InputGrafanaMinimumTLSVersion2 = "TLSv1.3"
)

func (e InputGrafanaMinimumTLSVersion2) ToPointer() *InputGrafanaMinimumTLSVersion2 {
	return &e
}

type InputGrafanaMaximumTLSVersion2 string

const (
	InputGrafanaMaximumTLSVersion2TlSv1  InputGrafanaMaximumTLSVersion2 = "TLSv1"
	InputGrafanaMaximumTLSVersion2TlSv11 InputGrafanaMaximumTLSVersion2 = "TLSv1.1"
	InputGrafanaMaximumTLSVersion2TlSv12 InputGrafanaMaximumTLSVersion2 = "TLSv1.2"
	InputGrafanaMaximumTLSVersion2TlSv13 InputGrafanaMaximumTLSVersion2 = "TLSv1.3"
)

func (e InputGrafanaMaximumTLSVersion2) ToPointer() *InputGrafanaMaximumTLSVersion2 {
	return &e
}

type InputGrafanaTLSSettingsServerSide2 struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                         `json:"caPath,omitempty"`
	MinVersion *InputGrafanaMinimumTLSVersion2 `json:"minVersion,omitempty"`
	MaxVersion *InputGrafanaMaximumTLSVersion2 `json:"maxVersion,omitempty"`
}

func (i InputGrafanaTLSSettingsServerSide2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaTLSSettingsServerSide2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputGrafanaTLSSettingsServerSide2) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputGrafanaTLSSettingsServerSide2) GetRequestCert() *bool {
	if i == nil {
		return nil
	}
	return i.RequestCert
}

func (i *InputGrafanaTLSSettingsServerSide2) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputGrafanaTLSSettingsServerSide2) GetCommonNameRegex() *string {
	if i == nil {
		return nil
	}
	return i.CommonNameRegex
}

func (i *InputGrafanaTLSSettingsServerSide2) GetCertificateName() *string {
	if i == nil {
		return nil
	}
	return i.CertificateName
}

func (i *InputGrafanaTLSSettingsServerSide2) GetPrivKeyPath() *string {
	if i == nil {
		return nil
	}
	return i.PrivKeyPath
}

func (i *InputGrafanaTLSSettingsServerSide2) GetPassphrase() *string {
	if i == nil {
		return nil
	}
	return i.Passphrase
}

func (i *InputGrafanaTLSSettingsServerSide2) GetCertPath() *string {
	if i == nil {
		return nil
	}
	return i.CertPath
}

func (i *InputGrafanaTLSSettingsServerSide2) GetCaPath() *string {
	if i == nil {
		return nil
	}
	return i.CaPath
}

func (i *InputGrafanaTLSSettingsServerSide2) GetMinVersion() *InputGrafanaMinimumTLSVersion2 {
	if i == nil {
		return nil
	}
	return i.MinVersion
}

func (i *InputGrafanaTLSSettingsServerSide2) GetMaxVersion() *InputGrafanaMaximumTLSVersion2 {
	if i == nil {
		return nil
	}
	return i.MaxVersion
}

// InputGrafanaPrometheusAuthAuthenticationType2 - Remote Write authentication type
type InputGrafanaPrometheusAuthAuthenticationType2 string

const (
	InputGrafanaPrometheusAuthAuthenticationType2None              InputGrafanaPrometheusAuthAuthenticationType2 = "none"
	InputGrafanaPrometheusAuthAuthenticationType2Basic             InputGrafanaPrometheusAuthAuthenticationType2 = "basic"
	InputGrafanaPrometheusAuthAuthenticationType2CredentialsSecret InputGrafanaPrometheusAuthAuthenticationType2 = "credentialsSecret"
	InputGrafanaPrometheusAuthAuthenticationType2Token             InputGrafanaPrometheusAuthAuthenticationType2 = "token"
	InputGrafanaPrometheusAuthAuthenticationType2TextSecret        InputGrafanaPrometheusAuthAuthenticationType2 = "textSecret"
	InputGrafanaPrometheusAuthAuthenticationType2Oauth             InputGrafanaPrometheusAuthAuthenticationType2 = "oauth"
)

func (e InputGrafanaPrometheusAuthAuthenticationType2) ToPointer() *InputGrafanaPrometheusAuthAuthenticationType2 {
	return &e
}

type PrometheusAuthOauthParam2 struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (p PrometheusAuthOauthParam2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PrometheusAuthOauthParam2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (p *PrometheusAuthOauthParam2) GetName() string {
	if p == nil {
		return ""
	}
	return p.Name
}

func (p *PrometheusAuthOauthParam2) GetValue() string {
	if p == nil {
		return ""
	}
	return p.Value
}

type PrometheusAuthOauthHeader2 struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (p PrometheusAuthOauthHeader2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PrometheusAuthOauthHeader2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (p *PrometheusAuthOauthHeader2) GetName() string {
	if p == nil {
		return ""
	}
	return p.Name
}

func (p *PrometheusAuthOauthHeader2) GetValue() string {
	if p == nil {
		return ""
	}
	return p.Value
}

type InputPrometheusAuth2 struct {
	// Remote Write authentication type
	AuthType *InputGrafanaPrometheusAuthAuthenticationType2 `default:"none" json:"authType"`
	Username *string                                        `json:"username,omitempty"`
	Password *string                                        `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []PrometheusAuthOauthParam2 `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []PrometheusAuthOauthHeader2 `json:"oauthHeaders,omitempty"`
}

func (i InputPrometheusAuth2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPrometheusAuth2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputPrometheusAuth2) GetAuthType() *InputGrafanaPrometheusAuthAuthenticationType2 {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputPrometheusAuth2) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputPrometheusAuth2) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputPrometheusAuth2) GetToken() *string {
	if i == nil {
		return nil
	}
	return i.Token
}

func (i *InputPrometheusAuth2) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputPrometheusAuth2) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputPrometheusAuth2) GetLoginURL() *string {
	if i == nil {
		return nil
	}
	return i.LoginURL
}

func (i *InputPrometheusAuth2) GetSecretParamName() *string {
	if i == nil {
		return nil
	}
	return i.SecretParamName
}

func (i *InputPrometheusAuth2) GetSecret() *string {
	if i == nil {
		return nil
	}
	return i.Secret
}

func (i *InputPrometheusAuth2) GetTokenAttributeName() *string {
	if i == nil {
		return nil
	}
	return i.TokenAttributeName
}

func (i *InputPrometheusAuth2) GetAuthHeaderExpr() *string {
	if i == nil {
		return nil
	}
	return i.AuthHeaderExpr
}

func (i *InputPrometheusAuth2) GetTokenTimeoutSecs() *float64 {
	if i == nil {
		return nil
	}
	return i.TokenTimeoutSecs
}

func (i *InputPrometheusAuth2) GetOauthParams() []PrometheusAuthOauthParam2 {
	if i == nil {
		return nil
	}
	return i.OauthParams
}

func (i *InputPrometheusAuth2) GetOauthHeaders() []PrometheusAuthOauthHeader2 {
	if i == nil {
		return nil
	}
	return i.OauthHeaders
}

// InputGrafanaLokiAuthAuthenticationType2 - Loki logs authentication type
type InputGrafanaLokiAuthAuthenticationType2 string

const (
	InputGrafanaLokiAuthAuthenticationType2None              InputGrafanaLokiAuthAuthenticationType2 = "none"
	InputGrafanaLokiAuthAuthenticationType2Basic             InputGrafanaLokiAuthAuthenticationType2 = "basic"
	InputGrafanaLokiAuthAuthenticationType2CredentialsSecret InputGrafanaLokiAuthAuthenticationType2 = "credentialsSecret"
	InputGrafanaLokiAuthAuthenticationType2Token             InputGrafanaLokiAuthAuthenticationType2 = "token"
	InputGrafanaLokiAuthAuthenticationType2TextSecret        InputGrafanaLokiAuthAuthenticationType2 = "textSecret"
	InputGrafanaLokiAuthAuthenticationType2Oauth             InputGrafanaLokiAuthAuthenticationType2 = "oauth"
)

func (e InputGrafanaLokiAuthAuthenticationType2) ToPointer() *InputGrafanaLokiAuthAuthenticationType2 {
	return &e
}

type LokiAuthOauthParam2 struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (l LokiAuthOauthParam2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(l, "", false)
}

func (l *LokiAuthOauthParam2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &l, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (l *LokiAuthOauthParam2) GetName() string {
	if l == nil {
		return ""
	}
	return l.Name
}

func (l *LokiAuthOauthParam2) GetValue() string {
	if l == nil {
		return ""
	}
	return l.Value
}

type LokiAuthOauthHeader2 struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (l LokiAuthOauthHeader2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(l, "", false)
}

func (l *LokiAuthOauthHeader2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &l, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (l *LokiAuthOauthHeader2) GetName() string {
	if l == nil {
		return ""
	}
	return l.Name
}

func (l *LokiAuthOauthHeader2) GetValue() string {
	if l == nil {
		return ""
	}
	return l.Value
}

type InputLokiAuth2 struct {
	// Loki logs authentication type
	AuthType *InputGrafanaLokiAuthAuthenticationType2 `default:"none" json:"authType"`
	Username *string                                  `json:"username,omitempty"`
	Password *string                                  `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []LokiAuthOauthParam2 `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []LokiAuthOauthHeader2 `json:"oauthHeaders,omitempty"`
}

func (i InputLokiAuth2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputLokiAuth2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputLokiAuth2) GetAuthType() *InputGrafanaLokiAuthAuthenticationType2 {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputLokiAuth2) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputLokiAuth2) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputLokiAuth2) GetToken() *string {
	if i == nil {
		return nil
	}
	return i.Token
}

func (i *InputLokiAuth2) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputLokiAuth2) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputLokiAuth2) GetLoginURL() *string {
	if i == nil {
		return nil
	}
	return i.LoginURL
}

func (i *InputLokiAuth2) GetSecretParamName() *string {
	if i == nil {
		return nil
	}
	return i.SecretParamName
}

func (i *InputLokiAuth2) GetSecret() *string {
	if i == nil {
		return nil
	}
	return i.Secret
}

func (i *InputLokiAuth2) GetTokenAttributeName() *string {
	if i == nil {
		return nil
	}
	return i.TokenAttributeName
}

func (i *InputLokiAuth2) GetAuthHeaderExpr() *string {
	if i == nil {
		return nil
	}
	return i.AuthHeaderExpr
}

func (i *InputLokiAuth2) GetTokenTimeoutSecs() *float64 {
	if i == nil {
		return nil
	}
	return i.TokenTimeoutSecs
}

func (i *InputLokiAuth2) GetOauthParams() []LokiAuthOauthParam2 {
	if i == nil {
		return nil
	}
	return i.OauthParams
}

func (i *InputLokiAuth2) GetOauthHeaders() []LokiAuthOauthHeader2 {
	if i == nil {
		return nil
	}
	return i.OauthHeaders
}

type InputGrafanaMetadatum2 struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (i InputGrafanaMetadatum2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaMetadatum2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (i *InputGrafanaMetadatum2) GetName() string {
	if i == nil {
		return ""
	}
	return i.Name
}

func (i *InputGrafanaMetadatum2) GetValue() string {
	if i == nil {
		return ""
	}
	return i.Value
}

type InputGrafanaGrafana2 struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     InputGrafanaType2 `json:"type"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputGrafanaConnection2 `json:"connections,omitempty"`
	Pq          *InputGrafanaPq2          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                             `json:"port"`
	TLS  *InputGrafanaTLSSettingsServerSide2 `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// Maximum time to wait for additional data, after the last response was sent, before closing a socket connection. This can be very useful when Grafana Agent remote write's request frequency is high so, reusing connections, would help mitigating the cost of creating a new connection per request. Note that Grafana Agent's embedded Prometheus would attempt to keep connections open for up to 5 minutes.
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Grafana Agent's Remote Write requests. Defaults to /api/prom/push, which will expand as: 'http://<your‑upstream‑URL>:<your‑port>/api/prom/push'. Either this field or 'Logs API endpoint' must be configured.
	PrometheusAPI *string `default:"/api/prom/push" json:"prometheusAPI"`
	// Absolute path on which to listen for Loki logs requests. Defaults to /loki/api/v1/push, which will (in this example) expand as: 'http://<your‑upstream‑URL>:<your‑port>/loki/api/v1/push'. Either this field or 'Remote Write API endpoint' must be configured.
	LokiAPI        *string               `default:"/loki/api/v1/push" json:"lokiAPI"`
	PrometheusAuth *InputPrometheusAuth2 `json:"prometheusAuth,omitempty"`
	LokiAuth       *InputLokiAuth2       `json:"lokiAuth,omitempty"`
	// Fields to add to events from this input
	Metadata             []InputGrafanaMetadatum2 `json:"metadata,omitempty"`
	Description          *string                  `json:"description,omitempty"`
	AdditionalProperties map[string]any           `additionalProperties:"true" json:"-"`
}

func (i InputGrafanaGrafana2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaGrafana2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port"}); err != nil {
		return err
	}
	return nil
}

func (i *InputGrafanaGrafana2) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputGrafanaGrafana2) GetType() InputGrafanaType2 {
	if i == nil {
		return InputGrafanaType2("")
	}
	return i.Type
}

func (i *InputGrafanaGrafana2) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputGrafanaGrafana2) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputGrafanaGrafana2) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputGrafanaGrafana2) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputGrafanaGrafana2) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputGrafanaGrafana2) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputGrafanaGrafana2) GetConnections() []InputGrafanaConnection2 {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputGrafanaGrafana2) GetPq() *InputGrafanaPq2 {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputGrafanaGrafana2) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputGrafanaGrafana2) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputGrafanaGrafana2) GetTLS() *InputGrafanaTLSSettingsServerSide2 {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputGrafanaGrafana2) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputGrafanaGrafana2) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputGrafanaGrafana2) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputGrafanaGrafana2) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputGrafanaGrafana2) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputGrafanaGrafana2) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputGrafanaGrafana2) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputGrafanaGrafana2) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputGrafanaGrafana2) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputGrafanaGrafana2) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputGrafanaGrafana2) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputGrafanaGrafana2) GetPrometheusAPI() *string {
	if i == nil {
		return nil
	}
	return i.PrometheusAPI
}

func (i *InputGrafanaGrafana2) GetLokiAPI() *string {
	if i == nil {
		return nil
	}
	return i.LokiAPI
}

func (i *InputGrafanaGrafana2) GetPrometheusAuth() *InputPrometheusAuth2 {
	if i == nil {
		return nil
	}
	return i.PrometheusAuth
}

func (i *InputGrafanaGrafana2) GetLokiAuth() *InputLokiAuth2 {
	if i == nil {
		return nil
	}
	return i.LokiAuth
}

func (i *InputGrafanaGrafana2) GetMetadata() []InputGrafanaMetadatum2 {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputGrafanaGrafana2) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputGrafanaGrafana2) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputGrafanaType1 string

const (
	InputGrafanaType1Grafana InputGrafanaType1 = "grafana"
)

func (e InputGrafanaType1) ToPointer() *InputGrafanaType1 {
	return &e
}
func (e *InputGrafanaType1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grafana":
		*e = InputGrafanaType1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaType1: %v", v)
	}
}

type InputGrafanaConnection1 struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (i InputGrafanaConnection1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaConnection1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (i *InputGrafanaConnection1) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputGrafanaConnection1) GetOutput() string {
	if i == nil {
		return ""
	}
	return i.Output
}

// InputGrafanaMode1 - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputGrafanaMode1 string

const (
	// InputGrafanaMode1Smart Smart
	InputGrafanaMode1Smart InputGrafanaMode1 = "smart"
	// InputGrafanaMode1Always Always On
	InputGrafanaMode1Always InputGrafanaMode1 = "always"
)

func (e InputGrafanaMode1) ToPointer() *InputGrafanaMode1 {
	return &e
}

// InputGrafanaCompression1 - Codec to use to compress the persisted data
type InputGrafanaCompression1 string

const (
	// InputGrafanaCompression1None None
	InputGrafanaCompression1None InputGrafanaCompression1 = "none"
	// InputGrafanaCompression1Gzip Gzip
	InputGrafanaCompression1Gzip InputGrafanaCompression1 = "gzip"
)

func (e InputGrafanaCompression1) ToPointer() *InputGrafanaCompression1 {
	return &e
}

type InputGrafanaPqControls1 struct {
}

func (i InputGrafanaPqControls1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaPqControls1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type InputGrafanaPq1 struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputGrafanaMode1 `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *InputGrafanaCompression1 `default:"none" json:"compress"`
	PqControls *InputGrafanaPqControls1  `json:"pqControls,omitempty"`
}

func (i InputGrafanaPq1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaPq1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputGrafanaPq1) GetMode() *InputGrafanaMode1 {
	if i == nil {
		return nil
	}
	return i.Mode
}

func (i *InputGrafanaPq1) GetMaxBufferSize() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBufferSize
}

func (i *InputGrafanaPq1) GetCommitFrequency() *float64 {
	if i == nil {
		return nil
	}
	return i.CommitFrequency
}

func (i *InputGrafanaPq1) GetMaxFileSize() *string {
	if i == nil {
		return nil
	}
	return i.MaxFileSize
}

func (i *InputGrafanaPq1) GetMaxSize() *string {
	if i == nil {
		return nil
	}
	return i.MaxSize
}

func (i *InputGrafanaPq1) GetPath() *string {
	if i == nil {
		return nil
	}
	return i.Path
}

func (i *InputGrafanaPq1) GetCompress() *InputGrafanaCompression1 {
	if i == nil {
		return nil
	}
	return i.Compress
}

func (i *InputGrafanaPq1) GetPqControls() *InputGrafanaPqControls1 {
	if i == nil {
		return nil
	}
	return i.PqControls
}

type InputGrafanaMinimumTLSVersion1 string

const (
	InputGrafanaMinimumTLSVersion1TlSv1  InputGrafanaMinimumTLSVersion1 = "TLSv1"
	InputGrafanaMinimumTLSVersion1TlSv11 InputGrafanaMinimumTLSVersion1 = "TLSv1.1"
	InputGrafanaMinimumTLSVersion1TlSv12 InputGrafanaMinimumTLSVersion1 = "TLSv1.2"
	InputGrafanaMinimumTLSVersion1TlSv13 InputGrafanaMinimumTLSVersion1 = "TLSv1.3"
)

func (e InputGrafanaMinimumTLSVersion1) ToPointer() *InputGrafanaMinimumTLSVersion1 {
	return &e
}

type InputGrafanaMaximumTLSVersion1 string

const (
	InputGrafanaMaximumTLSVersion1TlSv1  InputGrafanaMaximumTLSVersion1 = "TLSv1"
	InputGrafanaMaximumTLSVersion1TlSv11 InputGrafanaMaximumTLSVersion1 = "TLSv1.1"
	InputGrafanaMaximumTLSVersion1TlSv12 InputGrafanaMaximumTLSVersion1 = "TLSv1.2"
	InputGrafanaMaximumTLSVersion1TlSv13 InputGrafanaMaximumTLSVersion1 = "TLSv1.3"
)

func (e InputGrafanaMaximumTLSVersion1) ToPointer() *InputGrafanaMaximumTLSVersion1 {
	return &e
}

type InputGrafanaTLSSettingsServerSide1 struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                         `json:"caPath,omitempty"`
	MinVersion *InputGrafanaMinimumTLSVersion1 `json:"minVersion,omitempty"`
	MaxVersion *InputGrafanaMaximumTLSVersion1 `json:"maxVersion,omitempty"`
}

func (i InputGrafanaTLSSettingsServerSide1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaTLSSettingsServerSide1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputGrafanaTLSSettingsServerSide1) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputGrafanaTLSSettingsServerSide1) GetRequestCert() *bool {
	if i == nil {
		return nil
	}
	return i.RequestCert
}

func (i *InputGrafanaTLSSettingsServerSide1) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputGrafanaTLSSettingsServerSide1) GetCommonNameRegex() *string {
	if i == nil {
		return nil
	}
	return i.CommonNameRegex
}

func (i *InputGrafanaTLSSettingsServerSide1) GetCertificateName() *string {
	if i == nil {
		return nil
	}
	return i.CertificateName
}

func (i *InputGrafanaTLSSettingsServerSide1) GetPrivKeyPath() *string {
	if i == nil {
		return nil
	}
	return i.PrivKeyPath
}

func (i *InputGrafanaTLSSettingsServerSide1) GetPassphrase() *string {
	if i == nil {
		return nil
	}
	return i.Passphrase
}

func (i *InputGrafanaTLSSettingsServerSide1) GetCertPath() *string {
	if i == nil {
		return nil
	}
	return i.CertPath
}

func (i *InputGrafanaTLSSettingsServerSide1) GetCaPath() *string {
	if i == nil {
		return nil
	}
	return i.CaPath
}

func (i *InputGrafanaTLSSettingsServerSide1) GetMinVersion() *InputGrafanaMinimumTLSVersion1 {
	if i == nil {
		return nil
	}
	return i.MinVersion
}

func (i *InputGrafanaTLSSettingsServerSide1) GetMaxVersion() *InputGrafanaMaximumTLSVersion1 {
	if i == nil {
		return nil
	}
	return i.MaxVersion
}

// InputGrafanaPrometheusAuthAuthenticationType1 - Remote Write authentication type
type InputGrafanaPrometheusAuthAuthenticationType1 string

const (
	InputGrafanaPrometheusAuthAuthenticationType1None              InputGrafanaPrometheusAuthAuthenticationType1 = "none"
	InputGrafanaPrometheusAuthAuthenticationType1Basic             InputGrafanaPrometheusAuthAuthenticationType1 = "basic"
	InputGrafanaPrometheusAuthAuthenticationType1CredentialsSecret InputGrafanaPrometheusAuthAuthenticationType1 = "credentialsSecret"
	InputGrafanaPrometheusAuthAuthenticationType1Token             InputGrafanaPrometheusAuthAuthenticationType1 = "token"
	InputGrafanaPrometheusAuthAuthenticationType1TextSecret        InputGrafanaPrometheusAuthAuthenticationType1 = "textSecret"
	InputGrafanaPrometheusAuthAuthenticationType1Oauth             InputGrafanaPrometheusAuthAuthenticationType1 = "oauth"
)

func (e InputGrafanaPrometheusAuthAuthenticationType1) ToPointer() *InputGrafanaPrometheusAuthAuthenticationType1 {
	return &e
}

type PrometheusAuthOauthParam1 struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (p PrometheusAuthOauthParam1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PrometheusAuthOauthParam1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (p *PrometheusAuthOauthParam1) GetName() string {
	if p == nil {
		return ""
	}
	return p.Name
}

func (p *PrometheusAuthOauthParam1) GetValue() string {
	if p == nil {
		return ""
	}
	return p.Value
}

type PrometheusAuthOauthHeader1 struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (p PrometheusAuthOauthHeader1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PrometheusAuthOauthHeader1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (p *PrometheusAuthOauthHeader1) GetName() string {
	if p == nil {
		return ""
	}
	return p.Name
}

func (p *PrometheusAuthOauthHeader1) GetValue() string {
	if p == nil {
		return ""
	}
	return p.Value
}

type InputPrometheusAuth1 struct {
	// Remote Write authentication type
	AuthType *InputGrafanaPrometheusAuthAuthenticationType1 `default:"none" json:"authType"`
	Username *string                                        `json:"username,omitempty"`
	Password *string                                        `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []PrometheusAuthOauthParam1 `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []PrometheusAuthOauthHeader1 `json:"oauthHeaders,omitempty"`
}

func (i InputPrometheusAuth1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPrometheusAuth1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputPrometheusAuth1) GetAuthType() *InputGrafanaPrometheusAuthAuthenticationType1 {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputPrometheusAuth1) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputPrometheusAuth1) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputPrometheusAuth1) GetToken() *string {
	if i == nil {
		return nil
	}
	return i.Token
}

func (i *InputPrometheusAuth1) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputPrometheusAuth1) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputPrometheusAuth1) GetLoginURL() *string {
	if i == nil {
		return nil
	}
	return i.LoginURL
}

func (i *InputPrometheusAuth1) GetSecretParamName() *string {
	if i == nil {
		return nil
	}
	return i.SecretParamName
}

func (i *InputPrometheusAuth1) GetSecret() *string {
	if i == nil {
		return nil
	}
	return i.Secret
}

func (i *InputPrometheusAuth1) GetTokenAttributeName() *string {
	if i == nil {
		return nil
	}
	return i.TokenAttributeName
}

func (i *InputPrometheusAuth1) GetAuthHeaderExpr() *string {
	if i == nil {
		return nil
	}
	return i.AuthHeaderExpr
}

func (i *InputPrometheusAuth1) GetTokenTimeoutSecs() *float64 {
	if i == nil {
		return nil
	}
	return i.TokenTimeoutSecs
}

func (i *InputPrometheusAuth1) GetOauthParams() []PrometheusAuthOauthParam1 {
	if i == nil {
		return nil
	}
	return i.OauthParams
}

func (i *InputPrometheusAuth1) GetOauthHeaders() []PrometheusAuthOauthHeader1 {
	if i == nil {
		return nil
	}
	return i.OauthHeaders
}

// InputGrafanaLokiAuthAuthenticationType1 - Loki logs authentication type
type InputGrafanaLokiAuthAuthenticationType1 string

const (
	InputGrafanaLokiAuthAuthenticationType1None              InputGrafanaLokiAuthAuthenticationType1 = "none"
	InputGrafanaLokiAuthAuthenticationType1Basic             InputGrafanaLokiAuthAuthenticationType1 = "basic"
	InputGrafanaLokiAuthAuthenticationType1CredentialsSecret InputGrafanaLokiAuthAuthenticationType1 = "credentialsSecret"
	InputGrafanaLokiAuthAuthenticationType1Token             InputGrafanaLokiAuthAuthenticationType1 = "token"
	InputGrafanaLokiAuthAuthenticationType1TextSecret        InputGrafanaLokiAuthAuthenticationType1 = "textSecret"
	InputGrafanaLokiAuthAuthenticationType1Oauth             InputGrafanaLokiAuthAuthenticationType1 = "oauth"
)

func (e InputGrafanaLokiAuthAuthenticationType1) ToPointer() *InputGrafanaLokiAuthAuthenticationType1 {
	return &e
}

type LokiAuthOauthParam1 struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (l LokiAuthOauthParam1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(l, "", false)
}

func (l *LokiAuthOauthParam1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &l, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (l *LokiAuthOauthParam1) GetName() string {
	if l == nil {
		return ""
	}
	return l.Name
}

func (l *LokiAuthOauthParam1) GetValue() string {
	if l == nil {
		return ""
	}
	return l.Value
}

type LokiAuthOauthHeader1 struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (l LokiAuthOauthHeader1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(l, "", false)
}

func (l *LokiAuthOauthHeader1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &l, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (l *LokiAuthOauthHeader1) GetName() string {
	if l == nil {
		return ""
	}
	return l.Name
}

func (l *LokiAuthOauthHeader1) GetValue() string {
	if l == nil {
		return ""
	}
	return l.Value
}

type InputLokiAuth1 struct {
	// Loki logs authentication type
	AuthType *InputGrafanaLokiAuthAuthenticationType1 `default:"none" json:"authType"`
	Username *string                                  `json:"username,omitempty"`
	Password *string                                  `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []LokiAuthOauthParam1 `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []LokiAuthOauthHeader1 `json:"oauthHeaders,omitempty"`
}

func (i InputLokiAuth1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputLokiAuth1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputLokiAuth1) GetAuthType() *InputGrafanaLokiAuthAuthenticationType1 {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputLokiAuth1) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputLokiAuth1) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputLokiAuth1) GetToken() *string {
	if i == nil {
		return nil
	}
	return i.Token
}

func (i *InputLokiAuth1) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputLokiAuth1) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputLokiAuth1) GetLoginURL() *string {
	if i == nil {
		return nil
	}
	return i.LoginURL
}

func (i *InputLokiAuth1) GetSecretParamName() *string {
	if i == nil {
		return nil
	}
	return i.SecretParamName
}

func (i *InputLokiAuth1) GetSecret() *string {
	if i == nil {
		return nil
	}
	return i.Secret
}

func (i *InputLokiAuth1) GetTokenAttributeName() *string {
	if i == nil {
		return nil
	}
	return i.TokenAttributeName
}

func (i *InputLokiAuth1) GetAuthHeaderExpr() *string {
	if i == nil {
		return nil
	}
	return i.AuthHeaderExpr
}

func (i *InputLokiAuth1) GetTokenTimeoutSecs() *float64 {
	if i == nil {
		return nil
	}
	return i.TokenTimeoutSecs
}

func (i *InputLokiAuth1) GetOauthParams() []LokiAuthOauthParam1 {
	if i == nil {
		return nil
	}
	return i.OauthParams
}

func (i *InputLokiAuth1) GetOauthHeaders() []LokiAuthOauthHeader1 {
	if i == nil {
		return nil
	}
	return i.OauthHeaders
}

type InputGrafanaMetadatum1 struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (i InputGrafanaMetadatum1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaMetadatum1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (i *InputGrafanaMetadatum1) GetName() string {
	if i == nil {
		return ""
	}
	return i.Name
}

func (i *InputGrafanaMetadatum1) GetValue() string {
	if i == nil {
		return ""
	}
	return i.Value
}

type InputGrafanaGrafana1 struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     InputGrafanaType1 `json:"type"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputGrafanaConnection1 `json:"connections,omitempty"`
	Pq          *InputGrafanaPq1          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                             `json:"port"`
	TLS  *InputGrafanaTLSSettingsServerSide1 `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// Maximum time to wait for additional data, after the last response was sent, before closing a socket connection. This can be very useful when Grafana Agent remote write's request frequency is high so, reusing connections, would help mitigating the cost of creating a new connection per request. Note that Grafana Agent's embedded Prometheus would attempt to keep connections open for up to 5 minutes.
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Grafana Agent's Remote Write requests. Defaults to /api/prom/push, which will expand as: 'http://<your‑upstream‑URL>:<your‑port>/api/prom/push'. Either this field or 'Logs API endpoint' must be configured.
	PrometheusAPI *string `default:"/api/prom/push" json:"prometheusAPI"`
	// Absolute path on which to listen for Loki logs requests. Defaults to /loki/api/v1/push, which will (in this example) expand as: 'http://<your‑upstream‑URL>:<your‑port>/loki/api/v1/push'. Either this field or 'Remote Write API endpoint' must be configured.
	LokiAPI        *string               `default:"/loki/api/v1/push" json:"lokiAPI"`
	PrometheusAuth *InputPrometheusAuth1 `json:"prometheusAuth,omitempty"`
	LokiAuth       *InputLokiAuth1       `json:"lokiAuth,omitempty"`
	// Fields to add to events from this input
	Metadata             []InputGrafanaMetadatum1 `json:"metadata,omitempty"`
	Description          *string                  `json:"description,omitempty"`
	AdditionalProperties map[string]any           `additionalProperties:"true" json:"-"`
}

func (i InputGrafanaGrafana1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaGrafana1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port"}); err != nil {
		return err
	}
	return nil
}

func (i *InputGrafanaGrafana1) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputGrafanaGrafana1) GetType() InputGrafanaType1 {
	if i == nil {
		return InputGrafanaType1("")
	}
	return i.Type
}

func (i *InputGrafanaGrafana1) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputGrafanaGrafana1) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputGrafanaGrafana1) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputGrafanaGrafana1) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputGrafanaGrafana1) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputGrafanaGrafana1) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputGrafanaGrafana1) GetConnections() []InputGrafanaConnection1 {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputGrafanaGrafana1) GetPq() *InputGrafanaPq1 {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputGrafanaGrafana1) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputGrafanaGrafana1) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputGrafanaGrafana1) GetTLS() *InputGrafanaTLSSettingsServerSide1 {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputGrafanaGrafana1) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputGrafanaGrafana1) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputGrafanaGrafana1) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputGrafanaGrafana1) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputGrafanaGrafana1) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputGrafanaGrafana1) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputGrafanaGrafana1) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputGrafanaGrafana1) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputGrafanaGrafana1) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputGrafanaGrafana1) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputGrafanaGrafana1) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputGrafanaGrafana1) GetPrometheusAPI() *string {
	if i == nil {
		return nil
	}
	return i.PrometheusAPI
}

func (i *InputGrafanaGrafana1) GetLokiAPI() *string {
	if i == nil {
		return nil
	}
	return i.LokiAPI
}

func (i *InputGrafanaGrafana1) GetPrometheusAuth() *InputPrometheusAuth1 {
	if i == nil {
		return nil
	}
	return i.PrometheusAuth
}

func (i *InputGrafanaGrafana1) GetLokiAuth() *InputLokiAuth1 {
	if i == nil {
		return nil
	}
	return i.LokiAuth
}

func (i *InputGrafanaGrafana1) GetMetadata() []InputGrafanaMetadatum1 {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputGrafanaGrafana1) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputGrafanaGrafana1) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputGrafanaType string

const (
	InputGrafanaTypeInputGrafanaGrafana1 InputGrafanaType = "InputGrafana_Grafana_1"
	InputGrafanaTypeInputGrafanaGrafana2 InputGrafanaType = "InputGrafana_Grafana_2"
)

type InputGrafana struct {
	InputGrafanaGrafana1 *InputGrafanaGrafana1 `queryParam:"inline,name=InputGrafana"`
	InputGrafanaGrafana2 *InputGrafanaGrafana2 `queryParam:"inline,name=InputGrafana"`

	Type InputGrafanaType
}

func CreateInputGrafanaInputGrafanaGrafana1(inputGrafanaGrafana1 InputGrafanaGrafana1) InputGrafana {
	typ := InputGrafanaTypeInputGrafanaGrafana1

	return InputGrafana{
		InputGrafanaGrafana1: &inputGrafanaGrafana1,
		Type:                 typ,
	}
}

func CreateInputGrafanaInputGrafanaGrafana2(inputGrafanaGrafana2 InputGrafanaGrafana2) InputGrafana {
	typ := InputGrafanaTypeInputGrafanaGrafana2

	return InputGrafana{
		InputGrafanaGrafana2: &inputGrafanaGrafana2,
		Type:                 typ,
	}
}

func (u *InputGrafana) UnmarshalJSON(data []byte) error {

	var inputGrafanaGrafana1 InputGrafanaGrafana1 = InputGrafanaGrafana1{}
	if err := utils.UnmarshalJSON(data, &inputGrafanaGrafana1, "", true, nil); err == nil {
		u.InputGrafanaGrafana1 = &inputGrafanaGrafana1
		u.Type = InputGrafanaTypeInputGrafanaGrafana1
		return nil
	}

	var inputGrafanaGrafana2 InputGrafanaGrafana2 = InputGrafanaGrafana2{}
	if err := utils.UnmarshalJSON(data, &inputGrafanaGrafana2, "", true, nil); err == nil {
		u.InputGrafanaGrafana2 = &inputGrafanaGrafana2
		u.Type = InputGrafanaTypeInputGrafanaGrafana2
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for InputGrafana", string(data))
}

func (u InputGrafana) MarshalJSON() ([]byte, error) {
	if u.InputGrafanaGrafana1 != nil {
		return utils.MarshalJSON(u.InputGrafanaGrafana1, "", true)
	}

	if u.InputGrafanaGrafana2 != nil {
		return utils.MarshalJSON(u.InputGrafanaGrafana2, "", true)
	}

	return nil, errors.New("could not marshal union type InputGrafana: all fields are null")
}

type InputTypeConfluentCloud string

const (
	InputTypeConfluentCloudConfluentCloud InputTypeConfluentCloud = "confluent_cloud"
)

func (e InputTypeConfluentCloud) ToPointer() *InputTypeConfluentCloud {
	return &e
}
func (e *InputTypeConfluentCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "confluent_cloud":
		*e = InputTypeConfluentCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeConfluentCloud: %v", v)
	}
}

type ConnectionConfluentCloud struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionConfluentCloud) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionConfluentCloud) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// PqModeConfluentCloud - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeConfluentCloud string

const (
	// PqModeConfluentCloudSmart Smart
	PqModeConfluentCloudSmart PqModeConfluentCloud = "smart"
	// PqModeConfluentCloudAlways Always On
	PqModeConfluentCloudAlways PqModeConfluentCloud = "always"
)

func (e PqModeConfluentCloud) ToPointer() *PqModeConfluentCloud {
	return &e
}

// PqCompressionConfluentCloud - Codec to use to compress the persisted data
type PqCompressionConfluentCloud string

const (
	// PqCompressionConfluentCloudNone None
	PqCompressionConfluentCloudNone PqCompressionConfluentCloud = "none"
	// PqCompressionConfluentCloudGzip Gzip
	PqCompressionConfluentCloudGzip PqCompressionConfluentCloud = "gzip"
)

func (e PqCompressionConfluentCloud) ToPointer() *PqCompressionConfluentCloud {
	return &e
}

type InputPqControlsConfluentCloud struct {
}

func (i InputPqControlsConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPqControlsConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqConfluentCloud struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeConfluentCloud `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *PqCompressionConfluentCloud   `default:"none" json:"compress"`
	PqControls *InputPqControlsConfluentCloud `json:"pqControls,omitempty"`
}

func (p PqConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqConfluentCloud) GetMode() *PqModeConfluentCloud {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqConfluentCloud) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqConfluentCloud) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqConfluentCloud) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqConfluentCloud) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqConfluentCloud) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqConfluentCloud) GetCompress() *PqCompressionConfluentCloud {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqConfluentCloud) GetPqControls() *InputPqControlsConfluentCloud {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type InputMinimumTLSVersionConfluentCloud string

const (
	InputMinimumTLSVersionConfluentCloudTlSv1  InputMinimumTLSVersionConfluentCloud = "TLSv1"
	InputMinimumTLSVersionConfluentCloudTlSv11 InputMinimumTLSVersionConfluentCloud = "TLSv1.1"
	InputMinimumTLSVersionConfluentCloudTlSv12 InputMinimumTLSVersionConfluentCloud = "TLSv1.2"
	InputMinimumTLSVersionConfluentCloudTlSv13 InputMinimumTLSVersionConfluentCloud = "TLSv1.3"
)

func (e InputMinimumTLSVersionConfluentCloud) ToPointer() *InputMinimumTLSVersionConfluentCloud {
	return &e
}

type InputMaximumTLSVersionConfluentCloud string

const (
	InputMaximumTLSVersionConfluentCloudTlSv1  InputMaximumTLSVersionConfluentCloud = "TLSv1"
	InputMaximumTLSVersionConfluentCloudTlSv11 InputMaximumTLSVersionConfluentCloud = "TLSv1.1"
	InputMaximumTLSVersionConfluentCloudTlSv12 InputMaximumTLSVersionConfluentCloud = "TLSv1.2"
	InputMaximumTLSVersionConfluentCloudTlSv13 InputMaximumTLSVersionConfluentCloud = "TLSv1.3"
)

func (e InputMaximumTLSVersionConfluentCloud) ToPointer() *InputMaximumTLSVersionConfluentCloud {
	return &e
}

type InputTLSSettingsClientSideConfluentCloud struct {
	Disabled *bool `default:"false" json:"disabled"`
	// Reject certificates that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string                               `json:"passphrase,omitempty"`
	MinVersion *InputMinimumTLSVersionConfluentCloud `json:"minVersion,omitempty"`
	MaxVersion *InputMaximumTLSVersionConfluentCloud `json:"maxVersion,omitempty"`
}

func (i InputTLSSettingsClientSideConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTLSSettingsClientSideConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputTLSSettingsClientSideConfluentCloud) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputTLSSettingsClientSideConfluentCloud) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputTLSSettingsClientSideConfluentCloud) GetServername() *string {
	if i == nil {
		return nil
	}
	return i.Servername
}

func (i *InputTLSSettingsClientSideConfluentCloud) GetCertificateName() *string {
	if i == nil {
		return nil
	}
	return i.CertificateName
}

func (i *InputTLSSettingsClientSideConfluentCloud) GetCaPath() *string {
	if i == nil {
		return nil
	}
	return i.CaPath
}

func (i *InputTLSSettingsClientSideConfluentCloud) GetPrivKeyPath() *string {
	if i == nil {
		return nil
	}
	return i.PrivKeyPath
}

func (i *InputTLSSettingsClientSideConfluentCloud) GetCertPath() *string {
	if i == nil {
		return nil
	}
	return i.CertPath
}

func (i *InputTLSSettingsClientSideConfluentCloud) GetPassphrase() *string {
	if i == nil {
		return nil
	}
	return i.Passphrase
}

func (i *InputTLSSettingsClientSideConfluentCloud) GetMinVersion() *InputMinimumTLSVersionConfluentCloud {
	if i == nil {
		return nil
	}
	return i.MinVersion
}

func (i *InputTLSSettingsClientSideConfluentCloud) GetMaxVersion() *InputMaximumTLSVersionConfluentCloud {
	if i == nil {
		return nil
	}
	return i.MaxVersion
}

// InputAuthConfluentCloud - Credentials to use when authenticating with the schema registry using basic HTTP authentication
type InputAuthConfluentCloud struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (i InputAuthConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAuthConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputAuthConfluentCloud) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputAuthConfluentCloud) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

type InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud string

const (
	InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloudTlSv1  InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud = "TLSv1"
	InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloudTlSv11 InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud = "TLSv1.1"
	InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloudTlSv12 InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud = "TLSv1.2"
	InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloudTlSv13 InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud = "TLSv1.3"
)

func (e InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud) ToPointer() *InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud {
	return &e
}

type InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud string

const (
	InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloudTlSv1  InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud = "TLSv1"
	InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloudTlSv11 InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud = "TLSv1.1"
	InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloudTlSv12 InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud = "TLSv1.2"
	InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloudTlSv13 InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud = "TLSv1.3"
)

func (e InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud) ToPointer() *InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud {
	return &e
}

type InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certificates that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string                                                  `json:"passphrase,omitempty"`
	MinVersion *InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud `json:"minVersion,omitempty"`
	MaxVersion *InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud `json:"maxVersion,omitempty"`
}

func (i InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetServername() *string {
	if i == nil {
		return nil
	}
	return i.Servername
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetCertificateName() *string {
	if i == nil {
		return nil
	}
	return i.CertificateName
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetCaPath() *string {
	if i == nil {
		return nil
	}
	return i.CaPath
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetPrivKeyPath() *string {
	if i == nil {
		return nil
	}
	return i.PrivKeyPath
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetCertPath() *string {
	if i == nil {
		return nil
	}
	return i.CertPath
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetPassphrase() *string {
	if i == nil {
		return nil
	}
	return i.Passphrase
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetMinVersion() *InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud {
	if i == nil {
		return nil
	}
	return i.MinVersion
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetMaxVersion() *InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud {
	if i == nil {
		return nil
	}
	return i.MaxVersion
}

type InputKafkaSchemaRegistryAuthenticationConfluentCloud struct {
	Disabled *bool `default:"true" json:"disabled"`
	// URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
	SchemaRegistryURL *string `default:"http://localhost:8081" json:"schemaRegistryURL"`
	// Maximum time to wait for a Schema Registry connection to complete successfully
	ConnectionTimeout *float64 `default:"30000" json:"connectionTimeout"`
	// Maximum time to wait for the Schema Registry to respond to a request
	RequestTimeout *float64 `default:"30000" json:"requestTimeout"`
	// Maximum number of times to try fetching schemas from the Schema Registry
	MaxRetries *float64 `default:"1" json:"maxRetries"`
	// Credentials to use when authenticating with the schema registry using basic HTTP authentication
	Auth *InputAuthConfluentCloud                                     `json:"auth,omitempty"`
	TLS  *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud `json:"tls,omitempty"`
}

func (i InputKafkaSchemaRegistryAuthenticationConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafkaSchemaRegistryAuthenticationConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputKafkaSchemaRegistryAuthenticationConfluentCloud) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKafkaSchemaRegistryAuthenticationConfluentCloud) GetSchemaRegistryURL() *string {
	if i == nil {
		return nil
	}
	return i.SchemaRegistryURL
}

func (i *InputKafkaSchemaRegistryAuthenticationConfluentCloud) GetConnectionTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.ConnectionTimeout
}

func (i *InputKafkaSchemaRegistryAuthenticationConfluentCloud) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputKafkaSchemaRegistryAuthenticationConfluentCloud) GetMaxRetries() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxRetries
}

func (i *InputKafkaSchemaRegistryAuthenticationConfluentCloud) GetAuth() *InputAuthConfluentCloud {
	if i == nil {
		return nil
	}
	return i.Auth
}

func (i *InputKafkaSchemaRegistryAuthenticationConfluentCloud) GetTLS() *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud {
	if i == nil {
		return nil
	}
	return i.TLS
}

// InputAuthenticationMethodConfluentCloud - Enter credentials directly, or select a stored secret
type InputAuthenticationMethodConfluentCloud string

const (
	InputAuthenticationMethodConfluentCloudManual InputAuthenticationMethodConfluentCloud = "manual"
	InputAuthenticationMethodConfluentCloudSecret InputAuthenticationMethodConfluentCloud = "secret"
)

func (e InputAuthenticationMethodConfluentCloud) ToPointer() *InputAuthenticationMethodConfluentCloud {
	return &e
}

type InputSASLMechanismConfluentCloud string

const (
	// InputSASLMechanismConfluentCloudPlain PLAIN
	InputSASLMechanismConfluentCloudPlain InputSASLMechanismConfluentCloud = "plain"
	// InputSASLMechanismConfluentCloudScramSha256 SCRAM-SHA-256
	InputSASLMechanismConfluentCloudScramSha256 InputSASLMechanismConfluentCloud = "scram-sha-256"
	// InputSASLMechanismConfluentCloudScramSha512 SCRAM-SHA-512
	InputSASLMechanismConfluentCloudScramSha512 InputSASLMechanismConfluentCloud = "scram-sha-512"
	// InputSASLMechanismConfluentCloudKerberos GSSAPI/Kerberos
	InputSASLMechanismConfluentCloudKerberos InputSASLMechanismConfluentCloud = "kerberos"
)

func (e InputSASLMechanismConfluentCloud) ToPointer() *InputSASLMechanismConfluentCloud {
	return &e
}

type InputOauthParamConfluentCloud struct {
	Name  string `json:"name"`
	Value string `json:"value"`
}

func (i InputOauthParamConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOauthParamConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (i *InputOauthParamConfluentCloud) GetName() string {
	if i == nil {
		return ""
	}
	return i.Name
}

func (i *InputOauthParamConfluentCloud) GetValue() string {
	if i == nil {
		return ""
	}
	return i.Value
}

type InputSaslExtensionConfluentCloud struct {
	Name  string `json:"name"`
	Value string `json:"value"`
}

func (i InputSaslExtensionConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSaslExtensionConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (i *InputSaslExtensionConfluentCloud) GetName() string {
	if i == nil {
		return ""
	}
	return i.Name
}

func (i *InputSaslExtensionConfluentCloud) GetValue() string {
	if i == nil {
		return ""
	}
	return i.Value
}

// InputAuthenticationConfluentCloud - Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type InputAuthenticationConfluentCloud struct {
	Disabled *bool   `default:"true" json:"disabled"`
	Username *string `json:"username,omitempty"`
	Password *string `json:"password,omitempty"`
	// Enter credentials directly, or select a stored secret
	AuthType *InputAuthenticationMethodConfluentCloud `default:"manual" json:"authType"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string                           `json:"credentialsSecret,omitempty"`
	Mechanism         *InputSASLMechanismConfluentCloud `default:"plain" json:"mechanism"`
	// Location of keytab file for authentication principal
	KeytabLocation *string `json:"keytabLocation,omitempty"`
	// Authentication principal, such as `kafka_user@example.com`
	Principal *string `json:"principal,omitempty"`
	// Kerberos service class for Kafka brokers, such as `kafka`
	BrokerServiceClass *string `json:"brokerServiceClass,omitempty"`
	// Enable OAuth authentication
	OauthEnabled *bool `default:"false" json:"oauthEnabled"`
	// URL of the token endpoint to use for OAuth authentication
	TokenURL *string `json:"tokenUrl,omitempty"`
	// Client ID to use for OAuth authentication
	ClientID        *string `json:"clientId,omitempty"`
	OauthSecretType *string `default:"secret" json:"oauthSecretType"`
	// Select or create a stored text secret
	ClientTextSecret *string `json:"clientTextSecret,omitempty"`
	// Additional fields to send to the token endpoint, such as scope or audience
	OauthParams []InputOauthParamConfluentCloud `json:"oauthParams,omitempty"`
	// Additional SASL extension fields, such as Confluent's logicalCluster or identityPoolId
	SaslExtensions []InputSaslExtensionConfluentCloud `json:"saslExtensions,omitempty"`
}

func (i InputAuthenticationConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAuthenticationConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputAuthenticationConfluentCloud) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputAuthenticationConfluentCloud) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputAuthenticationConfluentCloud) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputAuthenticationConfluentCloud) GetAuthType() *InputAuthenticationMethodConfluentCloud {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputAuthenticationConfluentCloud) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputAuthenticationConfluentCloud) GetMechanism() *InputSASLMechanismConfluentCloud {
	if i == nil {
		return nil
	}
	return i.Mechanism
}

func (i *InputAuthenticationConfluentCloud) GetKeytabLocation() *string {
	if i == nil {
		return nil
	}
	return i.KeytabLocation
}

func (i *InputAuthenticationConfluentCloud) GetPrincipal() *string {
	if i == nil {
		return nil
	}
	return i.Principal
}

func (i *InputAuthenticationConfluentCloud) GetBrokerServiceClass() *string {
	if i == nil {
		return nil
	}
	return i.BrokerServiceClass
}

func (i *InputAuthenticationConfluentCloud) GetOauthEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.OauthEnabled
}

func (i *InputAuthenticationConfluentCloud) GetTokenURL() *string {
	if i == nil {
		return nil
	}
	return i.TokenURL
}

func (i *InputAuthenticationConfluentCloud) GetClientID() *string {
	if i == nil {
		return nil
	}
	return i.ClientID
}

func (i *InputAuthenticationConfluentCloud) GetOauthSecretType() *string {
	if i == nil {
		return nil
	}
	return i.OauthSecretType
}

func (i *InputAuthenticationConfluentCloud) GetClientTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.ClientTextSecret
}

func (i *InputAuthenticationConfluentCloud) GetOauthParams() []InputOauthParamConfluentCloud {
	if i == nil {
		return nil
	}
	return i.OauthParams
}

func (i *InputAuthenticationConfluentCloud) GetSaslExtensions() []InputSaslExtensionConfluentCloud {
	if i == nil {
		return nil
	}
	return i.SaslExtensions
}

type MetadatumConfluentCloud struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumConfluentCloud) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumConfluentCloud) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputConfluentCloud struct {
	// Unique ID for this input
	ID       *string                 `json:"id,omitempty"`
	Type     InputTypeConfluentCloud `json:"type"`
	Disabled *bool                   `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionConfluentCloud `json:"connections,omitempty"`
	Pq          *PqConfluentCloud          `json:"pq,omitempty"`
	// List of Confluent Cloud bootstrap servers to use, such as yourAccount.confluent.cloud:9092
	Brokers []string                                  `json:"brokers"`
	TLS     *InputTLSSettingsClientSideConfluentCloud `json:"tls,omitempty"`
	// Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to a single topic only.
	Topics []string `json:"topics"`
	// The consumer group to which this instance belongs. Defaults to 'Cribl'.
	GroupID *string `default:"Cribl" json:"groupId"`
	// Leave enabled if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
	FromBeginning       *bool                                                 `default:"true" json:"fromBeginning"`
	KafkaSchemaRegistry *InputKafkaSchemaRegistryAuthenticationConfluentCloud `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *InputAuthenticationConfluentCloud `json:"sasl,omitempty"`
	//       Timeout used to detect client failures when using Kafka's group-management facilities.
	//       If the client sends no heartbeats to the broker before the timeout expires,
	//       the broker will remove the client from the group and initiate a rebalance.
	//       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms) for details.
	SessionTimeout *float64 `default:"30000" json:"sessionTimeout"`
	//       Maximum allowed time for each worker to join the group after a rebalance begins.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms) for details.
	RebalanceTimeout *float64 `default:"60000" json:"rebalanceTimeout"`
	//       Expected time between heartbeats to the consumer coordinator when using Kafka's group-management facilities.
	//       Value must be lower than sessionTimeout and typically should not exceed 1/3 of the sessionTimeout value.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms) for details.
	HeartbeatInterval *float64 `default:"3000" json:"heartbeatInterval"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitempty"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitempty"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `default:"1048576" json:"maxBytesPerPartition"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `default:"10485760" json:"maxBytes"`
	// Maximum number of network errors before the consumer re-creates a socket
	MaxSocketErrors *float64 `default:"0" json:"maxSocketErrors"`
	// Fields to add to events from this input
	Metadata             []MetadatumConfluentCloud `json:"metadata,omitempty"`
	Description          *string                   `json:"description,omitempty"`
	AdditionalProperties map[string]any            `additionalProperties:"true" json:"-"`
}

func (i InputConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "brokers", "topics"}); err != nil {
		return err
	}
	return nil
}

func (i *InputConfluentCloud) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputConfluentCloud) GetType() InputTypeConfluentCloud {
	if i == nil {
		return InputTypeConfluentCloud("")
	}
	return i.Type
}

func (i *InputConfluentCloud) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputConfluentCloud) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputConfluentCloud) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputConfluentCloud) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputConfluentCloud) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputConfluentCloud) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputConfluentCloud) GetConnections() []ConnectionConfluentCloud {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputConfluentCloud) GetPq() *PqConfluentCloud {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputConfluentCloud) GetBrokers() []string {
	if i == nil {
		return []string{}
	}
	return i.Brokers
}

func (i *InputConfluentCloud) GetTLS() *InputTLSSettingsClientSideConfluentCloud {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputConfluentCloud) GetTopics() []string {
	if i == nil {
		return []string{}
	}
	return i.Topics
}

func (i *InputConfluentCloud) GetGroupID() *string {
	if i == nil {
		return nil
	}
	return i.GroupID
}

func (i *InputConfluentCloud) GetFromBeginning() *bool {
	if i == nil {
		return nil
	}
	return i.FromBeginning
}

func (i *InputConfluentCloud) GetKafkaSchemaRegistry() *InputKafkaSchemaRegistryAuthenticationConfluentCloud {
	if i == nil {
		return nil
	}
	return i.KafkaSchemaRegistry
}

func (i *InputConfluentCloud) GetConnectionTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.ConnectionTimeout
}

func (i *InputConfluentCloud) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputConfluentCloud) GetMaxRetries() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxRetries
}

func (i *InputConfluentCloud) GetMaxBackOff() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBackOff
}

func (i *InputConfluentCloud) GetInitialBackoff() *float64 {
	if i == nil {
		return nil
	}
	return i.InitialBackoff
}

func (i *InputConfluentCloud) GetBackoffRate() *float64 {
	if i == nil {
		return nil
	}
	return i.BackoffRate
}

func (i *InputConfluentCloud) GetAuthenticationTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.AuthenticationTimeout
}

func (i *InputConfluentCloud) GetReauthenticationThreshold() *float64 {
	if i == nil {
		return nil
	}
	return i.ReauthenticationThreshold
}

func (i *InputConfluentCloud) GetSasl() *InputAuthenticationConfluentCloud {
	if i == nil {
		return nil
	}
	return i.Sasl
}

func (i *InputConfluentCloud) GetSessionTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SessionTimeout
}

func (i *InputConfluentCloud) GetRebalanceTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RebalanceTimeout
}

func (i *InputConfluentCloud) GetHeartbeatInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.HeartbeatInterval
}

func (i *InputConfluentCloud) GetAutoCommitInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.AutoCommitInterval
}

func (i *InputConfluentCloud) GetAutoCommitThreshold() *float64 {
	if i == nil {
		return nil
	}
	return i.AutoCommitThreshold
}

func (i *InputConfluentCloud) GetMaxBytesPerPartition() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBytesPerPartition
}

func (i *InputConfluentCloud) GetMaxBytes() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBytes
}

func (i *InputConfluentCloud) GetMaxSocketErrors() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxSocketErrors
}

func (i *InputConfluentCloud) GetMetadata() []MetadatumConfluentCloud {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputConfluentCloud) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputConfluentCloud) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputTypeElastic string

const (
	InputTypeElasticElastic InputTypeElastic = "elastic"
)

func (e InputTypeElastic) ToPointer() *InputTypeElastic {
	return &e
}
func (e *InputTypeElastic) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "elastic":
		*e = InputTypeElastic(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeElastic: %v", v)
	}
}

type ConnectionElastic struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionElastic) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionElastic) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// PqModeElastic - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeElastic string

const (
	// PqModeElasticSmart Smart
	PqModeElasticSmart PqModeElastic = "smart"
	// PqModeElasticAlways Always On
	PqModeElasticAlways PqModeElastic = "always"
)

func (e PqModeElastic) ToPointer() *PqModeElastic {
	return &e
}

// PqCompressionElastic - Codec to use to compress the persisted data
type PqCompressionElastic string

const (
	// PqCompressionElasticNone None
	PqCompressionElasticNone PqCompressionElastic = "none"
	// PqCompressionElasticGzip Gzip
	PqCompressionElasticGzip PqCompressionElastic = "gzip"
)

func (e PqCompressionElastic) ToPointer() *PqCompressionElastic {
	return &e
}

type InputPqControlsElastic struct {
}

func (i InputPqControlsElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPqControlsElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqElastic struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeElastic `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *PqCompressionElastic   `default:"none" json:"compress"`
	PqControls *InputPqControlsElastic `json:"pqControls,omitempty"`
}

func (p PqElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqElastic) GetMode() *PqModeElastic {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqElastic) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqElastic) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqElastic) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqElastic) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqElastic) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqElastic) GetCompress() *PqCompressionElastic {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqElastic) GetPqControls() *InputPqControlsElastic {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MinimumTLSVersionElastic string

const (
	MinimumTLSVersionElasticTlSv1  MinimumTLSVersionElastic = "TLSv1"
	MinimumTLSVersionElasticTlSv11 MinimumTLSVersionElastic = "TLSv1.1"
	MinimumTLSVersionElasticTlSv12 MinimumTLSVersionElastic = "TLSv1.2"
	MinimumTLSVersionElasticTlSv13 MinimumTLSVersionElastic = "TLSv1.3"
)

func (e MinimumTLSVersionElastic) ToPointer() *MinimumTLSVersionElastic {
	return &e
}

type MaximumTLSVersionElastic string

const (
	MaximumTLSVersionElasticTlSv1  MaximumTLSVersionElastic = "TLSv1"
	MaximumTLSVersionElasticTlSv11 MaximumTLSVersionElastic = "TLSv1.1"
	MaximumTLSVersionElasticTlSv12 MaximumTLSVersionElastic = "TLSv1.2"
	MaximumTLSVersionElasticTlSv13 MaximumTLSVersionElastic = "TLSv1.3"
)

func (e MaximumTLSVersionElastic) ToPointer() *MaximumTLSVersionElastic {
	return &e
}

type TLSSettingsServerSideElastic struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                   `json:"caPath,omitempty"`
	MinVersion *MinimumTLSVersionElastic `json:"minVersion,omitempty"`
	MaxVersion *MaximumTLSVersionElastic `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideElastic) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideElastic) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideElastic) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideElastic) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideElastic) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideElastic) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideElastic) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideElastic) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideElastic) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideElastic) GetMinVersion() *MinimumTLSVersionElastic {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideElastic) GetMaxVersion() *MaximumTLSVersionElastic {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

type AuthenticationTypeElastic string

const (
	// AuthenticationTypeElasticNone None
	AuthenticationTypeElasticNone AuthenticationTypeElastic = "none"
	// AuthenticationTypeElasticBasic Basic
	AuthenticationTypeElasticBasic AuthenticationTypeElastic = "basic"
	// AuthenticationTypeElasticCredentialsSecret Basic (credentials secret)
	AuthenticationTypeElasticCredentialsSecret AuthenticationTypeElastic = "credentialsSecret"
	// AuthenticationTypeElasticAuthTokens Auth Tokens
	AuthenticationTypeElasticAuthTokens AuthenticationTypeElastic = "authTokens"
)

func (e AuthenticationTypeElastic) ToPointer() *AuthenticationTypeElastic {
	return &e
}

// InputAPIVersion - The API version to use for communicating with the server
type InputAPIVersion string

const (
	// InputAPIVersionSixDot8Dot4 6.8.4
	InputAPIVersionSixDot8Dot4 InputAPIVersion = "6.8.4"
	// InputAPIVersionEightDot3Dot2 8.3.2
	InputAPIVersionEightDot3Dot2 InputAPIVersion = "8.3.2"
	// InputAPIVersionCustom Custom
	InputAPIVersionCustom InputAPIVersion = "custom"
)

func (e InputAPIVersion) ToPointer() *InputAPIVersion {
	return &e
}

type InputExtraHTTPHeader struct {
	Name  *string `json:"name,omitempty"`
	Value string  `json:"value"`
}

func (i InputExtraHTTPHeader) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputExtraHTTPHeader) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"value"}); err != nil {
		return err
	}
	return nil
}

func (i *InputExtraHTTPHeader) GetName() *string {
	if i == nil {
		return nil
	}
	return i.Name
}

func (i *InputExtraHTTPHeader) GetValue() string {
	if i == nil {
		return ""
	}
	return i.Value
}

type MetadatumElastic struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumElastic) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumElastic) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

// ProxyModeAuthenticationMethod - Enter credentials directly, or select a stored secret
type ProxyModeAuthenticationMethod string

const (
	ProxyModeAuthenticationMethodNone   ProxyModeAuthenticationMethod = "none"
	ProxyModeAuthenticationMethodManual ProxyModeAuthenticationMethod = "manual"
	ProxyModeAuthenticationMethodSecret ProxyModeAuthenticationMethod = "secret"
)

func (e ProxyModeAuthenticationMethod) ToPointer() *ProxyModeAuthenticationMethod {
	return &e
}

type ProxyModeElastic struct {
	// Enable proxying of non-bulk API requests to an external Elastic server. Enable this only if you understand the implications. See [Cribl Docs](https://docs.cribl.io/stream/sources-elastic/#proxy-mode) for more details.
	Enabled *bool `default:"false" json:"enabled"`
	// Enter credentials directly, or select a stored secret
	AuthType *ProxyModeAuthenticationMethod `default:"none" json:"authType"`
	Username *string                        `json:"username,omitempty"`
	Password *string                        `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// URL of the Elastic server to proxy non-bulk requests to, such as http://elastic:9200
	URL *string `json:"url,omitempty"`
	// Reject certificates that cannot be verified against a valid CA (such as self-signed certificates)
	RejectUnauthorized *bool `default:"false" json:"rejectUnauthorized"`
	// List of headers to remove from the request to proxy
	RemoveHeaders []string `json:"removeHeaders,omitempty"`
	// Amount of time, in seconds, to wait for a proxy request to complete before canceling it
	TimeoutSec *float64 `default:"60" json:"timeoutSec"`
}

func (p ProxyModeElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *ProxyModeElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *ProxyModeElastic) GetEnabled() *bool {
	if p == nil {
		return nil
	}
	return p.Enabled
}

func (p *ProxyModeElastic) GetAuthType() *ProxyModeAuthenticationMethod {
	if p == nil {
		return nil
	}
	return p.AuthType
}

func (p *ProxyModeElastic) GetUsername() *string {
	if p == nil {
		return nil
	}
	return p.Username
}

func (p *ProxyModeElastic) GetPassword() *string {
	if p == nil {
		return nil
	}
	return p.Password
}

func (p *ProxyModeElastic) GetCredentialsSecret() *string {
	if p == nil {
		return nil
	}
	return p.CredentialsSecret
}

func (p *ProxyModeElastic) GetURL() *string {
	if p == nil {
		return nil
	}
	return p.URL
}

func (p *ProxyModeElastic) GetRejectUnauthorized() *bool {
	if p == nil {
		return nil
	}
	return p.RejectUnauthorized
}

func (p *ProxyModeElastic) GetRemoveHeaders() []string {
	if p == nil {
		return nil
	}
	return p.RemoveHeaders
}

func (p *ProxyModeElastic) GetTimeoutSec() *float64 {
	if p == nil {
		return nil
	}
	return p.TimeoutSec
}

type InputElastic struct {
	// Unique ID for this input
	ID       *string          `json:"id,omitempty"`
	Type     InputTypeElastic `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionElastic `json:"connections,omitempty"`
	Pq          *PqElastic          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                       `json:"port"`
	TLS  *TLSSettingsServerSideElastic `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Elasticsearch API requests. Defaults to /. _bulk will be appended automatically. For example, /myPath becomes /myPath/_bulk. Requests can then be made to either /myPath/_bulk or /myPath/<myIndexName>/_bulk. Other entries are faked as success.
	ElasticAPI *string                    `default:"/" json:"elasticAPI"`
	AuthType   *AuthenticationTypeElastic `default:"none" json:"authType"`
	// The API version to use for communicating with the server
	APIVersion *InputAPIVersion `default:"8.3.2" json:"apiVersion"`
	// Headers to add to all events
	ExtraHTTPHeaders []InputExtraHTTPHeader `json:"extraHttpHeaders,omitempty"`
	// Fields to add to events from this input
	Metadata    []MetadatumElastic `json:"metadata,omitempty"`
	ProxyMode   *ProxyModeElastic  `json:"proxyMode,omitempty"`
	Description *string            `json:"description,omitempty"`
	Username    *string            `json:"username,omitempty"`
	Password    *string            `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Bearer tokens to include in the authorization header
	AuthTokens []string `json:"authTokens,omitempty"`
	// Custom version information to respond to requests
	CustomAPIVersion     *string        `default:"{\n    \"name\": \"AzU84iL\",\n    \"cluster_name\": \"cribl\",\n    \"cluster_uuid\": \"Js6_Z2VKS3KbfRSxPmPbaw\",\n    \"version\": {\n        \"number\": \"8.3.2\",\n        \"build_type\": \"tar\",\n        \"build_hash\": \"bca0c8d\",\n        \"build_date\": \"2019-10-16T06:19:49.319352Z\",\n        \"build_snapshot\": false,\n        \"lucene_version\": \"9.7.2\",\n        \"minimum_wire_compatibility_version\": \"7.17.0\",\n        \"minimum_index_compatibility_version\": \"7.0.0\"\n    },\n    \"tagline\": \"You Know, for Search\"\n}" json:"customAPIVersion"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port"}); err != nil {
		return err
	}
	return nil
}

func (i *InputElastic) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputElastic) GetType() InputTypeElastic {
	if i == nil {
		return InputTypeElastic("")
	}
	return i.Type
}

func (i *InputElastic) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputElastic) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputElastic) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputElastic) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputElastic) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputElastic) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputElastic) GetConnections() []ConnectionElastic {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputElastic) GetPq() *PqElastic {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputElastic) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputElastic) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputElastic) GetTLS() *TLSSettingsServerSideElastic {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputElastic) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputElastic) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputElastic) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputElastic) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputElastic) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputElastic) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputElastic) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputElastic) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputElastic) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputElastic) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputElastic) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputElastic) GetElasticAPI() *string {
	if i == nil {
		return nil
	}
	return i.ElasticAPI
}

func (i *InputElastic) GetAuthType() *AuthenticationTypeElastic {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputElastic) GetAPIVersion() *InputAPIVersion {
	if i == nil {
		return nil
	}
	return i.APIVersion
}

func (i *InputElastic) GetExtraHTTPHeaders() []InputExtraHTTPHeader {
	if i == nil {
		return nil
	}
	return i.ExtraHTTPHeaders
}

func (i *InputElastic) GetMetadata() []MetadatumElastic {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputElastic) GetProxyMode() *ProxyModeElastic {
	if i == nil {
		return nil
	}
	return i.ProxyMode
}

func (i *InputElastic) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputElastic) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputElastic) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputElastic) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputElastic) GetAuthTokens() []string {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputElastic) GetCustomAPIVersion() *string {
	if i == nil {
		return nil
	}
	return i.CustomAPIVersion
}

func (i *InputElastic) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputTypeAzureBlob string

const (
	InputTypeAzureBlobAzureBlob InputTypeAzureBlob = "azure_blob"
)

func (e InputTypeAzureBlob) ToPointer() *InputTypeAzureBlob {
	return &e
}
func (e *InputTypeAzureBlob) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_blob":
		*e = InputTypeAzureBlob(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeAzureBlob: %v", v)
	}
}

type ConnectionAzureBlob struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionAzureBlob) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionAzureBlob) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionAzureBlob) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionAzureBlob) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeAzureBlob - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeAzureBlob string

const (
	// ModeAzureBlobSmart Smart
	ModeAzureBlobSmart ModeAzureBlob = "smart"
	// ModeAzureBlobAlways Always On
	ModeAzureBlobAlways ModeAzureBlob = "always"
)

func (e ModeAzureBlob) ToPointer() *ModeAzureBlob {
	return &e
}

// PqCompressionAzureBlob - Codec to use to compress the persisted data
type PqCompressionAzureBlob string

const (
	// PqCompressionAzureBlobNone None
	PqCompressionAzureBlobNone PqCompressionAzureBlob = "none"
	// PqCompressionAzureBlobGzip Gzip
	PqCompressionAzureBlobGzip PqCompressionAzureBlob = "gzip"
)

func (e PqCompressionAzureBlob) ToPointer() *PqCompressionAzureBlob {
	return &e
}

type PqControlsAzureBlob struct {
}

func (p PqControlsAzureBlob) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsAzureBlob) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqAzureBlob struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeAzureBlob `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *PqCompressionAzureBlob `default:"none" json:"compress"`
	PqControls *PqControlsAzureBlob    `json:"pqControls,omitempty"`
}

func (p PqAzureBlob) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqAzureBlob) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqAzureBlob) GetMode() *ModeAzureBlob {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqAzureBlob) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqAzureBlob) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqAzureBlob) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqAzureBlob) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqAzureBlob) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqAzureBlob) GetCompress() *PqCompressionAzureBlob {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqAzureBlob) GetPqControls() *PqControlsAzureBlob {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MetadatumAzureBlob struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumAzureBlob) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumAzureBlob) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumAzureBlob) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumAzureBlob) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputAuthenticationMethodAzureBlob string

const (
	InputAuthenticationMethodAzureBlobManual       InputAuthenticationMethodAzureBlob = "manual"
	InputAuthenticationMethodAzureBlobSecret       InputAuthenticationMethodAzureBlob = "secret"
	InputAuthenticationMethodAzureBlobClientSecret InputAuthenticationMethodAzureBlob = "clientSecret"
	InputAuthenticationMethodAzureBlobClientCert   InputAuthenticationMethodAzureBlob = "clientCert"
)

func (e InputAuthenticationMethodAzureBlob) ToPointer() *InputAuthenticationMethodAzureBlob {
	return &e
}

type InputCertificate struct {
	// The certificate you registered as credentials for your app in the Azure portal
	CertificateName string `json:"certificateName"`
}

func (i InputCertificate) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCertificate) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"certificateName"}); err != nil {
		return err
	}
	return nil
}

func (i *InputCertificate) GetCertificateName() string {
	if i == nil {
		return ""
	}
	return i.CertificateName
}

type InputAzureBlob struct {
	// Unique ID for this input
	ID       *string            `json:"id,omitempty"`
	Type     InputTypeAzureBlob `json:"type"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionAzureBlob `json:"connections,omitempty"`
	Pq          *PqAzureBlob          `json:"pq,omitempty"`
	// The storage account queue name blob notifications will be read from. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myQueue-${C.vars.myVar}`
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// The duration (in seconds) that the received messages are hidden from subsequent retrieve requests after being retrieved by a ReceiveMessage request.
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// The maximum number of messages to return in a poll request. Azure storage queues never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 32.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// The duration (in seconds) which pollers should be validated and restarted if exited
	ServicePeriodSecs *float64 `default:"5" json:"servicePeriodSecs"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Fields to add to events from this input
	Metadata []MetadatumAzureBlob `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `default:"5" json:"parquetChunkSizeMB"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64                            `default:"600" json:"parquetChunkDownloadTimeout"`
	AuthType                    *InputAuthenticationMethodAzureBlob `default:"manual" json:"authType"`
	Description                 *string                             `json:"description,omitempty"`
	// Enter your Azure Storage account connection string. If left blank, Stream will fall back to env.AZURE_STORAGE_CONNECTION_STRING.
	ConnectionString *string `json:"connectionString,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// The name of your Azure storage account
	StorageAccountName *string `json:"storageAccountName,omitempty"`
	// The service principal's tenant ID
	TenantID *string `json:"tenantId,omitempty"`
	// The service principal's client ID
	ClientID *string `json:"clientId,omitempty"`
	// The Azure cloud to use. Defaults to Azure Public Cloud.
	AzureCloud *string `json:"azureCloud,omitempty"`
	// Endpoint suffix for the service URL. Takes precedence over the Azure Cloud setting. Defaults to core.windows.net.
	EndpointSuffix *string `json:"endpointSuffix,omitempty"`
	// Select or create a stored text secret
	ClientTextSecret     *string           `json:"clientTextSecret,omitempty"`
	Certificate          *InputCertificate `json:"certificate,omitempty"`
	AdditionalProperties map[string]any    `additionalProperties:"true" json:"-"`
}

func (i InputAzureBlob) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAzureBlob) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "queueName"}); err != nil {
		return err
	}
	return nil
}

func (i *InputAzureBlob) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputAzureBlob) GetType() InputTypeAzureBlob {
	if i == nil {
		return InputTypeAzureBlob("")
	}
	return i.Type
}

func (i *InputAzureBlob) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputAzureBlob) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputAzureBlob) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputAzureBlob) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputAzureBlob) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputAzureBlob) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputAzureBlob) GetConnections() []ConnectionAzureBlob {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputAzureBlob) GetPq() *PqAzureBlob {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputAzureBlob) GetQueueName() string {
	if i == nil {
		return ""
	}
	return i.QueueName
}

func (i *InputAzureBlob) GetFileFilter() *string {
	if i == nil {
		return nil
	}
	return i.FileFilter
}

func (i *InputAzureBlob) GetVisibilityTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.VisibilityTimeout
}

func (i *InputAzureBlob) GetNumReceivers() *float64 {
	if i == nil {
		return nil
	}
	return i.NumReceivers
}

func (i *InputAzureBlob) GetMaxMessages() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMessages
}

func (i *InputAzureBlob) GetServicePeriodSecs() *float64 {
	if i == nil {
		return nil
	}
	return i.ServicePeriodSecs
}

func (i *InputAzureBlob) GetSkipOnError() *bool {
	if i == nil {
		return nil
	}
	return i.SkipOnError
}

func (i *InputAzureBlob) GetMetadata() []MetadatumAzureBlob {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputAzureBlob) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputAzureBlob) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputAzureBlob) GetParquetChunkSizeMB() *float64 {
	if i == nil {
		return nil
	}
	return i.ParquetChunkSizeMB
}

func (i *InputAzureBlob) GetParquetChunkDownloadTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.ParquetChunkDownloadTimeout
}

func (i *InputAzureBlob) GetAuthType() *InputAuthenticationMethodAzureBlob {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputAzureBlob) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputAzureBlob) GetConnectionString() *string {
	if i == nil {
		return nil
	}
	return i.ConnectionString
}

func (i *InputAzureBlob) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputAzureBlob) GetStorageAccountName() *string {
	if i == nil {
		return nil
	}
	return i.StorageAccountName
}

func (i *InputAzureBlob) GetTenantID() *string {
	if i == nil {
		return nil
	}
	return i.TenantID
}

func (i *InputAzureBlob) GetClientID() *string {
	if i == nil {
		return nil
	}
	return i.ClientID
}

func (i *InputAzureBlob) GetAzureCloud() *string {
	if i == nil {
		return nil
	}
	return i.AzureCloud
}

func (i *InputAzureBlob) GetEndpointSuffix() *string {
	if i == nil {
		return nil
	}
	return i.EndpointSuffix
}

func (i *InputAzureBlob) GetClientTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.ClientTextSecret
}

func (i *InputAzureBlob) GetCertificate() *InputCertificate {
	if i == nil {
		return nil
	}
	return i.Certificate
}

func (i *InputAzureBlob) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputTypeSplunkHec string

const (
	InputTypeSplunkHecSplunkHec InputTypeSplunkHec = "splunk_hec"
)

func (e InputTypeSplunkHec) ToPointer() *InputTypeSplunkHec {
	return &e
}
func (e *InputTypeSplunkHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk_hec":
		*e = InputTypeSplunkHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeSplunkHec: %v", v)
	}
}

type ConnectionSplunkHec struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionSplunkHec) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionSplunkHec) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// PqModeSplunkHec - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeSplunkHec string

const (
	// PqModeSplunkHecSmart Smart
	PqModeSplunkHecSmart PqModeSplunkHec = "smart"
	// PqModeSplunkHecAlways Always On
	PqModeSplunkHecAlways PqModeSplunkHec = "always"
)

func (e PqModeSplunkHec) ToPointer() *PqModeSplunkHec {
	return &e
}

// PqCompressionSplunkHec - Codec to use to compress the persisted data
type PqCompressionSplunkHec string

const (
	// PqCompressionSplunkHecNone None
	PqCompressionSplunkHecNone PqCompressionSplunkHec = "none"
	// PqCompressionSplunkHecGzip Gzip
	PqCompressionSplunkHecGzip PqCompressionSplunkHec = "gzip"
)

func (e PqCompressionSplunkHec) ToPointer() *PqCompressionSplunkHec {
	return &e
}

type InputPqControlsSplunkHec struct {
}

func (i InputPqControlsSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPqControlsSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqSplunkHec struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeSplunkHec `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *PqCompressionSplunkHec   `default:"none" json:"compress"`
	PqControls *InputPqControlsSplunkHec `json:"pqControls,omitempty"`
}

func (p PqSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqSplunkHec) GetMode() *PqModeSplunkHec {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqSplunkHec) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqSplunkHec) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqSplunkHec) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqSplunkHec) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqSplunkHec) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqSplunkHec) GetCompress() *PqCompressionSplunkHec {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqSplunkHec) GetPqControls() *InputPqControlsSplunkHec {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// AuthTokenAuthenticationMethodSplunkHec - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type AuthTokenAuthenticationMethodSplunkHec string

const (
	AuthTokenAuthenticationMethodSplunkHecManual AuthTokenAuthenticationMethodSplunkHec = "manual"
	AuthTokenAuthenticationMethodSplunkHecSecret AuthTokenAuthenticationMethodSplunkHec = "secret"
)

func (e AuthTokenAuthenticationMethodSplunkHec) ToPointer() *AuthTokenAuthenticationMethodSplunkHec {
	return &e
}

type AuthTokenMetadatumSplunkHec struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (a AuthTokenMetadatumSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokenMetadatumSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokenMetadatumSplunkHec) GetName() string {
	if a == nil {
		return ""
	}
	return a.Name
}

func (a *AuthTokenMetadatumSplunkHec) GetValue() string {
	if a == nil {
		return ""
	}
	return a.Value
}

type AuthTokenSplunkHec struct {
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *AuthTokenAuthenticationMethodSplunkHec `default:"manual" json:"authType"`
	TokenSecret any                                     `json:"tokenSecret,omitempty"`
	Token       any                                     `json:"token"`
	Enabled     *bool                                   `default:"true" json:"enabled"`
	// Optional token description
	Description *string `json:"description,omitempty"`
	// Enter the values you want to allow in the HEC event index field at the token level. Supports wildcards. To skip validation, leave blank.
	AllowedIndexesAtToken []string `json:"allowedIndexesAtToken,omitempty"`
	// Fields to add to events referencing this token
	Metadata []AuthTokenMetadatumSplunkHec `json:"metadata,omitempty"`
}

func (a AuthTokenSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokenSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, []string{"token"}); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokenSplunkHec) GetAuthType() *AuthTokenAuthenticationMethodSplunkHec {
	if a == nil {
		return nil
	}
	return a.AuthType
}

func (a *AuthTokenSplunkHec) GetTokenSecret() any {
	if a == nil {
		return nil
	}
	return a.TokenSecret
}

func (a *AuthTokenSplunkHec) GetToken() any {
	if a == nil {
		return nil
	}
	return a.Token
}

func (a *AuthTokenSplunkHec) GetEnabled() *bool {
	if a == nil {
		return nil
	}
	return a.Enabled
}

func (a *AuthTokenSplunkHec) GetDescription() *string {
	if a == nil {
		return nil
	}
	return a.Description
}

func (a *AuthTokenSplunkHec) GetAllowedIndexesAtToken() []string {
	if a == nil {
		return nil
	}
	return a.AllowedIndexesAtToken
}

func (a *AuthTokenSplunkHec) GetMetadata() []AuthTokenMetadatumSplunkHec {
	if a == nil {
		return nil
	}
	return a.Metadata
}

type InputMinimumTLSVersionSplunkHec string

const (
	InputMinimumTLSVersionSplunkHecTlSv1  InputMinimumTLSVersionSplunkHec = "TLSv1"
	InputMinimumTLSVersionSplunkHecTlSv11 InputMinimumTLSVersionSplunkHec = "TLSv1.1"
	InputMinimumTLSVersionSplunkHecTlSv12 InputMinimumTLSVersionSplunkHec = "TLSv1.2"
	InputMinimumTLSVersionSplunkHecTlSv13 InputMinimumTLSVersionSplunkHec = "TLSv1.3"
)

func (e InputMinimumTLSVersionSplunkHec) ToPointer() *InputMinimumTLSVersionSplunkHec {
	return &e
}

type InputMaximumTLSVersionSplunkHec string

const (
	InputMaximumTLSVersionSplunkHecTlSv1  InputMaximumTLSVersionSplunkHec = "TLSv1"
	InputMaximumTLSVersionSplunkHecTlSv11 InputMaximumTLSVersionSplunkHec = "TLSv1.1"
	InputMaximumTLSVersionSplunkHecTlSv12 InputMaximumTLSVersionSplunkHec = "TLSv1.2"
	InputMaximumTLSVersionSplunkHecTlSv13 InputMaximumTLSVersionSplunkHec = "TLSv1.3"
)

func (e InputMaximumTLSVersionSplunkHec) ToPointer() *InputMaximumTLSVersionSplunkHec {
	return &e
}

type TLSSettingsServerSideSplunkHec struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                          `json:"caPath,omitempty"`
	MinVersion *InputMinimumTLSVersionSplunkHec `json:"minVersion,omitempty"`
	MaxVersion *InputMaximumTLSVersionSplunkHec `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideSplunkHec) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideSplunkHec) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideSplunkHec) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideSplunkHec) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideSplunkHec) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideSplunkHec) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideSplunkHec) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideSplunkHec) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideSplunkHec) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideSplunkHec) GetMinVersion() *InputMinimumTLSVersionSplunkHec {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideSplunkHec) GetMaxVersion() *InputMaximumTLSVersionSplunkHec {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

type MetadatumSplunkHec struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumSplunkHec) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumSplunkHec) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputInputSplunkHec struct {
	// Unique ID for this input
	ID       *string            `json:"id,omitempty"`
	Type     InputTypeSplunkHec `json:"type"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSplunkHec `json:"connections,omitempty"`
	Pq          *PqSplunkHec          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []AuthTokenSplunkHec            `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideSplunkHec `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout  *float64 `default:"5" json:"keepAliveTimeout"`
	EnableHealthCheck any      `json:"enableHealthCheck,omitempty"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for the Splunk HTTP Event Collector API requests. This input supports the /event, /raw and /s2s endpoints.
	SplunkHecAPI *string `default:"/services/collector" json:"splunkHecAPI"`
	// Fields to add to every event. Overrides fields added at the token or request level. See [the Source documentation](https://docs.cribl.io/stream/sources-splunk-hec/#fields) for more info.
	Metadata []MetadatumSplunkHec `json:"metadata,omitempty"`
	// List values allowed in HEC event index field. Leave blank to skip validation. Supports wildcards. The values here can expand index validation at the token level.
	AllowedIndexes []string `json:"allowedIndexes,omitempty"`
	// Enable Splunk HEC acknowledgements
	SplunkHecAcks *bool `default:"false" json:"splunkHecAcks"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Event Breakers will determine events' time zone from UF-provided metadata, when TZ can't be inferred from the raw event
	UseFwdTimezone *bool `default:"true" json:"useFwdTimezone"`
	// Drop Splunk control fields such as `crcSalt` and `_savedPort`. If disabled, control fields are stored in the internal field `__ctrlFields`.
	DropControlFields *bool `default:"true" json:"dropControlFields"`
	// Extract and process Splunk-generated metrics as Cribl metrics
	ExtractMetrics *bool `default:"false" json:"extractMetrics"`
	// Optionally, list HTTP origins to which @{product} should send CORS (cross-origin resource sharing) Access-Control-Allow-* headers. Supports wildcards.
	AccessControlAllowOrigin []string `json:"accessControlAllowOrigin,omitempty"`
	// Optionally, list HTTP headers that @{product} will send to allowed origins as "Access-Control-Allow-Headers" in a CORS preflight response. Use "*" to allow all headers.
	AccessControlAllowHeaders []string `json:"accessControlAllowHeaders,omitempty"`
	// Emit per-token (<prefix>.http.perToken) and summary (<prefix>.http.summary) request metrics
	EmitTokenMetrics     *bool          `default:"false" json:"emitTokenMetrics"`
	Description          *string        `json:"description,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputInputSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputInputSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port"}); err != nil {
		return err
	}
	return nil
}

func (i *InputInputSplunkHec) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputInputSplunkHec) GetType() InputTypeSplunkHec {
	if i == nil {
		return InputTypeSplunkHec("")
	}
	return i.Type
}

func (i *InputInputSplunkHec) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputInputSplunkHec) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputInputSplunkHec) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputInputSplunkHec) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputInputSplunkHec) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputInputSplunkHec) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputInputSplunkHec) GetConnections() []ConnectionSplunkHec {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputInputSplunkHec) GetPq() *PqSplunkHec {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputInputSplunkHec) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputInputSplunkHec) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputInputSplunkHec) GetAuthTokens() []AuthTokenSplunkHec {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputInputSplunkHec) GetTLS() *TLSSettingsServerSideSplunkHec {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputInputSplunkHec) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputInputSplunkHec) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputInputSplunkHec) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputInputSplunkHec) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputInputSplunkHec) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputInputSplunkHec) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputInputSplunkHec) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputInputSplunkHec) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputInputSplunkHec) GetEnableHealthCheck() any {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputInputSplunkHec) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputInputSplunkHec) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputInputSplunkHec) GetSplunkHecAPI() *string {
	if i == nil {
		return nil
	}
	return i.SplunkHecAPI
}

func (i *InputInputSplunkHec) GetMetadata() []MetadatumSplunkHec {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputInputSplunkHec) GetAllowedIndexes() []string {
	if i == nil {
		return nil
	}
	return i.AllowedIndexes
}

func (i *InputInputSplunkHec) GetSplunkHecAcks() *bool {
	if i == nil {
		return nil
	}
	return i.SplunkHecAcks
}

func (i *InputInputSplunkHec) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputInputSplunkHec) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputInputSplunkHec) GetUseFwdTimezone() *bool {
	if i == nil {
		return nil
	}
	return i.UseFwdTimezone
}

func (i *InputInputSplunkHec) GetDropControlFields() *bool {
	if i == nil {
		return nil
	}
	return i.DropControlFields
}

func (i *InputInputSplunkHec) GetExtractMetrics() *bool {
	if i == nil {
		return nil
	}
	return i.ExtractMetrics
}

func (i *InputInputSplunkHec) GetAccessControlAllowOrigin() []string {
	if i == nil {
		return nil
	}
	return i.AccessControlAllowOrigin
}

func (i *InputInputSplunkHec) GetAccessControlAllowHeaders() []string {
	if i == nil {
		return nil
	}
	return i.AccessControlAllowHeaders
}

func (i *InputInputSplunkHec) GetEmitTokenMetrics() *bool {
	if i == nil {
		return nil
	}
	return i.EmitTokenMetrics
}

func (i *InputInputSplunkHec) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputInputSplunkHec) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeSplunkSearch string

const (
	TypeSplunkSearchSplunkSearch TypeSplunkSearch = "splunk_search"
)

func (e TypeSplunkSearch) ToPointer() *TypeSplunkSearch {
	return &e
}
func (e *TypeSplunkSearch) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk_search":
		*e = TypeSplunkSearch(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeSplunkSearch: %v", v)
	}
}

type ConnectionSplunkSearch struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionSplunkSearch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionSplunkSearch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionSplunkSearch) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionSplunkSearch) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeSplunkSearch - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeSplunkSearch string

const (
	// ModeSplunkSearchSmart Smart
	ModeSplunkSearchSmart ModeSplunkSearch = "smart"
	// ModeSplunkSearchAlways Always On
	ModeSplunkSearchAlways ModeSplunkSearch = "always"
)

func (e ModeSplunkSearch) ToPointer() *ModeSplunkSearch {
	return &e
}

// CompressionSplunkSearch - Codec to use to compress the persisted data
type CompressionSplunkSearch string

const (
	// CompressionSplunkSearchNone None
	CompressionSplunkSearchNone CompressionSplunkSearch = "none"
	// CompressionSplunkSearchGzip Gzip
	CompressionSplunkSearchGzip CompressionSplunkSearch = "gzip"
)

func (e CompressionSplunkSearch) ToPointer() *CompressionSplunkSearch {
	return &e
}

type PqControlsSplunkSearch struct {
}

func (p PqControlsSplunkSearch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsSplunkSearch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqSplunkSearch struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeSplunkSearch `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionSplunkSearch `default:"none" json:"compress"`
	PqControls *PqControlsSplunkSearch  `json:"pqControls,omitempty"`
}

func (p PqSplunkSearch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSplunkSearch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqSplunkSearch) GetMode() *ModeSplunkSearch {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqSplunkSearch) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqSplunkSearch) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqSplunkSearch) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqSplunkSearch) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqSplunkSearch) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqSplunkSearch) GetCompress() *CompressionSplunkSearch {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqSplunkSearch) GetPqControls() *PqControlsSplunkSearch {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// OutputMode - Format of the returned output
type OutputMode string

const (
	OutputModeCsv  OutputMode = "csv"
	OutputModeJSON OutputMode = "json"
)

func (e OutputMode) ToPointer() *OutputMode {
	return &e
}

type EndpointParam struct {
	Name string `json:"name"`
	// JavaScript expression to compute the parameter's value, normally enclosed in backticks (e.g., `${earliest}`). If a constant, use single quotes (e.g., 'earliest'). Values without delimiters (e.g., earliest) are evaluated as strings.
	Value string `json:"value"`
}

func (e EndpointParam) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(e, "", false)
}

func (e *EndpointParam) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &e, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (e *EndpointParam) GetName() string {
	if e == nil {
		return ""
	}
	return e.Name
}

func (e *EndpointParam) GetValue() string {
	if e == nil {
		return ""
	}
	return e.Value
}

type EndpointHeader struct {
	Name string `json:"name"`
	// JavaScript expression to compute the header's value, normally enclosed in backticks (e.g., `${earliest}`). If a constant, use single quotes (e.g., 'earliest'). Values without delimiters (e.g., earliest) are evaluated as strings.
	Value string `json:"value"`
}

func (e EndpointHeader) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(e, "", false)
}

func (e *EndpointHeader) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &e, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (e *EndpointHeader) GetName() string {
	if e == nil {
		return ""
	}
	return e.Name
}

func (e *EndpointHeader) GetValue() string {
	if e == nil {
		return ""
	}
	return e.Value
}

// LogLevelSplunkSearch - Collector runtime log level (verbosity)
type LogLevelSplunkSearch string

const (
	LogLevelSplunkSearchError LogLevelSplunkSearch = "error"
	LogLevelSplunkSearchWarn  LogLevelSplunkSearch = "warn"
	LogLevelSplunkSearchInfo  LogLevelSplunkSearch = "info"
	LogLevelSplunkSearchDebug LogLevelSplunkSearch = "debug"
)

func (e LogLevelSplunkSearch) ToPointer() *LogLevelSplunkSearch {
	return &e
}

type MetadatumSplunkSearch struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumSplunkSearch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumSplunkSearch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumSplunkSearch) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumSplunkSearch) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

// RetryTypeSplunkSearch - The algorithm to use when performing HTTP retries
type RetryTypeSplunkSearch string

const (
	// RetryTypeSplunkSearchNone Disabled
	RetryTypeSplunkSearchNone RetryTypeSplunkSearch = "none"
	// RetryTypeSplunkSearchBackoff Backoff
	RetryTypeSplunkSearchBackoff RetryTypeSplunkSearch = "backoff"
	// RetryTypeSplunkSearchStatic Static
	RetryTypeSplunkSearchStatic RetryTypeSplunkSearch = "static"
)

func (e RetryTypeSplunkSearch) ToPointer() *RetryTypeSplunkSearch {
	return &e
}

type RetryRulesSplunkSearch struct {
	// The algorithm to use when performing HTTP retries
	Type *RetryTypeSplunkSearch `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of HTTP codes that trigger a retry. Leave empty to use the default list of 429 and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (r RetryRulesSplunkSearch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RetryRulesSplunkSearch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (r *RetryRulesSplunkSearch) GetType() *RetryTypeSplunkSearch {
	if r == nil {
		return nil
	}
	return r.Type
}

func (r *RetryRulesSplunkSearch) GetInterval() *float64 {
	if r == nil {
		return nil
	}
	return r.Interval
}

func (r *RetryRulesSplunkSearch) GetLimit() *float64 {
	if r == nil {
		return nil
	}
	return r.Limit
}

func (r *RetryRulesSplunkSearch) GetMultiplier() *float64 {
	if r == nil {
		return nil
	}
	return r.Multiplier
}

func (r *RetryRulesSplunkSearch) GetCodes() []float64 {
	if r == nil {
		return nil
	}
	return r.Codes
}

func (r *RetryRulesSplunkSearch) GetEnableHeader() *bool {
	if r == nil {
		return nil
	}
	return r.EnableHeader
}

func (r *RetryRulesSplunkSearch) GetRetryConnectTimeout() *bool {
	if r == nil {
		return nil
	}
	return r.RetryConnectTimeout
}

func (r *RetryRulesSplunkSearch) GetRetryConnectReset() *bool {
	if r == nil {
		return nil
	}
	return r.RetryConnectReset
}

// AuthenticationTypeSplunkSearch - Splunk Search authentication type
type AuthenticationTypeSplunkSearch string

const (
	AuthenticationTypeSplunkSearchNone              AuthenticationTypeSplunkSearch = "none"
	AuthenticationTypeSplunkSearchBasic             AuthenticationTypeSplunkSearch = "basic"
	AuthenticationTypeSplunkSearchCredentialsSecret AuthenticationTypeSplunkSearch = "credentialsSecret"
	AuthenticationTypeSplunkSearchToken             AuthenticationTypeSplunkSearch = "token"
	AuthenticationTypeSplunkSearchTextSecret        AuthenticationTypeSplunkSearch = "textSecret"
	AuthenticationTypeSplunkSearchOauth             AuthenticationTypeSplunkSearch = "oauth"
)

func (e AuthenticationTypeSplunkSearch) ToPointer() *AuthenticationTypeSplunkSearch {
	return &e
}

type OauthParamSplunkSearch struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o OauthParamSplunkSearch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OauthParamSplunkSearch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (o *OauthParamSplunkSearch) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthParamSplunkSearch) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OauthHeaderSplunkSearch struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o OauthHeaderSplunkSearch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OauthHeaderSplunkSearch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (o *OauthHeaderSplunkSearch) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthHeaderSplunkSearch) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSplunkSearch struct {
	// Unique ID for this input
	ID       *string          `json:"id,omitempty"`
	Type     TypeSplunkSearch `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSplunkSearch `json:"connections,omitempty"`
	Pq          *PqSplunkSearch          `json:"pq,omitempty"`
	// Search head base URL. Can be an expression. Default is https://localhost:8089.
	SearchHead *string `default:"https://localhost:8089" json:"searchHead"`
	// Enter Splunk search here. Examples: 'index=myAppLogs level=error channel=myApp' OR '| mstats avg(myStat) as myStat WHERE index=myStatsIndex.'
	Search string `json:"search"`
	// The earliest time boundary for the search. Can be an exact or relative time. Examples: '2022-01-14T12:00:00Z' or '-16m@m'
	Earliest *string `default:"-16m@m" json:"earliest"`
	// The latest time boundary for the search. Can be an exact or relative time. Examples: '2022-01-14T12:00:00Z' or '-1m@m'
	Latest *string `default:"-1m@m" json:"latest"`
	// A cron schedule on which to run this job
	CronSchedule *string `default:"*/15 * * * *" json:"cronSchedule"`
	// REST API used to create a search
	Endpoint *string `default:"/services/search/v2/jobs/export" json:"endpoint"`
	// Format of the returned output
	OutputMode *OutputMode `default:"json" json:"outputMode"`
	// Optional request parameters to send to the endpoint
	EndpointParams []EndpointParam `json:"endpointParams,omitempty"`
	// Optional request headers to send to the endpoint
	EndpointHeaders []EndpointHeader `json:"endpointHeaders,omitempty"`
	// Collector runtime log level (verbosity)
	LogLevel *LogLevelSplunkSearch `json:"logLevel,omitempty"`
	// HTTP request inactivity timeout. Use 0 for no timeout.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Reject certificates that cannot be verified against a valid CA (such as self-signed certificates)
	RejectUnauthorized *bool `default:"false" json:"rejectUnauthorized"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding *string `json:"encoding,omitempty"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
	IgnoreGroupJobsLimit *bool `default:"false" json:"ignoreGroupJobsLimit"`
	// Fields to add to events from this input
	Metadata   []MetadatumSplunkSearch `json:"metadata,omitempty"`
	RetryRules *RetryRulesSplunkSearch `json:"retryRules,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Splunk Search authentication type
	AuthType    *AuthenticationTypeSplunkSearch `default:"basic" json:"authType"`
	Description *string                         `json:"description,omitempty"`
	Username    *string                         `json:"username,omitempty"`
	Password    *string                         `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []OauthParamSplunkSearch `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders         []OauthHeaderSplunkSearch `json:"oauthHeaders,omitempty"`
	AdditionalProperties map[string]any            `additionalProperties:"true" json:"-"`
}

func (i InputSplunkSearch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunkSearch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "search"}); err != nil {
		return err
	}
	return nil
}

func (i *InputSplunkSearch) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputSplunkSearch) GetType() TypeSplunkSearch {
	if i == nil {
		return TypeSplunkSearch("")
	}
	return i.Type
}

func (i *InputSplunkSearch) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSplunkSearch) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSplunkSearch) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputSplunkSearch) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputSplunkSearch) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputSplunkSearch) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputSplunkSearch) GetConnections() []ConnectionSplunkSearch {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputSplunkSearch) GetPq() *PqSplunkSearch {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputSplunkSearch) GetSearchHead() *string {
	if i == nil {
		return nil
	}
	return i.SearchHead
}

func (i *InputSplunkSearch) GetSearch() string {
	if i == nil {
		return ""
	}
	return i.Search
}

func (i *InputSplunkSearch) GetEarliest() *string {
	if i == nil {
		return nil
	}
	return i.Earliest
}

func (i *InputSplunkSearch) GetLatest() *string {
	if i == nil {
		return nil
	}
	return i.Latest
}

func (i *InputSplunkSearch) GetCronSchedule() *string {
	if i == nil {
		return nil
	}
	return i.CronSchedule
}

func (i *InputSplunkSearch) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputSplunkSearch) GetOutputMode() *OutputMode {
	if i == nil {
		return nil
	}
	return i.OutputMode
}

func (i *InputSplunkSearch) GetEndpointParams() []EndpointParam {
	if i == nil {
		return nil
	}
	return i.EndpointParams
}

func (i *InputSplunkSearch) GetEndpointHeaders() []EndpointHeader {
	if i == nil {
		return nil
	}
	return i.EndpointHeaders
}

func (i *InputSplunkSearch) GetLogLevel() *LogLevelSplunkSearch {
	if i == nil {
		return nil
	}
	return i.LogLevel
}

func (i *InputSplunkSearch) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputSplunkSearch) GetUseRoundRobinDNS() *bool {
	if i == nil {
		return nil
	}
	return i.UseRoundRobinDNS
}

func (i *InputSplunkSearch) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputSplunkSearch) GetEncoding() *string {
	if i == nil {
		return nil
	}
	return i.Encoding
}

func (i *InputSplunkSearch) GetKeepAliveTime() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTime
}

func (i *InputSplunkSearch) GetJobTimeout() *string {
	if i == nil {
		return nil
	}
	return i.JobTimeout
}

func (i *InputSplunkSearch) GetMaxMissedKeepAlives() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMissedKeepAlives
}

func (i *InputSplunkSearch) GetTTL() *string {
	if i == nil {
		return nil
	}
	return i.TTL
}

func (i *InputSplunkSearch) GetIgnoreGroupJobsLimit() *bool {
	if i == nil {
		return nil
	}
	return i.IgnoreGroupJobsLimit
}

func (i *InputSplunkSearch) GetMetadata() []MetadatumSplunkSearch {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputSplunkSearch) GetRetryRules() *RetryRulesSplunkSearch {
	if i == nil {
		return nil
	}
	return i.RetryRules
}

func (i *InputSplunkSearch) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputSplunkSearch) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputSplunkSearch) GetAuthType() *AuthenticationTypeSplunkSearch {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputSplunkSearch) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputSplunkSearch) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputSplunkSearch) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputSplunkSearch) GetToken() *string {
	if i == nil {
		return nil
	}
	return i.Token
}

func (i *InputSplunkSearch) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputSplunkSearch) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputSplunkSearch) GetLoginURL() *string {
	if i == nil {
		return nil
	}
	return i.LoginURL
}

func (i *InputSplunkSearch) GetSecretParamName() *string {
	if i == nil {
		return nil
	}
	return i.SecretParamName
}

func (i *InputSplunkSearch) GetSecret() *string {
	if i == nil {
		return nil
	}
	return i.Secret
}

func (i *InputSplunkSearch) GetTokenAttributeName() *string {
	if i == nil {
		return nil
	}
	return i.TokenAttributeName
}

func (i *InputSplunkSearch) GetAuthHeaderExpr() *string {
	if i == nil {
		return nil
	}
	return i.AuthHeaderExpr
}

func (i *InputSplunkSearch) GetTokenTimeoutSecs() *float64 {
	if i == nil {
		return nil
	}
	return i.TokenTimeoutSecs
}

func (i *InputSplunkSearch) GetOauthParams() []OauthParamSplunkSearch {
	if i == nil {
		return nil
	}
	return i.OauthParams
}

func (i *InputSplunkSearch) GetOauthHeaders() []OauthHeaderSplunkSearch {
	if i == nil {
		return nil
	}
	return i.OauthHeaders
}

func (i *InputSplunkSearch) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputTypeSplunk string

const (
	InputTypeSplunkSplunk InputTypeSplunk = "splunk"
)

func (e InputTypeSplunk) ToPointer() *InputTypeSplunk {
	return &e
}
func (e *InputTypeSplunk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk":
		*e = InputTypeSplunk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeSplunk: %v", v)
	}
}

type ConnectionSplunk struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionSplunk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionSplunk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionSplunk) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionSplunk) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// PqModeSplunk - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeSplunk string

const (
	// PqModeSplunkSmart Smart
	PqModeSplunkSmart PqModeSplunk = "smart"
	// PqModeSplunkAlways Always On
	PqModeSplunkAlways PqModeSplunk = "always"
)

func (e PqModeSplunk) ToPointer() *PqModeSplunk {
	return &e
}

// PqCompressionSplunk - Codec to use to compress the persisted data
type PqCompressionSplunk string

const (
	// PqCompressionSplunkNone None
	PqCompressionSplunkNone PqCompressionSplunk = "none"
	// PqCompressionSplunkGzip Gzip
	PqCompressionSplunkGzip PqCompressionSplunk = "gzip"
)

func (e PqCompressionSplunk) ToPointer() *PqCompressionSplunk {
	return &e
}

type InputPqControlsSplunk struct {
}

func (i InputPqControlsSplunk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPqControlsSplunk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqSplunk struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeSplunk `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *PqCompressionSplunk   `default:"none" json:"compress"`
	PqControls *InputPqControlsSplunk `json:"pqControls,omitempty"`
}

func (p PqSplunk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSplunk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqSplunk) GetMode() *PqModeSplunk {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqSplunk) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqSplunk) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqSplunk) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqSplunk) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqSplunk) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqSplunk) GetCompress() *PqCompressionSplunk {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqSplunk) GetPqControls() *InputPqControlsSplunk {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type InputMinimumTLSVersionSplunk string

const (
	InputMinimumTLSVersionSplunkTlSv1  InputMinimumTLSVersionSplunk = "TLSv1"
	InputMinimumTLSVersionSplunkTlSv11 InputMinimumTLSVersionSplunk = "TLSv1.1"
	InputMinimumTLSVersionSplunkTlSv12 InputMinimumTLSVersionSplunk = "TLSv1.2"
	InputMinimumTLSVersionSplunkTlSv13 InputMinimumTLSVersionSplunk = "TLSv1.3"
)

func (e InputMinimumTLSVersionSplunk) ToPointer() *InputMinimumTLSVersionSplunk {
	return &e
}

type InputMaximumTLSVersionSplunk string

const (
	InputMaximumTLSVersionSplunkTlSv1  InputMaximumTLSVersionSplunk = "TLSv1"
	InputMaximumTLSVersionSplunkTlSv11 InputMaximumTLSVersionSplunk = "TLSv1.1"
	InputMaximumTLSVersionSplunkTlSv12 InputMaximumTLSVersionSplunk = "TLSv1.2"
	InputMaximumTLSVersionSplunkTlSv13 InputMaximumTLSVersionSplunk = "TLSv1.3"
)

func (e InputMaximumTLSVersionSplunk) ToPointer() *InputMaximumTLSVersionSplunk {
	return &e
}

type TLSSettingsServerSideSplunk struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                       `json:"caPath,omitempty"`
	MinVersion *InputMinimumTLSVersionSplunk `json:"minVersion,omitempty"`
	MaxVersion *InputMaximumTLSVersionSplunk `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideSplunk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideSplunk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideSplunk) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideSplunk) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideSplunk) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideSplunk) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideSplunk) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideSplunk) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideSplunk) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideSplunk) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideSplunk) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideSplunk) GetMinVersion() *InputMinimumTLSVersionSplunk {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideSplunk) GetMaxVersion() *InputMaximumTLSVersionSplunk {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

type MetadatumSplunk struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumSplunk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumSplunk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumSplunk) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumSplunk) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type AuthTokenSplunk struct {
	// Shared secrets to be provided by any Splunk forwarder. If empty, unauthorized access is permitted.
	Token       string  `json:"token"`
	Description *string `json:"description,omitempty"`
}

func (a AuthTokenSplunk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokenSplunk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, []string{"token"}); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokenSplunk) GetToken() string {
	if a == nil {
		return ""
	}
	return a.Token
}

func (a *AuthTokenSplunk) GetDescription() *string {
	if a == nil {
		return nil
	}
	return a.Description
}

// InputMaxS2SVersion - The highest S2S protocol version to advertise during handshake
type InputMaxS2SVersion string

const (
	// InputMaxS2SVersionV3 v3
	InputMaxS2SVersionV3 InputMaxS2SVersion = "v3"
	// InputMaxS2SVersionV4 v4
	InputMaxS2SVersionV4 InputMaxS2SVersion = "v4"
)

func (e InputMaxS2SVersion) ToPointer() *InputMaxS2SVersion {
	return &e
}

// InputCompressionSplunk - Controls whether to support reading compressed data from a forwarder. Select 'Automatic' to match the forwarder's configuration, or 'Disabled' to reject compressed connections.
type InputCompressionSplunk string

const (
	// InputCompressionSplunkDisabled Disabled
	InputCompressionSplunkDisabled InputCompressionSplunk = "disabled"
	// InputCompressionSplunkAuto Automatic
	InputCompressionSplunkAuto InputCompressionSplunk = "auto"
	// InputCompressionSplunkAlways Always
	InputCompressionSplunkAlways InputCompressionSplunk = "always"
)

func (e InputCompressionSplunk) ToPointer() *InputCompressionSplunk {
	return &e
}

type InputSplunk struct {
	// Unique ID for this input
	ID       *string         `json:"id,omitempty"`
	Type     InputTypeSplunk `json:"type"`
	Disabled *bool           `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSplunk `json:"connections,omitempty"`
	Pq          *PqSplunk          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                      `json:"port"`
	TLS  *TLSSettingsServerSideSplunk `json:"tls,omitempty"`
	// Regex matching IP addresses that are allowed to establish a connection
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `default:"0" json:"socketMaxLifespan"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Fields to add to events from this input
	Metadata []MetadatumSplunk `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Shared secrets to be provided by any Splunk forwarder. If empty, unauthorized access is permitted.
	AuthTokens []AuthTokenSplunk `json:"authTokens,omitempty"`
	// The highest S2S protocol version to advertise during handshake
	MaxS2Sversion *InputMaxS2SVersion `default:"v3" json:"maxS2Sversion"`
	Description   *string             `json:"description,omitempty"`
	// Event Breakers will determine events' time zone from UF-provided metadata, when TZ can't be inferred from the raw event
	UseFwdTimezone *bool `default:"true" json:"useFwdTimezone"`
	// Drop Splunk control fields such as `crcSalt` and `_savedPort`. If disabled, control fields are stored in the internal field `__ctrlFields`.
	DropControlFields *bool `default:"true" json:"dropControlFields"`
	// Extract and process Splunk-generated metrics as Cribl metrics
	ExtractMetrics *bool `default:"false" json:"extractMetrics"`
	// Controls whether to support reading compressed data from a forwarder. Select 'Automatic' to match the forwarder's configuration, or 'Disabled' to reject compressed connections.
	Compress             *InputCompressionSplunk `default:"disabled" json:"compress"`
	AdditionalProperties map[string]any          `additionalProperties:"true" json:"-"`
}

func (i InputSplunk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port"}); err != nil {
		return err
	}
	return nil
}

func (i *InputSplunk) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputSplunk) GetType() InputTypeSplunk {
	if i == nil {
		return InputTypeSplunk("")
	}
	return i.Type
}

func (i *InputSplunk) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSplunk) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSplunk) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputSplunk) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputSplunk) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputSplunk) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputSplunk) GetConnections() []ConnectionSplunk {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputSplunk) GetPq() *PqSplunk {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputSplunk) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputSplunk) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputSplunk) GetTLS() *TLSSettingsServerSideSplunk {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputSplunk) GetIPWhitelistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPWhitelistRegex
}

func (i *InputSplunk) GetMaxActiveCxn() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveCxn
}

func (i *InputSplunk) GetSocketIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketIdleTimeout
}

func (i *InputSplunk) GetSocketEndingMaxWait() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketEndingMaxWait
}

func (i *InputSplunk) GetSocketMaxLifespan() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketMaxLifespan
}

func (i *InputSplunk) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputSplunk) GetMetadata() []MetadatumSplunk {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputSplunk) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputSplunk) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputSplunk) GetAuthTokens() []AuthTokenSplunk {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputSplunk) GetMaxS2Sversion() *InputMaxS2SVersion {
	if i == nil {
		return nil
	}
	return i.MaxS2Sversion
}

func (i *InputSplunk) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputSplunk) GetUseFwdTimezone() *bool {
	if i == nil {
		return nil
	}
	return i.UseFwdTimezone
}

func (i *InputSplunk) GetDropControlFields() *bool {
	if i == nil {
		return nil
	}
	return i.DropControlFields
}

func (i *InputSplunk) GetExtractMetrics() *bool {
	if i == nil {
		return nil
	}
	return i.ExtractMetrics
}

func (i *InputSplunk) GetCompress() *InputCompressionSplunk {
	if i == nil {
		return nil
	}
	return i.Compress
}

func (i *InputSplunk) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type TypeHTTP string

const (
	TypeHTTPHTTP TypeHTTP = "http"
)

func (e TypeHTTP) ToPointer() *TypeHTTP {
	return &e
}
func (e *TypeHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http":
		*e = TypeHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeHTTP: %v", v)
	}
}

type ConnectionHTTP struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionHTTP) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionHTTP) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeHTTP - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeHTTP string

const (
	// ModeHTTPSmart Smart
	ModeHTTPSmart ModeHTTP = "smart"
	// ModeHTTPAlways Always On
	ModeHTTPAlways ModeHTTP = "always"
)

func (e ModeHTTP) ToPointer() *ModeHTTP {
	return &e
}

// CompressionHTTP - Codec to use to compress the persisted data
type CompressionHTTP string

const (
	// CompressionHTTPNone None
	CompressionHTTPNone CompressionHTTP = "none"
	// CompressionHTTPGzip Gzip
	CompressionHTTPGzip CompressionHTTP = "gzip"
)

func (e CompressionHTTP) ToPointer() *CompressionHTTP {
	return &e
}

type PqControlsHTTP struct {
}

func (p PqControlsHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqHTTP struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeHTTP `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionHTTP `default:"none" json:"compress"`
	PqControls *PqControlsHTTP  `json:"pqControls,omitempty"`
}

func (p PqHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqHTTP) GetMode() *ModeHTTP {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqHTTP) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqHTTP) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqHTTP) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqHTTP) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqHTTP) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqHTTP) GetCompress() *CompressionHTTP {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqHTTP) GetPqControls() *PqControlsHTTP {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MinimumTLSVersionHTTP string

const (
	MinimumTLSVersionHTTPTlSv1  MinimumTLSVersionHTTP = "TLSv1"
	MinimumTLSVersionHTTPTlSv11 MinimumTLSVersionHTTP = "TLSv1.1"
	MinimumTLSVersionHTTPTlSv12 MinimumTLSVersionHTTP = "TLSv1.2"
	MinimumTLSVersionHTTPTlSv13 MinimumTLSVersionHTTP = "TLSv1.3"
)

func (e MinimumTLSVersionHTTP) ToPointer() *MinimumTLSVersionHTTP {
	return &e
}

type MaximumTLSVersionHTTP string

const (
	MaximumTLSVersionHTTPTlSv1  MaximumTLSVersionHTTP = "TLSv1"
	MaximumTLSVersionHTTPTlSv11 MaximumTLSVersionHTTP = "TLSv1.1"
	MaximumTLSVersionHTTPTlSv12 MaximumTLSVersionHTTP = "TLSv1.2"
	MaximumTLSVersionHTTPTlSv13 MaximumTLSVersionHTTP = "TLSv1.3"
)

func (e MaximumTLSVersionHTTP) ToPointer() *MaximumTLSVersionHTTP {
	return &e
}

type TLSSettingsServerSideHTTP struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert *bool `default:"false" json:"requestCert"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath     *string                `json:"caPath,omitempty"`
	MinVersion *MinimumTLSVersionHTTP `json:"minVersion,omitempty"`
	MaxVersion *MaximumTLSVersionHTTP `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *TLSSettingsServerSideHTTP) GetDisabled() *bool {
	if t == nil {
		return nil
	}
	return t.Disabled
}

func (t *TLSSettingsServerSideHTTP) GetRequestCert() *bool {
	if t == nil {
		return nil
	}
	return t.RequestCert
}

func (t *TLSSettingsServerSideHTTP) GetRejectUnauthorized() *bool {
	if t == nil {
		return nil
	}
	return t.RejectUnauthorized
}

func (t *TLSSettingsServerSideHTTP) GetCommonNameRegex() *string {
	if t == nil {
		return nil
	}
	return t.CommonNameRegex
}

func (t *TLSSettingsServerSideHTTP) GetCertificateName() *string {
	if t == nil {
		return nil
	}
	return t.CertificateName
}

func (t *TLSSettingsServerSideHTTP) GetPrivKeyPath() *string {
	if t == nil {
		return nil
	}
	return t.PrivKeyPath
}

func (t *TLSSettingsServerSideHTTP) GetPassphrase() *string {
	if t == nil {
		return nil
	}
	return t.Passphrase
}

func (t *TLSSettingsServerSideHTTP) GetCertPath() *string {
	if t == nil {
		return nil
	}
	return t.CertPath
}

func (t *TLSSettingsServerSideHTTP) GetCaPath() *string {
	if t == nil {
		return nil
	}
	return t.CaPath
}

func (t *TLSSettingsServerSideHTTP) GetMinVersion() *MinimumTLSVersionHTTP {
	if t == nil {
		return nil
	}
	return t.MinVersion
}

func (t *TLSSettingsServerSideHTTP) GetMaxVersion() *MaximumTLSVersionHTTP {
	if t == nil {
		return nil
	}
	return t.MaxVersion
}

type MetadatumHTTP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumHTTP) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumHTTP) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type AuthTokensExtMetadatumHTTP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (a AuthTokensExtMetadatumHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokensExtMetadatumHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokensExtMetadatumHTTP) GetName() string {
	if a == nil {
		return ""
	}
	return a.Name
}

func (a *AuthTokensExtMetadatumHTTP) GetValue() string {
	if a == nil {
		return ""
	}
	return a.Value
}

type AuthTokensExtHTTP struct {
	// Shared secret to be provided by any client (Authorization: <token>)
	Token       string  `json:"token"`
	Description *string `json:"description,omitempty"`
	// Fields to add to events referencing this token
	Metadata []AuthTokensExtMetadatumHTTP `json:"metadata,omitempty"`
}

func (a AuthTokensExtHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokensExtHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, []string{"token"}); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokensExtHTTP) GetToken() string {
	if a == nil {
		return ""
	}
	return a.Token
}

func (a *AuthTokensExtHTTP) GetDescription() *string {
	if a == nil {
		return nil
	}
	return a.Description
}

func (a *AuthTokensExtHTTP) GetMetadata() []AuthTokensExtMetadatumHTTP {
	if a == nil {
		return nil
	}
	return a.Metadata
}

type InputHTTP struct {
	// Unique ID for this input
	ID       *string  `json:"id,omitempty"`
	Type     TypeHTTP `json:"type"`
	Disabled *bool    `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionHTTP `json:"connections,omitempty"`
	Pq          *PqHTTP          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                   `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideHTTP `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for the Cribl HTTP API requests. Only _bulk (default /cribl/_bulk) is available. Use empty string to disable.
	CriblAPI *string `default:"/cribl" json:"criblAPI"`
	// Absolute path on which to listen for the Elasticsearch API requests. Only _bulk (default /elastic/_bulk) is available. Use empty string to disable.
	ElasticAPI *string `default:"/elastic" json:"elasticAPI"`
	// Absolute path on which listen for the Splunk HTTP Event Collector API requests. Use empty string to disable.
	SplunkHecAPI  *string `default:"/services/collector" json:"splunkHecAPI"`
	SplunkHecAcks *bool   `default:"false" json:"splunkHecAcks"`
	// Fields to add to events from this input
	Metadata []MetadatumHTTP `json:"metadata,omitempty"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokensExt        []AuthTokensExtHTTP `json:"authTokensExt,omitempty"`
	Description          *string             `json:"description,omitempty"`
	AdditionalProperties map[string]any      `additionalProperties:"true" json:"-"`
}

func (i InputHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "port"}); err != nil {
		return err
	}
	return nil
}

func (i *InputHTTP) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputHTTP) GetType() TypeHTTP {
	if i == nil {
		return TypeHTTP("")
	}
	return i.Type
}

func (i *InputHTTP) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputHTTP) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputHTTP) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputHTTP) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputHTTP) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputHTTP) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputHTTP) GetConnections() []ConnectionHTTP {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputHTTP) GetPq() *PqHTTP {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputHTTP) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputHTTP) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputHTTP) GetAuthTokens() []string {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputHTTP) GetTLS() *TLSSettingsServerSideHTTP {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputHTTP) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputHTTP) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputHTTP) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputHTTP) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputHTTP) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputHTTP) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputHTTP) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputHTTP) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputHTTP) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputHTTP) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputHTTP) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputHTTP) GetCriblAPI() *string {
	if i == nil {
		return nil
	}
	return i.CriblAPI
}

func (i *InputHTTP) GetElasticAPI() *string {
	if i == nil {
		return nil
	}
	return i.ElasticAPI
}

func (i *InputHTTP) GetSplunkHecAPI() *string {
	if i == nil {
		return nil
	}
	return i.SplunkHecAPI
}

func (i *InputHTTP) GetSplunkHecAcks() *bool {
	if i == nil {
		return nil
	}
	return i.SplunkHecAcks
}

func (i *InputHTTP) GetMetadata() []MetadatumHTTP {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputHTTP) GetAuthTokensExt() []AuthTokensExtHTTP {
	if i == nil {
		return nil
	}
	return i.AuthTokensExt
}

func (i *InputHTTP) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputHTTP) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputTypeMsk string

const (
	InputTypeMskMsk InputTypeMsk = "msk"
)

func (e InputTypeMsk) ToPointer() *InputTypeMsk {
	return &e
}
func (e *InputTypeMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "msk":
		*e = InputTypeMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeMsk: %v", v)
	}
}

type ConnectionMsk struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionMsk) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionMsk) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// PqModeMsk - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeMsk string

const (
	// PqModeMskSmart Smart
	PqModeMskSmart PqModeMsk = "smart"
	// PqModeMskAlways Always On
	PqModeMskAlways PqModeMsk = "always"
)

func (e PqModeMsk) ToPointer() *PqModeMsk {
	return &e
}

// PqCompressionMsk - Codec to use to compress the persisted data
type PqCompressionMsk string

const (
	// PqCompressionMskNone None
	PqCompressionMskNone PqCompressionMsk = "none"
	// PqCompressionMskGzip Gzip
	PqCompressionMskGzip PqCompressionMsk = "gzip"
)

func (e PqCompressionMsk) ToPointer() *PqCompressionMsk {
	return &e
}

type InputPqControlsMsk struct {
}

func (i InputPqControlsMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPqControlsMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqMsk struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeMsk `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *PqCompressionMsk   `default:"none" json:"compress"`
	PqControls *InputPqControlsMsk `json:"pqControls,omitempty"`
}

func (p PqMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqMsk) GetMode() *PqModeMsk {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqMsk) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqMsk) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqMsk) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqMsk) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqMsk) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqMsk) GetCompress() *PqCompressionMsk {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqMsk) GetPqControls() *InputPqControlsMsk {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type MetadatumMsk struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumMsk) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumMsk) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

// InputAuthMsk - Credentials to use when authenticating with the schema registry using basic HTTP authentication
type InputAuthMsk struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (i InputAuthMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAuthMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputAuthMsk) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputAuthMsk) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

type InputKafkaSchemaRegistryMinimumTLSVersionMsk string

const (
	InputKafkaSchemaRegistryMinimumTLSVersionMskTlSv1  InputKafkaSchemaRegistryMinimumTLSVersionMsk = "TLSv1"
	InputKafkaSchemaRegistryMinimumTLSVersionMskTlSv11 InputKafkaSchemaRegistryMinimumTLSVersionMsk = "TLSv1.1"
	InputKafkaSchemaRegistryMinimumTLSVersionMskTlSv12 InputKafkaSchemaRegistryMinimumTLSVersionMsk = "TLSv1.2"
	InputKafkaSchemaRegistryMinimumTLSVersionMskTlSv13 InputKafkaSchemaRegistryMinimumTLSVersionMsk = "TLSv1.3"
)

func (e InputKafkaSchemaRegistryMinimumTLSVersionMsk) ToPointer() *InputKafkaSchemaRegistryMinimumTLSVersionMsk {
	return &e
}

type InputKafkaSchemaRegistryMaximumTLSVersionMsk string

const (
	InputKafkaSchemaRegistryMaximumTLSVersionMskTlSv1  InputKafkaSchemaRegistryMaximumTLSVersionMsk = "TLSv1"
	InputKafkaSchemaRegistryMaximumTLSVersionMskTlSv11 InputKafkaSchemaRegistryMaximumTLSVersionMsk = "TLSv1.1"
	InputKafkaSchemaRegistryMaximumTLSVersionMskTlSv12 InputKafkaSchemaRegistryMaximumTLSVersionMsk = "TLSv1.2"
	InputKafkaSchemaRegistryMaximumTLSVersionMskTlSv13 InputKafkaSchemaRegistryMaximumTLSVersionMsk = "TLSv1.3"
)

func (e InputKafkaSchemaRegistryMaximumTLSVersionMsk) ToPointer() *InputKafkaSchemaRegistryMaximumTLSVersionMsk {
	return &e
}

type InputKafkaSchemaRegistryTLSSettingsClientSideMsk struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certificates that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string                                       `json:"passphrase,omitempty"`
	MinVersion *InputKafkaSchemaRegistryMinimumTLSVersionMsk `json:"minVersion,omitempty"`
	MaxVersion *InputKafkaSchemaRegistryMaximumTLSVersionMsk `json:"maxVersion,omitempty"`
}

func (i InputKafkaSchemaRegistryTLSSettingsClientSideMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetServername() *string {
	if i == nil {
		return nil
	}
	return i.Servername
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetCertificateName() *string {
	if i == nil {
		return nil
	}
	return i.CertificateName
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetCaPath() *string {
	if i == nil {
		return nil
	}
	return i.CaPath
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetPrivKeyPath() *string {
	if i == nil {
		return nil
	}
	return i.PrivKeyPath
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetCertPath() *string {
	if i == nil {
		return nil
	}
	return i.CertPath
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetPassphrase() *string {
	if i == nil {
		return nil
	}
	return i.Passphrase
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetMinVersion() *InputKafkaSchemaRegistryMinimumTLSVersionMsk {
	if i == nil {
		return nil
	}
	return i.MinVersion
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetMaxVersion() *InputKafkaSchemaRegistryMaximumTLSVersionMsk {
	if i == nil {
		return nil
	}
	return i.MaxVersion
}

type InputKafkaSchemaRegistryAuthenticationMsk struct {
	Disabled *bool `default:"true" json:"disabled"`
	// URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
	SchemaRegistryURL *string `default:"http://localhost:8081" json:"schemaRegistryURL"`
	// Maximum time to wait for a Schema Registry connection to complete successfully
	ConnectionTimeout *float64 `default:"30000" json:"connectionTimeout"`
	// Maximum time to wait for the Schema Registry to respond to a request
	RequestTimeout *float64 `default:"30000" json:"requestTimeout"`
	// Maximum number of times to try fetching schemas from the Schema Registry
	MaxRetries *float64 `default:"1" json:"maxRetries"`
	// Credentials to use when authenticating with the schema registry using basic HTTP authentication
	Auth *InputAuthMsk                                     `json:"auth,omitempty"`
	TLS  *InputKafkaSchemaRegistryTLSSettingsClientSideMsk `json:"tls,omitempty"`
}

func (i InputKafkaSchemaRegistryAuthenticationMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafkaSchemaRegistryAuthenticationMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputKafkaSchemaRegistryAuthenticationMsk) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKafkaSchemaRegistryAuthenticationMsk) GetSchemaRegistryURL() *string {
	if i == nil {
		return nil
	}
	return i.SchemaRegistryURL
}

func (i *InputKafkaSchemaRegistryAuthenticationMsk) GetConnectionTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.ConnectionTimeout
}

func (i *InputKafkaSchemaRegistryAuthenticationMsk) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputKafkaSchemaRegistryAuthenticationMsk) GetMaxRetries() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxRetries
}

func (i *InputKafkaSchemaRegistryAuthenticationMsk) GetAuth() *InputAuthMsk {
	if i == nil {
		return nil
	}
	return i.Auth
}

func (i *InputKafkaSchemaRegistryAuthenticationMsk) GetTLS() *InputKafkaSchemaRegistryTLSSettingsClientSideMsk {
	if i == nil {
		return nil
	}
	return i.TLS
}

// InputAuthenticationMethodMsk - AWS authentication method. Choose Auto to use IAM roles.
type InputAuthenticationMethodMsk string

const (
	// InputAuthenticationMethodMskAuto Auto
	InputAuthenticationMethodMskAuto InputAuthenticationMethodMsk = "auto"
	// InputAuthenticationMethodMskManual Manual
	InputAuthenticationMethodMskManual InputAuthenticationMethodMsk = "manual"
	// InputAuthenticationMethodMskSecret Secret Key pair
	InputAuthenticationMethodMskSecret InputAuthenticationMethodMsk = "secret"
)

func (e InputAuthenticationMethodMsk) ToPointer() *InputAuthenticationMethodMsk {
	return &e
}

// InputSignatureVersionMsk - Signature version to use for signing MSK cluster requests
type InputSignatureVersionMsk string

const (
	InputSignatureVersionMskV2 InputSignatureVersionMsk = "v2"
	InputSignatureVersionMskV4 InputSignatureVersionMsk = "v4"
)

func (e InputSignatureVersionMsk) ToPointer() *InputSignatureVersionMsk {
	return &e
}

type InputMinimumTLSVersionMsk string

const (
	InputMinimumTLSVersionMskTlSv1  InputMinimumTLSVersionMsk = "TLSv1"
	InputMinimumTLSVersionMskTlSv11 InputMinimumTLSVersionMsk = "TLSv1.1"
	InputMinimumTLSVersionMskTlSv12 InputMinimumTLSVersionMsk = "TLSv1.2"
	InputMinimumTLSVersionMskTlSv13 InputMinimumTLSVersionMsk = "TLSv1.3"
)

func (e InputMinimumTLSVersionMsk) ToPointer() *InputMinimumTLSVersionMsk {
	return &e
}

type InputMaximumTLSVersionMsk string

const (
	InputMaximumTLSVersionMskTlSv1  InputMaximumTLSVersionMsk = "TLSv1"
	InputMaximumTLSVersionMskTlSv11 InputMaximumTLSVersionMsk = "TLSv1.1"
	InputMaximumTLSVersionMskTlSv12 InputMaximumTLSVersionMsk = "TLSv1.2"
	InputMaximumTLSVersionMskTlSv13 InputMaximumTLSVersionMsk = "TLSv1.3"
)

func (e InputMaximumTLSVersionMsk) ToPointer() *InputMaximumTLSVersionMsk {
	return &e
}

type InputTLSSettingsClientSideMsk struct {
	Disabled *bool `default:"false" json:"disabled"`
	// Reject certificates that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string                    `json:"passphrase,omitempty"`
	MinVersion *InputMinimumTLSVersionMsk `json:"minVersion,omitempty"`
	MaxVersion *InputMaximumTLSVersionMsk `json:"maxVersion,omitempty"`
}

func (i InputTLSSettingsClientSideMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTLSSettingsClientSideMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputTLSSettingsClientSideMsk) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputTLSSettingsClientSideMsk) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputTLSSettingsClientSideMsk) GetServername() *string {
	if i == nil {
		return nil
	}
	return i.Servername
}

func (i *InputTLSSettingsClientSideMsk) GetCertificateName() *string {
	if i == nil {
		return nil
	}
	return i.CertificateName
}

func (i *InputTLSSettingsClientSideMsk) GetCaPath() *string {
	if i == nil {
		return nil
	}
	return i.CaPath
}

func (i *InputTLSSettingsClientSideMsk) GetPrivKeyPath() *string {
	if i == nil {
		return nil
	}
	return i.PrivKeyPath
}

func (i *InputTLSSettingsClientSideMsk) GetCertPath() *string {
	if i == nil {
		return nil
	}
	return i.CertPath
}

func (i *InputTLSSettingsClientSideMsk) GetPassphrase() *string {
	if i == nil {
		return nil
	}
	return i.Passphrase
}

func (i *InputTLSSettingsClientSideMsk) GetMinVersion() *InputMinimumTLSVersionMsk {
	if i == nil {
		return nil
	}
	return i.MinVersion
}

func (i *InputTLSSettingsClientSideMsk) GetMaxVersion() *InputMaximumTLSVersionMsk {
	if i == nil {
		return nil
	}
	return i.MaxVersion
}

type InputMsk struct {
	// Unique ID for this input
	ID       *string      `json:"id,omitempty"`
	Type     InputTypeMsk `json:"type"`
	Disabled *bool        `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionMsk `json:"connections,omitempty"`
	Pq          *PqMsk          `json:"pq,omitempty"`
	// Enter each Kafka bootstrap server you want to use. Specify the hostname and port (such as mykafkabroker:9092) or just the hostname (in which case @{product} will assign port 9092).
	Brokers []string `json:"brokers"`
	// Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to a single topic only.
	Topics []string `json:"topics"`
	// The consumer group to which this instance belongs. Defaults to 'Cribl'.
	GroupID *string `default:"Cribl" json:"groupId"`
	// Leave enabled if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
	FromBeginning *bool `default:"true" json:"fromBeginning"`
	//       Timeout used to detect client failures when using Kafka's group-management facilities.
	//       If the client sends no heartbeats to the broker before the timeout expires,
	//       the broker will remove the client from the group and initiate a rebalance.
	//       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms) for details.
	SessionTimeout *float64 `default:"30000" json:"sessionTimeout"`
	//       Maximum allowed time for each worker to join the group after a rebalance begins.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms) for details.
	RebalanceTimeout *float64 `default:"60000" json:"rebalanceTimeout"`
	//       Expected time between heartbeats to the consumer coordinator when using Kafka's group-management facilities.
	//       Value must be lower than sessionTimeout and typically should not exceed 1/3 of the sessionTimeout value.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms) for details.
	HeartbeatInterval *float64 `default:"3000" json:"heartbeatInterval"`
	// Fields to add to events from this input
	Metadata            []MetadatumMsk                             `json:"metadata,omitempty"`
	KafkaSchemaRegistry *InputKafkaSchemaRegistryAuthenticationMsk `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *InputAuthenticationMethodMsk `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                       `json:"awsSecretKey,omitempty"`
	// Region where the MSK cluster is located
	Region string `json:"region"`
	// MSK cluster service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to MSK cluster-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing MSK cluster requests
	SignatureVersion *InputSignatureVersionMsk `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access MSK
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64                       `default:"3600" json:"durationSeconds"`
	TLS             *InputTLSSettingsClientSideMsk `json:"tls,omitempty"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitempty"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitempty"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `default:"1048576" json:"maxBytesPerPartition"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `default:"10485760" json:"maxBytes"`
	// Maximum number of network errors before the consumer re-creates a socket
	MaxSocketErrors *float64 `default:"0" json:"maxSocketErrors"`
	Description     *string  `json:"description,omitempty"`
	AwsAPIKey       *string  `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret            *string        `json:"awsSecret,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "brokers", "topics", "region"}); err != nil {
		return err
	}
	return nil
}

func (i *InputMsk) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputMsk) GetType() InputTypeMsk {
	if i == nil {
		return InputTypeMsk("")
	}
	return i.Type
}

func (i *InputMsk) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputMsk) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputMsk) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputMsk) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputMsk) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputMsk) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputMsk) GetConnections() []ConnectionMsk {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputMsk) GetPq() *PqMsk {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputMsk) GetBrokers() []string {
	if i == nil {
		return []string{}
	}
	return i.Brokers
}

func (i *InputMsk) GetTopics() []string {
	if i == nil {
		return []string{}
	}
	return i.Topics
}

func (i *InputMsk) GetGroupID() *string {
	if i == nil {
		return nil
	}
	return i.GroupID
}

func (i *InputMsk) GetFromBeginning() *bool {
	if i == nil {
		return nil
	}
	return i.FromBeginning
}

func (i *InputMsk) GetSessionTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SessionTimeout
}

func (i *InputMsk) GetRebalanceTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RebalanceTimeout
}

func (i *InputMsk) GetHeartbeatInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.HeartbeatInterval
}

func (i *InputMsk) GetMetadata() []MetadatumMsk {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputMsk) GetKafkaSchemaRegistry() *InputKafkaSchemaRegistryAuthenticationMsk {
	if i == nil {
		return nil
	}
	return i.KafkaSchemaRegistry
}

func (i *InputMsk) GetConnectionTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.ConnectionTimeout
}

func (i *InputMsk) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputMsk) GetMaxRetries() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxRetries
}

func (i *InputMsk) GetMaxBackOff() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBackOff
}

func (i *InputMsk) GetInitialBackoff() *float64 {
	if i == nil {
		return nil
	}
	return i.InitialBackoff
}

func (i *InputMsk) GetBackoffRate() *float64 {
	if i == nil {
		return nil
	}
	return i.BackoffRate
}

func (i *InputMsk) GetAuthenticationTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.AuthenticationTimeout
}

func (i *InputMsk) GetReauthenticationThreshold() *float64 {
	if i == nil {
		return nil
	}
	return i.ReauthenticationThreshold
}

func (i *InputMsk) GetAwsAuthenticationMethod() *InputAuthenticationMethodMsk {
	if i == nil {
		return nil
	}
	return i.AwsAuthenticationMethod
}

func (i *InputMsk) GetAwsSecretKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecretKey
}

func (i *InputMsk) GetRegion() string {
	if i == nil {
		return ""
	}
	return i.Region
}

func (i *InputMsk) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputMsk) GetSignatureVersion() *InputSignatureVersionMsk {
	if i == nil {
		return nil
	}
	return i.SignatureVersion
}

func (i *InputMsk) GetReuseConnections() *bool {
	if i == nil {
		return nil
	}
	return i.ReuseConnections
}

func (i *InputMsk) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputMsk) GetEnableAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableAssumeRole
}

func (i *InputMsk) GetAssumeRoleArn() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleArn
}

func (i *InputMsk) GetAssumeRoleExternalID() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleExternalID
}

func (i *InputMsk) GetDurationSeconds() *float64 {
	if i == nil {
		return nil
	}
	return i.DurationSeconds
}

func (i *InputMsk) GetTLS() *InputTLSSettingsClientSideMsk {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputMsk) GetAutoCommitInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.AutoCommitInterval
}

func (i *InputMsk) GetAutoCommitThreshold() *float64 {
	if i == nil {
		return nil
	}
	return i.AutoCommitThreshold
}

func (i *InputMsk) GetMaxBytesPerPartition() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBytesPerPartition
}

func (i *InputMsk) GetMaxBytes() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBytes
}

func (i *InputMsk) GetMaxSocketErrors() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxSocketErrors
}

func (i *InputMsk) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputMsk) GetAwsAPIKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsAPIKey
}

func (i *InputMsk) GetAwsSecret() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecret
}

func (i *InputMsk) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputTypeKafka string

const (
	InputTypeKafkaKafka InputTypeKafka = "kafka"
)

func (e InputTypeKafka) ToPointer() *InputTypeKafka {
	return &e
}
func (e *InputTypeKafka) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kafka":
		*e = InputTypeKafka(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeKafka: %v", v)
	}
}

type ConnectionKafka struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionKafka) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionKafka) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// PqModeKafka - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeKafka string

const (
	// PqModeKafkaSmart Smart
	PqModeKafkaSmart PqModeKafka = "smart"
	// PqModeKafkaAlways Always On
	PqModeKafkaAlways PqModeKafka = "always"
)

func (e PqModeKafka) ToPointer() *PqModeKafka {
	return &e
}

// PqCompressionKafka - Codec to use to compress the persisted data
type PqCompressionKafka string

const (
	// PqCompressionKafkaNone None
	PqCompressionKafkaNone PqCompressionKafka = "none"
	// PqCompressionKafkaGzip Gzip
	PqCompressionKafkaGzip PqCompressionKafka = "gzip"
)

func (e PqCompressionKafka) ToPointer() *PqCompressionKafka {
	return &e
}

type InputPqControlsKafka struct {
}

func (i InputPqControlsKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPqControlsKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqKafka struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeKafka `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *PqCompressionKafka   `default:"none" json:"compress"`
	PqControls *InputPqControlsKafka `json:"pqControls,omitempty"`
}

func (p PqKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqKafka) GetMode() *PqModeKafka {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqKafka) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqKafka) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqKafka) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqKafka) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqKafka) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqKafka) GetCompress() *PqCompressionKafka {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqKafka) GetPqControls() *InputPqControlsKafka {
	if p == nil {
		return nil
	}
	return p.PqControls
}

// InputAuthKafka - Credentials to use when authenticating with the schema registry using basic HTTP authentication
type InputAuthKafka struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (i InputAuthKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAuthKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputAuthKafka) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputAuthKafka) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

type InputKafkaSchemaRegistryMinimumTLSVersionKafka string

const (
	InputKafkaSchemaRegistryMinimumTLSVersionKafkaTlSv1  InputKafkaSchemaRegistryMinimumTLSVersionKafka = "TLSv1"
	InputKafkaSchemaRegistryMinimumTLSVersionKafkaTlSv11 InputKafkaSchemaRegistryMinimumTLSVersionKafka = "TLSv1.1"
	InputKafkaSchemaRegistryMinimumTLSVersionKafkaTlSv12 InputKafkaSchemaRegistryMinimumTLSVersionKafka = "TLSv1.2"
	InputKafkaSchemaRegistryMinimumTLSVersionKafkaTlSv13 InputKafkaSchemaRegistryMinimumTLSVersionKafka = "TLSv1.3"
)

func (e InputKafkaSchemaRegistryMinimumTLSVersionKafka) ToPointer() *InputKafkaSchemaRegistryMinimumTLSVersionKafka {
	return &e
}

type InputKafkaSchemaRegistryMaximumTLSVersionKafka string

const (
	InputKafkaSchemaRegistryMaximumTLSVersionKafkaTlSv1  InputKafkaSchemaRegistryMaximumTLSVersionKafka = "TLSv1"
	InputKafkaSchemaRegistryMaximumTLSVersionKafkaTlSv11 InputKafkaSchemaRegistryMaximumTLSVersionKafka = "TLSv1.1"
	InputKafkaSchemaRegistryMaximumTLSVersionKafkaTlSv12 InputKafkaSchemaRegistryMaximumTLSVersionKafka = "TLSv1.2"
	InputKafkaSchemaRegistryMaximumTLSVersionKafkaTlSv13 InputKafkaSchemaRegistryMaximumTLSVersionKafka = "TLSv1.3"
)

func (e InputKafkaSchemaRegistryMaximumTLSVersionKafka) ToPointer() *InputKafkaSchemaRegistryMaximumTLSVersionKafka {
	return &e
}

type InputKafkaSchemaRegistryTLSSettingsClientSideKafka struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certificates that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string                                         `json:"passphrase,omitempty"`
	MinVersion *InputKafkaSchemaRegistryMinimumTLSVersionKafka `json:"minVersion,omitempty"`
	MaxVersion *InputKafkaSchemaRegistryMaximumTLSVersionKafka `json:"maxVersion,omitempty"`
}

func (i InputKafkaSchemaRegistryTLSSettingsClientSideKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetServername() *string {
	if i == nil {
		return nil
	}
	return i.Servername
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetCertificateName() *string {
	if i == nil {
		return nil
	}
	return i.CertificateName
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetCaPath() *string {
	if i == nil {
		return nil
	}
	return i.CaPath
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetPrivKeyPath() *string {
	if i == nil {
		return nil
	}
	return i.PrivKeyPath
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetCertPath() *string {
	if i == nil {
		return nil
	}
	return i.CertPath
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetPassphrase() *string {
	if i == nil {
		return nil
	}
	return i.Passphrase
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetMinVersion() *InputKafkaSchemaRegistryMinimumTLSVersionKafka {
	if i == nil {
		return nil
	}
	return i.MinVersion
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetMaxVersion() *InputKafkaSchemaRegistryMaximumTLSVersionKafka {
	if i == nil {
		return nil
	}
	return i.MaxVersion
}

type InputKafkaSchemaRegistryAuthenticationKafka struct {
	Disabled *bool `default:"true" json:"disabled"`
	// URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
	SchemaRegistryURL *string `default:"http://localhost:8081" json:"schemaRegistryURL"`
	// Maximum time to wait for a Schema Registry connection to complete successfully
	ConnectionTimeout *float64 `default:"30000" json:"connectionTimeout"`
	// Maximum time to wait for the Schema Registry to respond to a request
	RequestTimeout *float64 `default:"30000" json:"requestTimeout"`
	// Maximum number of times to try fetching schemas from the Schema Registry
	MaxRetries *float64 `default:"1" json:"maxRetries"`
	// Credentials to use when authenticating with the schema registry using basic HTTP authentication
	Auth *InputAuthKafka                                     `json:"auth,omitempty"`
	TLS  *InputKafkaSchemaRegistryTLSSettingsClientSideKafka `json:"tls,omitempty"`
}

func (i InputKafkaSchemaRegistryAuthenticationKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafkaSchemaRegistryAuthenticationKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputKafkaSchemaRegistryAuthenticationKafka) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKafkaSchemaRegistryAuthenticationKafka) GetSchemaRegistryURL() *string {
	if i == nil {
		return nil
	}
	return i.SchemaRegistryURL
}

func (i *InputKafkaSchemaRegistryAuthenticationKafka) GetConnectionTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.ConnectionTimeout
}

func (i *InputKafkaSchemaRegistryAuthenticationKafka) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputKafkaSchemaRegistryAuthenticationKafka) GetMaxRetries() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxRetries
}

func (i *InputKafkaSchemaRegistryAuthenticationKafka) GetAuth() *InputAuthKafka {
	if i == nil {
		return nil
	}
	return i.Auth
}

func (i *InputKafkaSchemaRegistryAuthenticationKafka) GetTLS() *InputKafkaSchemaRegistryTLSSettingsClientSideKafka {
	if i == nil {
		return nil
	}
	return i.TLS
}

// InputAuthenticationMethodKafka - Enter credentials directly, or select a stored secret
type InputAuthenticationMethodKafka string

const (
	InputAuthenticationMethodKafkaManual InputAuthenticationMethodKafka = "manual"
	InputAuthenticationMethodKafkaSecret InputAuthenticationMethodKafka = "secret"
)

func (e InputAuthenticationMethodKafka) ToPointer() *InputAuthenticationMethodKafka {
	return &e
}

type InputSASLMechanismKafka string

const (
	// InputSASLMechanismKafkaPlain PLAIN
	InputSASLMechanismKafkaPlain InputSASLMechanismKafka = "plain"
	// InputSASLMechanismKafkaScramSha256 SCRAM-SHA-256
	InputSASLMechanismKafkaScramSha256 InputSASLMechanismKafka = "scram-sha-256"
	// InputSASLMechanismKafkaScramSha512 SCRAM-SHA-512
	InputSASLMechanismKafkaScramSha512 InputSASLMechanismKafka = "scram-sha-512"
	// InputSASLMechanismKafkaKerberos GSSAPI/Kerberos
	InputSASLMechanismKafkaKerberos InputSASLMechanismKafka = "kerberos"
)

func (e InputSASLMechanismKafka) ToPointer() *InputSASLMechanismKafka {
	return &e
}

type InputOauthParamKafka struct {
	Name  string `json:"name"`
	Value string `json:"value"`
}

func (i InputOauthParamKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOauthParamKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (i *InputOauthParamKafka) GetName() string {
	if i == nil {
		return ""
	}
	return i.Name
}

func (i *InputOauthParamKafka) GetValue() string {
	if i == nil {
		return ""
	}
	return i.Value
}

type InputSaslExtensionKafka struct {
	Name  string `json:"name"`
	Value string `json:"value"`
}

func (i InputSaslExtensionKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSaslExtensionKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (i *InputSaslExtensionKafka) GetName() string {
	if i == nil {
		return ""
	}
	return i.Name
}

func (i *InputSaslExtensionKafka) GetValue() string {
	if i == nil {
		return ""
	}
	return i.Value
}

// InputAuthenticationKafka - Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type InputAuthenticationKafka struct {
	Disabled *bool   `default:"true" json:"disabled"`
	Username *string `json:"username,omitempty"`
	Password *string `json:"password,omitempty"`
	// Enter credentials directly, or select a stored secret
	AuthType *InputAuthenticationMethodKafka `default:"manual" json:"authType"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string                  `json:"credentialsSecret,omitempty"`
	Mechanism         *InputSASLMechanismKafka `default:"plain" json:"mechanism"`
	// Location of keytab file for authentication principal
	KeytabLocation *string `json:"keytabLocation,omitempty"`
	// Authentication principal, such as `kafka_user@example.com`
	Principal *string `json:"principal,omitempty"`
	// Kerberos service class for Kafka brokers, such as `kafka`
	BrokerServiceClass *string `json:"brokerServiceClass,omitempty"`
	// Enable OAuth authentication
	OauthEnabled *bool `default:"false" json:"oauthEnabled"`
	// URL of the token endpoint to use for OAuth authentication
	TokenURL *string `json:"tokenUrl,omitempty"`
	// Client ID to use for OAuth authentication
	ClientID        *string `json:"clientId,omitempty"`
	OauthSecretType *string `default:"secret" json:"oauthSecretType"`
	// Select or create a stored text secret
	ClientTextSecret *string `json:"clientTextSecret,omitempty"`
	// Additional fields to send to the token endpoint, such as scope or audience
	OauthParams []InputOauthParamKafka `json:"oauthParams,omitempty"`
	// Additional SASL extension fields, such as Confluent's logicalCluster or identityPoolId
	SaslExtensions []InputSaslExtensionKafka `json:"saslExtensions,omitempty"`
}

func (i InputAuthenticationKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAuthenticationKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputAuthenticationKafka) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputAuthenticationKafka) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputAuthenticationKafka) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputAuthenticationKafka) GetAuthType() *InputAuthenticationMethodKafka {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputAuthenticationKafka) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputAuthenticationKafka) GetMechanism() *InputSASLMechanismKafka {
	if i == nil {
		return nil
	}
	return i.Mechanism
}

func (i *InputAuthenticationKafka) GetKeytabLocation() *string {
	if i == nil {
		return nil
	}
	return i.KeytabLocation
}

func (i *InputAuthenticationKafka) GetPrincipal() *string {
	if i == nil {
		return nil
	}
	return i.Principal
}

func (i *InputAuthenticationKafka) GetBrokerServiceClass() *string {
	if i == nil {
		return nil
	}
	return i.BrokerServiceClass
}

func (i *InputAuthenticationKafka) GetOauthEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.OauthEnabled
}

func (i *InputAuthenticationKafka) GetTokenURL() *string {
	if i == nil {
		return nil
	}
	return i.TokenURL
}

func (i *InputAuthenticationKafka) GetClientID() *string {
	if i == nil {
		return nil
	}
	return i.ClientID
}

func (i *InputAuthenticationKafka) GetOauthSecretType() *string {
	if i == nil {
		return nil
	}
	return i.OauthSecretType
}

func (i *InputAuthenticationKafka) GetClientTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.ClientTextSecret
}

func (i *InputAuthenticationKafka) GetOauthParams() []InputOauthParamKafka {
	if i == nil {
		return nil
	}
	return i.OauthParams
}

func (i *InputAuthenticationKafka) GetSaslExtensions() []InputSaslExtensionKafka {
	if i == nil {
		return nil
	}
	return i.SaslExtensions
}

type InputMinimumTLSVersionKafka string

const (
	InputMinimumTLSVersionKafkaTlSv1  InputMinimumTLSVersionKafka = "TLSv1"
	InputMinimumTLSVersionKafkaTlSv11 InputMinimumTLSVersionKafka = "TLSv1.1"
	InputMinimumTLSVersionKafkaTlSv12 InputMinimumTLSVersionKafka = "TLSv1.2"
	InputMinimumTLSVersionKafkaTlSv13 InputMinimumTLSVersionKafka = "TLSv1.3"
)

func (e InputMinimumTLSVersionKafka) ToPointer() *InputMinimumTLSVersionKafka {
	return &e
}

type InputMaximumTLSVersionKafka string

const (
	InputMaximumTLSVersionKafkaTlSv1  InputMaximumTLSVersionKafka = "TLSv1"
	InputMaximumTLSVersionKafkaTlSv11 InputMaximumTLSVersionKafka = "TLSv1.1"
	InputMaximumTLSVersionKafkaTlSv12 InputMaximumTLSVersionKafka = "TLSv1.2"
	InputMaximumTLSVersionKafkaTlSv13 InputMaximumTLSVersionKafka = "TLSv1.3"
)

func (e InputMaximumTLSVersionKafka) ToPointer() *InputMaximumTLSVersionKafka {
	return &e
}

type InputTLSSettingsClientSideKafka struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certificates that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string                      `json:"passphrase,omitempty"`
	MinVersion *InputMinimumTLSVersionKafka `json:"minVersion,omitempty"`
	MaxVersion *InputMaximumTLSVersionKafka `json:"maxVersion,omitempty"`
}

func (i InputTLSSettingsClientSideKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTLSSettingsClientSideKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputTLSSettingsClientSideKafka) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputTLSSettingsClientSideKafka) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputTLSSettingsClientSideKafka) GetServername() *string {
	if i == nil {
		return nil
	}
	return i.Servername
}

func (i *InputTLSSettingsClientSideKafka) GetCertificateName() *string {
	if i == nil {
		return nil
	}
	return i.CertificateName
}

func (i *InputTLSSettingsClientSideKafka) GetCaPath() *string {
	if i == nil {
		return nil
	}
	return i.CaPath
}

func (i *InputTLSSettingsClientSideKafka) GetPrivKeyPath() *string {
	if i == nil {
		return nil
	}
	return i.PrivKeyPath
}

func (i *InputTLSSettingsClientSideKafka) GetCertPath() *string {
	if i == nil {
		return nil
	}
	return i.CertPath
}

func (i *InputTLSSettingsClientSideKafka) GetPassphrase() *string {
	if i == nil {
		return nil
	}
	return i.Passphrase
}

func (i *InputTLSSettingsClientSideKafka) GetMinVersion() *InputMinimumTLSVersionKafka {
	if i == nil {
		return nil
	}
	return i.MinVersion
}

func (i *InputTLSSettingsClientSideKafka) GetMaxVersion() *InputMaximumTLSVersionKafka {
	if i == nil {
		return nil
	}
	return i.MaxVersion
}

type MetadatumKafka struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumKafka) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumKafka) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputKafka struct {
	// Unique ID for this input
	ID       *string        `json:"id,omitempty"`
	Type     InputTypeKafka `json:"type"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionKafka `json:"connections,omitempty"`
	Pq          *PqKafka          `json:"pq,omitempty"`
	// Enter each Kafka bootstrap server you want to use. Specify the hostname and port (such as mykafkabroker:9092) or just the hostname (in which case @{product} will assign port 9092).
	Brokers []string `json:"brokers"`
	// Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to a single topic only.
	Topics []string `json:"topics"`
	// The consumer group to which this instance belongs. Defaults to 'Cribl'.
	GroupID *string `default:"Cribl" json:"groupId"`
	// Leave enabled if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
	FromBeginning       *bool                                        `default:"true" json:"fromBeginning"`
	KafkaSchemaRegistry *InputKafkaSchemaRegistryAuthenticationKafka `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *InputAuthenticationKafka        `json:"sasl,omitempty"`
	TLS  *InputTLSSettingsClientSideKafka `json:"tls,omitempty"`
	//       Timeout used to detect client failures when using Kafka's group-management facilities.
	//       If the client sends no heartbeats to the broker before the timeout expires,
	//       the broker will remove the client from the group and initiate a rebalance.
	//       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms) for details.
	SessionTimeout *float64 `default:"30000" json:"sessionTimeout"`
	//       Maximum allowed time for each worker to join the group after a rebalance begins.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms) for details.
	RebalanceTimeout *float64 `default:"60000" json:"rebalanceTimeout"`
	//       Expected time between heartbeats to the consumer coordinator when using Kafka's group-management facilities.
	//       Value must be lower than sessionTimeout and typically should not exceed 1/3 of the sessionTimeout value.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms) for details.
	HeartbeatInterval *float64 `default:"3000" json:"heartbeatInterval"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitempty"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitempty"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `default:"1048576" json:"maxBytesPerPartition"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `default:"10485760" json:"maxBytes"`
	// Maximum number of network errors before the consumer re-creates a socket
	MaxSocketErrors *float64 `default:"0" json:"maxSocketErrors"`
	// Fields to add to events from this input
	Metadata             []MetadatumKafka `json:"metadata,omitempty"`
	Description          *string          `json:"description,omitempty"`
	AdditionalProperties map[string]any   `additionalProperties:"true" json:"-"`
}

func (i InputKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "brokers", "topics"}); err != nil {
		return err
	}
	return nil
}

func (i *InputKafka) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputKafka) GetType() InputTypeKafka {
	if i == nil {
		return InputTypeKafka("")
	}
	return i.Type
}

func (i *InputKafka) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKafka) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputKafka) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputKafka) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputKafka) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputKafka) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputKafka) GetConnections() []ConnectionKafka {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputKafka) GetPq() *PqKafka {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputKafka) GetBrokers() []string {
	if i == nil {
		return []string{}
	}
	return i.Brokers
}

func (i *InputKafka) GetTopics() []string {
	if i == nil {
		return []string{}
	}
	return i.Topics
}

func (i *InputKafka) GetGroupID() *string {
	if i == nil {
		return nil
	}
	return i.GroupID
}

func (i *InputKafka) GetFromBeginning() *bool {
	if i == nil {
		return nil
	}
	return i.FromBeginning
}

func (i *InputKafka) GetKafkaSchemaRegistry() *InputKafkaSchemaRegistryAuthenticationKafka {
	if i == nil {
		return nil
	}
	return i.KafkaSchemaRegistry
}

func (i *InputKafka) GetConnectionTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.ConnectionTimeout
}

func (i *InputKafka) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputKafka) GetMaxRetries() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxRetries
}

func (i *InputKafka) GetMaxBackOff() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBackOff
}

func (i *InputKafka) GetInitialBackoff() *float64 {
	if i == nil {
		return nil
	}
	return i.InitialBackoff
}

func (i *InputKafka) GetBackoffRate() *float64 {
	if i == nil {
		return nil
	}
	return i.BackoffRate
}

func (i *InputKafka) GetAuthenticationTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.AuthenticationTimeout
}

func (i *InputKafka) GetReauthenticationThreshold() *float64 {
	if i == nil {
		return nil
	}
	return i.ReauthenticationThreshold
}

func (i *InputKafka) GetSasl() *InputAuthenticationKafka {
	if i == nil {
		return nil
	}
	return i.Sasl
}

func (i *InputKafka) GetTLS() *InputTLSSettingsClientSideKafka {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputKafka) GetSessionTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SessionTimeout
}

func (i *InputKafka) GetRebalanceTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RebalanceTimeout
}

func (i *InputKafka) GetHeartbeatInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.HeartbeatInterval
}

func (i *InputKafka) GetAutoCommitInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.AutoCommitInterval
}

func (i *InputKafka) GetAutoCommitThreshold() *float64 {
	if i == nil {
		return nil
	}
	return i.AutoCommitThreshold
}

func (i *InputKafka) GetMaxBytesPerPartition() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBytesPerPartition
}

func (i *InputKafka) GetMaxBytes() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBytes
}

func (i *InputKafka) GetMaxSocketErrors() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxSocketErrors
}

func (i *InputKafka) GetMetadata() []MetadatumKafka {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputKafka) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputKafka) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputTypeCollection string

const (
	InputTypeCollectionCollection InputTypeCollection = "collection"
)

func (e InputTypeCollection) ToPointer() *InputTypeCollection {
	return &e
}
func (e *InputTypeCollection) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "collection":
		*e = InputTypeCollection(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeCollection: %v", v)
	}
}

type ConnectionCollection struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (c ConnectionCollection) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ConnectionCollection) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (c *ConnectionCollection) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *ConnectionCollection) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

// ModeCollection - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeCollection string

const (
	// ModeCollectionSmart Smart
	ModeCollectionSmart ModeCollection = "smart"
	// ModeCollectionAlways Always On
	ModeCollectionAlways ModeCollection = "always"
)

func (e ModeCollection) ToPointer() *ModeCollection {
	return &e
}

// CompressionCollection - Codec to use to compress the persisted data
type CompressionCollection string

const (
	// CompressionCollectionNone None
	CompressionCollectionNone CompressionCollection = "none"
	// CompressionCollectionGzip Gzip
	CompressionCollectionGzip CompressionCollection = "gzip"
)

func (e CompressionCollection) ToPointer() *CompressionCollection {
	return &e
}

type PqControlsCollection struct {
}

func (p PqControlsCollection) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsCollection) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type PqCollection struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeCollection `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress   *CompressionCollection `default:"none" json:"compress"`
	PqControls *PqControlsCollection  `json:"pqControls,omitempty"`
}

func (p PqCollection) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqCollection) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PqCollection) GetMode() *ModeCollection {
	if p == nil {
		return nil
	}
	return p.Mode
}

func (p *PqCollection) GetMaxBufferSize() *float64 {
	if p == nil {
		return nil
	}
	return p.MaxBufferSize
}

func (p *PqCollection) GetCommitFrequency() *float64 {
	if p == nil {
		return nil
	}
	return p.CommitFrequency
}

func (p *PqCollection) GetMaxFileSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxFileSize
}

func (p *PqCollection) GetMaxSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxSize
}

func (p *PqCollection) GetPath() *string {
	if p == nil {
		return nil
	}
	return p.Path
}

func (p *PqCollection) GetCompress() *CompressionCollection {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PqCollection) GetPqControls() *PqControlsCollection {
	if p == nil {
		return nil
	}
	return p.PqControls
}

type PreprocessCollection struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (p PreprocessCollection) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PreprocessCollection) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PreprocessCollection) GetDisabled() *bool {
	if p == nil {
		return nil
	}
	return p.Disabled
}

func (p *PreprocessCollection) GetCommand() *string {
	if p == nil {
		return nil
	}
	return p.Command
}

func (p *PreprocessCollection) GetArgs() []string {
	if p == nil {
		return nil
	}
	return p.Args
}

type MetadatumCollection struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m MetadatumCollection) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MetadatumCollection) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (m *MetadatumCollection) GetName() string {
	if m == nil {
		return ""
	}
	return m.Name
}

func (m *MetadatumCollection) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type InputCollection struct {
	// Unique ID for this input
	ID       *string              `json:"id,omitempty"`
	Type     *InputTypeCollection `default:"collection" json:"type"`
	Disabled *bool                `default:"false" json:"disabled"`
	// Pipeline to process results
	Pipeline *string `json:"pipeline,omitempty"`
	// Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionCollection `json:"connections,omitempty"`
	Pq          *PqCollection          `json:"pq,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64              `default:"10000" json:"staleChannelFlushMs"`
	Preprocess          *PreprocessCollection `json:"preprocess,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `default:"0" json:"throttleRatePerSec"`
	// Fields to add to events from this input
	Metadata []MetadatumCollection `json:"metadata,omitempty"`
	// Destination to send results to
	Output               *string        `json:"output,omitempty"`
	AdditionalProperties map[string]any `additionalProperties:"true" json:"-"`
}

func (i InputCollection) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollection) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputCollection) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputCollection) GetType() *InputTypeCollection {
	if i == nil {
		return nil
	}
	return i.Type
}

func (i *InputCollection) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputCollection) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputCollection) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputCollection) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputCollection) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputCollection) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputCollection) GetConnections() []ConnectionCollection {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputCollection) GetPq() *PqCollection {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputCollection) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputCollection) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputCollection) GetPreprocess() *PreprocessCollection {
	if i == nil {
		return nil
	}
	return i.Preprocess
}

func (i *InputCollection) GetThrottleRatePerSec() *string {
	if i == nil {
		return nil
	}
	return i.ThrottleRatePerSec
}

func (i *InputCollection) GetMetadata() []MetadatumCollection {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputCollection) GetOutput() *string {
	if i == nil {
		return nil
	}
	return i.Output
}

func (i *InputCollection) GetAdditionalProperties() map[string]any {
	if i == nil {
		return nil
	}
	return i.AdditionalProperties
}

type InputType string

const (
	InputTypeCollectionValue      InputType = "collection"
	InputTypeKafkaValue           InputType = "kafka"
	InputTypeMskValue             InputType = "msk"
	InputTypeHTTP                 InputType = "http"
	InputTypeSplunkValue          InputType = "splunk"
	InputTypeSplunkSearch         InputType = "splunk_search"
	InputTypeSplunkHecValue       InputType = "splunk_hec"
	InputTypeAzureBlobValue       InputType = "azure_blob"
	InputTypeElasticValue         InputType = "elastic"
	InputTypeConfluentCloudValue  InputType = "confluent_cloud"
	InputTypeGrafana              InputType = "grafana"
	InputTypeLokiValue            InputType = "loki"
	InputTypePrometheusRw         InputType = "prometheus_rw"
	InputTypePrometheusValue      InputType = "prometheus"
	InputTypeEdgePrometheus       InputType = "edge_prometheus"
	InputTypeOffice365Mgmt        InputType = "office365_mgmt"
	InputTypeOffice365Service     InputType = "office365_service"
	InputTypeOffice365MsgTrace    InputType = "office365_msg_trace"
	InputTypeEventhub             InputType = "eventhub"
	InputTypeExec                 InputType = "exec"
	InputTypeFirehose             InputType = "firehose"
	InputTypeGooglePubsubValue    InputType = "google_pubsub"
	InputTypeCribl                InputType = "cribl"
	InputTypeCriblTCPValue        InputType = "cribl_tcp"
	InputTypeCriblHTTPValue       InputType = "cribl_http"
	InputTypeCriblLakeHTTP        InputType = "cribl_lake_http"
	InputTypeTcpjsonValue         InputType = "tcpjson"
	InputTypeSystemMetrics        InputType = "system_metrics"
	InputTypeSystemState          InputType = "system_state"
	InputTypeKubeMetrics          InputType = "kube_metrics"
	InputTypeKubeLogs             InputType = "kube_logs"
	InputTypeKubeEvents           InputType = "kube_events"
	InputTypeWindowsMetrics       InputType = "windows_metrics"
	InputTypeCrowdstrike          InputType = "crowdstrike"
	InputTypeDatadogAgent         InputType = "datadog_agent"
	InputTypeDatagen              InputType = "datagen"
	InputTypeHTTPRaw              InputType = "http_raw"
	InputTypeKinesisValue         InputType = "kinesis"
	InputTypeCriblmetrics         InputType = "criblmetrics"
	InputTypeMetrics              InputType = "metrics"
	InputTypeS3Value              InputType = "s3"
	InputTypeS3Inventory          InputType = "s3_inventory"
	InputTypeSnmpValue            InputType = "snmp"
	InputTypeOpenTelemetryValue   InputType = "open_telemetry"
	InputTypeModelDrivenTelemetry InputType = "model_driven_telemetry"
	InputTypeSqsValue             InputType = "sqs"
	InputTypeSyslog               InputType = "syslog"
	InputTypeFile                 InputType = "file"
	InputTypeTCP                  InputType = "tcp"
	InputTypeAppscope             InputType = "appscope"
	InputTypeWef                  InputType = "wef"
	InputTypeWinEventLogs         InputType = "win_event_logs"
	InputTypeRawUDP               InputType = "raw_udp"
	InputTypeJournalFiles         InputType = "journal_files"
	InputTypeWiz                  InputType = "wiz"
	InputTypeWizWebhook           InputType = "wiz_webhook"
	InputTypeNetflowValue         InputType = "netflow"
	InputTypeSecurityLakeValue    InputType = "security_lake"
	InputTypeZscalerHec           InputType = "zscaler_hec"
	InputTypeCloudflareHec        InputType = "cloudflare_hec"
)

type Input struct {
	InputCollection           *InputCollection           `queryParam:"inline,name=Input"`
	InputKafka                *InputKafka                `queryParam:"inline,name=Input"`
	InputMsk                  *InputMsk                  `queryParam:"inline,name=Input"`
	InputHTTP                 *InputHTTP                 `queryParam:"inline,name=Input"`
	InputSplunk               *InputSplunk               `queryParam:"inline,name=Input"`
	InputSplunkSearch         *InputSplunkSearch         `queryParam:"inline,name=Input"`
	InputInputSplunkHec       *InputInputSplunkHec       `queryParam:"inline,name=Input"`
	InputAzureBlob            *InputAzureBlob            `queryParam:"inline,name=Input"`
	InputElastic              *InputElastic              `queryParam:"inline,name=Input"`
	InputConfluentCloud       *InputConfluentCloud       `queryParam:"inline,name=Input"`
	InputGrafana              *InputGrafana              `queryParam:"inline,name=Input"`
	InputLoki                 *InputLoki                 `queryParam:"inline,name=Input"`
	InputPrometheusRw         *InputPrometheusRw         `queryParam:"inline,name=Input"`
	InputPrometheus           *InputPrometheus           `queryParam:"inline,name=Input"`
	InputEdgePrometheus       *InputEdgePrometheus       `queryParam:"inline,name=Input"`
	InputOffice365Mgmt        *InputOffice365Mgmt        `queryParam:"inline,name=Input"`
	InputOffice365Service     *InputOffice365Service     `queryParam:"inline,name=Input"`
	InputOffice365MsgTrace    *InputOffice365MsgTrace    `queryParam:"inline,name=Input"`
	InputEventhub             *InputEventhub             `queryParam:"inline,name=Input"`
	InputExec                 *InputExec                 `queryParam:"inline,name=Input"`
	InputFirehose             *InputFirehose             `queryParam:"inline,name=Input"`
	InputGooglePubsub         *InputGooglePubsub         `queryParam:"inline,name=Input"`
	InputCribl                *InputCribl                `queryParam:"inline,name=Input"`
	InputCriblTCP             *InputCriblTCP             `queryParam:"inline,name=Input"`
	InputCriblHTTP            *InputCriblHTTP            `queryParam:"inline,name=Input"`
	InputCriblLakeHTTP        *InputCriblLakeHTTP        `queryParam:"inline,name=Input"`
	InputTcpjson              *InputTcpjson              `queryParam:"inline,name=Input"`
	InputSystemMetrics        *InputSystemMetrics        `queryParam:"inline,name=Input"`
	InputSystemState          *InputSystemState          `queryParam:"inline,name=Input"`
	InputKubeMetrics          *InputKubeMetrics          `queryParam:"inline,name=Input"`
	InputKubeLogs             *InputKubeLogs             `queryParam:"inline,name=Input"`
	InputKubeEvents           *InputKubeEvents           `queryParam:"inline,name=Input"`
	InputWindowsMetrics       *InputWindowsMetrics       `queryParam:"inline,name=Input"`
	InputCrowdstrike          *InputCrowdstrike          `queryParam:"inline,name=Input"`
	InputDatadogAgent         *InputDatadogAgent         `queryParam:"inline,name=Input"`
	InputDatagen              *InputDatagen              `queryParam:"inline,name=Input"`
	InputHTTPRaw              *InputHTTPRaw              `queryParam:"inline,name=Input"`
	InputKinesis              *InputKinesis              `queryParam:"inline,name=Input"`
	InputCriblmetrics         *InputCriblmetrics         `queryParam:"inline,name=Input"`
	InputMetrics              *InputMetrics              `queryParam:"inline,name=Input"`
	InputS3                   *InputS3                   `queryParam:"inline,name=Input"`
	InputS3Inventory          *InputS3Inventory          `queryParam:"inline,name=Input"`
	InputSnmp                 *InputSnmp                 `queryParam:"inline,name=Input"`
	InputOpenTelemetry        *InputOpenTelemetry        `queryParam:"inline,name=Input"`
	InputModelDrivenTelemetry *InputModelDrivenTelemetry `queryParam:"inline,name=Input"`
	InputSqs                  *InputSqs                  `queryParam:"inline,name=Input"`
	InputSyslog               *InputSyslog               `queryParam:"inline,name=Input"`
	InputFile                 *InputFile                 `queryParam:"inline,name=Input"`
	InputTCP                  *InputTCP                  `queryParam:"inline,name=Input"`
	InputAppscope             *InputAppscope             `queryParam:"inline,name=Input"`
	InputWef                  *InputWef                  `queryParam:"inline,name=Input"`
	InputWinEventLogs         *InputWinEventLogs         `queryParam:"inline,name=Input"`
	InputRawUDP               *InputRawUDP               `queryParam:"inline,name=Input"`
	InputJournalFiles         *InputJournalFiles         `queryParam:"inline,name=Input"`
	InputWiz                  *InputWiz                  `queryParam:"inline,name=Input"`
	InputWizWebhook           *InputWizWebhook           `queryParam:"inline,name=Input"`
	InputNetflow              *InputNetflow              `queryParam:"inline,name=Input"`
	InputSecurityLake         *InputSecurityLake         `queryParam:"inline,name=Input"`
	InputZscalerHec           *InputZscalerHec           `queryParam:"inline,name=Input"`
	InputCloudflareHec        *InputCloudflareHec        `queryParam:"inline,name=Input"`

	Type InputType
}

func CreateInputCollection(collection InputCollection) Input {
	typ := InputTypeCollectionValue

	typStr := InputTypeCollection(typ)
	collection.Type = &typStr

	return Input{
		InputCollection: &collection,
		Type:            typ,
	}
}

func CreateInputKafka(kafka InputKafka) Input {
	typ := InputTypeKafkaValue

	typStr := InputTypeKafka(typ)
	kafka.Type = typStr

	return Input{
		InputKafka: &kafka,
		Type:       typ,
	}
}

func CreateInputMsk(msk InputMsk) Input {
	typ := InputTypeMskValue

	typStr := InputTypeMsk(typ)
	msk.Type = typStr

	return Input{
		InputMsk: &msk,
		Type:     typ,
	}
}

func CreateInputHTTP(http InputHTTP) Input {
	typ := InputTypeHTTP

	typStr := TypeHTTP(typ)
	http.Type = typStr

	return Input{
		InputHTTP: &http,
		Type:      typ,
	}
}

func CreateInputSplunk(splunk InputSplunk) Input {
	typ := InputTypeSplunkValue

	typStr := InputTypeSplunk(typ)
	splunk.Type = typStr

	return Input{
		InputSplunk: &splunk,
		Type:        typ,
	}
}

func CreateInputSplunkSearch(splunkSearch InputSplunkSearch) Input {
	typ := InputTypeSplunkSearch

	typStr := TypeSplunkSearch(typ)
	splunkSearch.Type = typStr

	return Input{
		InputSplunkSearch: &splunkSearch,
		Type:              typ,
	}
}

func CreateInputSplunkHec(splunkHec InputInputSplunkHec) Input {
	typ := InputTypeSplunkHecValue

	typStr := InputTypeSplunkHec(typ)
	splunkHec.Type = typStr

	return Input{
		InputInputSplunkHec: &splunkHec,
		Type:                typ,
	}
}

func CreateInputAzureBlob(azureBlob InputAzureBlob) Input {
	typ := InputTypeAzureBlobValue

	typStr := InputTypeAzureBlob(typ)
	azureBlob.Type = typStr

	return Input{
		InputAzureBlob: &azureBlob,
		Type:           typ,
	}
}

func CreateInputElastic(elastic InputElastic) Input {
	typ := InputTypeElasticValue

	typStr := InputTypeElastic(typ)
	elastic.Type = typStr

	return Input{
		InputElastic: &elastic,
		Type:         typ,
	}
}

func CreateInputConfluentCloud(confluentCloud InputConfluentCloud) Input {
	typ := InputTypeConfluentCloudValue

	typStr := InputTypeConfluentCloud(typ)
	confluentCloud.Type = typStr

	return Input{
		InputConfluentCloud: &confluentCloud,
		Type:                typ,
	}
}

func CreateInputGrafana(grafana InputGrafana) Input {
	typ := InputTypeGrafana

	return Input{
		InputGrafana: &grafana,
		Type:         typ,
	}
}

func CreateInputLoki(loki InputLoki) Input {
	typ := InputTypeLokiValue

	typStr := InputTypeLoki(typ)
	loki.Type = typStr

	return Input{
		InputLoki: &loki,
		Type:      typ,
	}
}

func CreateInputPrometheusRw(prometheusRw InputPrometheusRw) Input {
	typ := InputTypePrometheusRw

	typStr := TypePrometheusRw(typ)
	prometheusRw.Type = typStr

	return Input{
		InputPrometheusRw: &prometheusRw,
		Type:              typ,
	}
}

func CreateInputPrometheus(prometheus InputPrometheus) Input {
	typ := InputTypePrometheusValue

	typStr := InputTypePrometheus(typ)
	prometheus.Type = typStr

	return Input{
		InputPrometheus: &prometheus,
		Type:            typ,
	}
}

func CreateInputEdgePrometheus(edgePrometheus InputEdgePrometheus) Input {
	typ := InputTypeEdgePrometheus

	typStr := TypeEdgePrometheus(typ)
	edgePrometheus.Type = typStr

	return Input{
		InputEdgePrometheus: &edgePrometheus,
		Type:                typ,
	}
}

func CreateInputOffice365Mgmt(office365Mgmt InputOffice365Mgmt) Input {
	typ := InputTypeOffice365Mgmt

	typStr := TypeOffice365Mgmt(typ)
	office365Mgmt.Type = typStr

	return Input{
		InputOffice365Mgmt: &office365Mgmt,
		Type:               typ,
	}
}

func CreateInputOffice365Service(office365Service InputOffice365Service) Input {
	typ := InputTypeOffice365Service

	typStr := TypeOffice365Service(typ)
	office365Service.Type = typStr

	return Input{
		InputOffice365Service: &office365Service,
		Type:                  typ,
	}
}

func CreateInputOffice365MsgTrace(office365MsgTrace InputOffice365MsgTrace) Input {
	typ := InputTypeOffice365MsgTrace

	typStr := TypeOffice365MsgTrace(typ)
	office365MsgTrace.Type = typStr

	return Input{
		InputOffice365MsgTrace: &office365MsgTrace,
		Type:                   typ,
	}
}

func CreateInputEventhub(eventhub InputEventhub) Input {
	typ := InputTypeEventhub

	typStr := TypeEventhub(typ)
	eventhub.Type = typStr

	return Input{
		InputEventhub: &eventhub,
		Type:          typ,
	}
}

func CreateInputExec(exec InputExec) Input {
	typ := InputTypeExec

	typStr := InputExecType(typ)
	exec.Type = typStr

	return Input{
		InputExec: &exec,
		Type:      typ,
	}
}

func CreateInputFirehose(firehose InputFirehose) Input {
	typ := InputTypeFirehose

	typStr := TypeFirehose(typ)
	firehose.Type = typStr

	return Input{
		InputFirehose: &firehose,
		Type:          typ,
	}
}

func CreateInputGooglePubsub(googlePubsub InputGooglePubsub) Input {
	typ := InputTypeGooglePubsubValue

	typStr := InputTypeGooglePubsub(typ)
	googlePubsub.Type = typStr

	return Input{
		InputGooglePubsub: &googlePubsub,
		Type:              typ,
	}
}

func CreateInputCribl(cribl InputCribl) Input {
	typ := InputTypeCribl

	typStr := TypeCribl(typ)
	cribl.Type = typStr

	return Input{
		InputCribl: &cribl,
		Type:       typ,
	}
}

func CreateInputCriblTCP(criblTCP InputCriblTCP) Input {
	typ := InputTypeCriblTCPValue

	typStr := InputTypeCriblTCP(typ)
	criblTCP.Type = typStr

	return Input{
		InputCriblTCP: &criblTCP,
		Type:          typ,
	}
}

func CreateInputCriblHTTP(criblHTTP InputCriblHTTP) Input {
	typ := InputTypeCriblHTTPValue

	typStr := InputTypeCriblHTTP(typ)
	criblHTTP.Type = typStr

	return Input{
		InputCriblHTTP: &criblHTTP,
		Type:           typ,
	}
}

func CreateInputCriblLakeHTTP(criblLakeHTTP InputCriblLakeHTTP) Input {
	typ := InputTypeCriblLakeHTTP

	typStr := TypeCriblLakeHTTP(typ)
	criblLakeHTTP.Type = typStr

	return Input{
		InputCriblLakeHTTP: &criblLakeHTTP,
		Type:               typ,
	}
}

func CreateInputTcpjson(tcpjson InputTcpjson) Input {
	typ := InputTypeTcpjsonValue

	typStr := InputTypeTcpjson(typ)
	tcpjson.Type = typStr

	return Input{
		InputTcpjson: &tcpjson,
		Type:         typ,
	}
}

func CreateInputSystemMetrics(systemMetrics InputSystemMetrics) Input {
	typ := InputTypeSystemMetrics

	typStr := TypeSystemMetrics(typ)
	systemMetrics.Type = typStr

	return Input{
		InputSystemMetrics: &systemMetrics,
		Type:               typ,
	}
}

func CreateInputSystemState(systemState InputSystemState) Input {
	typ := InputTypeSystemState

	typStr := TypeSystemState(typ)
	systemState.Type = typStr

	return Input{
		InputSystemState: &systemState,
		Type:             typ,
	}
}

func CreateInputKubeMetrics(kubeMetrics InputKubeMetrics) Input {
	typ := InputTypeKubeMetrics

	typStr := TypeKubeMetrics(typ)
	kubeMetrics.Type = typStr

	return Input{
		InputKubeMetrics: &kubeMetrics,
		Type:             typ,
	}
}

func CreateInputKubeLogs(kubeLogs InputKubeLogs) Input {
	typ := InputTypeKubeLogs

	typStr := TypeKubeLogs(typ)
	kubeLogs.Type = typStr

	return Input{
		InputKubeLogs: &kubeLogs,
		Type:          typ,
	}
}

func CreateInputKubeEvents(kubeEvents InputKubeEvents) Input {
	typ := InputTypeKubeEvents

	typStr := TypeKubeEvents(typ)
	kubeEvents.Type = typStr

	return Input{
		InputKubeEvents: &kubeEvents,
		Type:            typ,
	}
}

func CreateInputWindowsMetrics(windowsMetrics InputWindowsMetrics) Input {
	typ := InputTypeWindowsMetrics

	typStr := TypeWindowsMetrics(typ)
	windowsMetrics.Type = typStr

	return Input{
		InputWindowsMetrics: &windowsMetrics,
		Type:                typ,
	}
}

func CreateInputCrowdstrike(crowdstrike InputCrowdstrike) Input {
	typ := InputTypeCrowdstrike

	typStr := TypeCrowdstrike(typ)
	crowdstrike.Type = typStr

	return Input{
		InputCrowdstrike: &crowdstrike,
		Type:             typ,
	}
}

func CreateInputDatadogAgent(datadogAgent InputDatadogAgent) Input {
	typ := InputTypeDatadogAgent

	typStr := TypeDatadogAgent(typ)
	datadogAgent.Type = typStr

	return Input{
		InputDatadogAgent: &datadogAgent,
		Type:              typ,
	}
}

func CreateInputDatagen(datagen InputDatagen) Input {
	typ := InputTypeDatagen

	typStr := TypeDatagen(typ)
	datagen.Type = typStr

	return Input{
		InputDatagen: &datagen,
		Type:         typ,
	}
}

func CreateInputHTTPRaw(httpRaw InputHTTPRaw) Input {
	typ := InputTypeHTTPRaw

	typStr := TypeHTTPRaw(typ)
	httpRaw.Type = typStr

	return Input{
		InputHTTPRaw: &httpRaw,
		Type:         typ,
	}
}

func CreateInputKinesis(kinesis InputKinesis) Input {
	typ := InputTypeKinesisValue

	typStr := InputTypeKinesis(typ)
	kinesis.Type = typStr

	return Input{
		InputKinesis: &kinesis,
		Type:         typ,
	}
}

func CreateInputCriblmetrics(criblmetrics InputCriblmetrics) Input {
	typ := InputTypeCriblmetrics

	typStr := TypeCriblmetrics(typ)
	criblmetrics.Type = typStr

	return Input{
		InputCriblmetrics: &criblmetrics,
		Type:              typ,
	}
}

func CreateInputMetrics(metrics InputMetrics) Input {
	typ := InputTypeMetrics

	typStr := TypeMetrics(typ)
	metrics.Type = typStr

	return Input{
		InputMetrics: &metrics,
		Type:         typ,
	}
}

func CreateInputS3(s3 InputS3) Input {
	typ := InputTypeS3Value

	typStr := InputTypeS3(typ)
	s3.Type = typStr

	return Input{
		InputS3: &s3,
		Type:    typ,
	}
}

func CreateInputS3Inventory(s3Inventory InputS3Inventory) Input {
	typ := InputTypeS3Inventory

	typStr := TypeS3Inventory(typ)
	s3Inventory.Type = typStr

	return Input{
		InputS3Inventory: &s3Inventory,
		Type:             typ,
	}
}

func CreateInputSnmp(snmp InputSnmp) Input {
	typ := InputTypeSnmpValue

	typStr := InputTypeSnmp(typ)
	snmp.Type = typStr

	return Input{
		InputSnmp: &snmp,
		Type:      typ,
	}
}

func CreateInputOpenTelemetry(openTelemetry InputOpenTelemetry) Input {
	typ := InputTypeOpenTelemetryValue

	typStr := InputTypeOpenTelemetry(typ)
	openTelemetry.Type = typStr

	return Input{
		InputOpenTelemetry: &openTelemetry,
		Type:               typ,
	}
}

func CreateInputModelDrivenTelemetry(modelDrivenTelemetry InputModelDrivenTelemetry) Input {
	typ := InputTypeModelDrivenTelemetry

	typStr := TypeModelDrivenTelemetry(typ)
	modelDrivenTelemetry.Type = typStr

	return Input{
		InputModelDrivenTelemetry: &modelDrivenTelemetry,
		Type:                      typ,
	}
}

func CreateInputSqs(sqs InputSqs) Input {
	typ := InputTypeSqsValue

	typStr := InputTypeSqs(typ)
	sqs.Type = typStr

	return Input{
		InputSqs: &sqs,
		Type:     typ,
	}
}

func CreateInputSyslog(syslog InputSyslog) Input {
	typ := InputTypeSyslog

	return Input{
		InputSyslog: &syslog,
		Type:        typ,
	}
}

func CreateInputFile(file InputFile) Input {
	typ := InputTypeFile

	typStr := InputFileType(typ)
	file.Type = typStr

	return Input{
		InputFile: &file,
		Type:      typ,
	}
}

func CreateInputTCP(tcp InputTCP) Input {
	typ := InputTypeTCP

	typStr := TypeTCP(typ)
	tcp.Type = typStr

	return Input{
		InputTCP: &tcp,
		Type:     typ,
	}
}

func CreateInputAppscope(appscope InputAppscope) Input {
	typ := InputTypeAppscope

	typStr := TypeAppscope(typ)
	appscope.Type = typStr

	return Input{
		InputAppscope: &appscope,
		Type:          typ,
	}
}

func CreateInputWef(wef InputWef) Input {
	typ := InputTypeWef

	typStr := TypeWef(typ)
	wef.Type = typStr

	return Input{
		InputWef: &wef,
		Type:     typ,
	}
}

func CreateInputWinEventLogs(winEventLogs InputWinEventLogs) Input {
	typ := InputTypeWinEventLogs

	typStr := TypeWinEventLogs(typ)
	winEventLogs.Type = typStr

	return Input{
		InputWinEventLogs: &winEventLogs,
		Type:              typ,
	}
}

func CreateInputRawUDP(rawUDP InputRawUDP) Input {
	typ := InputTypeRawUDP

	typStr := TypeRawUDP(typ)
	rawUDP.Type = typStr

	return Input{
		InputRawUDP: &rawUDP,
		Type:        typ,
	}
}

func CreateInputJournalFiles(journalFiles InputJournalFiles) Input {
	typ := InputTypeJournalFiles

	typStr := InputJournalFilesType(typ)
	journalFiles.Type = typStr

	return Input{
		InputJournalFiles: &journalFiles,
		Type:              typ,
	}
}

func CreateInputWiz(wiz InputWiz) Input {
	typ := InputTypeWiz

	typStr := TypeWiz(typ)
	wiz.Type = typStr

	return Input{
		InputWiz: &wiz,
		Type:     typ,
	}
}

func CreateInputWizWebhook(wizWebhook InputWizWebhook) Input {
	typ := InputTypeWizWebhook

	typStr := TypeWizWebhook(typ)
	wizWebhook.Type = typStr

	return Input{
		InputWizWebhook: &wizWebhook,
		Type:            typ,
	}
}

func CreateInputNetflow(netflow InputNetflow) Input {
	typ := InputTypeNetflowValue

	typStr := InputTypeNetflow(typ)
	netflow.Type = typStr

	return Input{
		InputNetflow: &netflow,
		Type:         typ,
	}
}

func CreateInputSecurityLake(securityLake InputSecurityLake) Input {
	typ := InputTypeSecurityLakeValue

	typStr := InputTypeSecurityLake(typ)
	securityLake.Type = typStr

	return Input{
		InputSecurityLake: &securityLake,
		Type:              typ,
	}
}

func CreateInputZscalerHec(zscalerHec InputZscalerHec) Input {
	typ := InputTypeZscalerHec

	typStr := TypeZscalerHec(typ)
	zscalerHec.Type = typStr

	return Input{
		InputZscalerHec: &zscalerHec,
		Type:            typ,
	}
}

func CreateInputCloudflareHec(cloudflareHec InputCloudflareHec) Input {
	typ := InputTypeCloudflareHec

	typStr := TypeCloudflareHec(typ)
	cloudflareHec.Type = typStr

	return Input{
		InputCloudflareHec: &cloudflareHec,
		Type:               typ,
	}
}

func (u *Input) UnmarshalJSON(data []byte) error {

	type discriminator struct {
		Type string `json:"type"`
	}

	dis := new(discriminator)
	if err := json.Unmarshal(data, &dis); err != nil {
		return fmt.Errorf("could not unmarshal discriminator: %w", err)
	}

	switch dis.Type {
	case "collection":
		inputCollection := new(InputCollection)
		if err := utils.UnmarshalJSON(data, &inputCollection, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == collection) type InputCollection within Input: %w", string(data), err)
		}

		u.InputCollection = inputCollection
		u.Type = InputTypeCollectionValue
		return nil
	case "kafka":
		inputKafka := new(InputKafka)
		if err := utils.UnmarshalJSON(data, &inputKafka, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == kafka) type InputKafka within Input: %w", string(data), err)
		}

		u.InputKafka = inputKafka
		u.Type = InputTypeKafkaValue
		return nil
	case "msk":
		inputMsk := new(InputMsk)
		if err := utils.UnmarshalJSON(data, &inputMsk, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == msk) type InputMsk within Input: %w", string(data), err)
		}

		u.InputMsk = inputMsk
		u.Type = InputTypeMskValue
		return nil
	case "http":
		inputHTTP := new(InputHTTP)
		if err := utils.UnmarshalJSON(data, &inputHTTP, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == http) type InputHTTP within Input: %w", string(data), err)
		}

		u.InputHTTP = inputHTTP
		u.Type = InputTypeHTTP
		return nil
	case "splunk":
		inputSplunk := new(InputSplunk)
		if err := utils.UnmarshalJSON(data, &inputSplunk, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == splunk) type InputSplunk within Input: %w", string(data), err)
		}

		u.InputSplunk = inputSplunk
		u.Type = InputTypeSplunkValue
		return nil
	case "splunk_search":
		inputSplunkSearch := new(InputSplunkSearch)
		if err := utils.UnmarshalJSON(data, &inputSplunkSearch, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == splunk_search) type InputSplunkSearch within Input: %w", string(data), err)
		}

		u.InputSplunkSearch = inputSplunkSearch
		u.Type = InputTypeSplunkSearch
		return nil
	case "splunk_hec":
		inputInputSplunkHec := new(InputInputSplunkHec)
		if err := utils.UnmarshalJSON(data, &inputInputSplunkHec, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == splunk_hec) type InputInputSplunkHec within Input: %w", string(data), err)
		}

		u.InputInputSplunkHec = inputInputSplunkHec
		u.Type = InputTypeSplunkHecValue
		return nil
	case "azure_blob":
		inputAzureBlob := new(InputAzureBlob)
		if err := utils.UnmarshalJSON(data, &inputAzureBlob, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == azure_blob) type InputAzureBlob within Input: %w", string(data), err)
		}

		u.InputAzureBlob = inputAzureBlob
		u.Type = InputTypeAzureBlobValue
		return nil
	case "elastic":
		inputElastic := new(InputElastic)
		if err := utils.UnmarshalJSON(data, &inputElastic, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == elastic) type InputElastic within Input: %w", string(data), err)
		}

		u.InputElastic = inputElastic
		u.Type = InputTypeElasticValue
		return nil
	case "confluent_cloud":
		inputConfluentCloud := new(InputConfluentCloud)
		if err := utils.UnmarshalJSON(data, &inputConfluentCloud, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == confluent_cloud) type InputConfluentCloud within Input: %w", string(data), err)
		}

		u.InputConfluentCloud = inputConfluentCloud
		u.Type = InputTypeConfluentCloudValue
		return nil
	case "grafana":
		inputGrafana := new(InputGrafana)
		if err := utils.UnmarshalJSON(data, &inputGrafana, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == grafana) type InputGrafana within Input: %w", string(data), err)
		}

		u.InputGrafana = inputGrafana
		u.Type = InputTypeGrafana
		return nil
	case "loki":
		inputLoki := new(InputLoki)
		if err := utils.UnmarshalJSON(data, &inputLoki, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == loki) type InputLoki within Input: %w", string(data), err)
		}

		u.InputLoki = inputLoki
		u.Type = InputTypeLokiValue
		return nil
	case "prometheus_rw":
		inputPrometheusRw := new(InputPrometheusRw)
		if err := utils.UnmarshalJSON(data, &inputPrometheusRw, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == prometheus_rw) type InputPrometheusRw within Input: %w", string(data), err)
		}

		u.InputPrometheusRw = inputPrometheusRw
		u.Type = InputTypePrometheusRw
		return nil
	case "prometheus":
		inputPrometheus := new(InputPrometheus)
		if err := utils.UnmarshalJSON(data, &inputPrometheus, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == prometheus) type InputPrometheus within Input: %w", string(data), err)
		}

		u.InputPrometheus = inputPrometheus
		u.Type = InputTypePrometheusValue
		return nil
	case "edge_prometheus":
		inputEdgePrometheus := new(InputEdgePrometheus)
		if err := utils.UnmarshalJSON(data, &inputEdgePrometheus, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == edge_prometheus) type InputEdgePrometheus within Input: %w", string(data), err)
		}

		u.InputEdgePrometheus = inputEdgePrometheus
		u.Type = InputTypeEdgePrometheus
		return nil
	case "office365_mgmt":
		inputOffice365Mgmt := new(InputOffice365Mgmt)
		if err := utils.UnmarshalJSON(data, &inputOffice365Mgmt, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == office365_mgmt) type InputOffice365Mgmt within Input: %w", string(data), err)
		}

		u.InputOffice365Mgmt = inputOffice365Mgmt
		u.Type = InputTypeOffice365Mgmt
		return nil
	case "office365_service":
		inputOffice365Service := new(InputOffice365Service)
		if err := utils.UnmarshalJSON(data, &inputOffice365Service, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == office365_service) type InputOffice365Service within Input: %w", string(data), err)
		}

		u.InputOffice365Service = inputOffice365Service
		u.Type = InputTypeOffice365Service
		return nil
	case "office365_msg_trace":
		inputOffice365MsgTrace := new(InputOffice365MsgTrace)
		if err := utils.UnmarshalJSON(data, &inputOffice365MsgTrace, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == office365_msg_trace) type InputOffice365MsgTrace within Input: %w", string(data), err)
		}

		u.InputOffice365MsgTrace = inputOffice365MsgTrace
		u.Type = InputTypeOffice365MsgTrace
		return nil
	case "eventhub":
		inputEventhub := new(InputEventhub)
		if err := utils.UnmarshalJSON(data, &inputEventhub, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == eventhub) type InputEventhub within Input: %w", string(data), err)
		}

		u.InputEventhub = inputEventhub
		u.Type = InputTypeEventhub
		return nil
	case "exec":
		inputExec := new(InputExec)
		if err := utils.UnmarshalJSON(data, &inputExec, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == exec) type InputExec within Input: %w", string(data), err)
		}

		u.InputExec = inputExec
		u.Type = InputTypeExec
		return nil
	case "firehose":
		inputFirehose := new(InputFirehose)
		if err := utils.UnmarshalJSON(data, &inputFirehose, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == firehose) type InputFirehose within Input: %w", string(data), err)
		}

		u.InputFirehose = inputFirehose
		u.Type = InputTypeFirehose
		return nil
	case "google_pubsub":
		inputGooglePubsub := new(InputGooglePubsub)
		if err := utils.UnmarshalJSON(data, &inputGooglePubsub, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == google_pubsub) type InputGooglePubsub within Input: %w", string(data), err)
		}

		u.InputGooglePubsub = inputGooglePubsub
		u.Type = InputTypeGooglePubsubValue
		return nil
	case "cribl":
		inputCribl := new(InputCribl)
		if err := utils.UnmarshalJSON(data, &inputCribl, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == cribl) type InputCribl within Input: %w", string(data), err)
		}

		u.InputCribl = inputCribl
		u.Type = InputTypeCribl
		return nil
	case "cribl_tcp":
		inputCriblTCP := new(InputCriblTCP)
		if err := utils.UnmarshalJSON(data, &inputCriblTCP, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == cribl_tcp) type InputCriblTCP within Input: %w", string(data), err)
		}

		u.InputCriblTCP = inputCriblTCP
		u.Type = InputTypeCriblTCPValue
		return nil
	case "cribl_http":
		inputCriblHTTP := new(InputCriblHTTP)
		if err := utils.UnmarshalJSON(data, &inputCriblHTTP, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == cribl_http) type InputCriblHTTP within Input: %w", string(data), err)
		}

		u.InputCriblHTTP = inputCriblHTTP
		u.Type = InputTypeCriblHTTPValue
		return nil
	case "cribl_lake_http":
		inputCriblLakeHTTP := new(InputCriblLakeHTTP)
		if err := utils.UnmarshalJSON(data, &inputCriblLakeHTTP, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == cribl_lake_http) type InputCriblLakeHTTP within Input: %w", string(data), err)
		}

		u.InputCriblLakeHTTP = inputCriblLakeHTTP
		u.Type = InputTypeCriblLakeHTTP
		return nil
	case "tcpjson":
		inputTcpjson := new(InputTcpjson)
		if err := utils.UnmarshalJSON(data, &inputTcpjson, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == tcpjson) type InputTcpjson within Input: %w", string(data), err)
		}

		u.InputTcpjson = inputTcpjson
		u.Type = InputTypeTcpjsonValue
		return nil
	case "system_metrics":
		inputSystemMetrics := new(InputSystemMetrics)
		if err := utils.UnmarshalJSON(data, &inputSystemMetrics, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == system_metrics) type InputSystemMetrics within Input: %w", string(data), err)
		}

		u.InputSystemMetrics = inputSystemMetrics
		u.Type = InputTypeSystemMetrics
		return nil
	case "system_state":
		inputSystemState := new(InputSystemState)
		if err := utils.UnmarshalJSON(data, &inputSystemState, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == system_state) type InputSystemState within Input: %w", string(data), err)
		}

		u.InputSystemState = inputSystemState
		u.Type = InputTypeSystemState
		return nil
	case "kube_metrics":
		inputKubeMetrics := new(InputKubeMetrics)
		if err := utils.UnmarshalJSON(data, &inputKubeMetrics, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == kube_metrics) type InputKubeMetrics within Input: %w", string(data), err)
		}

		u.InputKubeMetrics = inputKubeMetrics
		u.Type = InputTypeKubeMetrics
		return nil
	case "kube_logs":
		inputKubeLogs := new(InputKubeLogs)
		if err := utils.UnmarshalJSON(data, &inputKubeLogs, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == kube_logs) type InputKubeLogs within Input: %w", string(data), err)
		}

		u.InputKubeLogs = inputKubeLogs
		u.Type = InputTypeKubeLogs
		return nil
	case "kube_events":
		inputKubeEvents := new(InputKubeEvents)
		if err := utils.UnmarshalJSON(data, &inputKubeEvents, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == kube_events) type InputKubeEvents within Input: %w", string(data), err)
		}

		u.InputKubeEvents = inputKubeEvents
		u.Type = InputTypeKubeEvents
		return nil
	case "windows_metrics":
		inputWindowsMetrics := new(InputWindowsMetrics)
		if err := utils.UnmarshalJSON(data, &inputWindowsMetrics, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == windows_metrics) type InputWindowsMetrics within Input: %w", string(data), err)
		}

		u.InputWindowsMetrics = inputWindowsMetrics
		u.Type = InputTypeWindowsMetrics
		return nil
	case "crowdstrike":
		inputCrowdstrike := new(InputCrowdstrike)
		if err := utils.UnmarshalJSON(data, &inputCrowdstrike, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == crowdstrike) type InputCrowdstrike within Input: %w", string(data), err)
		}

		u.InputCrowdstrike = inputCrowdstrike
		u.Type = InputTypeCrowdstrike
		return nil
	case "datadog_agent":
		inputDatadogAgent := new(InputDatadogAgent)
		if err := utils.UnmarshalJSON(data, &inputDatadogAgent, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == datadog_agent) type InputDatadogAgent within Input: %w", string(data), err)
		}

		u.InputDatadogAgent = inputDatadogAgent
		u.Type = InputTypeDatadogAgent
		return nil
	case "datagen":
		inputDatagen := new(InputDatagen)
		if err := utils.UnmarshalJSON(data, &inputDatagen, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == datagen) type InputDatagen within Input: %w", string(data), err)
		}

		u.InputDatagen = inputDatagen
		u.Type = InputTypeDatagen
		return nil
	case "http_raw":
		inputHTTPRaw := new(InputHTTPRaw)
		if err := utils.UnmarshalJSON(data, &inputHTTPRaw, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == http_raw) type InputHTTPRaw within Input: %w", string(data), err)
		}

		u.InputHTTPRaw = inputHTTPRaw
		u.Type = InputTypeHTTPRaw
		return nil
	case "kinesis":
		inputKinesis := new(InputKinesis)
		if err := utils.UnmarshalJSON(data, &inputKinesis, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == kinesis) type InputKinesis within Input: %w", string(data), err)
		}

		u.InputKinesis = inputKinesis
		u.Type = InputTypeKinesisValue
		return nil
	case "criblmetrics":
		inputCriblmetrics := new(InputCriblmetrics)
		if err := utils.UnmarshalJSON(data, &inputCriblmetrics, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == criblmetrics) type InputCriblmetrics within Input: %w", string(data), err)
		}

		u.InputCriblmetrics = inputCriblmetrics
		u.Type = InputTypeCriblmetrics
		return nil
	case "metrics":
		inputMetrics := new(InputMetrics)
		if err := utils.UnmarshalJSON(data, &inputMetrics, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == metrics) type InputMetrics within Input: %w", string(data), err)
		}

		u.InputMetrics = inputMetrics
		u.Type = InputTypeMetrics
		return nil
	case "s3":
		inputS3 := new(InputS3)
		if err := utils.UnmarshalJSON(data, &inputS3, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == s3) type InputS3 within Input: %w", string(data), err)
		}

		u.InputS3 = inputS3
		u.Type = InputTypeS3Value
		return nil
	case "s3_inventory":
		inputS3Inventory := new(InputS3Inventory)
		if err := utils.UnmarshalJSON(data, &inputS3Inventory, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == s3_inventory) type InputS3Inventory within Input: %w", string(data), err)
		}

		u.InputS3Inventory = inputS3Inventory
		u.Type = InputTypeS3Inventory
		return nil
	case "snmp":
		inputSnmp := new(InputSnmp)
		if err := utils.UnmarshalJSON(data, &inputSnmp, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == snmp) type InputSnmp within Input: %w", string(data), err)
		}

		u.InputSnmp = inputSnmp
		u.Type = InputTypeSnmpValue
		return nil
	case "open_telemetry":
		inputOpenTelemetry := new(InputOpenTelemetry)
		if err := utils.UnmarshalJSON(data, &inputOpenTelemetry, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == open_telemetry) type InputOpenTelemetry within Input: %w", string(data), err)
		}

		u.InputOpenTelemetry = inputOpenTelemetry
		u.Type = InputTypeOpenTelemetryValue
		return nil
	case "model_driven_telemetry":
		inputModelDrivenTelemetry := new(InputModelDrivenTelemetry)
		if err := utils.UnmarshalJSON(data, &inputModelDrivenTelemetry, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == model_driven_telemetry) type InputModelDrivenTelemetry within Input: %w", string(data), err)
		}

		u.InputModelDrivenTelemetry = inputModelDrivenTelemetry
		u.Type = InputTypeModelDrivenTelemetry
		return nil
	case "sqs":
		inputSqs := new(InputSqs)
		if err := utils.UnmarshalJSON(data, &inputSqs, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == sqs) type InputSqs within Input: %w", string(data), err)
		}

		u.InputSqs = inputSqs
		u.Type = InputTypeSqsValue
		return nil
	case "syslog":
		inputSyslog := new(InputSyslog)
		if err := utils.UnmarshalJSON(data, &inputSyslog, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == syslog) type InputSyslog within Input: %w", string(data), err)
		}

		u.InputSyslog = inputSyslog
		u.Type = InputTypeSyslog
		return nil
	case "file":
		inputFile := new(InputFile)
		if err := utils.UnmarshalJSON(data, &inputFile, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == file) type InputFile within Input: %w", string(data), err)
		}

		u.InputFile = inputFile
		u.Type = InputTypeFile
		return nil
	case "tcp":
		inputTCP := new(InputTCP)
		if err := utils.UnmarshalJSON(data, &inputTCP, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == tcp) type InputTCP within Input: %w", string(data), err)
		}

		u.InputTCP = inputTCP
		u.Type = InputTypeTCP
		return nil
	case "appscope":
		inputAppscope := new(InputAppscope)
		if err := utils.UnmarshalJSON(data, &inputAppscope, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == appscope) type InputAppscope within Input: %w", string(data), err)
		}

		u.InputAppscope = inputAppscope
		u.Type = InputTypeAppscope
		return nil
	case "wef":
		inputWef := new(InputWef)
		if err := utils.UnmarshalJSON(data, &inputWef, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == wef) type InputWef within Input: %w", string(data), err)
		}

		u.InputWef = inputWef
		u.Type = InputTypeWef
		return nil
	case "win_event_logs":
		inputWinEventLogs := new(InputWinEventLogs)
		if err := utils.UnmarshalJSON(data, &inputWinEventLogs, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == win_event_logs) type InputWinEventLogs within Input: %w", string(data), err)
		}

		u.InputWinEventLogs = inputWinEventLogs
		u.Type = InputTypeWinEventLogs
		return nil
	case "raw_udp":
		inputRawUDP := new(InputRawUDP)
		if err := utils.UnmarshalJSON(data, &inputRawUDP, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == raw_udp) type InputRawUDP within Input: %w", string(data), err)
		}

		u.InputRawUDP = inputRawUDP
		u.Type = InputTypeRawUDP
		return nil
	case "journal_files":
		inputJournalFiles := new(InputJournalFiles)
		if err := utils.UnmarshalJSON(data, &inputJournalFiles, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == journal_files) type InputJournalFiles within Input: %w", string(data), err)
		}

		u.InputJournalFiles = inputJournalFiles
		u.Type = InputTypeJournalFiles
		return nil
	case "wiz":
		inputWiz := new(InputWiz)
		if err := utils.UnmarshalJSON(data, &inputWiz, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == wiz) type InputWiz within Input: %w", string(data), err)
		}

		u.InputWiz = inputWiz
		u.Type = InputTypeWiz
		return nil
	case "wiz_webhook":
		inputWizWebhook := new(InputWizWebhook)
		if err := utils.UnmarshalJSON(data, &inputWizWebhook, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == wiz_webhook) type InputWizWebhook within Input: %w", string(data), err)
		}

		u.InputWizWebhook = inputWizWebhook
		u.Type = InputTypeWizWebhook
		return nil
	case "netflow":
		inputNetflow := new(InputNetflow)
		if err := utils.UnmarshalJSON(data, &inputNetflow, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == netflow) type InputNetflow within Input: %w", string(data), err)
		}

		u.InputNetflow = inputNetflow
		u.Type = InputTypeNetflowValue
		return nil
	case "security_lake":
		inputSecurityLake := new(InputSecurityLake)
		if err := utils.UnmarshalJSON(data, &inputSecurityLake, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == security_lake) type InputSecurityLake within Input: %w", string(data), err)
		}

		u.InputSecurityLake = inputSecurityLake
		u.Type = InputTypeSecurityLakeValue
		return nil
	case "zscaler_hec":
		inputZscalerHec := new(InputZscalerHec)
		if err := utils.UnmarshalJSON(data, &inputZscalerHec, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == zscaler_hec) type InputZscalerHec within Input: %w", string(data), err)
		}

		u.InputZscalerHec = inputZscalerHec
		u.Type = InputTypeZscalerHec
		return nil
	case "cloudflare_hec":
		inputCloudflareHec := new(InputCloudflareHec)
		if err := utils.UnmarshalJSON(data, &inputCloudflareHec, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == cloudflare_hec) type InputCloudflareHec within Input: %w", string(data), err)
		}

		u.InputCloudflareHec = inputCloudflareHec
		u.Type = InputTypeCloudflareHec
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for Input", string(data))
}

func (u Input) MarshalJSON() ([]byte, error) {
	if u.InputCollection != nil {
		return utils.MarshalJSON(u.InputCollection, "", true)
	}

	if u.InputKafka != nil {
		return utils.MarshalJSON(u.InputKafka, "", true)
	}

	if u.InputMsk != nil {
		return utils.MarshalJSON(u.InputMsk, "", true)
	}

	if u.InputHTTP != nil {
		return utils.MarshalJSON(u.InputHTTP, "", true)
	}

	if u.InputSplunk != nil {
		return utils.MarshalJSON(u.InputSplunk, "", true)
	}

	if u.InputSplunkSearch != nil {
		return utils.MarshalJSON(u.InputSplunkSearch, "", true)
	}

	if u.InputInputSplunkHec != nil {
		return utils.MarshalJSON(u.InputInputSplunkHec, "", true)
	}

	if u.InputAzureBlob != nil {
		return utils.MarshalJSON(u.InputAzureBlob, "", true)
	}

	if u.InputElastic != nil {
		return utils.MarshalJSON(u.InputElastic, "", true)
	}

	if u.InputConfluentCloud != nil {
		return utils.MarshalJSON(u.InputConfluentCloud, "", true)
	}

	if u.InputGrafana != nil {
		return utils.MarshalJSON(u.InputGrafana, "", true)
	}

	if u.InputLoki != nil {
		return utils.MarshalJSON(u.InputLoki, "", true)
	}

	if u.InputPrometheusRw != nil {
		return utils.MarshalJSON(u.InputPrometheusRw, "", true)
	}

	if u.InputPrometheus != nil {
		return utils.MarshalJSON(u.InputPrometheus, "", true)
	}

	if u.InputEdgePrometheus != nil {
		return utils.MarshalJSON(u.InputEdgePrometheus, "", true)
	}

	if u.InputOffice365Mgmt != nil {
		return utils.MarshalJSON(u.InputOffice365Mgmt, "", true)
	}

	if u.InputOffice365Service != nil {
		return utils.MarshalJSON(u.InputOffice365Service, "", true)
	}

	if u.InputOffice365MsgTrace != nil {
		return utils.MarshalJSON(u.InputOffice365MsgTrace, "", true)
	}

	if u.InputEventhub != nil {
		return utils.MarshalJSON(u.InputEventhub, "", true)
	}

	if u.InputExec != nil {
		return utils.MarshalJSON(u.InputExec, "", true)
	}

	if u.InputFirehose != nil {
		return utils.MarshalJSON(u.InputFirehose, "", true)
	}

	if u.InputGooglePubsub != nil {
		return utils.MarshalJSON(u.InputGooglePubsub, "", true)
	}

	if u.InputCribl != nil {
		return utils.MarshalJSON(u.InputCribl, "", true)
	}

	if u.InputCriblTCP != nil {
		return utils.MarshalJSON(u.InputCriblTCP, "", true)
	}

	if u.InputCriblHTTP != nil {
		return utils.MarshalJSON(u.InputCriblHTTP, "", true)
	}

	if u.InputCriblLakeHTTP != nil {
		return utils.MarshalJSON(u.InputCriblLakeHTTP, "", true)
	}

	if u.InputTcpjson != nil {
		return utils.MarshalJSON(u.InputTcpjson, "", true)
	}

	if u.InputSystemMetrics != nil {
		return utils.MarshalJSON(u.InputSystemMetrics, "", true)
	}

	if u.InputSystemState != nil {
		return utils.MarshalJSON(u.InputSystemState, "", true)
	}

	if u.InputKubeMetrics != nil {
		return utils.MarshalJSON(u.InputKubeMetrics, "", true)
	}

	if u.InputKubeLogs != nil {
		return utils.MarshalJSON(u.InputKubeLogs, "", true)
	}

	if u.InputKubeEvents != nil {
		return utils.MarshalJSON(u.InputKubeEvents, "", true)
	}

	if u.InputWindowsMetrics != nil {
		return utils.MarshalJSON(u.InputWindowsMetrics, "", true)
	}

	if u.InputCrowdstrike != nil {
		return utils.MarshalJSON(u.InputCrowdstrike, "", true)
	}

	if u.InputDatadogAgent != nil {
		return utils.MarshalJSON(u.InputDatadogAgent, "", true)
	}

	if u.InputDatagen != nil {
		return utils.MarshalJSON(u.InputDatagen, "", true)
	}

	if u.InputHTTPRaw != nil {
		return utils.MarshalJSON(u.InputHTTPRaw, "", true)
	}

	if u.InputKinesis != nil {
		return utils.MarshalJSON(u.InputKinesis, "", true)
	}

	if u.InputCriblmetrics != nil {
		return utils.MarshalJSON(u.InputCriblmetrics, "", true)
	}

	if u.InputMetrics != nil {
		return utils.MarshalJSON(u.InputMetrics, "", true)
	}

	if u.InputS3 != nil {
		return utils.MarshalJSON(u.InputS3, "", true)
	}

	if u.InputS3Inventory != nil {
		return utils.MarshalJSON(u.InputS3Inventory, "", true)
	}

	if u.InputSnmp != nil {
		return utils.MarshalJSON(u.InputSnmp, "", true)
	}

	if u.InputOpenTelemetry != nil {
		return utils.MarshalJSON(u.InputOpenTelemetry, "", true)
	}

	if u.InputModelDrivenTelemetry != nil {
		return utils.MarshalJSON(u.InputModelDrivenTelemetry, "", true)
	}

	if u.InputSqs != nil {
		return utils.MarshalJSON(u.InputSqs, "", true)
	}

	if u.InputSyslog != nil {
		return utils.MarshalJSON(u.InputSyslog, "", true)
	}

	if u.InputFile != nil {
		return utils.MarshalJSON(u.InputFile, "", true)
	}

	if u.InputTCP != nil {
		return utils.MarshalJSON(u.InputTCP, "", true)
	}

	if u.InputAppscope != nil {
		return utils.MarshalJSON(u.InputAppscope, "", true)
	}

	if u.InputWef != nil {
		return utils.MarshalJSON(u.InputWef, "", true)
	}

	if u.InputWinEventLogs != nil {
		return utils.MarshalJSON(u.InputWinEventLogs, "", true)
	}

	if u.InputRawUDP != nil {
		return utils.MarshalJSON(u.InputRawUDP, "", true)
	}

	if u.InputJournalFiles != nil {
		return utils.MarshalJSON(u.InputJournalFiles, "", true)
	}

	if u.InputWiz != nil {
		return utils.MarshalJSON(u.InputWiz, "", true)
	}

	if u.InputWizWebhook != nil {
		return utils.MarshalJSON(u.InputWizWebhook, "", true)
	}

	if u.InputNetflow != nil {
		return utils.MarshalJSON(u.InputNetflow, "", true)
	}

	if u.InputSecurityLake != nil {
		return utils.MarshalJSON(u.InputSecurityLake, "", true)
	}

	if u.InputZscalerHec != nil {
		return utils.MarshalJSON(u.InputZscalerHec, "", true)
	}

	if u.InputCloudflareHec != nil {
		return utils.MarshalJSON(u.InputCloudflareHec, "", true)
	}

	return nil, errors.New("could not marshal union type Input: all fields are null")
}
