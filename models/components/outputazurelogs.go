// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package components

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/criblio/cribl-control-plane-sdk-go/internal/utils"
)

type OutputAzureLogsType4 string

const (
	OutputAzureLogsType4AzureLogs OutputAzureLogsType4 = "azure_logs"
)

func (e OutputAzureLogsType4) ToPointer() *OutputAzureLogsType4 {
	return &e
}
func (e *OutputAzureLogsType4) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_logs":
		*e = OutputAzureLogsType4(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureLogsType4: %v", v)
	}
}

type OutputAzureLogsAzureLogs4 struct {
	// Enter credentials directly, or select a stored secret
	AuthType *AuthType2Options `default:"manual" json:"authType"`
	// Unique ID for this output
	ID   *string              `json:"id,omitempty"`
	Type OutputAzureLogsType4 `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The Log Type of events sent to this LogAnalytics workspace. Defaults to `Cribl`. Use only letters, numbers, and `_` characters, and can't exceed 100 characters. Can be overwritten by event field __logType.
	LogType *string `default:"Cribl" json:"logType"`
	// Optional Resource ID of the Azure resource to associate the data with. Can be overridden by the __resourceId event field. This ID populates the _ResourceId property, allowing the data to be included in resource-centric queries. If the ID is neither specified nor overridden, resource-centric queries will omit the data.
	ResourceID *string `json:"resourceId,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"1024" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	Compress         *bool    `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events
	ExtraHTTPHeaders []ExtraHTTPHeadersType `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *FailedRequestLoggingModeOptions `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// The DNS name of the Log API endpoint that sends log data to a Log Analytics workspace in Azure Monitor. Defaults to .ods.opinsights.azure.com. @{product} will add a prefix and suffix to construct a URI in this format: <https://<Workspace_ID><your_DNS_name>/api/logs?api-version=<API version>.
	APIURL *string `default:".ods.opinsights.azure.com" json:"apiUrl"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []ResponseRetrySettingsType `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *TimeoutRetrySettingsType   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"true" json:"responseHonorRetryAfterHeader"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *OnBackpressureOptions `default:"block" json:"onBackpressure"`
	Description    *string                `json:"description,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `default:"true" json:"pqStrictOrdering"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `default:"0" json:"pqRatePerSec"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *PqModeOptions `default:"error" json:"pqMode"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `default:"42" json:"pqMaxBufferSize"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `default:"30" json:"pqMaxBackpressureSec"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data
	PqCompress *PqCompressOptions `default:"none" json:"pqCompress"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *PqOnBackpressureOptions `default:"block" json:"pqOnBackpressure"`
	PqControls       *MetadataType            `json:"pqControls,omitempty"`
	// Azure Log Analytics Workspace ID. See Azure Dashboard Workspace > Advanced settings.
	WorkspaceID *string `json:"workspaceId,omitempty"`
	// Azure Log Analytics Workspace Primary or Secondary Shared Key. See Azure Dashboard Workspace > Advanced settings.
	WorkspaceKey *string `json:"workspaceKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	KeypairSecret string `json:"keypairSecret"`
}

func (o OutputAzureLogsAzureLogs4) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureLogsAzureLogs4) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"type", "keypairSecret"}); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureLogsAzureLogs4) GetAuthType() *AuthType2Options {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputAzureLogsAzureLogs4) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputAzureLogsAzureLogs4) GetType() OutputAzureLogsType4 {
	if o == nil {
		return OutputAzureLogsType4("")
	}
	return o.Type
}

func (o *OutputAzureLogsAzureLogs4) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputAzureLogsAzureLogs4) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputAzureLogsAzureLogs4) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputAzureLogsAzureLogs4) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputAzureLogsAzureLogs4) GetLogType() *string {
	if o == nil {
		return nil
	}
	return o.LogType
}

func (o *OutputAzureLogsAzureLogs4) GetResourceID() *string {
	if o == nil {
		return nil
	}
	return o.ResourceID
}

func (o *OutputAzureLogsAzureLogs4) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputAzureLogsAzureLogs4) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputAzureLogsAzureLogs4) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputAzureLogsAzureLogs4) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputAzureLogsAzureLogs4) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputAzureLogsAzureLogs4) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputAzureLogsAzureLogs4) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputAzureLogsAzureLogs4) GetExtraHTTPHeaders() []ExtraHTTPHeadersType {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputAzureLogsAzureLogs4) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputAzureLogsAzureLogs4) GetFailedRequestLoggingMode() *FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputAzureLogsAzureLogs4) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputAzureLogsAzureLogs4) GetAPIURL() *string {
	if o == nil {
		return nil
	}
	return o.APIURL
}

func (o *OutputAzureLogsAzureLogs4) GetResponseRetrySettings() []ResponseRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputAzureLogsAzureLogs4) GetTimeoutRetrySettings() *TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputAzureLogsAzureLogs4) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputAzureLogsAzureLogs4) GetOnBackpressure() *OnBackpressureOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputAzureLogsAzureLogs4) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputAzureLogsAzureLogs4) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputAzureLogsAzureLogs4) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputAzureLogsAzureLogs4) GetPqMode() *PqModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputAzureLogsAzureLogs4) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputAzureLogsAzureLogs4) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputAzureLogsAzureLogs4) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputAzureLogsAzureLogs4) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputAzureLogsAzureLogs4) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputAzureLogsAzureLogs4) GetPqCompress() *PqCompressOptions {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputAzureLogsAzureLogs4) GetPqOnBackpressure() *PqOnBackpressureOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputAzureLogsAzureLogs4) GetPqControls() *MetadataType {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputAzureLogsAzureLogs4) GetWorkspaceID() *string {
	if o == nil {
		return nil
	}
	return o.WorkspaceID
}

func (o *OutputAzureLogsAzureLogs4) GetWorkspaceKey() *string {
	if o == nil {
		return nil
	}
	return o.WorkspaceKey
}

func (o *OutputAzureLogsAzureLogs4) GetKeypairSecret() string {
	if o == nil {
		return ""
	}
	return o.KeypairSecret
}

type OutputAzureLogsType3 string

const (
	OutputAzureLogsType3AzureLogs OutputAzureLogsType3 = "azure_logs"
)

func (e OutputAzureLogsType3) ToPointer() *OutputAzureLogsType3 {
	return &e
}
func (e *OutputAzureLogsType3) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_logs":
		*e = OutputAzureLogsType3(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureLogsType3: %v", v)
	}
}

type OutputAzureLogsAzureLogs3 struct {
	// Enter credentials directly, or select a stored secret
	AuthType *AuthType2Options `default:"manual" json:"authType"`
	// Unique ID for this output
	ID   *string              `json:"id,omitempty"`
	Type OutputAzureLogsType3 `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The Log Type of events sent to this LogAnalytics workspace. Defaults to `Cribl`. Use only letters, numbers, and `_` characters, and can't exceed 100 characters. Can be overwritten by event field __logType.
	LogType *string `default:"Cribl" json:"logType"`
	// Optional Resource ID of the Azure resource to associate the data with. Can be overridden by the __resourceId event field. This ID populates the _ResourceId property, allowing the data to be included in resource-centric queries. If the ID is neither specified nor overridden, resource-centric queries will omit the data.
	ResourceID *string `json:"resourceId,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"1024" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	Compress         *bool    `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events
	ExtraHTTPHeaders []ExtraHTTPHeadersType `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *FailedRequestLoggingModeOptions `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// The DNS name of the Log API endpoint that sends log data to a Log Analytics workspace in Azure Monitor. Defaults to .ods.opinsights.azure.com. @{product} will add a prefix and suffix to construct a URI in this format: <https://<Workspace_ID><your_DNS_name>/api/logs?api-version=<API version>.
	APIURL *string `default:".ods.opinsights.azure.com" json:"apiUrl"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []ResponseRetrySettingsType `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *TimeoutRetrySettingsType   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"true" json:"responseHonorRetryAfterHeader"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *OnBackpressureOptions `default:"block" json:"onBackpressure"`
	Description    *string                `json:"description,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `default:"true" json:"pqStrictOrdering"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `default:"0" json:"pqRatePerSec"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *PqModeOptions `default:"error" json:"pqMode"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `default:"42" json:"pqMaxBufferSize"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `default:"30" json:"pqMaxBackpressureSec"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data
	PqCompress *PqCompressOptions `default:"none" json:"pqCompress"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *PqOnBackpressureOptions `default:"block" json:"pqOnBackpressure"`
	PqControls       *MetadataType            `json:"pqControls,omitempty"`
	// Azure Log Analytics Workspace ID. See Azure Dashboard Workspace > Advanced settings.
	WorkspaceID string `json:"workspaceId"`
	// Azure Log Analytics Workspace Primary or Secondary Shared Key. See Azure Dashboard Workspace > Advanced settings.
	WorkspaceKey string `json:"workspaceKey"`
	// Select or create a stored secret that references your access key and secret key
	KeypairSecret *string `json:"keypairSecret,omitempty"`
}

func (o OutputAzureLogsAzureLogs3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureLogsAzureLogs3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"type", "workspaceId", "workspaceKey"}); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureLogsAzureLogs3) GetAuthType() *AuthType2Options {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputAzureLogsAzureLogs3) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputAzureLogsAzureLogs3) GetType() OutputAzureLogsType3 {
	if o == nil {
		return OutputAzureLogsType3("")
	}
	return o.Type
}

func (o *OutputAzureLogsAzureLogs3) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputAzureLogsAzureLogs3) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputAzureLogsAzureLogs3) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputAzureLogsAzureLogs3) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputAzureLogsAzureLogs3) GetLogType() *string {
	if o == nil {
		return nil
	}
	return o.LogType
}

func (o *OutputAzureLogsAzureLogs3) GetResourceID() *string {
	if o == nil {
		return nil
	}
	return o.ResourceID
}

func (o *OutputAzureLogsAzureLogs3) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputAzureLogsAzureLogs3) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputAzureLogsAzureLogs3) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputAzureLogsAzureLogs3) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputAzureLogsAzureLogs3) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputAzureLogsAzureLogs3) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputAzureLogsAzureLogs3) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputAzureLogsAzureLogs3) GetExtraHTTPHeaders() []ExtraHTTPHeadersType {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputAzureLogsAzureLogs3) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputAzureLogsAzureLogs3) GetFailedRequestLoggingMode() *FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputAzureLogsAzureLogs3) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputAzureLogsAzureLogs3) GetAPIURL() *string {
	if o == nil {
		return nil
	}
	return o.APIURL
}

func (o *OutputAzureLogsAzureLogs3) GetResponseRetrySettings() []ResponseRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputAzureLogsAzureLogs3) GetTimeoutRetrySettings() *TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputAzureLogsAzureLogs3) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputAzureLogsAzureLogs3) GetOnBackpressure() *OnBackpressureOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputAzureLogsAzureLogs3) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputAzureLogsAzureLogs3) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputAzureLogsAzureLogs3) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputAzureLogsAzureLogs3) GetPqMode() *PqModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputAzureLogsAzureLogs3) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputAzureLogsAzureLogs3) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputAzureLogsAzureLogs3) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputAzureLogsAzureLogs3) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputAzureLogsAzureLogs3) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputAzureLogsAzureLogs3) GetPqCompress() *PqCompressOptions {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputAzureLogsAzureLogs3) GetPqOnBackpressure() *PqOnBackpressureOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputAzureLogsAzureLogs3) GetPqControls() *MetadataType {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputAzureLogsAzureLogs3) GetWorkspaceID() string {
	if o == nil {
		return ""
	}
	return o.WorkspaceID
}

func (o *OutputAzureLogsAzureLogs3) GetWorkspaceKey() string {
	if o == nil {
		return ""
	}
	return o.WorkspaceKey
}

func (o *OutputAzureLogsAzureLogs3) GetKeypairSecret() *string {
	if o == nil {
		return nil
	}
	return o.KeypairSecret
}

type OutputAzureLogsType2 string

const (
	OutputAzureLogsType2AzureLogs OutputAzureLogsType2 = "azure_logs"
)

func (e OutputAzureLogsType2) ToPointer() *OutputAzureLogsType2 {
	return &e
}
func (e *OutputAzureLogsType2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_logs":
		*e = OutputAzureLogsType2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureLogsType2: %v", v)
	}
}

type OutputAzureLogsAzureLogs2 struct {
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *OnBackpressureOptions `default:"block" json:"onBackpressure"`
	// Unique ID for this output
	ID   *string              `json:"id,omitempty"`
	Type OutputAzureLogsType2 `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The Log Type of events sent to this LogAnalytics workspace. Defaults to `Cribl`. Use only letters, numbers, and `_` characters, and can't exceed 100 characters. Can be overwritten by event field __logType.
	LogType *string `default:"Cribl" json:"logType"`
	// Optional Resource ID of the Azure resource to associate the data with. Can be overridden by the __resourceId event field. This ID populates the _ResourceId property, allowing the data to be included in resource-centric queries. If the ID is neither specified nor overridden, resource-centric queries will omit the data.
	ResourceID *string `json:"resourceId,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"1024" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	Compress         *bool    `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events
	ExtraHTTPHeaders []ExtraHTTPHeadersType `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *FailedRequestLoggingModeOptions `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// The DNS name of the Log API endpoint that sends log data to a Log Analytics workspace in Azure Monitor. Defaults to .ods.opinsights.azure.com. @{product} will add a prefix and suffix to construct a URI in this format: <https://<Workspace_ID><your_DNS_name>/api/logs?api-version=<API version>.
	APIURL *string `default:".ods.opinsights.azure.com" json:"apiUrl"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []ResponseRetrySettingsType `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *TimeoutRetrySettingsType   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"true" json:"responseHonorRetryAfterHeader"`
	// Enter credentials directly, or select a stored secret
	AuthType    *AuthType2Options `default:"manual" json:"authType"`
	Description *string           `json:"description,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `default:"true" json:"pqStrictOrdering"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `default:"0" json:"pqRatePerSec"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *PqModeOptions `default:"error" json:"pqMode"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `default:"42" json:"pqMaxBufferSize"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `default:"30" json:"pqMaxBackpressureSec"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data
	PqCompress *PqCompressOptions `default:"none" json:"pqCompress"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *PqOnBackpressureOptions `default:"block" json:"pqOnBackpressure"`
	PqControls       MetadataType             `json:"pqControls"`
	// Azure Log Analytics Workspace ID. See Azure Dashboard Workspace > Advanced settings.
	WorkspaceID *string `json:"workspaceId,omitempty"`
	// Azure Log Analytics Workspace Primary or Secondary Shared Key. See Azure Dashboard Workspace > Advanced settings.
	WorkspaceKey *string `json:"workspaceKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	KeypairSecret *string `json:"keypairSecret,omitempty"`
}

func (o OutputAzureLogsAzureLogs2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureLogsAzureLogs2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"type", "pqControls"}); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureLogsAzureLogs2) GetOnBackpressure() *OnBackpressureOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputAzureLogsAzureLogs2) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputAzureLogsAzureLogs2) GetType() OutputAzureLogsType2 {
	if o == nil {
		return OutputAzureLogsType2("")
	}
	return o.Type
}

func (o *OutputAzureLogsAzureLogs2) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputAzureLogsAzureLogs2) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputAzureLogsAzureLogs2) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputAzureLogsAzureLogs2) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputAzureLogsAzureLogs2) GetLogType() *string {
	if o == nil {
		return nil
	}
	return o.LogType
}

func (o *OutputAzureLogsAzureLogs2) GetResourceID() *string {
	if o == nil {
		return nil
	}
	return o.ResourceID
}

func (o *OutputAzureLogsAzureLogs2) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputAzureLogsAzureLogs2) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputAzureLogsAzureLogs2) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputAzureLogsAzureLogs2) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputAzureLogsAzureLogs2) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputAzureLogsAzureLogs2) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputAzureLogsAzureLogs2) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputAzureLogsAzureLogs2) GetExtraHTTPHeaders() []ExtraHTTPHeadersType {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputAzureLogsAzureLogs2) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputAzureLogsAzureLogs2) GetFailedRequestLoggingMode() *FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputAzureLogsAzureLogs2) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputAzureLogsAzureLogs2) GetAPIURL() *string {
	if o == nil {
		return nil
	}
	return o.APIURL
}

func (o *OutputAzureLogsAzureLogs2) GetResponseRetrySettings() []ResponseRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputAzureLogsAzureLogs2) GetTimeoutRetrySettings() *TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputAzureLogsAzureLogs2) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputAzureLogsAzureLogs2) GetAuthType() *AuthType2Options {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputAzureLogsAzureLogs2) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputAzureLogsAzureLogs2) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputAzureLogsAzureLogs2) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputAzureLogsAzureLogs2) GetPqMode() *PqModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputAzureLogsAzureLogs2) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputAzureLogsAzureLogs2) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputAzureLogsAzureLogs2) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputAzureLogsAzureLogs2) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputAzureLogsAzureLogs2) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputAzureLogsAzureLogs2) GetPqCompress() *PqCompressOptions {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputAzureLogsAzureLogs2) GetPqOnBackpressure() *PqOnBackpressureOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputAzureLogsAzureLogs2) GetPqControls() MetadataType {
	if o == nil {
		return MetadataType{}
	}
	return o.PqControls
}

func (o *OutputAzureLogsAzureLogs2) GetWorkspaceID() *string {
	if o == nil {
		return nil
	}
	return o.WorkspaceID
}

func (o *OutputAzureLogsAzureLogs2) GetWorkspaceKey() *string {
	if o == nil {
		return nil
	}
	return o.WorkspaceKey
}

func (o *OutputAzureLogsAzureLogs2) GetKeypairSecret() *string {
	if o == nil {
		return nil
	}
	return o.KeypairSecret
}

type OutputAzureLogsType1 string

const (
	OutputAzureLogsType1AzureLogs OutputAzureLogsType1 = "azure_logs"
)

func (e OutputAzureLogsType1) ToPointer() *OutputAzureLogsType1 {
	return &e
}
func (e *OutputAzureLogsType1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_logs":
		*e = OutputAzureLogsType1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureLogsType1: %v", v)
	}
}

type OutputAzureLogsAzureLogs1 struct {
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *OnBackpressureOptions `default:"block" json:"onBackpressure"`
	// Unique ID for this output
	ID   *string              `json:"id,omitempty"`
	Type OutputAzureLogsType1 `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The Log Type of events sent to this LogAnalytics workspace. Defaults to `Cribl`. Use only letters, numbers, and `_` characters, and can't exceed 100 characters. Can be overwritten by event field __logType.
	LogType *string `default:"Cribl" json:"logType"`
	// Optional Resource ID of the Azure resource to associate the data with. Can be overridden by the __resourceId event field. This ID populates the _ResourceId property, allowing the data to be included in resource-centric queries. If the ID is neither specified nor overridden, resource-centric queries will omit the data.
	ResourceID *string `json:"resourceId,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"1024" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	Compress         *bool    `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events
	ExtraHTTPHeaders []ExtraHTTPHeadersType `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *FailedRequestLoggingModeOptions `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// The DNS name of the Log API endpoint that sends log data to a Log Analytics workspace in Azure Monitor. Defaults to .ods.opinsights.azure.com. @{product} will add a prefix and suffix to construct a URI in this format: <https://<Workspace_ID><your_DNS_name>/api/logs?api-version=<API version>.
	APIURL *string `default:".ods.opinsights.azure.com" json:"apiUrl"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []ResponseRetrySettingsType `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *TimeoutRetrySettingsType   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"true" json:"responseHonorRetryAfterHeader"`
	// Enter credentials directly, or select a stored secret
	AuthType    *AuthType2Options `default:"manual" json:"authType"`
	Description *string           `json:"description,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `default:"true" json:"pqStrictOrdering"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `default:"0" json:"pqRatePerSec"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *PqModeOptions `default:"error" json:"pqMode"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `default:"42" json:"pqMaxBufferSize"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `default:"30" json:"pqMaxBackpressureSec"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data
	PqCompress *PqCompressOptions `default:"none" json:"pqCompress"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *PqOnBackpressureOptions `default:"block" json:"pqOnBackpressure"`
	PqControls       *MetadataType            `json:"pqControls,omitempty"`
	// Azure Log Analytics Workspace ID. See Azure Dashboard Workspace > Advanced settings.
	WorkspaceID *string `json:"workspaceId,omitempty"`
	// Azure Log Analytics Workspace Primary or Secondary Shared Key. See Azure Dashboard Workspace > Advanced settings.
	WorkspaceKey *string `json:"workspaceKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	KeypairSecret *string `json:"keypairSecret,omitempty"`
}

func (o OutputAzureLogsAzureLogs1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureLogsAzureLogs1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureLogsAzureLogs1) GetOnBackpressure() *OnBackpressureOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputAzureLogsAzureLogs1) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputAzureLogsAzureLogs1) GetType() OutputAzureLogsType1 {
	if o == nil {
		return OutputAzureLogsType1("")
	}
	return o.Type
}

func (o *OutputAzureLogsAzureLogs1) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputAzureLogsAzureLogs1) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputAzureLogsAzureLogs1) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputAzureLogsAzureLogs1) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputAzureLogsAzureLogs1) GetLogType() *string {
	if o == nil {
		return nil
	}
	return o.LogType
}

func (o *OutputAzureLogsAzureLogs1) GetResourceID() *string {
	if o == nil {
		return nil
	}
	return o.ResourceID
}

func (o *OutputAzureLogsAzureLogs1) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputAzureLogsAzureLogs1) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputAzureLogsAzureLogs1) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputAzureLogsAzureLogs1) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputAzureLogsAzureLogs1) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputAzureLogsAzureLogs1) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputAzureLogsAzureLogs1) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputAzureLogsAzureLogs1) GetExtraHTTPHeaders() []ExtraHTTPHeadersType {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputAzureLogsAzureLogs1) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputAzureLogsAzureLogs1) GetFailedRequestLoggingMode() *FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputAzureLogsAzureLogs1) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputAzureLogsAzureLogs1) GetAPIURL() *string {
	if o == nil {
		return nil
	}
	return o.APIURL
}

func (o *OutputAzureLogsAzureLogs1) GetResponseRetrySettings() []ResponseRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputAzureLogsAzureLogs1) GetTimeoutRetrySettings() *TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputAzureLogsAzureLogs1) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputAzureLogsAzureLogs1) GetAuthType() *AuthType2Options {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputAzureLogsAzureLogs1) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputAzureLogsAzureLogs1) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputAzureLogsAzureLogs1) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputAzureLogsAzureLogs1) GetPqMode() *PqModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputAzureLogsAzureLogs1) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputAzureLogsAzureLogs1) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputAzureLogsAzureLogs1) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputAzureLogsAzureLogs1) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputAzureLogsAzureLogs1) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputAzureLogsAzureLogs1) GetPqCompress() *PqCompressOptions {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputAzureLogsAzureLogs1) GetPqOnBackpressure() *PqOnBackpressureOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputAzureLogsAzureLogs1) GetPqControls() *MetadataType {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputAzureLogsAzureLogs1) GetWorkspaceID() *string {
	if o == nil {
		return nil
	}
	return o.WorkspaceID
}

func (o *OutputAzureLogsAzureLogs1) GetWorkspaceKey() *string {
	if o == nil {
		return nil
	}
	return o.WorkspaceKey
}

func (o *OutputAzureLogsAzureLogs1) GetKeypairSecret() *string {
	if o == nil {
		return nil
	}
	return o.KeypairSecret
}

type OutputAzureLogsType string

const (
	OutputAzureLogsTypeOutputAzureLogsAzureLogs1 OutputAzureLogsType = "OutputAzureLogs_AzureLogs_1"
	OutputAzureLogsTypeOutputAzureLogsAzureLogs2 OutputAzureLogsType = "OutputAzureLogs_AzureLogs_2"
	OutputAzureLogsTypeOutputAzureLogsAzureLogs3 OutputAzureLogsType = "OutputAzureLogs_AzureLogs_3"
	OutputAzureLogsTypeOutputAzureLogsAzureLogs4 OutputAzureLogsType = "OutputAzureLogs_AzureLogs_4"
)

type OutputAzureLogs struct {
	OutputAzureLogsAzureLogs1 *OutputAzureLogsAzureLogs1 `queryParam:"inline,name=OutputAzureLogs"`
	OutputAzureLogsAzureLogs2 *OutputAzureLogsAzureLogs2 `queryParam:"inline,name=OutputAzureLogs"`
	OutputAzureLogsAzureLogs3 *OutputAzureLogsAzureLogs3 `queryParam:"inline,name=OutputAzureLogs"`
	OutputAzureLogsAzureLogs4 *OutputAzureLogsAzureLogs4 `queryParam:"inline,name=OutputAzureLogs"`

	Type OutputAzureLogsType
}

func CreateOutputAzureLogsOutputAzureLogsAzureLogs1(outputAzureLogsAzureLogs1 OutputAzureLogsAzureLogs1) OutputAzureLogs {
	typ := OutputAzureLogsTypeOutputAzureLogsAzureLogs1

	return OutputAzureLogs{
		OutputAzureLogsAzureLogs1: &outputAzureLogsAzureLogs1,
		Type:                      typ,
	}
}

func CreateOutputAzureLogsOutputAzureLogsAzureLogs2(outputAzureLogsAzureLogs2 OutputAzureLogsAzureLogs2) OutputAzureLogs {
	typ := OutputAzureLogsTypeOutputAzureLogsAzureLogs2

	return OutputAzureLogs{
		OutputAzureLogsAzureLogs2: &outputAzureLogsAzureLogs2,
		Type:                      typ,
	}
}

func CreateOutputAzureLogsOutputAzureLogsAzureLogs3(outputAzureLogsAzureLogs3 OutputAzureLogsAzureLogs3) OutputAzureLogs {
	typ := OutputAzureLogsTypeOutputAzureLogsAzureLogs3

	return OutputAzureLogs{
		OutputAzureLogsAzureLogs3: &outputAzureLogsAzureLogs3,
		Type:                      typ,
	}
}

func CreateOutputAzureLogsOutputAzureLogsAzureLogs4(outputAzureLogsAzureLogs4 OutputAzureLogsAzureLogs4) OutputAzureLogs {
	typ := OutputAzureLogsTypeOutputAzureLogsAzureLogs4

	return OutputAzureLogs{
		OutputAzureLogsAzureLogs4: &outputAzureLogsAzureLogs4,
		Type:                      typ,
	}
}

func (u *OutputAzureLogs) UnmarshalJSON(data []byte) error {

	var outputAzureLogsAzureLogs3 OutputAzureLogsAzureLogs3 = OutputAzureLogsAzureLogs3{}
	if err := utils.UnmarshalJSON(data, &outputAzureLogsAzureLogs3, "", true, nil); err == nil {
		u.OutputAzureLogsAzureLogs3 = &outputAzureLogsAzureLogs3
		u.Type = OutputAzureLogsTypeOutputAzureLogsAzureLogs3
		return nil
	}

	var outputAzureLogsAzureLogs2 OutputAzureLogsAzureLogs2 = OutputAzureLogsAzureLogs2{}
	if err := utils.UnmarshalJSON(data, &outputAzureLogsAzureLogs2, "", true, nil); err == nil {
		u.OutputAzureLogsAzureLogs2 = &outputAzureLogsAzureLogs2
		u.Type = OutputAzureLogsTypeOutputAzureLogsAzureLogs2
		return nil
	}

	var outputAzureLogsAzureLogs4 OutputAzureLogsAzureLogs4 = OutputAzureLogsAzureLogs4{}
	if err := utils.UnmarshalJSON(data, &outputAzureLogsAzureLogs4, "", true, nil); err == nil {
		u.OutputAzureLogsAzureLogs4 = &outputAzureLogsAzureLogs4
		u.Type = OutputAzureLogsTypeOutputAzureLogsAzureLogs4
		return nil
	}

	var outputAzureLogsAzureLogs1 OutputAzureLogsAzureLogs1 = OutputAzureLogsAzureLogs1{}
	if err := utils.UnmarshalJSON(data, &outputAzureLogsAzureLogs1, "", true, nil); err == nil {
		u.OutputAzureLogsAzureLogs1 = &outputAzureLogsAzureLogs1
		u.Type = OutputAzureLogsTypeOutputAzureLogsAzureLogs1
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for OutputAzureLogs", string(data))
}

func (u OutputAzureLogs) MarshalJSON() ([]byte, error) {
	if u.OutputAzureLogsAzureLogs1 != nil {
		return utils.MarshalJSON(u.OutputAzureLogsAzureLogs1, "", true)
	}

	if u.OutputAzureLogsAzureLogs2 != nil {
		return utils.MarshalJSON(u.OutputAzureLogsAzureLogs2, "", true)
	}

	if u.OutputAzureLogsAzureLogs3 != nil {
		return utils.MarshalJSON(u.OutputAzureLogsAzureLogs3, "", true)
	}

	if u.OutputAzureLogsAzureLogs4 != nil {
		return utils.MarshalJSON(u.OutputAzureLogsAzureLogs4, "", true)
	}

	return nil, errors.New("could not marshal union type OutputAzureLogs: all fields are null")
}
