// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package components

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/criblio/cribl-control-plane-sdk-go/internal/utils"
)

type InputKubeLogsType4 string

const (
	InputKubeLogsType4KubeLogs InputKubeLogsType4 = "kube_logs"
)

func (e InputKubeLogsType4) ToPointer() *InputKubeLogsType4 {
	return &e
}
func (e *InputKubeLogsType4) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kube_logs":
		*e = InputKubeLogsType4(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKubeLogsType4: %v", v)
	}
}

type InputKubeLogsKubeLogs4 struct {
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Unique ID for this input
	ID       *string            `json:"id,omitempty"`
	Type     InputKubeLogsType4 `json:"type"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionsType `json:"connections,omitempty"`
	Pq          PqType            `json:"pq"`
	// Time, in seconds, between checks for new containers. Default is 15 secs.
	Interval *float64 `default:"15" json:"interval"`
	// Add rules to decide which Pods to collect logs from. Logs are collected if no rules are given or if all the rules' expressions evaluate to true.
	Rules []PodFilterType `json:"rules,omitempty"`
	// For use when containers do not emit a timestamp, prefix each line of output with a timestamp. If you enable this setting, you can use the Kubernetes Logs Event Breaker and the kubernetes_logs Pre-processing Pipeline to remove them from the events after the timestamps are extracted.
	Timestamps *bool `default:"false" json:"timestamps"`
	// Fields to add to events from this input
	Metadata    []Metadata1Type  `json:"metadata,omitempty"`
	Persistence *PersistenceType `json:"persistence,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool   `default:"false" json:"enableLoadBalancing"`
	Description         *string `json:"description,omitempty"`
}

func (i InputKubeLogsKubeLogs4) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeLogsKubeLogs4) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "pq"}); err != nil {
		return err
	}
	return nil
}

func (i *InputKubeLogsKubeLogs4) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputKubeLogsKubeLogs4) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputKubeLogsKubeLogs4) GetType() InputKubeLogsType4 {
	if i == nil {
		return InputKubeLogsType4("")
	}
	return i.Type
}

func (i *InputKubeLogsKubeLogs4) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKubeLogsKubeLogs4) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputKubeLogsKubeLogs4) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputKubeLogsKubeLogs4) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputKubeLogsKubeLogs4) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputKubeLogsKubeLogs4) GetConnections() []ConnectionsType {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputKubeLogsKubeLogs4) GetPq() PqType {
	if i == nil {
		return PqType{}
	}
	return i.Pq
}

func (i *InputKubeLogsKubeLogs4) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputKubeLogsKubeLogs4) GetRules() []PodFilterType {
	if i == nil {
		return nil
	}
	return i.Rules
}

func (i *InputKubeLogsKubeLogs4) GetTimestamps() *bool {
	if i == nil {
		return nil
	}
	return i.Timestamps
}

func (i *InputKubeLogsKubeLogs4) GetMetadata() []Metadata1Type {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputKubeLogsKubeLogs4) GetPersistence() *PersistenceType {
	if i == nil {
		return nil
	}
	return i.Persistence
}

func (i *InputKubeLogsKubeLogs4) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputKubeLogsKubeLogs4) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputKubeLogsKubeLogs4) GetEnableLoadBalancing() *bool {
	if i == nil {
		return nil
	}
	return i.EnableLoadBalancing
}

func (i *InputKubeLogsKubeLogs4) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type InputKubeLogsType3 string

const (
	InputKubeLogsType3KubeLogs InputKubeLogsType3 = "kube_logs"
)

func (e InputKubeLogsType3) ToPointer() *InputKubeLogsType3 {
	return &e
}
func (e *InputKubeLogsType3) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kube_logs":
		*e = InputKubeLogsType3(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKubeLogsType3: %v", v)
	}
}

type InputKubeLogsKubeLogs3 struct {
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Unique ID for this input
	ID       *string            `json:"id,omitempty"`
	Type     InputKubeLogsType3 `json:"type"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionsType `json:"connections,omitempty"`
	Pq          *PqType           `json:"pq,omitempty"`
	// Time, in seconds, between checks for new containers. Default is 15 secs.
	Interval *float64 `default:"15" json:"interval"`
	// Add rules to decide which Pods to collect logs from. Logs are collected if no rules are given or if all the rules' expressions evaluate to true.
	Rules []PodFilterType `json:"rules,omitempty"`
	// For use when containers do not emit a timestamp, prefix each line of output with a timestamp. If you enable this setting, you can use the Kubernetes Logs Event Breaker and the kubernetes_logs Pre-processing Pipeline to remove them from the events after the timestamps are extracted.
	Timestamps *bool `default:"false" json:"timestamps"`
	// Fields to add to events from this input
	Metadata    []Metadata1Type  `json:"metadata,omitempty"`
	Persistence *PersistenceType `json:"persistence,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool   `default:"false" json:"enableLoadBalancing"`
	Description         *string `json:"description,omitempty"`
}

func (i InputKubeLogsKubeLogs3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeLogsKubeLogs3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputKubeLogsKubeLogs3) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputKubeLogsKubeLogs3) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputKubeLogsKubeLogs3) GetType() InputKubeLogsType3 {
	if i == nil {
		return InputKubeLogsType3("")
	}
	return i.Type
}

func (i *InputKubeLogsKubeLogs3) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKubeLogsKubeLogs3) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputKubeLogsKubeLogs3) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputKubeLogsKubeLogs3) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputKubeLogsKubeLogs3) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputKubeLogsKubeLogs3) GetConnections() []ConnectionsType {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputKubeLogsKubeLogs3) GetPq() *PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputKubeLogsKubeLogs3) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputKubeLogsKubeLogs3) GetRules() []PodFilterType {
	if i == nil {
		return nil
	}
	return i.Rules
}

func (i *InputKubeLogsKubeLogs3) GetTimestamps() *bool {
	if i == nil {
		return nil
	}
	return i.Timestamps
}

func (i *InputKubeLogsKubeLogs3) GetMetadata() []Metadata1Type {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputKubeLogsKubeLogs3) GetPersistence() *PersistenceType {
	if i == nil {
		return nil
	}
	return i.Persistence
}

func (i *InputKubeLogsKubeLogs3) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputKubeLogsKubeLogs3) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputKubeLogsKubeLogs3) GetEnableLoadBalancing() *bool {
	if i == nil {
		return nil
	}
	return i.EnableLoadBalancing
}

func (i *InputKubeLogsKubeLogs3) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type InputKubeLogsType2 string

const (
	InputKubeLogsType2KubeLogs InputKubeLogsType2 = "kube_logs"
)

func (e InputKubeLogsType2) ToPointer() *InputKubeLogsType2 {
	return &e
}
func (e *InputKubeLogsType2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kube_logs":
		*e = InputKubeLogsType2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKubeLogsType2: %v", v)
	}
}

type InputKubeLogsKubeLogs2 struct {
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Unique ID for this input
	ID       *string            `json:"id,omitempty"`
	Type     InputKubeLogsType2 `json:"type"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionsType `json:"connections"`
	Pq          *PqType           `json:"pq,omitempty"`
	// Time, in seconds, between checks for new containers. Default is 15 secs.
	Interval *float64 `default:"15" json:"interval"`
	// Add rules to decide which Pods to collect logs from. Logs are collected if no rules are given or if all the rules' expressions evaluate to true.
	Rules []PodFilterType `json:"rules,omitempty"`
	// For use when containers do not emit a timestamp, prefix each line of output with a timestamp. If you enable this setting, you can use the Kubernetes Logs Event Breaker and the kubernetes_logs Pre-processing Pipeline to remove them from the events after the timestamps are extracted.
	Timestamps *bool `default:"false" json:"timestamps"`
	// Fields to add to events from this input
	Metadata    []Metadata1Type  `json:"metadata,omitempty"`
	Persistence *PersistenceType `json:"persistence,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool   `default:"false" json:"enableLoadBalancing"`
	Description         *string `json:"description,omitempty"`
}

func (i InputKubeLogsKubeLogs2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeLogsKubeLogs2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "connections"}); err != nil {
		return err
	}
	return nil
}

func (i *InputKubeLogsKubeLogs2) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputKubeLogsKubeLogs2) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputKubeLogsKubeLogs2) GetType() InputKubeLogsType2 {
	if i == nil {
		return InputKubeLogsType2("")
	}
	return i.Type
}

func (i *InputKubeLogsKubeLogs2) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKubeLogsKubeLogs2) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputKubeLogsKubeLogs2) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputKubeLogsKubeLogs2) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputKubeLogsKubeLogs2) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputKubeLogsKubeLogs2) GetConnections() []ConnectionsType {
	if i == nil {
		return []ConnectionsType{}
	}
	return i.Connections
}

func (i *InputKubeLogsKubeLogs2) GetPq() *PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputKubeLogsKubeLogs2) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputKubeLogsKubeLogs2) GetRules() []PodFilterType {
	if i == nil {
		return nil
	}
	return i.Rules
}

func (i *InputKubeLogsKubeLogs2) GetTimestamps() *bool {
	if i == nil {
		return nil
	}
	return i.Timestamps
}

func (i *InputKubeLogsKubeLogs2) GetMetadata() []Metadata1Type {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputKubeLogsKubeLogs2) GetPersistence() *PersistenceType {
	if i == nil {
		return nil
	}
	return i.Persistence
}

func (i *InputKubeLogsKubeLogs2) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputKubeLogsKubeLogs2) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputKubeLogsKubeLogs2) GetEnableLoadBalancing() *bool {
	if i == nil {
		return nil
	}
	return i.EnableLoadBalancing
}

func (i *InputKubeLogsKubeLogs2) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type InputKubeLogsType1 string

const (
	InputKubeLogsType1KubeLogs InputKubeLogsType1 = "kube_logs"
)

func (e InputKubeLogsType1) ToPointer() *InputKubeLogsType1 {
	return &e
}
func (e *InputKubeLogsType1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kube_logs":
		*e = InputKubeLogsType1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKubeLogsType1: %v", v)
	}
}

type InputKubeLogsKubeLogs1 struct {
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Unique ID for this input
	ID       *string            `json:"id,omitempty"`
	Type     InputKubeLogsType1 `json:"type"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionsType `json:"connections,omitempty"`
	Pq          *PqType           `json:"pq,omitempty"`
	// Time, in seconds, between checks for new containers. Default is 15 secs.
	Interval *float64 `default:"15" json:"interval"`
	// Add rules to decide which Pods to collect logs from. Logs are collected if no rules are given or if all the rules' expressions evaluate to true.
	Rules []PodFilterType `json:"rules,omitempty"`
	// For use when containers do not emit a timestamp, prefix each line of output with a timestamp. If you enable this setting, you can use the Kubernetes Logs Event Breaker and the kubernetes_logs Pre-processing Pipeline to remove them from the events after the timestamps are extracted.
	Timestamps *bool `default:"false" json:"timestamps"`
	// Fields to add to events from this input
	Metadata    []Metadata1Type  `json:"metadata,omitempty"`
	Persistence *PersistenceType `json:"persistence,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool   `default:"false" json:"enableLoadBalancing"`
	Description         *string `json:"description,omitempty"`
}

func (i InputKubeLogsKubeLogs1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeLogsKubeLogs1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputKubeLogsKubeLogs1) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputKubeLogsKubeLogs1) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputKubeLogsKubeLogs1) GetType() InputKubeLogsType1 {
	if i == nil {
		return InputKubeLogsType1("")
	}
	return i.Type
}

func (i *InputKubeLogsKubeLogs1) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKubeLogsKubeLogs1) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputKubeLogsKubeLogs1) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputKubeLogsKubeLogs1) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputKubeLogsKubeLogs1) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputKubeLogsKubeLogs1) GetConnections() []ConnectionsType {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputKubeLogsKubeLogs1) GetPq() *PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputKubeLogsKubeLogs1) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputKubeLogsKubeLogs1) GetRules() []PodFilterType {
	if i == nil {
		return nil
	}
	return i.Rules
}

func (i *InputKubeLogsKubeLogs1) GetTimestamps() *bool {
	if i == nil {
		return nil
	}
	return i.Timestamps
}

func (i *InputKubeLogsKubeLogs1) GetMetadata() []Metadata1Type {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputKubeLogsKubeLogs1) GetPersistence() *PersistenceType {
	if i == nil {
		return nil
	}
	return i.Persistence
}

func (i *InputKubeLogsKubeLogs1) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputKubeLogsKubeLogs1) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputKubeLogsKubeLogs1) GetEnableLoadBalancing() *bool {
	if i == nil {
		return nil
	}
	return i.EnableLoadBalancing
}

func (i *InputKubeLogsKubeLogs1) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type InputKubeLogsType string

const (
	InputKubeLogsTypeInputKubeLogsKubeLogs1 InputKubeLogsType = "InputKubeLogs_KubeLogs_1"
	InputKubeLogsTypeInputKubeLogsKubeLogs2 InputKubeLogsType = "InputKubeLogs_KubeLogs_2"
	InputKubeLogsTypeInputKubeLogsKubeLogs3 InputKubeLogsType = "InputKubeLogs_KubeLogs_3"
	InputKubeLogsTypeInputKubeLogsKubeLogs4 InputKubeLogsType = "InputKubeLogs_KubeLogs_4"
)

type InputKubeLogs struct {
	InputKubeLogsKubeLogs1 *InputKubeLogsKubeLogs1 `queryParam:"inline,name=InputKubeLogs"`
	InputKubeLogsKubeLogs2 *InputKubeLogsKubeLogs2 `queryParam:"inline,name=InputKubeLogs"`
	InputKubeLogsKubeLogs3 *InputKubeLogsKubeLogs3 `queryParam:"inline,name=InputKubeLogs"`
	InputKubeLogsKubeLogs4 *InputKubeLogsKubeLogs4 `queryParam:"inline,name=InputKubeLogs"`

	Type InputKubeLogsType
}

func CreateInputKubeLogsInputKubeLogsKubeLogs1(inputKubeLogsKubeLogs1 InputKubeLogsKubeLogs1) InputKubeLogs {
	typ := InputKubeLogsTypeInputKubeLogsKubeLogs1

	return InputKubeLogs{
		InputKubeLogsKubeLogs1: &inputKubeLogsKubeLogs1,
		Type:                   typ,
	}
}

func CreateInputKubeLogsInputKubeLogsKubeLogs2(inputKubeLogsKubeLogs2 InputKubeLogsKubeLogs2) InputKubeLogs {
	typ := InputKubeLogsTypeInputKubeLogsKubeLogs2

	return InputKubeLogs{
		InputKubeLogsKubeLogs2: &inputKubeLogsKubeLogs2,
		Type:                   typ,
	}
}

func CreateInputKubeLogsInputKubeLogsKubeLogs3(inputKubeLogsKubeLogs3 InputKubeLogsKubeLogs3) InputKubeLogs {
	typ := InputKubeLogsTypeInputKubeLogsKubeLogs3

	return InputKubeLogs{
		InputKubeLogsKubeLogs3: &inputKubeLogsKubeLogs3,
		Type:                   typ,
	}
}

func CreateInputKubeLogsInputKubeLogsKubeLogs4(inputKubeLogsKubeLogs4 InputKubeLogsKubeLogs4) InputKubeLogs {
	typ := InputKubeLogsTypeInputKubeLogsKubeLogs4

	return InputKubeLogs{
		InputKubeLogsKubeLogs4: &inputKubeLogsKubeLogs4,
		Type:                   typ,
	}
}

func (u *InputKubeLogs) UnmarshalJSON(data []byte) error {

	var inputKubeLogsKubeLogs2 InputKubeLogsKubeLogs2 = InputKubeLogsKubeLogs2{}
	if err := utils.UnmarshalJSON(data, &inputKubeLogsKubeLogs2, "", true, nil); err == nil {
		u.InputKubeLogsKubeLogs2 = &inputKubeLogsKubeLogs2
		u.Type = InputKubeLogsTypeInputKubeLogsKubeLogs2
		return nil
	}

	var inputKubeLogsKubeLogs4 InputKubeLogsKubeLogs4 = InputKubeLogsKubeLogs4{}
	if err := utils.UnmarshalJSON(data, &inputKubeLogsKubeLogs4, "", true, nil); err == nil {
		u.InputKubeLogsKubeLogs4 = &inputKubeLogsKubeLogs4
		u.Type = InputKubeLogsTypeInputKubeLogsKubeLogs4
		return nil
	}

	var inputKubeLogsKubeLogs1 InputKubeLogsKubeLogs1 = InputKubeLogsKubeLogs1{}
	if err := utils.UnmarshalJSON(data, &inputKubeLogsKubeLogs1, "", true, nil); err == nil {
		u.InputKubeLogsKubeLogs1 = &inputKubeLogsKubeLogs1
		u.Type = InputKubeLogsTypeInputKubeLogsKubeLogs1
		return nil
	}

	var inputKubeLogsKubeLogs3 InputKubeLogsKubeLogs3 = InputKubeLogsKubeLogs3{}
	if err := utils.UnmarshalJSON(data, &inputKubeLogsKubeLogs3, "", true, nil); err == nil {
		u.InputKubeLogsKubeLogs3 = &inputKubeLogsKubeLogs3
		u.Type = InputKubeLogsTypeInputKubeLogsKubeLogs3
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for InputKubeLogs", string(data))
}

func (u InputKubeLogs) MarshalJSON() ([]byte, error) {
	if u.InputKubeLogsKubeLogs1 != nil {
		return utils.MarshalJSON(u.InputKubeLogsKubeLogs1, "", true)
	}

	if u.InputKubeLogsKubeLogs2 != nil {
		return utils.MarshalJSON(u.InputKubeLogsKubeLogs2, "", true)
	}

	if u.InputKubeLogsKubeLogs3 != nil {
		return utils.MarshalJSON(u.InputKubeLogsKubeLogs3, "", true)
	}

	if u.InputKubeLogsKubeLogs4 != nil {
		return utils.MarshalJSON(u.InputKubeLogsKubeLogs4, "", true)
	}

	return nil, errors.New("could not marshal union type InputKubeLogs: all fields are null")
}
