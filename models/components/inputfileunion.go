// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package components

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/criblio/cribl-control-plane-sdk-go/internal/utils"
)

type InputFileType8 string

const (
	InputFileType8File InputFileType8 = "file"
)

func (e InputFileType8) ToPointer() *InputFileType8 {
	return &e
}
func (e *InputFileType8) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "file":
		*e = InputFileType8(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFileType8: %v", v)
	}
}

// InputFileMode8 - Choose how to discover files to monitor
type InputFileMode8 string

const (
	// InputFileMode8Manual Manual
	InputFileMode8Manual InputFileMode8 = "manual"
	// InputFileMode8Auto Auto
	InputFileMode8Auto InputFileMode8 = "auto"
)

func (e InputFileMode8) ToPointer() *InputFileMode8 {
	return &e
}

type InputFile8 struct {
	// Forces files containing binary data to be streamed as text
	ForceText *bool `default:"false" json:"forceText"`
	// Unique ID for this input
	ID       *string        `json:"id,omitempty"`
	Type     InputFileType8 `json:"type"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionsType `json:"connections,omitempty"`
	Pq          *PqType           `json:"pq,omitempty"`
	// Choose how to discover files to monitor
	Mode *InputFileMode8 `default:"manual" json:"mode"`
	// Time, in seconds, between scanning for files
	Interval *float64 `default:"10" json:"interval"`
	// The full path of discovered files are matched against this wildcard list
	Filenames []string `json:"filenames,omitempty"`
	// Apply filename allowlist to file entries in archive file types, like tar or zip.
	FilterArchivedFiles *bool `default:"false" json:"filterArchivedFiles"`
	// Read only new entries at the end of all files discovered at next startup. @{product} will then read newly discovered files from the head. Disable this to resume reading all files from head.
	TailOnly *bool `default:"true" json:"tailOnly"`
	// Time, in seconds, before an idle file is closed
	IdleTimeout *float64 `default:"300" json:"idleTimeout"`
	// The minimum age of files to monitor. Format examples: 30s, 15m, 1h. Age is relative to file modification time. Leave empty to apply no age filters.
	MinAgeDur *string `json:"minAgeDur,omitempty"`
	// The maximum age of event timestamps to collect. Format examples: 60s, 4h, 3d, 1w. Can be used in conjuction with "Check file modification times". Leave empty to apply no age filters.
	MaxAgeDur *string `json:"maxAgeDur,omitempty"`
	// Skip files with modification times earlier than the maximum age duration
	CheckFileModTime *bool `default:"false" json:"checkFileModTime"`
	// Length of file header bytes to use in hash for unique file identification
	HashLen *float64 `default:"256" json:"hashLen"`
	// Fields to add to events from this input
	Metadata []Metadata1Type `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	Description         *string  `json:"description,omitempty"`
	// Directory path to search for files. Environment variables will be resolved, e.g. $CRIBL_HOME/log/.
	Path *string `json:"path,omitempty"`
	// Set how many subdirectories deep to search. Use 0 to search only files in the given path, 1 to also look in its immediate subdirectories, etc. Leave it empty for unlimited depth.
	Depth                     *float64 `json:"depth,omitempty"`
	SuppressMissingPathErrors *bool    `default:"false" json:"suppressMissingPathErrors"`
	// Delete files after they have been collected
	DeleteFiles *bool `default:"false" json:"deleteFiles"`
	// Stream binary files as Base64-encoded chunks.
	IncludeUnidentifiableBinary *bool `default:"false" json:"includeUnidentifiableBinary"`
}

func (i InputFile8) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFile8) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputFile8) GetForceText() *bool {
	if i == nil {
		return nil
	}
	return i.ForceText
}

func (i *InputFile8) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputFile8) GetType() InputFileType8 {
	if i == nil {
		return InputFileType8("")
	}
	return i.Type
}

func (i *InputFile8) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputFile8) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputFile8) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputFile8) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputFile8) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputFile8) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputFile8) GetConnections() []ConnectionsType {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputFile8) GetPq() *PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputFile8) GetMode() *InputFileMode8 {
	if i == nil {
		return nil
	}
	return i.Mode
}

func (i *InputFile8) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputFile8) GetFilenames() []string {
	if i == nil {
		return nil
	}
	return i.Filenames
}

func (i *InputFile8) GetFilterArchivedFiles() *bool {
	if i == nil {
		return nil
	}
	return i.FilterArchivedFiles
}

func (i *InputFile8) GetTailOnly() *bool {
	if i == nil {
		return nil
	}
	return i.TailOnly
}

func (i *InputFile8) GetIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.IdleTimeout
}

func (i *InputFile8) GetMinAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MinAgeDur
}

func (i *InputFile8) GetMaxAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MaxAgeDur
}

func (i *InputFile8) GetCheckFileModTime() *bool {
	if i == nil {
		return nil
	}
	return i.CheckFileModTime
}

func (i *InputFile8) GetHashLen() *float64 {
	if i == nil {
		return nil
	}
	return i.HashLen
}

func (i *InputFile8) GetMetadata() []Metadata1Type {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputFile8) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputFile8) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputFile8) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputFile8) GetPath() *string {
	if i == nil {
		return nil
	}
	return i.Path
}

func (i *InputFile8) GetDepth() *float64 {
	if i == nil {
		return nil
	}
	return i.Depth
}

func (i *InputFile8) GetSuppressMissingPathErrors() *bool {
	if i == nil {
		return nil
	}
	return i.SuppressMissingPathErrors
}

func (i *InputFile8) GetDeleteFiles() *bool {
	if i == nil {
		return nil
	}
	return i.DeleteFiles
}

func (i *InputFile8) GetIncludeUnidentifiableBinary() *bool {
	if i == nil {
		return nil
	}
	return i.IncludeUnidentifiableBinary
}

type InputFileType7 string

const (
	InputFileType7File InputFileType7 = "file"
)

func (e InputFileType7) ToPointer() *InputFileType7 {
	return &e
}
func (e *InputFileType7) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "file":
		*e = InputFileType7(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFileType7: %v", v)
	}
}

// InputFileMode7 - Choose how to discover files to monitor
type InputFileMode7 string

const (
	// InputFileMode7Manual Manual
	InputFileMode7Manual InputFileMode7 = "manual"
	// InputFileMode7Auto Auto
	InputFileMode7Auto InputFileMode7 = "auto"
)

func (e InputFileMode7) ToPointer() *InputFileMode7 {
	return &e
}

type InputFile7 struct {
	// Forces files containing binary data to be streamed as text
	ForceText *bool `default:"false" json:"forceText"`
	// Unique ID for this input
	ID       *string        `json:"id,omitempty"`
	Type     InputFileType7 `json:"type"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionsType `json:"connections,omitempty"`
	Pq          *PqType           `json:"pq,omitempty"`
	// Choose how to discover files to monitor
	Mode *InputFileMode7 `default:"manual" json:"mode"`
	// Time, in seconds, between scanning for files
	Interval *float64 `default:"10" json:"interval"`
	// The full path of discovered files are matched against this wildcard list
	Filenames []string `json:"filenames,omitempty"`
	// Apply filename allowlist to file entries in archive file types, like tar or zip.
	FilterArchivedFiles *bool `default:"false" json:"filterArchivedFiles"`
	// Read only new entries at the end of all files discovered at next startup. @{product} will then read newly discovered files from the head. Disable this to resume reading all files from head.
	TailOnly *bool `default:"true" json:"tailOnly"`
	// Time, in seconds, before an idle file is closed
	IdleTimeout *float64 `default:"300" json:"idleTimeout"`
	// The minimum age of files to monitor. Format examples: 30s, 15m, 1h. Age is relative to file modification time. Leave empty to apply no age filters.
	MinAgeDur *string `json:"minAgeDur,omitempty"`
	// The maximum age of event timestamps to collect. Format examples: 60s, 4h, 3d, 1w. Can be used in conjuction with "Check file modification times". Leave empty to apply no age filters.
	MaxAgeDur *string `json:"maxAgeDur,omitempty"`
	// Skip files with modification times earlier than the maximum age duration
	CheckFileModTime *bool `default:"false" json:"checkFileModTime"`
	// Length of file header bytes to use in hash for unique file identification
	HashLen *float64 `default:"256" json:"hashLen"`
	// Fields to add to events from this input
	Metadata []Metadata1Type `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	Description         *string  `json:"description,omitempty"`
	// Directory path to search for files. Environment variables will be resolved, e.g. $CRIBL_HOME/log/.
	Path *string `json:"path,omitempty"`
	// Set how many subdirectories deep to search. Use 0 to search only files in the given path, 1 to also look in its immediate subdirectories, etc. Leave it empty for unlimited depth.
	Depth                     *float64 `json:"depth,omitempty"`
	SuppressMissingPathErrors *bool    `default:"false" json:"suppressMissingPathErrors"`
	// Delete files after they have been collected
	DeleteFiles *bool `default:"false" json:"deleteFiles"`
	// Stream binary files as Base64-encoded chunks.
	IncludeUnidentifiableBinary *bool `default:"false" json:"includeUnidentifiableBinary"`
}

func (i InputFile7) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFile7) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputFile7) GetForceText() *bool {
	if i == nil {
		return nil
	}
	return i.ForceText
}

func (i *InputFile7) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputFile7) GetType() InputFileType7 {
	if i == nil {
		return InputFileType7("")
	}
	return i.Type
}

func (i *InputFile7) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputFile7) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputFile7) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputFile7) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputFile7) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputFile7) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputFile7) GetConnections() []ConnectionsType {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputFile7) GetPq() *PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputFile7) GetMode() *InputFileMode7 {
	if i == nil {
		return nil
	}
	return i.Mode
}

func (i *InputFile7) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputFile7) GetFilenames() []string {
	if i == nil {
		return nil
	}
	return i.Filenames
}

func (i *InputFile7) GetFilterArchivedFiles() *bool {
	if i == nil {
		return nil
	}
	return i.FilterArchivedFiles
}

func (i *InputFile7) GetTailOnly() *bool {
	if i == nil {
		return nil
	}
	return i.TailOnly
}

func (i *InputFile7) GetIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.IdleTimeout
}

func (i *InputFile7) GetMinAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MinAgeDur
}

func (i *InputFile7) GetMaxAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MaxAgeDur
}

func (i *InputFile7) GetCheckFileModTime() *bool {
	if i == nil {
		return nil
	}
	return i.CheckFileModTime
}

func (i *InputFile7) GetHashLen() *float64 {
	if i == nil {
		return nil
	}
	return i.HashLen
}

func (i *InputFile7) GetMetadata() []Metadata1Type {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputFile7) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputFile7) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputFile7) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputFile7) GetPath() *string {
	if i == nil {
		return nil
	}
	return i.Path
}

func (i *InputFile7) GetDepth() *float64 {
	if i == nil {
		return nil
	}
	return i.Depth
}

func (i *InputFile7) GetSuppressMissingPathErrors() *bool {
	if i == nil {
		return nil
	}
	return i.SuppressMissingPathErrors
}

func (i *InputFile7) GetDeleteFiles() *bool {
	if i == nil {
		return nil
	}
	return i.DeleteFiles
}

func (i *InputFile7) GetIncludeUnidentifiableBinary() *bool {
	if i == nil {
		return nil
	}
	return i.IncludeUnidentifiableBinary
}

// InputFileMode6 - Choose how to discover files to monitor
type InputFileMode6 string

const (
	// InputFileMode6Manual Manual
	InputFileMode6Manual InputFileMode6 = "manual"
	// InputFileMode6Auto Auto
	InputFileMode6Auto InputFileMode6 = "auto"
)

func (e InputFileMode6) ToPointer() *InputFileMode6 {
	return &e
}

type InputFileType6 string

const (
	InputFileType6File InputFileType6 = "file"
)

func (e InputFileType6) ToPointer() *InputFileType6 {
	return &e
}
func (e *InputFileType6) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "file":
		*e = InputFileType6(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFileType6: %v", v)
	}
}

type InputFile6 struct {
	// Choose how to discover files to monitor
	Mode *InputFileMode6 `default:"manual" json:"mode"`
	// Unique ID for this input
	ID       *string        `json:"id,omitempty"`
	Type     InputFileType6 `json:"type"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionsType `json:"connections,omitempty"`
	Pq          *PqType           `json:"pq,omitempty"`
	// Time, in seconds, between scanning for files
	Interval *float64 `default:"10" json:"interval"`
	// The full path of discovered files are matched against this wildcard list
	Filenames []string `json:"filenames,omitempty"`
	// Apply filename allowlist to file entries in archive file types, like tar or zip.
	FilterArchivedFiles *bool `default:"false" json:"filterArchivedFiles"`
	// Read only new entries at the end of all files discovered at next startup. @{product} will then read newly discovered files from the head. Disable this to resume reading all files from head.
	TailOnly *bool `default:"true" json:"tailOnly"`
	// Time, in seconds, before an idle file is closed
	IdleTimeout *float64 `default:"300" json:"idleTimeout"`
	// The minimum age of files to monitor. Format examples: 30s, 15m, 1h. Age is relative to file modification time. Leave empty to apply no age filters.
	MinAgeDur *string `json:"minAgeDur,omitempty"`
	// The maximum age of event timestamps to collect. Format examples: 60s, 4h, 3d, 1w. Can be used in conjuction with "Check file modification times". Leave empty to apply no age filters.
	MaxAgeDur *string `json:"maxAgeDur,omitempty"`
	// Skip files with modification times earlier than the maximum age duration
	CheckFileModTime *bool `default:"false" json:"checkFileModTime"`
	// Forces files containing binary data to be streamed as text
	ForceText *bool `default:"false" json:"forceText"`
	// Length of file header bytes to use in hash for unique file identification
	HashLen *float64 `default:"256" json:"hashLen"`
	// Fields to add to events from this input
	Metadata []Metadata1Type `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	Description         *string  `json:"description,omitempty"`
	// Directory path to search for files. Environment variables will be resolved, e.g. $CRIBL_HOME/log/.
	Path string `json:"path"`
	// Set how many subdirectories deep to search. Use 0 to search only files in the given path, 1 to also look in its immediate subdirectories, etc. Leave it empty for unlimited depth.
	Depth                     float64 `json:"depth"`
	SuppressMissingPathErrors *bool   `default:"false" json:"suppressMissingPathErrors"`
	// Delete files after they have been collected
	DeleteFiles *bool `default:"false" json:"deleteFiles"`
	// Stream binary files as Base64-encoded chunks.
	IncludeUnidentifiableBinary *bool `default:"false" json:"includeUnidentifiableBinary"`
}

func (i InputFile6) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFile6) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "path", "depth"}); err != nil {
		return err
	}
	return nil
}

func (i *InputFile6) GetMode() *InputFileMode6 {
	if i == nil {
		return nil
	}
	return i.Mode
}

func (i *InputFile6) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputFile6) GetType() InputFileType6 {
	if i == nil {
		return InputFileType6("")
	}
	return i.Type
}

func (i *InputFile6) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputFile6) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputFile6) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputFile6) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputFile6) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputFile6) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputFile6) GetConnections() []ConnectionsType {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputFile6) GetPq() *PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputFile6) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputFile6) GetFilenames() []string {
	if i == nil {
		return nil
	}
	return i.Filenames
}

func (i *InputFile6) GetFilterArchivedFiles() *bool {
	if i == nil {
		return nil
	}
	return i.FilterArchivedFiles
}

func (i *InputFile6) GetTailOnly() *bool {
	if i == nil {
		return nil
	}
	return i.TailOnly
}

func (i *InputFile6) GetIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.IdleTimeout
}

func (i *InputFile6) GetMinAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MinAgeDur
}

func (i *InputFile6) GetMaxAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MaxAgeDur
}

func (i *InputFile6) GetCheckFileModTime() *bool {
	if i == nil {
		return nil
	}
	return i.CheckFileModTime
}

func (i *InputFile6) GetForceText() *bool {
	if i == nil {
		return nil
	}
	return i.ForceText
}

func (i *InputFile6) GetHashLen() *float64 {
	if i == nil {
		return nil
	}
	return i.HashLen
}

func (i *InputFile6) GetMetadata() []Metadata1Type {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputFile6) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputFile6) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputFile6) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputFile6) GetPath() string {
	if i == nil {
		return ""
	}
	return i.Path
}

func (i *InputFile6) GetDepth() float64 {
	if i == nil {
		return 0.0
	}
	return i.Depth
}

func (i *InputFile6) GetSuppressMissingPathErrors() *bool {
	if i == nil {
		return nil
	}
	return i.SuppressMissingPathErrors
}

func (i *InputFile6) GetDeleteFiles() *bool {
	if i == nil {
		return nil
	}
	return i.DeleteFiles
}

func (i *InputFile6) GetIncludeUnidentifiableBinary() *bool {
	if i == nil {
		return nil
	}
	return i.IncludeUnidentifiableBinary
}

// InputFileMode5 - Choose how to discover files to monitor
type InputFileMode5 string

const (
	// InputFileMode5Manual Manual
	InputFileMode5Manual InputFileMode5 = "manual"
	// InputFileMode5Auto Auto
	InputFileMode5Auto InputFileMode5 = "auto"
)

func (e InputFileMode5) ToPointer() *InputFileMode5 {
	return &e
}

type InputFileType5 string

const (
	InputFileType5File InputFileType5 = "file"
)

func (e InputFileType5) ToPointer() *InputFileType5 {
	return &e
}
func (e *InputFileType5) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "file":
		*e = InputFileType5(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFileType5: %v", v)
	}
}

type InputFile5 struct {
	// Choose how to discover files to monitor
	Mode *InputFileMode5 `default:"manual" json:"mode"`
	// Unique ID for this input
	ID       *string        `json:"id,omitempty"`
	Type     InputFileType5 `json:"type"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionsType `json:"connections,omitempty"`
	Pq          *PqType           `json:"pq,omitempty"`
	// Time, in seconds, between scanning for files
	Interval *float64 `default:"10" json:"interval"`
	// The full path of discovered files are matched against this wildcard list
	Filenames []string `json:"filenames,omitempty"`
	// Apply filename allowlist to file entries in archive file types, like tar or zip.
	FilterArchivedFiles *bool `default:"false" json:"filterArchivedFiles"`
	// Read only new entries at the end of all files discovered at next startup. @{product} will then read newly discovered files from the head. Disable this to resume reading all files from head.
	TailOnly *bool `default:"true" json:"tailOnly"`
	// Time, in seconds, before an idle file is closed
	IdleTimeout *float64 `default:"300" json:"idleTimeout"`
	// The minimum age of files to monitor. Format examples: 30s, 15m, 1h. Age is relative to file modification time. Leave empty to apply no age filters.
	MinAgeDur *string `json:"minAgeDur,omitempty"`
	// The maximum age of event timestamps to collect. Format examples: 60s, 4h, 3d, 1w. Can be used in conjuction with "Check file modification times". Leave empty to apply no age filters.
	MaxAgeDur *string `json:"maxAgeDur,omitempty"`
	// Skip files with modification times earlier than the maximum age duration
	CheckFileModTime *bool `default:"false" json:"checkFileModTime"`
	// Forces files containing binary data to be streamed as text
	ForceText *bool `default:"false" json:"forceText"`
	// Length of file header bytes to use in hash for unique file identification
	HashLen *float64 `default:"256" json:"hashLen"`
	// Fields to add to events from this input
	Metadata []Metadata1Type `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	Description         *string  `json:"description,omitempty"`
	// Directory path to search for files. Environment variables will be resolved, e.g. $CRIBL_HOME/log/.
	Path *string `json:"path,omitempty"`
	// Set how many subdirectories deep to search. Use 0 to search only files in the given path, 1 to also look in its immediate subdirectories, etc. Leave it empty for unlimited depth.
	Depth                     *float64 `json:"depth,omitempty"`
	SuppressMissingPathErrors *bool    `default:"false" json:"suppressMissingPathErrors"`
	// Delete files after they have been collected
	DeleteFiles *bool `default:"false" json:"deleteFiles"`
	// Stream binary files as Base64-encoded chunks.
	IncludeUnidentifiableBinary *bool `default:"false" json:"includeUnidentifiableBinary"`
}

func (i InputFile5) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFile5) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputFile5) GetMode() *InputFileMode5 {
	if i == nil {
		return nil
	}
	return i.Mode
}

func (i *InputFile5) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputFile5) GetType() InputFileType5 {
	if i == nil {
		return InputFileType5("")
	}
	return i.Type
}

func (i *InputFile5) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputFile5) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputFile5) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputFile5) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputFile5) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputFile5) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputFile5) GetConnections() []ConnectionsType {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputFile5) GetPq() *PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputFile5) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputFile5) GetFilenames() []string {
	if i == nil {
		return nil
	}
	return i.Filenames
}

func (i *InputFile5) GetFilterArchivedFiles() *bool {
	if i == nil {
		return nil
	}
	return i.FilterArchivedFiles
}

func (i *InputFile5) GetTailOnly() *bool {
	if i == nil {
		return nil
	}
	return i.TailOnly
}

func (i *InputFile5) GetIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.IdleTimeout
}

func (i *InputFile5) GetMinAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MinAgeDur
}

func (i *InputFile5) GetMaxAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MaxAgeDur
}

func (i *InputFile5) GetCheckFileModTime() *bool {
	if i == nil {
		return nil
	}
	return i.CheckFileModTime
}

func (i *InputFile5) GetForceText() *bool {
	if i == nil {
		return nil
	}
	return i.ForceText
}

func (i *InputFile5) GetHashLen() *float64 {
	if i == nil {
		return nil
	}
	return i.HashLen
}

func (i *InputFile5) GetMetadata() []Metadata1Type {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputFile5) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputFile5) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputFile5) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputFile5) GetPath() *string {
	if i == nil {
		return nil
	}
	return i.Path
}

func (i *InputFile5) GetDepth() *float64 {
	if i == nil {
		return nil
	}
	return i.Depth
}

func (i *InputFile5) GetSuppressMissingPathErrors() *bool {
	if i == nil {
		return nil
	}
	return i.SuppressMissingPathErrors
}

func (i *InputFile5) GetDeleteFiles() *bool {
	if i == nil {
		return nil
	}
	return i.DeleteFiles
}

func (i *InputFile5) GetIncludeUnidentifiableBinary() *bool {
	if i == nil {
		return nil
	}
	return i.IncludeUnidentifiableBinary
}

type InputFileType4 string

const (
	InputFileType4File InputFileType4 = "file"
)

func (e InputFileType4) ToPointer() *InputFileType4 {
	return &e
}
func (e *InputFileType4) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "file":
		*e = InputFileType4(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFileType4: %v", v)
	}
}

// InputFileMode4 - Choose how to discover files to monitor
type InputFileMode4 string

const (
	// InputFileMode4Manual Manual
	InputFileMode4Manual InputFileMode4 = "manual"
	// InputFileMode4Auto Auto
	InputFileMode4Auto InputFileMode4 = "auto"
)

func (e InputFileMode4) ToPointer() *InputFileMode4 {
	return &e
}

type InputFile4 struct {
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Unique ID for this input
	ID       *string        `json:"id,omitempty"`
	Type     InputFileType4 `json:"type"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionsType `json:"connections,omitempty"`
	Pq          PqType            `json:"pq"`
	// Choose how to discover files to monitor
	Mode *InputFileMode4 `default:"manual" json:"mode"`
	// Time, in seconds, between scanning for files
	Interval *float64 `default:"10" json:"interval"`
	// The full path of discovered files are matched against this wildcard list
	Filenames []string `json:"filenames,omitempty"`
	// Apply filename allowlist to file entries in archive file types, like tar or zip.
	FilterArchivedFiles *bool `default:"false" json:"filterArchivedFiles"`
	// Read only new entries at the end of all files discovered at next startup. @{product} will then read newly discovered files from the head. Disable this to resume reading all files from head.
	TailOnly *bool `default:"true" json:"tailOnly"`
	// Time, in seconds, before an idle file is closed
	IdleTimeout *float64 `default:"300" json:"idleTimeout"`
	// The minimum age of files to monitor. Format examples: 30s, 15m, 1h. Age is relative to file modification time. Leave empty to apply no age filters.
	MinAgeDur *string `json:"minAgeDur,omitempty"`
	// The maximum age of event timestamps to collect. Format examples: 60s, 4h, 3d, 1w. Can be used in conjuction with "Check file modification times". Leave empty to apply no age filters.
	MaxAgeDur *string `json:"maxAgeDur,omitempty"`
	// Skip files with modification times earlier than the maximum age duration
	CheckFileModTime *bool `default:"false" json:"checkFileModTime"`
	// Forces files containing binary data to be streamed as text
	ForceText *bool `default:"false" json:"forceText"`
	// Length of file header bytes to use in hash for unique file identification
	HashLen *float64 `default:"256" json:"hashLen"`
	// Fields to add to events from this input
	Metadata []Metadata1Type `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	Description         *string  `json:"description,omitempty"`
	// Directory path to search for files. Environment variables will be resolved, e.g. $CRIBL_HOME/log/.
	Path *string `json:"path,omitempty"`
	// Set how many subdirectories deep to search. Use 0 to search only files in the given path, 1 to also look in its immediate subdirectories, etc. Leave it empty for unlimited depth.
	Depth                     *float64 `json:"depth,omitempty"`
	SuppressMissingPathErrors *bool    `default:"false" json:"suppressMissingPathErrors"`
	// Delete files after they have been collected
	DeleteFiles *bool `default:"false" json:"deleteFiles"`
	// Stream binary files as Base64-encoded chunks.
	IncludeUnidentifiableBinary *bool `default:"false" json:"includeUnidentifiableBinary"`
}

func (i InputFile4) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFile4) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "pq"}); err != nil {
		return err
	}
	return nil
}

func (i *InputFile4) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputFile4) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputFile4) GetType() InputFileType4 {
	if i == nil {
		return InputFileType4("")
	}
	return i.Type
}

func (i *InputFile4) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputFile4) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputFile4) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputFile4) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputFile4) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputFile4) GetConnections() []ConnectionsType {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputFile4) GetPq() PqType {
	if i == nil {
		return PqType{}
	}
	return i.Pq
}

func (i *InputFile4) GetMode() *InputFileMode4 {
	if i == nil {
		return nil
	}
	return i.Mode
}

func (i *InputFile4) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputFile4) GetFilenames() []string {
	if i == nil {
		return nil
	}
	return i.Filenames
}

func (i *InputFile4) GetFilterArchivedFiles() *bool {
	if i == nil {
		return nil
	}
	return i.FilterArchivedFiles
}

func (i *InputFile4) GetTailOnly() *bool {
	if i == nil {
		return nil
	}
	return i.TailOnly
}

func (i *InputFile4) GetIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.IdleTimeout
}

func (i *InputFile4) GetMinAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MinAgeDur
}

func (i *InputFile4) GetMaxAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MaxAgeDur
}

func (i *InputFile4) GetCheckFileModTime() *bool {
	if i == nil {
		return nil
	}
	return i.CheckFileModTime
}

func (i *InputFile4) GetForceText() *bool {
	if i == nil {
		return nil
	}
	return i.ForceText
}

func (i *InputFile4) GetHashLen() *float64 {
	if i == nil {
		return nil
	}
	return i.HashLen
}

func (i *InputFile4) GetMetadata() []Metadata1Type {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputFile4) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputFile4) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputFile4) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputFile4) GetPath() *string {
	if i == nil {
		return nil
	}
	return i.Path
}

func (i *InputFile4) GetDepth() *float64 {
	if i == nil {
		return nil
	}
	return i.Depth
}

func (i *InputFile4) GetSuppressMissingPathErrors() *bool {
	if i == nil {
		return nil
	}
	return i.SuppressMissingPathErrors
}

func (i *InputFile4) GetDeleteFiles() *bool {
	if i == nil {
		return nil
	}
	return i.DeleteFiles
}

func (i *InputFile4) GetIncludeUnidentifiableBinary() *bool {
	if i == nil {
		return nil
	}
	return i.IncludeUnidentifiableBinary
}

type InputFileType3 string

const (
	InputFileType3File InputFileType3 = "file"
)

func (e InputFileType3) ToPointer() *InputFileType3 {
	return &e
}
func (e *InputFileType3) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "file":
		*e = InputFileType3(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFileType3: %v", v)
	}
}

// InputFileMode3 - Choose how to discover files to monitor
type InputFileMode3 string

const (
	// InputFileMode3Manual Manual
	InputFileMode3Manual InputFileMode3 = "manual"
	// InputFileMode3Auto Auto
	InputFileMode3Auto InputFileMode3 = "auto"
)

func (e InputFileMode3) ToPointer() *InputFileMode3 {
	return &e
}

type InputFile3 struct {
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Unique ID for this input
	ID       *string        `json:"id,omitempty"`
	Type     InputFileType3 `json:"type"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionsType `json:"connections,omitempty"`
	Pq          *PqType           `json:"pq,omitempty"`
	// Choose how to discover files to monitor
	Mode *InputFileMode3 `default:"manual" json:"mode"`
	// Time, in seconds, between scanning for files
	Interval *float64 `default:"10" json:"interval"`
	// The full path of discovered files are matched against this wildcard list
	Filenames []string `json:"filenames,omitempty"`
	// Apply filename allowlist to file entries in archive file types, like tar or zip.
	FilterArchivedFiles *bool `default:"false" json:"filterArchivedFiles"`
	// Read only new entries at the end of all files discovered at next startup. @{product} will then read newly discovered files from the head. Disable this to resume reading all files from head.
	TailOnly *bool `default:"true" json:"tailOnly"`
	// Time, in seconds, before an idle file is closed
	IdleTimeout *float64 `default:"300" json:"idleTimeout"`
	// The minimum age of files to monitor. Format examples: 30s, 15m, 1h. Age is relative to file modification time. Leave empty to apply no age filters.
	MinAgeDur *string `json:"minAgeDur,omitempty"`
	// The maximum age of event timestamps to collect. Format examples: 60s, 4h, 3d, 1w. Can be used in conjuction with "Check file modification times". Leave empty to apply no age filters.
	MaxAgeDur *string `json:"maxAgeDur,omitempty"`
	// Skip files with modification times earlier than the maximum age duration
	CheckFileModTime *bool `default:"false" json:"checkFileModTime"`
	// Forces files containing binary data to be streamed as text
	ForceText *bool `default:"false" json:"forceText"`
	// Length of file header bytes to use in hash for unique file identification
	HashLen *float64 `default:"256" json:"hashLen"`
	// Fields to add to events from this input
	Metadata []Metadata1Type `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	Description         *string  `json:"description,omitempty"`
	// Directory path to search for files. Environment variables will be resolved, e.g. $CRIBL_HOME/log/.
	Path *string `json:"path,omitempty"`
	// Set how many subdirectories deep to search. Use 0 to search only files in the given path, 1 to also look in its immediate subdirectories, etc. Leave it empty for unlimited depth.
	Depth                     *float64 `json:"depth,omitempty"`
	SuppressMissingPathErrors *bool    `default:"false" json:"suppressMissingPathErrors"`
	// Delete files after they have been collected
	DeleteFiles *bool `default:"false" json:"deleteFiles"`
	// Stream binary files as Base64-encoded chunks.
	IncludeUnidentifiableBinary *bool `default:"false" json:"includeUnidentifiableBinary"`
}

func (i InputFile3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFile3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputFile3) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputFile3) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputFile3) GetType() InputFileType3 {
	if i == nil {
		return InputFileType3("")
	}
	return i.Type
}

func (i *InputFile3) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputFile3) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputFile3) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputFile3) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputFile3) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputFile3) GetConnections() []ConnectionsType {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputFile3) GetPq() *PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputFile3) GetMode() *InputFileMode3 {
	if i == nil {
		return nil
	}
	return i.Mode
}

func (i *InputFile3) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputFile3) GetFilenames() []string {
	if i == nil {
		return nil
	}
	return i.Filenames
}

func (i *InputFile3) GetFilterArchivedFiles() *bool {
	if i == nil {
		return nil
	}
	return i.FilterArchivedFiles
}

func (i *InputFile3) GetTailOnly() *bool {
	if i == nil {
		return nil
	}
	return i.TailOnly
}

func (i *InputFile3) GetIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.IdleTimeout
}

func (i *InputFile3) GetMinAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MinAgeDur
}

func (i *InputFile3) GetMaxAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MaxAgeDur
}

func (i *InputFile3) GetCheckFileModTime() *bool {
	if i == nil {
		return nil
	}
	return i.CheckFileModTime
}

func (i *InputFile3) GetForceText() *bool {
	if i == nil {
		return nil
	}
	return i.ForceText
}

func (i *InputFile3) GetHashLen() *float64 {
	if i == nil {
		return nil
	}
	return i.HashLen
}

func (i *InputFile3) GetMetadata() []Metadata1Type {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputFile3) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputFile3) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputFile3) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputFile3) GetPath() *string {
	if i == nil {
		return nil
	}
	return i.Path
}

func (i *InputFile3) GetDepth() *float64 {
	if i == nil {
		return nil
	}
	return i.Depth
}

func (i *InputFile3) GetSuppressMissingPathErrors() *bool {
	if i == nil {
		return nil
	}
	return i.SuppressMissingPathErrors
}

func (i *InputFile3) GetDeleteFiles() *bool {
	if i == nil {
		return nil
	}
	return i.DeleteFiles
}

func (i *InputFile3) GetIncludeUnidentifiableBinary() *bool {
	if i == nil {
		return nil
	}
	return i.IncludeUnidentifiableBinary
}

type InputFileType2 string

const (
	InputFileType2File InputFileType2 = "file"
)

func (e InputFileType2) ToPointer() *InputFileType2 {
	return &e
}
func (e *InputFileType2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "file":
		*e = InputFileType2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFileType2: %v", v)
	}
}

// InputFileMode2 - Choose how to discover files to monitor
type InputFileMode2 string

const (
	// InputFileMode2Manual Manual
	InputFileMode2Manual InputFileMode2 = "manual"
	// InputFileMode2Auto Auto
	InputFileMode2Auto InputFileMode2 = "auto"
)

func (e InputFileMode2) ToPointer() *InputFileMode2 {
	return &e
}

type InputFile2 struct {
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Unique ID for this input
	ID       *string        `json:"id,omitempty"`
	Type     InputFileType2 `json:"type"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionsType `json:"connections"`
	Pq          *PqType           `json:"pq,omitempty"`
	// Choose how to discover files to monitor
	Mode *InputFileMode2 `default:"manual" json:"mode"`
	// Time, in seconds, between scanning for files
	Interval *float64 `default:"10" json:"interval"`
	// The full path of discovered files are matched against this wildcard list
	Filenames []string `json:"filenames,omitempty"`
	// Apply filename allowlist to file entries in archive file types, like tar or zip.
	FilterArchivedFiles *bool `default:"false" json:"filterArchivedFiles"`
	// Read only new entries at the end of all files discovered at next startup. @{product} will then read newly discovered files from the head. Disable this to resume reading all files from head.
	TailOnly *bool `default:"true" json:"tailOnly"`
	// Time, in seconds, before an idle file is closed
	IdleTimeout *float64 `default:"300" json:"idleTimeout"`
	// The minimum age of files to monitor. Format examples: 30s, 15m, 1h. Age is relative to file modification time. Leave empty to apply no age filters.
	MinAgeDur *string `json:"minAgeDur,omitempty"`
	// The maximum age of event timestamps to collect. Format examples: 60s, 4h, 3d, 1w. Can be used in conjuction with "Check file modification times". Leave empty to apply no age filters.
	MaxAgeDur *string `json:"maxAgeDur,omitempty"`
	// Skip files with modification times earlier than the maximum age duration
	CheckFileModTime *bool `default:"false" json:"checkFileModTime"`
	// Forces files containing binary data to be streamed as text
	ForceText *bool `default:"false" json:"forceText"`
	// Length of file header bytes to use in hash for unique file identification
	HashLen *float64 `default:"256" json:"hashLen"`
	// Fields to add to events from this input
	Metadata []Metadata1Type `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	Description         *string  `json:"description,omitempty"`
	// Directory path to search for files. Environment variables will be resolved, e.g. $CRIBL_HOME/log/.
	Path *string `json:"path,omitempty"`
	// Set how many subdirectories deep to search. Use 0 to search only files in the given path, 1 to also look in its immediate subdirectories, etc. Leave it empty for unlimited depth.
	Depth                     *float64 `json:"depth,omitempty"`
	SuppressMissingPathErrors *bool    `default:"false" json:"suppressMissingPathErrors"`
	// Delete files after they have been collected
	DeleteFiles *bool `default:"false" json:"deleteFiles"`
	// Stream binary files as Base64-encoded chunks.
	IncludeUnidentifiableBinary *bool `default:"false" json:"includeUnidentifiableBinary"`
}

func (i InputFile2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFile2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "connections"}); err != nil {
		return err
	}
	return nil
}

func (i *InputFile2) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputFile2) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputFile2) GetType() InputFileType2 {
	if i == nil {
		return InputFileType2("")
	}
	return i.Type
}

func (i *InputFile2) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputFile2) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputFile2) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputFile2) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputFile2) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputFile2) GetConnections() []ConnectionsType {
	if i == nil {
		return []ConnectionsType{}
	}
	return i.Connections
}

func (i *InputFile2) GetPq() *PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputFile2) GetMode() *InputFileMode2 {
	if i == nil {
		return nil
	}
	return i.Mode
}

func (i *InputFile2) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputFile2) GetFilenames() []string {
	if i == nil {
		return nil
	}
	return i.Filenames
}

func (i *InputFile2) GetFilterArchivedFiles() *bool {
	if i == nil {
		return nil
	}
	return i.FilterArchivedFiles
}

func (i *InputFile2) GetTailOnly() *bool {
	if i == nil {
		return nil
	}
	return i.TailOnly
}

func (i *InputFile2) GetIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.IdleTimeout
}

func (i *InputFile2) GetMinAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MinAgeDur
}

func (i *InputFile2) GetMaxAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MaxAgeDur
}

func (i *InputFile2) GetCheckFileModTime() *bool {
	if i == nil {
		return nil
	}
	return i.CheckFileModTime
}

func (i *InputFile2) GetForceText() *bool {
	if i == nil {
		return nil
	}
	return i.ForceText
}

func (i *InputFile2) GetHashLen() *float64 {
	if i == nil {
		return nil
	}
	return i.HashLen
}

func (i *InputFile2) GetMetadata() []Metadata1Type {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputFile2) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputFile2) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputFile2) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputFile2) GetPath() *string {
	if i == nil {
		return nil
	}
	return i.Path
}

func (i *InputFile2) GetDepth() *float64 {
	if i == nil {
		return nil
	}
	return i.Depth
}

func (i *InputFile2) GetSuppressMissingPathErrors() *bool {
	if i == nil {
		return nil
	}
	return i.SuppressMissingPathErrors
}

func (i *InputFile2) GetDeleteFiles() *bool {
	if i == nil {
		return nil
	}
	return i.DeleteFiles
}

func (i *InputFile2) GetIncludeUnidentifiableBinary() *bool {
	if i == nil {
		return nil
	}
	return i.IncludeUnidentifiableBinary
}

type InputFileType1 string

const (
	InputFileType1File InputFileType1 = "file"
)

func (e InputFileType1) ToPointer() *InputFileType1 {
	return &e
}
func (e *InputFileType1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "file":
		*e = InputFileType1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFileType1: %v", v)
	}
}

// InputFileMode1 - Choose how to discover files to monitor
type InputFileMode1 string

const (
	// InputFileMode1Manual Manual
	InputFileMode1Manual InputFileMode1 = "manual"
	// InputFileMode1Auto Auto
	InputFileMode1Auto InputFileMode1 = "auto"
)

func (e InputFileMode1) ToPointer() *InputFileMode1 {
	return &e
}

type InputFile1 struct {
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Unique ID for this input
	ID       *string        `json:"id,omitempty"`
	Type     InputFileType1 `json:"type"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionsType `json:"connections,omitempty"`
	Pq          *PqType           `json:"pq,omitempty"`
	// Choose how to discover files to monitor
	Mode *InputFileMode1 `default:"manual" json:"mode"`
	// Time, in seconds, between scanning for files
	Interval *float64 `default:"10" json:"interval"`
	// The full path of discovered files are matched against this wildcard list
	Filenames []string `json:"filenames,omitempty"`
	// Apply filename allowlist to file entries in archive file types, like tar or zip.
	FilterArchivedFiles *bool `default:"false" json:"filterArchivedFiles"`
	// Read only new entries at the end of all files discovered at next startup. @{product} will then read newly discovered files from the head. Disable this to resume reading all files from head.
	TailOnly *bool `default:"true" json:"tailOnly"`
	// Time, in seconds, before an idle file is closed
	IdleTimeout *float64 `default:"300" json:"idleTimeout"`
	// The minimum age of files to monitor. Format examples: 30s, 15m, 1h. Age is relative to file modification time. Leave empty to apply no age filters.
	MinAgeDur *string `json:"minAgeDur,omitempty"`
	// The maximum age of event timestamps to collect. Format examples: 60s, 4h, 3d, 1w. Can be used in conjuction with "Check file modification times". Leave empty to apply no age filters.
	MaxAgeDur *string `json:"maxAgeDur,omitempty"`
	// Skip files with modification times earlier than the maximum age duration
	CheckFileModTime *bool `default:"false" json:"checkFileModTime"`
	// Forces files containing binary data to be streamed as text
	ForceText *bool `default:"false" json:"forceText"`
	// Length of file header bytes to use in hash for unique file identification
	HashLen *float64 `default:"256" json:"hashLen"`
	// Fields to add to events from this input
	Metadata []Metadata1Type `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	Description         *string  `json:"description,omitempty"`
	// Directory path to search for files. Environment variables will be resolved, e.g. $CRIBL_HOME/log/.
	Path *string `json:"path,omitempty"`
	// Set how many subdirectories deep to search. Use 0 to search only files in the given path, 1 to also look in its immediate subdirectories, etc. Leave it empty for unlimited depth.
	Depth                     *float64 `json:"depth,omitempty"`
	SuppressMissingPathErrors *bool    `default:"false" json:"suppressMissingPathErrors"`
	// Delete files after they have been collected
	DeleteFiles *bool `default:"false" json:"deleteFiles"`
	// Stream binary files as Base64-encoded chunks.
	IncludeUnidentifiableBinary *bool `default:"false" json:"includeUnidentifiableBinary"`
}

func (i InputFile1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFile1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (i *InputFile1) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputFile1) GetID() *string {
	if i == nil {
		return nil
	}
	return i.ID
}

func (i *InputFile1) GetType() InputFileType1 {
	if i == nil {
		return InputFileType1("")
	}
	return i.Type
}

func (i *InputFile1) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputFile1) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputFile1) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputFile1) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputFile1) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputFile1) GetConnections() []ConnectionsType {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputFile1) GetPq() *PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputFile1) GetMode() *InputFileMode1 {
	if i == nil {
		return nil
	}
	return i.Mode
}

func (i *InputFile1) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputFile1) GetFilenames() []string {
	if i == nil {
		return nil
	}
	return i.Filenames
}

func (i *InputFile1) GetFilterArchivedFiles() *bool {
	if i == nil {
		return nil
	}
	return i.FilterArchivedFiles
}

func (i *InputFile1) GetTailOnly() *bool {
	if i == nil {
		return nil
	}
	return i.TailOnly
}

func (i *InputFile1) GetIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.IdleTimeout
}

func (i *InputFile1) GetMinAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MinAgeDur
}

func (i *InputFile1) GetMaxAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MaxAgeDur
}

func (i *InputFile1) GetCheckFileModTime() *bool {
	if i == nil {
		return nil
	}
	return i.CheckFileModTime
}

func (i *InputFile1) GetForceText() *bool {
	if i == nil {
		return nil
	}
	return i.ForceText
}

func (i *InputFile1) GetHashLen() *float64 {
	if i == nil {
		return nil
	}
	return i.HashLen
}

func (i *InputFile1) GetMetadata() []Metadata1Type {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputFile1) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputFile1) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputFile1) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputFile1) GetPath() *string {
	if i == nil {
		return nil
	}
	return i.Path
}

func (i *InputFile1) GetDepth() *float64 {
	if i == nil {
		return nil
	}
	return i.Depth
}

func (i *InputFile1) GetSuppressMissingPathErrors() *bool {
	if i == nil {
		return nil
	}
	return i.SuppressMissingPathErrors
}

func (i *InputFile1) GetDeleteFiles() *bool {
	if i == nil {
		return nil
	}
	return i.DeleteFiles
}

func (i *InputFile1) GetIncludeUnidentifiableBinary() *bool {
	if i == nil {
		return nil
	}
	return i.IncludeUnidentifiableBinary
}

type InputFileUnionType string

const (
	InputFileUnionTypeInputFile1 InputFileUnionType = "InputFile_1"
	InputFileUnionTypeInputFile2 InputFileUnionType = "InputFile_2"
	InputFileUnionTypeInputFile3 InputFileUnionType = "InputFile_3"
	InputFileUnionTypeInputFile4 InputFileUnionType = "InputFile_4"
	InputFileUnionTypeInputFile5 InputFileUnionType = "InputFile_5"
	InputFileUnionTypeInputFile6 InputFileUnionType = "InputFile_6"
	InputFileUnionTypeInputFile7 InputFileUnionType = "InputFile_7"
	InputFileUnionTypeInputFile8 InputFileUnionType = "InputFile_8"
)

type InputFileUnion struct {
	InputFile1 *InputFile1 `queryParam:"inline,name=InputFile"`
	InputFile2 *InputFile2 `queryParam:"inline,name=InputFile"`
	InputFile3 *InputFile3 `queryParam:"inline,name=InputFile"`
	InputFile4 *InputFile4 `queryParam:"inline,name=InputFile"`
	InputFile5 *InputFile5 `queryParam:"inline,name=InputFile"`
	InputFile6 *InputFile6 `queryParam:"inline,name=InputFile"`
	InputFile7 *InputFile7 `queryParam:"inline,name=InputFile"`
	InputFile8 *InputFile8 `queryParam:"inline,name=InputFile"`

	Type InputFileUnionType
}

func CreateInputFileUnionInputFile1(inputFile1 InputFile1) InputFileUnion {
	typ := InputFileUnionTypeInputFile1

	return InputFileUnion{
		InputFile1: &inputFile1,
		Type:       typ,
	}
}

func CreateInputFileUnionInputFile2(inputFile2 InputFile2) InputFileUnion {
	typ := InputFileUnionTypeInputFile2

	return InputFileUnion{
		InputFile2: &inputFile2,
		Type:       typ,
	}
}

func CreateInputFileUnionInputFile3(inputFile3 InputFile3) InputFileUnion {
	typ := InputFileUnionTypeInputFile3

	return InputFileUnion{
		InputFile3: &inputFile3,
		Type:       typ,
	}
}

func CreateInputFileUnionInputFile4(inputFile4 InputFile4) InputFileUnion {
	typ := InputFileUnionTypeInputFile4

	return InputFileUnion{
		InputFile4: &inputFile4,
		Type:       typ,
	}
}

func CreateInputFileUnionInputFile5(inputFile5 InputFile5) InputFileUnion {
	typ := InputFileUnionTypeInputFile5

	return InputFileUnion{
		InputFile5: &inputFile5,
		Type:       typ,
	}
}

func CreateInputFileUnionInputFile6(inputFile6 InputFile6) InputFileUnion {
	typ := InputFileUnionTypeInputFile6

	return InputFileUnion{
		InputFile6: &inputFile6,
		Type:       typ,
	}
}

func CreateInputFileUnionInputFile7(inputFile7 InputFile7) InputFileUnion {
	typ := InputFileUnionTypeInputFile7

	return InputFileUnion{
		InputFile7: &inputFile7,
		Type:       typ,
	}
}

func CreateInputFileUnionInputFile8(inputFile8 InputFile8) InputFileUnion {
	typ := InputFileUnionTypeInputFile8

	return InputFileUnion{
		InputFile8: &inputFile8,
		Type:       typ,
	}
}

func (u *InputFileUnion) UnmarshalJSON(data []byte) error {

	var inputFile6 InputFile6 = InputFile6{}
	if err := utils.UnmarshalJSON(data, &inputFile6, "", true, nil); err == nil {
		u.InputFile6 = &inputFile6
		u.Type = InputFileUnionTypeInputFile6
		return nil
	}

	var inputFile2 InputFile2 = InputFile2{}
	if err := utils.UnmarshalJSON(data, &inputFile2, "", true, nil); err == nil {
		u.InputFile2 = &inputFile2
		u.Type = InputFileUnionTypeInputFile2
		return nil
	}

	var inputFile4 InputFile4 = InputFile4{}
	if err := utils.UnmarshalJSON(data, &inputFile4, "", true, nil); err == nil {
		u.InputFile4 = &inputFile4
		u.Type = InputFileUnionTypeInputFile4
		return nil
	}

	var inputFile1 InputFile1 = InputFile1{}
	if err := utils.UnmarshalJSON(data, &inputFile1, "", true, nil); err == nil {
		u.InputFile1 = &inputFile1
		u.Type = InputFileUnionTypeInputFile1
		return nil
	}

	var inputFile3 InputFile3 = InputFile3{}
	if err := utils.UnmarshalJSON(data, &inputFile3, "", true, nil); err == nil {
		u.InputFile3 = &inputFile3
		u.Type = InputFileUnionTypeInputFile3
		return nil
	}

	var inputFile5 InputFile5 = InputFile5{}
	if err := utils.UnmarshalJSON(data, &inputFile5, "", true, nil); err == nil {
		u.InputFile5 = &inputFile5
		u.Type = InputFileUnionTypeInputFile5
		return nil
	}

	var inputFile7 InputFile7 = InputFile7{}
	if err := utils.UnmarshalJSON(data, &inputFile7, "", true, nil); err == nil {
		u.InputFile7 = &inputFile7
		u.Type = InputFileUnionTypeInputFile7
		return nil
	}

	var inputFile8 InputFile8 = InputFile8{}
	if err := utils.UnmarshalJSON(data, &inputFile8, "", true, nil); err == nil {
		u.InputFile8 = &inputFile8
		u.Type = InputFileUnionTypeInputFile8
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for InputFileUnion", string(data))
}

func (u InputFileUnion) MarshalJSON() ([]byte, error) {
	if u.InputFile1 != nil {
		return utils.MarshalJSON(u.InputFile1, "", true)
	}

	if u.InputFile2 != nil {
		return utils.MarshalJSON(u.InputFile2, "", true)
	}

	if u.InputFile3 != nil {
		return utils.MarshalJSON(u.InputFile3, "", true)
	}

	if u.InputFile4 != nil {
		return utils.MarshalJSON(u.InputFile4, "", true)
	}

	if u.InputFile5 != nil {
		return utils.MarshalJSON(u.InputFile5, "", true)
	}

	if u.InputFile6 != nil {
		return utils.MarshalJSON(u.InputFile6, "", true)
	}

	if u.InputFile7 != nil {
		return utils.MarshalJSON(u.InputFile7, "", true)
	}

	if u.InputFile8 != nil {
		return utils.MarshalJSON(u.InputFile8, "", true)
	}

	return nil, errors.New("could not marshal union type InputFileUnion: all fields are null")
}
