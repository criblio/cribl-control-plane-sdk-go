// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
// @generated-id: 383e2aa668cd

package components

import (
	"encoding/json"
	"fmt"
	"github.com/criblio/cribl-control-plane-sdk-go/internal/utils"
)

type OutputKinesisType string

const (
	OutputKinesisTypeKinesis OutputKinesisType = "kinesis"
)

func (e OutputKinesisType) ToPointer() *OutputKinesisType {
	return &e
}
func (e *OutputKinesisType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kinesis":
		*e = OutputKinesisType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKinesisType: %v", v)
	}
}

// OutputKinesisCompression - Compression type to use for records
type OutputKinesisCompression string

const (
	// OutputKinesisCompressionNone None
	OutputKinesisCompressionNone OutputKinesisCompression = "none"
	// OutputKinesisCompressionGzip Gzip
	OutputKinesisCompressionGzip OutputKinesisCompression = "gzip"
)

func (e OutputKinesisCompression) ToPointer() *OutputKinesisCompression {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *OutputKinesisCompression) IsExact() bool {
	if e != nil {
		switch *e {
		case "none", "gzip":
			return true
		}
	}
	return false
}

type OutputKinesisPqControls struct {
}

func (o OutputKinesisPqControls) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputKinesisPqControls) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputKinesis struct {
	// Unique ID for this output
	ID   *string           `json:"id,omitempty"`
	Type OutputKinesisType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Kinesis stream name to send events to.
	StreamName string `json:"streamName"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitempty"`
	AwsSecretKey            *string                                     `json:"awsSecretKey,omitempty"`
	// Region where the Kinesis stream is located
	Region string `json:"region"`
	// Kinesis stream service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to Kinesis stream-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing Kinesis stream requests
	SignatureVersion *SignatureVersionOptions2 `json:"signatureVersion,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Use Assume Role credentials to access Kinesis stream
	EnableAssumeRole *bool `json:"enableAssumeRole,omitempty"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitempty"`
	// Maximum number of ongoing put requests before blocking.
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size (KB) of each individual record before compression. For uncompressed or non-compressible data 1MB is the max recommended size
	MaxRecordSizeKB *float64 `json:"maxRecordSizeKB,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Compression type to use for records
	Compression *OutputKinesisCompression `json:"compression,omitempty"`
	// Provides higher stream rate limits, improving delivery speed and reliability by minimizing throttling. See the [ListShards API](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_ListShards.html) documentation for details.
	UseListShards *bool `json:"useListShards,omitempty"`
	// Batch events into a single record as NDJSON
	AsNdjson *bool `json:"asNdjson,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                      `json:"description,omitempty"`
	AwsAPIKey      *string                      `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Maximum number of records to send in a single request
	MaxEventsPerFlush *float64 `json:"maxEventsPerFlush,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *OutputKinesisPqControls  `json:"pqControls,omitempty"`
}

func (o OutputKinesis) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputKinesis) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputKinesis) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputKinesis) GetType() OutputKinesisType {
	if o == nil {
		return OutputKinesisType("")
	}
	return o.Type
}

func (o *OutputKinesis) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputKinesis) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputKinesis) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputKinesis) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputKinesis) GetStreamName() string {
	if o == nil {
		return ""
	}
	return o.StreamName
}

func (o *OutputKinesis) GetAwsAuthenticationMethod() *AuthenticationMethodOptionsS3CollectorConf {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputKinesis) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputKinesis) GetRegion() string {
	if o == nil {
		return ""
	}
	return o.Region
}

func (o *OutputKinesis) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputKinesis) GetSignatureVersion() *SignatureVersionOptions2 {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputKinesis) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputKinesis) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputKinesis) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *OutputKinesis) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *OutputKinesis) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *OutputKinesis) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *OutputKinesis) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputKinesis) GetMaxRecordSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRecordSizeKB
}

func (o *OutputKinesis) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputKinesis) GetCompression() *OutputKinesisCompression {
	if o == nil {
		return nil
	}
	return o.Compression
}

func (o *OutputKinesis) GetUseListShards() *bool {
	if o == nil {
		return nil
	}
	return o.UseListShards
}

func (o *OutputKinesis) GetAsNdjson() *bool {
	if o == nil {
		return nil
	}
	return o.AsNdjson
}

func (o *OutputKinesis) GetOnBackpressure() *BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputKinesis) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputKinesis) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputKinesis) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *OutputKinesis) GetMaxEventsPerFlush() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxEventsPerFlush
}

func (o *OutputKinesis) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputKinesis) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputKinesis) GetPqMode() *ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputKinesis) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputKinesis) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputKinesis) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputKinesis) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputKinesis) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputKinesis) GetPqCompress() *CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputKinesis) GetPqOnBackpressure() *QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputKinesis) GetPqControls() *OutputKinesisPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}
