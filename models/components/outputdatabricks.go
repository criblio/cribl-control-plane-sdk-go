// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package components

import (
	"encoding/json"
	"fmt"
	"github.com/criblio/cribl-control-plane-sdk-go/internal/utils"
)

type OutputDatabricksType string

const (
	OutputDatabricksTypeDatabricks OutputDatabricksType = "databricks"
)

func (e OutputDatabricksType) ToPointer() *OutputDatabricksType {
	return &e
}
func (e *OutputDatabricksType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "databricks":
		*e = OutputDatabricksType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDatabricksType: %v", v)
	}
}

type OutputDatabricks struct {
	// Unique ID for this output
	ID   *string              `json:"id,omitempty"`
	Type OutputDatabricksType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Optional path to prepend to files before uploading.
	DestPath *string `json:"destPath,omitempty"`
	// Filesystem location in which to buffer files before compressing and moving to final destination. Use performant, stable storage.
	StagePath *string `json:"stagePath,omitempty"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
	PartitionExpr *string `json:"partitionExpr,omitempty"`
	// Format of the output data
	Format *DataFormatOptions `json:"format,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `json:"baseFileName,omitempty"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `json:"fileNameSuffix,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `json:"maxFileSizeMB,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `json:"maxOpenFiles,omitempty"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `json:"headerLine,omitempty"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `json:"writeHighWaterMark,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `json:"deadletterEnabled,omitempty"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *DiskSpaceProtectionOptions `json:"onDiskFullBackpressure,omitempty"`
	// Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
	ForceCloseOnShutdown *bool              `json:"forceCloseOnShutdown,omitempty"`
	RetrySettings        *RetrySettingsType `json:"retrySettings,omitempty"`
	// Databricks workspace ID
	WorkspaceID string `json:"workspaceId"`
	// OAuth scope for Unity Catalog authentication
	Scope string `json:"scope"`
	// OAuth client ID for Unity Catalog authentication
	ClientID string `json:"clientId"`
	// Name of the catalog to use for the output
	Catalog string `json:"catalog"`
	// Name of the catalog schema to use for the output
	Schema string `json:"schema"`
	// Name of the events volume in Databricks
	EventsVolumeName string `json:"eventsVolumeName"`
	// OAuth client secret for Unity Catalog authentication
	ClientTextSecret string `json:"clientTextSecret"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec  *float64 `json:"timeoutSec,omitempty"`
	Description *string  `json:"description,omitempty"`
	// Data compression format to apply to HTTP content before it is delivered
	Compress *CompressionOptions2 `json:"compress,omitempty"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *CompressionLevelOptions `json:"compressionLevel,omitempty"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `json:"automaticSchema,omitempty"`
	// To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
	ParquetSchema *string `json:"parquetSchema,omitempty"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *ParquetVersionOptions `json:"parquetVersion,omitempty"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *DataPageVersionOptions `json:"parquetDataPageVersion,omitempty"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `json:"parquetRowGroupLength,omitempty"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
	KeyValueMetadata []ItemsTypeKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `json:"enableStatistics,omitempty"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `json:"enableWritePageIndex,omitempty"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `json:"enablePageChecksum,omitempty"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `json:"emptyDirCleanupSec,omitempty"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `json:"directoryBatchSize,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `json:"deadletterPath,omitempty"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `json:"maxRetryNum,omitempty"`
	// Binds 'format' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'format' at runtime.
	TemplateFormat *string `json:"__template_format,omitempty"`
}

func (o OutputDatabricks) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDatabricks) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"type", "workspaceId", "scope", "clientId", "catalog", "schema", "eventsVolumeName", "clientTextSecret"}); err != nil {
		return err
	}
	return nil
}

func (o *OutputDatabricks) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputDatabricks) GetType() OutputDatabricksType {
	if o == nil {
		return OutputDatabricksType("")
	}
	return o.Type
}

func (o *OutputDatabricks) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputDatabricks) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputDatabricks) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputDatabricks) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputDatabricks) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

func (o *OutputDatabricks) GetStagePath() *string {
	if o == nil {
		return nil
	}
	return o.StagePath
}

func (o *OutputDatabricks) GetAddIDToStagePath() *bool {
	if o == nil {
		return nil
	}
	return o.AddIDToStagePath
}

func (o *OutputDatabricks) GetRemoveEmptyDirs() *bool {
	if o == nil {
		return nil
	}
	return o.RemoveEmptyDirs
}

func (o *OutputDatabricks) GetPartitionExpr() *string {
	if o == nil {
		return nil
	}
	return o.PartitionExpr
}

func (o *OutputDatabricks) GetFormat() *DataFormatOptions {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputDatabricks) GetBaseFileName() *string {
	if o == nil {
		return nil
	}
	return o.BaseFileName
}

func (o *OutputDatabricks) GetFileNameSuffix() *string {
	if o == nil {
		return nil
	}
	return o.FileNameSuffix
}

func (o *OutputDatabricks) GetMaxFileSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileSizeMB
}

func (o *OutputDatabricks) GetMaxFileOpenTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileOpenTimeSec
}

func (o *OutputDatabricks) GetMaxFileIdleTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileIdleTimeSec
}

func (o *OutputDatabricks) GetMaxOpenFiles() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxOpenFiles
}

func (o *OutputDatabricks) GetHeaderLine() *string {
	if o == nil {
		return nil
	}
	return o.HeaderLine
}

func (o *OutputDatabricks) GetWriteHighWaterMark() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteHighWaterMark
}

func (o *OutputDatabricks) GetOnBackpressure() *BackpressureBehaviorOptions1 {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputDatabricks) GetDeadletterEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.DeadletterEnabled
}

func (o *OutputDatabricks) GetOnDiskFullBackpressure() *DiskSpaceProtectionOptions {
	if o == nil {
		return nil
	}
	return o.OnDiskFullBackpressure
}

func (o *OutputDatabricks) GetForceCloseOnShutdown() *bool {
	if o == nil {
		return nil
	}
	return o.ForceCloseOnShutdown
}

func (o *OutputDatabricks) GetRetrySettings() *RetrySettingsType {
	if o == nil {
		return nil
	}
	return o.RetrySettings
}

func (o *OutputDatabricks) GetWorkspaceID() string {
	if o == nil {
		return ""
	}
	return o.WorkspaceID
}

func (o *OutputDatabricks) GetScope() string {
	if o == nil {
		return ""
	}
	return o.Scope
}

func (o *OutputDatabricks) GetClientID() string {
	if o == nil {
		return ""
	}
	return o.ClientID
}

func (o *OutputDatabricks) GetCatalog() string {
	if o == nil {
		return ""
	}
	return o.Catalog
}

func (o *OutputDatabricks) GetSchema() string {
	if o == nil {
		return ""
	}
	return o.Schema
}

func (o *OutputDatabricks) GetEventsVolumeName() string {
	if o == nil {
		return ""
	}
	return o.EventsVolumeName
}

func (o *OutputDatabricks) GetClientTextSecret() string {
	if o == nil {
		return ""
	}
	return o.ClientTextSecret
}

func (o *OutputDatabricks) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputDatabricks) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputDatabricks) GetCompress() *CompressionOptions2 {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputDatabricks) GetCompressionLevel() *CompressionLevelOptions {
	if o == nil {
		return nil
	}
	return o.CompressionLevel
}

func (o *OutputDatabricks) GetAutomaticSchema() *bool {
	if o == nil {
		return nil
	}
	return o.AutomaticSchema
}

func (o *OutputDatabricks) GetParquetSchema() *string {
	if o == nil {
		return nil
	}
	return o.ParquetSchema
}

func (o *OutputDatabricks) GetParquetVersion() *ParquetVersionOptions {
	if o == nil {
		return nil
	}
	return o.ParquetVersion
}

func (o *OutputDatabricks) GetParquetDataPageVersion() *DataPageVersionOptions {
	if o == nil {
		return nil
	}
	return o.ParquetDataPageVersion
}

func (o *OutputDatabricks) GetParquetRowGroupLength() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetRowGroupLength
}

func (o *OutputDatabricks) GetParquetPageSize() *string {
	if o == nil {
		return nil
	}
	return o.ParquetPageSize
}

func (o *OutputDatabricks) GetShouldLogInvalidRows() *bool {
	if o == nil {
		return nil
	}
	return o.ShouldLogInvalidRows
}

func (o *OutputDatabricks) GetKeyValueMetadata() []ItemsTypeKeyValueMetadata {
	if o == nil {
		return nil
	}
	return o.KeyValueMetadata
}

func (o *OutputDatabricks) GetEnableStatistics() *bool {
	if o == nil {
		return nil
	}
	return o.EnableStatistics
}

func (o *OutputDatabricks) GetEnableWritePageIndex() *bool {
	if o == nil {
		return nil
	}
	return o.EnableWritePageIndex
}

func (o *OutputDatabricks) GetEnablePageChecksum() *bool {
	if o == nil {
		return nil
	}
	return o.EnablePageChecksum
}

func (o *OutputDatabricks) GetEmptyDirCleanupSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EmptyDirCleanupSec
}

func (o *OutputDatabricks) GetDirectoryBatchSize() *float64 {
	if o == nil {
		return nil
	}
	return o.DirectoryBatchSize
}

func (o *OutputDatabricks) GetDeadletterPath() *string {
	if o == nil {
		return nil
	}
	return o.DeadletterPath
}

func (o *OutputDatabricks) GetMaxRetryNum() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetryNum
}

func (o *OutputDatabricks) GetTemplateFormat() *string {
	if o == nil {
		return nil
	}
	return o.TemplateFormat
}
