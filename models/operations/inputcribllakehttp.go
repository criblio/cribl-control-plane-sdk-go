// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package operations

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/criblio/cribl-control-plane-sdk-go/internal/utils"
	"github.com/criblio/cribl-control-plane-sdk-go/models/components"
)

type TypeCloudflareHec string

const (
	TypeCloudflareHecCloudflareHec TypeCloudflareHec = "cloudflare_hec"
)

func (e TypeCloudflareHec) ToPointer() *TypeCloudflareHec {
	return &e
}
func (e *TypeCloudflareHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cloudflare_hec":
		*e = TypeCloudflareHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCloudflareHec: %v", v)
	}
}

// AuthTokenAuthenticationMethod - Select Secret to use a text secret to authenticate
type AuthTokenAuthenticationMethod string

const (
	AuthTokenAuthenticationMethodSecret AuthTokenAuthenticationMethod = "secret"
	AuthTokenAuthenticationMethodManual AuthTokenAuthenticationMethod = "manual"
)

func (e AuthTokenAuthenticationMethod) ToPointer() *AuthTokenAuthenticationMethod {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *AuthTokenAuthenticationMethod) IsExact() bool {
	if e != nil {
		switch *e {
		case "secret", "manual":
			return true
		}
	}
	return false
}

type AuthTokenCloudflareHec struct {
	// Select Secret to use a text secret to authenticate
	AuthType *AuthTokenAuthenticationMethod `json:"authType,omitzero"`
	// Select or create a stored text secret
	TokenSecret *string `json:"tokenSecret,omitzero"`
	// Shared secret to be provided by any client (Authorization: <token>)
	Token       *string `json:"token,omitzero"`
	Enabled     *bool   `json:"enabled,omitzero"`
	Description *string `json:"description,omitzero"`
	// Enter the values you want to allow in the HEC event index field at the token level. Supports wildcards. To skip validation, leave blank.
	AllowedIndexesAtToken []string `json:"allowedIndexesAtToken,omitzero"`
	// Fields to add to events referencing this token
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
}

func (a AuthTokenCloudflareHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokenCloudflareHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokenCloudflareHec) GetAuthType() *AuthTokenAuthenticationMethod {
	if a == nil {
		return nil
	}
	return a.AuthType
}

func (a *AuthTokenCloudflareHec) GetTokenSecret() *string {
	if a == nil {
		return nil
	}
	return a.TokenSecret
}

func (a *AuthTokenCloudflareHec) GetToken() *string {
	if a == nil {
		return nil
	}
	return a.Token
}

func (a *AuthTokenCloudflareHec) GetEnabled() *bool {
	if a == nil {
		return nil
	}
	return a.Enabled
}

func (a *AuthTokenCloudflareHec) GetDescription() *string {
	if a == nil {
		return nil
	}
	return a.Description
}

func (a *AuthTokenCloudflareHec) GetAllowedIndexesAtToken() []string {
	if a == nil {
		return nil
	}
	return a.AllowedIndexesAtToken
}

func (a *AuthTokenCloudflareHec) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if a == nil {
		return nil
	}
	return a.Metadata
}

type InputCloudflareHec struct {
	// Unique ID for this input
	ID       string            `json:"id"`
	Type     TypeCloudflareHec `json:"type"`
	Disabled *bool             `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []AuthTokenCloudflareHec              `json:"authTokens,omitzero"`
	TLS        *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `json:"maxActiveReq,omitzero"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `json:"maxRequestsPerSocket,omitzero"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `json:"captureHeaders,omitzero"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `json:"activityLogSampleRate,omitzero"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout  *float64 `json:"keepAliveTimeout,omitzero"`
	EnableHealthCheck any      `json:"enableHealthCheck,omitzero"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `json:"ipAllowlistRegex,omitzero"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `json:"ipDenylistRegex,omitzero"`
	// Absolute path on which to listen for the Cloudflare HTTP Event Collector API requests. This input supports the /event endpoint.
	HecAPI string `json:"hecAPI"`
	// Fields to add to every event. May be overridden by fields added at the token or request level.
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// List values allowed in HEC event index field. Leave blank to skip validation. Supports wildcards. The values here can expand index validation at the token level.
	AllowedIndexes []string `json:"allowedIndexes,omitzero"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitzero"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `json:"staleChannelFlushMs,omitzero"`
	// HTTP origins to which @{product} should send CORS (cross-origin resource sharing) Access-Control-Allow-* headers. Supports wildcards.
	AccessControlAllowOrigin []string `json:"accessControlAllowOrigin,omitzero"`
	// HTTP headers that @{product} will send to allowed origins as "Access-Control-Allow-Headers" in a CORS preflight response. Use "*" to allow all headers.
	AccessControlAllowHeaders []string `json:"accessControlAllowHeaders,omitzero"`
	// Emit per-token (<prefix>.http.perToken) and summary (<prefix>.http.summary) request metrics
	EmitTokenMetrics *bool   `json:"emitTokenMetrics,omitzero"`
	Description      *string `json:"description,omitzero"`
}

func (i InputCloudflareHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCloudflareHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputCloudflareHec) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputCloudflareHec) GetType() TypeCloudflareHec {
	if i == nil {
		return TypeCloudflareHec("")
	}
	return i.Type
}

func (i *InputCloudflareHec) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputCloudflareHec) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputCloudflareHec) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputCloudflareHec) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputCloudflareHec) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputCloudflareHec) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputCloudflareHec) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputCloudflareHec) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputCloudflareHec) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputCloudflareHec) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputCloudflareHec) GetAuthTokens() []AuthTokenCloudflareHec {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputCloudflareHec) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputCloudflareHec) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputCloudflareHec) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputCloudflareHec) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputCloudflareHec) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputCloudflareHec) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputCloudflareHec) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputCloudflareHec) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputCloudflareHec) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputCloudflareHec) GetEnableHealthCheck() any {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputCloudflareHec) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputCloudflareHec) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputCloudflareHec) GetHecAPI() string {
	if i == nil {
		return ""
	}
	return i.HecAPI
}

func (i *InputCloudflareHec) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputCloudflareHec) GetAllowedIndexes() []string {
	if i == nil {
		return nil
	}
	return i.AllowedIndexes
}

func (i *InputCloudflareHec) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputCloudflareHec) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputCloudflareHec) GetAccessControlAllowOrigin() []string {
	if i == nil {
		return nil
	}
	return i.AccessControlAllowOrigin
}

func (i *InputCloudflareHec) GetAccessControlAllowHeaders() []string {
	if i == nil {
		return nil
	}
	return i.AccessControlAllowHeaders
}

func (i *InputCloudflareHec) GetEmitTokenMetrics() *bool {
	if i == nil {
		return nil
	}
	return i.EmitTokenMetrics
}

func (i *InputCloudflareHec) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type TypeZscalerHec string

const (
	TypeZscalerHecZscalerHec TypeZscalerHec = "zscaler_hec"
)

func (e TypeZscalerHec) ToPointer() *TypeZscalerHec {
	return &e
}
func (e *TypeZscalerHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "zscaler_hec":
		*e = TypeZscalerHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeZscalerHec: %v", v)
	}
}

type AuthTokenZscalerHec struct {
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitzero"`
	// Select or create a stored text secret
	TokenSecret *string `json:"tokenSecret,omitzero"`
	// Shared secret to be provided by any client (Authorization: <token>)
	Token       string  `json:"token"`
	Enabled     *bool   `json:"enabled,omitzero"`
	Description *string `json:"description,omitzero"`
	// Enter the values you want to allow in the HEC event index field at the token level. Supports wildcards. To skip validation, leave blank.
	AllowedIndexesAtToken []string `json:"allowedIndexesAtToken,omitzero"`
	// Fields to add to events referencing this token
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
}

func (a AuthTokenZscalerHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokenZscalerHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokenZscalerHec) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if a == nil {
		return nil
	}
	return a.AuthType
}

func (a *AuthTokenZscalerHec) GetTokenSecret() *string {
	if a == nil {
		return nil
	}
	return a.TokenSecret
}

func (a *AuthTokenZscalerHec) GetToken() string {
	if a == nil {
		return ""
	}
	return a.Token
}

func (a *AuthTokenZscalerHec) GetEnabled() *bool {
	if a == nil {
		return nil
	}
	return a.Enabled
}

func (a *AuthTokenZscalerHec) GetDescription() *string {
	if a == nil {
		return nil
	}
	return a.Description
}

func (a *AuthTokenZscalerHec) GetAllowedIndexesAtToken() []string {
	if a == nil {
		return nil
	}
	return a.AllowedIndexesAtToken
}

func (a *AuthTokenZscalerHec) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if a == nil {
		return nil
	}
	return a.Metadata
}

type InputZscalerHec struct {
	// Unique ID for this input
	ID       string         `json:"id"`
	Type     TypeZscalerHec `json:"type"`
	Disabled *bool          `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []AuthTokenZscalerHec                 `json:"authTokens,omitzero"`
	TLS        *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `json:"maxActiveReq,omitzero"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `json:"maxRequestsPerSocket,omitzero"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `json:"captureHeaders,omitzero"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `json:"activityLogSampleRate,omitzero"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout  *float64 `json:"keepAliveTimeout,omitzero"`
	EnableHealthCheck any      `json:"enableHealthCheck,omitzero"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `json:"ipAllowlistRegex,omitzero"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `json:"ipDenylistRegex,omitzero"`
	// Absolute path on which to listen for the Zscaler HTTP Event Collector API requests. This input supports the /event endpoint.
	HecAPI string `json:"hecAPI"`
	// Fields to add to every event. May be overridden by fields added at the token or request level.
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// List values allowed in HEC event index field. Leave blank to skip validation. Supports wildcards. The values here can expand index validation at the token level.
	AllowedIndexes []string `json:"allowedIndexes,omitzero"`
	// Whether to enable Zscaler HEC acknowledgements
	HecAcks *bool `json:"hecAcks,omitzero"`
	// Optionally, list HTTP origins to which @{product} should send CORS (cross-origin resource sharing) Access-Control-Allow-* headers. Supports wildcards.
	AccessControlAllowOrigin []string `json:"accessControlAllowOrigin,omitzero"`
	// Optionally, list HTTP headers that @{product} will send to allowed origins as "Access-Control-Allow-Headers" in a CORS preflight response. Use "*" to allow all headers.
	AccessControlAllowHeaders []string `json:"accessControlAllowHeaders,omitzero"`
	// Enable to emit per-token (<prefix>.http.perToken) and summary (<prefix>.http.summary) request metrics
	EmitTokenMetrics *bool   `json:"emitTokenMetrics,omitzero"`
	Description      *string `json:"description,omitzero"`
}

func (i InputZscalerHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputZscalerHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputZscalerHec) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputZscalerHec) GetType() TypeZscalerHec {
	if i == nil {
		return TypeZscalerHec("")
	}
	return i.Type
}

func (i *InputZscalerHec) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputZscalerHec) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputZscalerHec) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputZscalerHec) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputZscalerHec) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputZscalerHec) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputZscalerHec) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputZscalerHec) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputZscalerHec) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputZscalerHec) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputZscalerHec) GetAuthTokens() []AuthTokenZscalerHec {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputZscalerHec) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputZscalerHec) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputZscalerHec) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputZscalerHec) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputZscalerHec) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputZscalerHec) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputZscalerHec) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputZscalerHec) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputZscalerHec) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputZscalerHec) GetEnableHealthCheck() any {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputZscalerHec) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputZscalerHec) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputZscalerHec) GetHecAPI() string {
	if i == nil {
		return ""
	}
	return i.HecAPI
}

func (i *InputZscalerHec) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputZscalerHec) GetAllowedIndexes() []string {
	if i == nil {
		return nil
	}
	return i.AllowedIndexes
}

func (i *InputZscalerHec) GetHecAcks() *bool {
	if i == nil {
		return nil
	}
	return i.HecAcks
}

func (i *InputZscalerHec) GetAccessControlAllowOrigin() []string {
	if i == nil {
		return nil
	}
	return i.AccessControlAllowOrigin
}

func (i *InputZscalerHec) GetAccessControlAllowHeaders() []string {
	if i == nil {
		return nil
	}
	return i.AccessControlAllowHeaders
}

func (i *InputZscalerHec) GetEmitTokenMetrics() *bool {
	if i == nil {
		return nil
	}
	return i.EmitTokenMetrics
}

func (i *InputZscalerHec) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type CreateInputTypeSecurityLake string

const (
	CreateInputTypeSecurityLakeSecurityLake CreateInputTypeSecurityLake = "security_lake"
)

func (e CreateInputTypeSecurityLake) ToPointer() *CreateInputTypeSecurityLake {
	return &e
}
func (e *CreateInputTypeSecurityLake) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "security_lake":
		*e = CreateInputTypeSecurityLake(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeSecurityLake: %v", v)
	}
}

type InputSecurityLake struct {
	// Unique ID for this input
	ID       string                      `json:"id"`
	Type     CreateInputTypeSecurityLake `json:"type"`
	Disabled *bool                       `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `json:"fileFilter,omitzero"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitzero"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitzero"`
	AwsSecretKey            *string                                                `json:"awsSecretKey,omitzero"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitzero"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitzero"`
	// Signature version to use for signing S3 requests
	SignatureVersion *components.SignatureVersionOptionsS3CollectorConf `json:"signatureVersion,omitzero"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitzero"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitzero"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitzero"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `json:"staleChannelFlushMs,omitzero"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `json:"maxMessages,omitzero"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `json:"visibilityTimeout,omitzero"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `json:"numReceivers,omitzero"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `json:"skipOnError,omitzero"`
	// Attach SQS notification metadata to a __sqsMetadata field on each event
	IncludeSqsMetadata *bool `json:"includeSqsMetadata,omitzero"`
	// Use Assume Role credentials to access Amazon S3
	EnableAssumeRole *bool `json:"enableAssumeRole,omitzero"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitzero"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitzero"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitzero"`
	// Use Assume Role credentials when accessing Amazon SQS
	EnableSQSAssumeRole *bool                                             `json:"enableSQSAssumeRole,omitzero"`
	Preprocess          *components.PreprocessTypeSavedJobCollectionInput `json:"preprocess,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `json:"parquetChunkSizeMB,omitzero"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64                      `json:"parquetChunkDownloadTimeout,omitzero"`
	Checkpointing               *components.CheckpointingType `json:"checkpointing,omitzero"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `json:"pollTimeout,omitzero"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding    *string `json:"encoding,omitzero"`
	Description *string `json:"description,omitzero"`
	AwsAPIKey   *string `json:"awsApiKey,omitzero"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret          *string                               `json:"awsSecret,omitzero"`
	TagAfterProcessing *components.TagAfterProcessingOptions `json:"tagAfterProcessing,omitzero"`
	// The key for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagKey *string `json:"processedTagKey,omitzero"`
	// The value for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagValue *string `json:"processedTagValue,omitzero"`
}

func (i InputSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputSecurityLake) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputSecurityLake) GetType() CreateInputTypeSecurityLake {
	if i == nil {
		return CreateInputTypeSecurityLake("")
	}
	return i.Type
}

func (i *InputSecurityLake) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSecurityLake) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSecurityLake) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputSecurityLake) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputSecurityLake) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputSecurityLake) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputSecurityLake) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputSecurityLake) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputSecurityLake) GetQueueName() string {
	if i == nil {
		return ""
	}
	return i.QueueName
}

func (i *InputSecurityLake) GetFileFilter() *string {
	if i == nil {
		return nil
	}
	return i.FileFilter
}

func (i *InputSecurityLake) GetAwsAccountID() *string {
	if i == nil {
		return nil
	}
	return i.AwsAccountID
}

func (i *InputSecurityLake) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if i == nil {
		return nil
	}
	return i.AwsAuthenticationMethod
}

func (i *InputSecurityLake) GetAwsSecretKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecretKey
}

func (i *InputSecurityLake) GetRegion() *string {
	if i == nil {
		return nil
	}
	return i.Region
}

func (i *InputSecurityLake) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputSecurityLake) GetSignatureVersion() *components.SignatureVersionOptionsS3CollectorConf {
	if i == nil {
		return nil
	}
	return i.SignatureVersion
}

func (i *InputSecurityLake) GetReuseConnections() *bool {
	if i == nil {
		return nil
	}
	return i.ReuseConnections
}

func (i *InputSecurityLake) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputSecurityLake) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputSecurityLake) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputSecurityLake) GetMaxMessages() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMessages
}

func (i *InputSecurityLake) GetVisibilityTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.VisibilityTimeout
}

func (i *InputSecurityLake) GetNumReceivers() *float64 {
	if i == nil {
		return nil
	}
	return i.NumReceivers
}

func (i *InputSecurityLake) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputSecurityLake) GetSkipOnError() *bool {
	if i == nil {
		return nil
	}
	return i.SkipOnError
}

func (i *InputSecurityLake) GetIncludeSqsMetadata() *bool {
	if i == nil {
		return nil
	}
	return i.IncludeSqsMetadata
}

func (i *InputSecurityLake) GetEnableAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableAssumeRole
}

func (i *InputSecurityLake) GetAssumeRoleArn() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleArn
}

func (i *InputSecurityLake) GetAssumeRoleExternalID() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleExternalID
}

func (i *InputSecurityLake) GetDurationSeconds() *float64 {
	if i == nil {
		return nil
	}
	return i.DurationSeconds
}

func (i *InputSecurityLake) GetEnableSQSAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableSQSAssumeRole
}

func (i *InputSecurityLake) GetPreprocess() *components.PreprocessTypeSavedJobCollectionInput {
	if i == nil {
		return nil
	}
	return i.Preprocess
}

func (i *InputSecurityLake) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputSecurityLake) GetParquetChunkSizeMB() *float64 {
	if i == nil {
		return nil
	}
	return i.ParquetChunkSizeMB
}

func (i *InputSecurityLake) GetParquetChunkDownloadTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.ParquetChunkDownloadTimeout
}

func (i *InputSecurityLake) GetCheckpointing() *components.CheckpointingType {
	if i == nil {
		return nil
	}
	return i.Checkpointing
}

func (i *InputSecurityLake) GetPollTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.PollTimeout
}

func (i *InputSecurityLake) GetEncoding() *string {
	if i == nil {
		return nil
	}
	return i.Encoding
}

func (i *InputSecurityLake) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputSecurityLake) GetAwsAPIKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsAPIKey
}

func (i *InputSecurityLake) GetAwsSecret() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecret
}

func (i *InputSecurityLake) GetTagAfterProcessing() *components.TagAfterProcessingOptions {
	if i == nil {
		return nil
	}
	return i.TagAfterProcessing
}

func (i *InputSecurityLake) GetProcessedTagKey() *string {
	if i == nil {
		return nil
	}
	return i.ProcessedTagKey
}

func (i *InputSecurityLake) GetProcessedTagValue() *string {
	if i == nil {
		return nil
	}
	return i.ProcessedTagValue
}

type CreateInputTypeNetflow string

const (
	CreateInputTypeNetflowNetflow CreateInputTypeNetflow = "netflow"
)

func (e CreateInputTypeNetflow) ToPointer() *CreateInputTypeNetflow {
	return &e
}
func (e *CreateInputTypeNetflow) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "netflow":
		*e = CreateInputTypeNetflow(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeNetflow: %v", v)
	}
}

type InputNetflow struct {
	// Unique ID for this input
	ID       string                 `json:"id"`
	Type     CreateInputTypeNetflow `json:"type"`
	Disabled *bool                  `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host string `json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Allow forwarding of events to a NetFlow destination. Enabling this feature will generate an extra event containing __netflowRaw which can be routed to a NetFlow destination. Note that these events will not count against ingest quota.
	EnablePassThrough *bool `json:"enablePassThrough,omitzero"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist.
	IPAllowlistRegex *string `json:"ipAllowlistRegex,omitzero"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `json:"ipDenylistRegex,omitzero"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitzero"`
	// Specifies how many minutes NetFlow v9 templates are cached before being discarded if not refreshed. Adjust based on your network's template update frequency to optimize performance and memory usage.
	TemplateCacheMinutes *float64 `json:"templateCacheMinutes,omitzero"`
	// Accept messages in Netflow V5 format.
	V5Enabled *bool `json:"v5Enabled,omitzero"`
	// Accept messages in Netflow V9 format.
	V9Enabled *bool `json:"v9Enabled,omitzero"`
	// Accept messages in IPFIX format.
	IpfixEnabled *bool `json:"ipfixEnabled,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
}

func (i InputNetflow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputNetflow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputNetflow) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputNetflow) GetType() CreateInputTypeNetflow {
	if i == nil {
		return CreateInputTypeNetflow("")
	}
	return i.Type
}

func (i *InputNetflow) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputNetflow) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputNetflow) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputNetflow) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputNetflow) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputNetflow) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputNetflow) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputNetflow) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputNetflow) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputNetflow) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputNetflow) GetEnablePassThrough() *bool {
	if i == nil {
		return nil
	}
	return i.EnablePassThrough
}

func (i *InputNetflow) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputNetflow) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputNetflow) GetUDPSocketRxBufSize() *float64 {
	if i == nil {
		return nil
	}
	return i.UDPSocketRxBufSize
}

func (i *InputNetflow) GetTemplateCacheMinutes() *float64 {
	if i == nil {
		return nil
	}
	return i.TemplateCacheMinutes
}

func (i *InputNetflow) GetV5Enabled() *bool {
	if i == nil {
		return nil
	}
	return i.V5Enabled
}

func (i *InputNetflow) GetV9Enabled() *bool {
	if i == nil {
		return nil
	}
	return i.V9Enabled
}

func (i *InputNetflow) GetIpfixEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.IpfixEnabled
}

func (i *InputNetflow) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputNetflow) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type TypeWizWebhook string

const (
	TypeWizWebhookWizWebhook TypeWizWebhook = "wiz_webhook"
)

func (e TypeWizWebhook) ToPointer() *TypeWizWebhook {
	return &e
}
func (e *TypeWizWebhook) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "wiz_webhook":
		*e = TypeWizWebhook(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeWizWebhook: %v", v)
	}
}

type InputWizWebhook struct {
	// Unique ID for this input
	ID       string         `json:"id"`
	Type     TypeWizWebhook `json:"type"`
	Disabled *bool          `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                              `json:"authTokens,omitzero"`
	TLS        *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `json:"maxActiveReq,omitzero"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `json:"maxRequestsPerSocket,omitzero"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `json:"captureHeaders,omitzero"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `json:"activityLogSampleRate,omitzero"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitzero"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `json:"enableHealthCheck,omitzero"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `json:"ipAllowlistRegex,omitzero"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `json:"ipDenylistRegex,omitzero"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitzero"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `json:"staleChannelFlushMs,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// List of URI paths accepted by this input. Wildcards are supported (such as /api/v*/hook). Defaults to allow all.
	AllowedPaths []string `json:"allowedPaths,omitzero"`
	// List of HTTP methods accepted by this input. Wildcards are supported (such as P*, GET). Defaults to allow all.
	AllowedMethods []string `json:"allowedMethods,omitzero"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokensExt []components.ItemsTypeAuthTokensExt `json:"authTokensExt,omitzero"`
	Description   *string                             `json:"description,omitzero"`
}

func (i InputWizWebhook) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWizWebhook) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputWizWebhook) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputWizWebhook) GetType() TypeWizWebhook {
	if i == nil {
		return TypeWizWebhook("")
	}
	return i.Type
}

func (i *InputWizWebhook) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputWizWebhook) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputWizWebhook) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputWizWebhook) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputWizWebhook) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputWizWebhook) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputWizWebhook) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputWizWebhook) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputWizWebhook) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputWizWebhook) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputWizWebhook) GetAuthTokens() []string {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputWizWebhook) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputWizWebhook) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputWizWebhook) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputWizWebhook) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputWizWebhook) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputWizWebhook) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputWizWebhook) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputWizWebhook) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputWizWebhook) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputWizWebhook) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputWizWebhook) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputWizWebhook) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputWizWebhook) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputWizWebhook) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputWizWebhook) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputWizWebhook) GetAllowedPaths() []string {
	if i == nil {
		return nil
	}
	return i.AllowedPaths
}

func (i *InputWizWebhook) GetAllowedMethods() []string {
	if i == nil {
		return nil
	}
	return i.AllowedMethods
}

func (i *InputWizWebhook) GetAuthTokensExt() []components.ItemsTypeAuthTokensExt {
	if i == nil {
		return nil
	}
	return i.AuthTokensExt
}

func (i *InputWizWebhook) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type TypeWiz string

const (
	TypeWizWiz TypeWiz = "wiz"
)

func (e TypeWiz) ToPointer() *TypeWiz {
	return &e
}
func (e *TypeWiz) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "wiz":
		*e = TypeWiz(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeWiz: %v", v)
	}
}

type ManageState struct {
}

func (m ManageState) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *ManageState) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, nil); err != nil {
		return err
	}
	return nil
}

// ContentConfigLogLevel - Collector runtime log level
type ContentConfigLogLevel string

const (
	ContentConfigLogLevelError ContentConfigLogLevel = "error"
	ContentConfigLogLevelWarn  ContentConfigLogLevel = "warn"
	ContentConfigLogLevelInfo  ContentConfigLogLevel = "info"
	ContentConfigLogLevelDebug ContentConfigLogLevel = "debug"
	ContentConfigLogLevelSilly ContentConfigLogLevel = "silly"
)

func (e ContentConfigLogLevel) ToPointer() *ContentConfigLogLevel {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *ContentConfigLogLevel) IsExact() bool {
	if e != nil {
		switch *e {
		case "error", "warn", "info", "debug", "silly":
			return true
		}
	}
	return false
}

type ContentConfigWiz struct {
	// The name of the Wiz query
	ContentType        string  `json:"contentType"`
	ContentDescription *string `json:"contentDescription,omitzero"`
	Enabled            *bool   `json:"enabled,omitzero"`
	// Track collection progress between consecutive scheduled executions
	StateTracking *bool `json:"stateTracking,omitzero"`
	// JavaScript expression that defines how to update the state from an event. Use the event's data and the current state to compute the new state. See [Understanding State Expression Fields](https://docs.cribl.io/stream/collectors-rest#state-tracking-expression-fields) for more information.
	StateUpdateExpression *string `json:"stateUpdateExpression,omitzero"`
	// JavaScript expression that defines which state to keep when merging a task's newly reported state with previously saved state. Evaluates `prevState` and `newState` variables, resolving to the state to keep.
	StateMergeExpression *string      `json:"stateMergeExpression,omitzero"`
	ManageState          *ManageState `json:"manageState,omitzero"`
	// Template for POST body to send with the Collect request. Reference global variables, or functions using template params: `${C.vars.myVar}`, or `${Date.now()}`, `${param}`.
	ContentQuery string `json:"contentQuery"`
	// A cron schedule on which to run this job
	CronSchedule string `json:"cronSchedule"`
	// Earliest time, relative to now. Format supported: [+|-]<time_integer><time_unit>@<snap-to_time_unit> (ex: -1hr, -42m, -42m@h)
	Earliest string `json:"earliest"`
	// Latest time, relative to now. Format supported: [+|-]<time_integer><time_unit>@<snap-to_time_unit> (ex: -1hr, -42m, -42m@h)
	Latest string `json:"latest"`
	// Maximum time the job is allowed to run (examples: 30, 45s, 15m). Units default to seconds if not specified. Enter 0 for unlimited time.
	JobTimeout *string `json:"jobTimeout,omitzero"`
	// Collector runtime log level
	LogLevel *ContentConfigLogLevel `json:"logLevel,omitzero"`
	// Maximum number of pages to retrieve per collection task. Defaults to 0. Set to 0 to retrieve all pages.
	MaxPages *float64 `json:"maxPages,omitzero"`
}

func (c ContentConfigWiz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ContentConfigWiz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *ContentConfigWiz) GetContentType() string {
	if c == nil {
		return ""
	}
	return c.ContentType
}

func (c *ContentConfigWiz) GetContentDescription() *string {
	if c == nil {
		return nil
	}
	return c.ContentDescription
}

func (c *ContentConfigWiz) GetEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.Enabled
}

func (c *ContentConfigWiz) GetStateTracking() *bool {
	if c == nil {
		return nil
	}
	return c.StateTracking
}

func (c *ContentConfigWiz) GetStateUpdateExpression() *string {
	if c == nil {
		return nil
	}
	return c.StateUpdateExpression
}

func (c *ContentConfigWiz) GetStateMergeExpression() *string {
	if c == nil {
		return nil
	}
	return c.StateMergeExpression
}

func (c *ContentConfigWiz) GetManageState() *ManageState {
	if c == nil {
		return nil
	}
	return c.ManageState
}

func (c *ContentConfigWiz) GetContentQuery() string {
	if c == nil {
		return ""
	}
	return c.ContentQuery
}

func (c *ContentConfigWiz) GetCronSchedule() string {
	if c == nil {
		return ""
	}
	return c.CronSchedule
}

func (c *ContentConfigWiz) GetEarliest() string {
	if c == nil {
		return ""
	}
	return c.Earliest
}

func (c *ContentConfigWiz) GetLatest() string {
	if c == nil {
		return ""
	}
	return c.Latest
}

func (c *ContentConfigWiz) GetJobTimeout() *string {
	if c == nil {
		return nil
	}
	return c.JobTimeout
}

func (c *ContentConfigWiz) GetLogLevel() *ContentConfigLogLevel {
	if c == nil {
		return nil
	}
	return c.LogLevel
}

func (c *ContentConfigWiz) GetMaxPages() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPages
}

type InputWiz struct {
	// Unique ID for this input
	ID       string  `json:"id"`
	Type     TypeWiz `json:"type"`
	Disabled *bool   `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// The Wiz GraphQL API endpoint. Example: https://api.us1.app.wiz.io/graphql
	Endpoint string `json:"endpoint"`
	// The authentication URL to generate an OAuth token
	AuthURL string `json:"authUrl"`
	// The audience to use when requesting an OAuth token for a custom auth URL. When not specified, `wiz-api` will be used.
	AuthAudienceOverride *string `json:"authAudienceOverride,omitzero"`
	// The client ID of the Wiz application
	ClientID      string             `json:"clientId"`
	ContentConfig []ContentConfigWiz `json:"contentConfig"`
	// HTTP request inactivity timeout. Use 0 to disable.
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `json:"keepAliveTime,omitzero"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `json:"maxMissedKeepAlives,omitzero"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `json:"ttl,omitzero"`
	// When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
	IgnoreGroupJobsLimit *bool `json:"ignoreGroupJobsLimit,omitzero"`
	// Fields to add to events from this input
	Metadata   []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	RetryRules *components.RetryRulesType                 `json:"retryRules,omitzero"`
	// Enter client secret directly, or select a stored secret
	AuthType    *components.AuthenticationMethodOptions1 `json:"authType,omitzero"`
	Description *string                                  `json:"description,omitzero"`
	// The client secret of the Wiz application
	ClientSecret *string `json:"clientSecret,omitzero"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitzero"`
}

func (i InputWiz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWiz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputWiz) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputWiz) GetType() TypeWiz {
	if i == nil {
		return TypeWiz("")
	}
	return i.Type
}

func (i *InputWiz) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputWiz) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputWiz) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputWiz) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputWiz) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputWiz) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputWiz) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputWiz) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputWiz) GetEndpoint() string {
	if i == nil {
		return ""
	}
	return i.Endpoint
}

func (i *InputWiz) GetAuthURL() string {
	if i == nil {
		return ""
	}
	return i.AuthURL
}

func (i *InputWiz) GetAuthAudienceOverride() *string {
	if i == nil {
		return nil
	}
	return i.AuthAudienceOverride
}

func (i *InputWiz) GetClientID() string {
	if i == nil {
		return ""
	}
	return i.ClientID
}

func (i *InputWiz) GetContentConfig() []ContentConfigWiz {
	if i == nil {
		return []ContentConfigWiz{}
	}
	return i.ContentConfig
}

func (i *InputWiz) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputWiz) GetKeepAliveTime() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTime
}

func (i *InputWiz) GetMaxMissedKeepAlives() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMissedKeepAlives
}

func (i *InputWiz) GetTTL() *string {
	if i == nil {
		return nil
	}
	return i.TTL
}

func (i *InputWiz) GetIgnoreGroupJobsLimit() *bool {
	if i == nil {
		return nil
	}
	return i.IgnoreGroupJobsLimit
}

func (i *InputWiz) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputWiz) GetRetryRules() *components.RetryRulesType {
	if i == nil {
		return nil
	}
	return i.RetryRules
}

func (i *InputWiz) GetAuthType() *components.AuthenticationMethodOptions1 {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputWiz) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputWiz) GetClientSecret() *string {
	if i == nil {
		return nil
	}
	return i.ClientSecret
}

func (i *InputWiz) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

type InputJournalFilesType string

const (
	InputJournalFilesTypeJournalFiles InputJournalFilesType = "journal_files"
)

func (e InputJournalFilesType) ToPointer() *InputJournalFilesType {
	return &e
}
func (e *InputJournalFilesType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "journal_files":
		*e = InputJournalFilesType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputJournalFilesType: %v", v)
	}
}

type InputJournalFilesRule struct {
	// JavaScript expression applied to Journal objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitzero"`
}

func (i InputJournalFilesRule) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputJournalFilesRule) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputJournalFilesRule) GetFilter() string {
	if i == nil {
		return ""
	}
	return i.Filter
}

func (i *InputJournalFilesRule) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type InputJournalFiles struct {
	// Unique ID for this input
	ID       string                `json:"id"`
	Type     InputJournalFilesType `json:"type"`
	Disabled *bool                 `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Directory path to search for journals. Environment variables will be resolved, e.g. $CRIBL_EDGE_FS_ROOT/var/log/journal/$MACHINE_ID.
	Path string `json:"path"`
	// Time, in seconds, between scanning for journals.
	Interval *float64 `json:"interval,omitzero"`
	// The full path of discovered journals are matched against this wildcard list.
	Journals []string `json:"journals"`
	// Add rules to decide which journal objects to allow. Events are generated if no rules are given or if all the rules' expressions evaluate to true.
	Rules []InputJournalFilesRule `json:"rules,omitzero"`
	// Skip log messages that are not part of the current boot session.
	CurrentBoot *bool `json:"currentBoot,omitzero"`
	// The maximum log message age, in duration form (e.g,: 60s, 4h, 3d, 1w).  Default of no value will apply no max age filters.
	MaxAgeDur *string `json:"maxAgeDur,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
}

func (i InputJournalFiles) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputJournalFiles) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputJournalFiles) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputJournalFiles) GetType() InputJournalFilesType {
	if i == nil {
		return InputJournalFilesType("")
	}
	return i.Type
}

func (i *InputJournalFiles) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputJournalFiles) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputJournalFiles) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputJournalFiles) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputJournalFiles) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputJournalFiles) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputJournalFiles) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputJournalFiles) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputJournalFiles) GetPath() string {
	if i == nil {
		return ""
	}
	return i.Path
}

func (i *InputJournalFiles) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputJournalFiles) GetJournals() []string {
	if i == nil {
		return []string{}
	}
	return i.Journals
}

func (i *InputJournalFiles) GetRules() []InputJournalFilesRule {
	if i == nil {
		return nil
	}
	return i.Rules
}

func (i *InputJournalFiles) GetCurrentBoot() *bool {
	if i == nil {
		return nil
	}
	return i.CurrentBoot
}

func (i *InputJournalFiles) GetMaxAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MaxAgeDur
}

func (i *InputJournalFiles) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputJournalFiles) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type TypeRawUDP string

const (
	TypeRawUDPRawUDP TypeRawUDP = "raw_udp"
)

func (e TypeRawUDP) ToPointer() *TypeRawUDP {
	return &e
}
func (e *TypeRawUDP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "raw_udp":
		*e = TypeRawUDP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeRawUDP: %v", v)
	}
}

type InputRawUDP struct {
	// Unique ID for this input
	ID       string     `json:"id"`
	Type     TypeRawUDP `json:"type"`
	Disabled *bool      `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host string `json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Maximum number of events to buffer when downstream is blocking.
	MaxBufferSize *float64 `json:"maxBufferSize,omitzero"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `json:"ipWhitelistRegex,omitzero"`
	// If true, each UDP packet is assumed to contain a single message. If false, each UDP packet is assumed to contain multiple messages, separated by newlines.
	SingleMsgUDPPackets *bool `json:"singleMsgUdpPackets,omitzero"`
	// If true, a __rawBytes field will be added to each event containing the raw bytes of the datagram.
	IngestRawBytes *bool `json:"ingestRawBytes,omitzero"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
}

func (i InputRawUDP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputRawUDP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputRawUDP) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputRawUDP) GetType() TypeRawUDP {
	if i == nil {
		return TypeRawUDP("")
	}
	return i.Type
}

func (i *InputRawUDP) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputRawUDP) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputRawUDP) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputRawUDP) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputRawUDP) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputRawUDP) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputRawUDP) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputRawUDP) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputRawUDP) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputRawUDP) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputRawUDP) GetMaxBufferSize() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBufferSize
}

func (i *InputRawUDP) GetIPWhitelistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPWhitelistRegex
}

func (i *InputRawUDP) GetSingleMsgUDPPackets() *bool {
	if i == nil {
		return nil
	}
	return i.SingleMsgUDPPackets
}

func (i *InputRawUDP) GetIngestRawBytes() *bool {
	if i == nil {
		return nil
	}
	return i.IngestRawBytes
}

func (i *InputRawUDP) GetUDPSocketRxBufSize() *float64 {
	if i == nil {
		return nil
	}
	return i.UDPSocketRxBufSize
}

func (i *InputRawUDP) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputRawUDP) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type TypeWinEventLogs string

const (
	TypeWinEventLogsWinEventLogs TypeWinEventLogs = "win_event_logs"
)

func (e TypeWinEventLogs) ToPointer() *TypeWinEventLogs {
	return &e
}
func (e *TypeWinEventLogs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "win_event_logs":
		*e = TypeWinEventLogs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeWinEventLogs: %v", v)
	}
}

// ReadMode - Read all stored and future event logs, or only future events
type ReadMode string

const (
	// ReadModeOldest Entire log
	ReadModeOldest ReadMode = "oldest"
	// ReadModeNewest From last entry
	ReadModeNewest ReadMode = "newest"
)

func (e ReadMode) ToPointer() *ReadMode {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *ReadMode) IsExact() bool {
	if e != nil {
		switch *e {
		case "oldest", "newest":
			return true
		}
	}
	return false
}

// EventFormat - Format of individual events
type EventFormat string

const (
	// EventFormatJSON JSON
	EventFormatJSON EventFormat = "json"
	// EventFormatXML XML
	EventFormatXML EventFormat = "xml"
)

func (e EventFormat) ToPointer() *EventFormat {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *EventFormat) IsExact() bool {
	if e != nil {
		switch *e {
		case "json", "xml":
			return true
		}
	}
	return false
}

type InputWinEventLogs struct {
	// Unique ID for this input
	ID       string           `json:"id"`
	Type     TypeWinEventLogs `json:"type"`
	Disabled *bool            `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Enter the event logs to collect. Run "Get-WinEvent -ListLog *" in PowerShell to see the available logs.
	LogNames []string `json:"logNames"`
	// Read all stored and future event logs, or only future events
	ReadMode *ReadMode `json:"readMode,omitzero"`
	// Format of individual events
	EventFormat *EventFormat `json:"eventFormat,omitzero"`
	// Enable to use built-in tools (PowerShell for JSON, wevtutil for XML) to collect event logs instead of native API (default) [Learn more](https://docs.cribl.io/edge/sources-windows-event-logs/#advanced-settings)
	DisableNativeModule *bool `json:"disableNativeModule,omitzero"`
	// Time, in seconds, between checking for new entries (Applicable for pre-4.8.0 nodes that use Windows Tools)
	Interval *float64 `json:"interval,omitzero"`
	// The maximum number of events to read in one polling interval. A batch size higher than 500 can cause delays when pulling from multiple event logs. (Applicable for pre-4.8.0 nodes that use Windows Tools)
	BatchSize *float64 `json:"batchSize,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// The maximum number of bytes in an event before it is flushed to the pipelines
	MaxEventBytes *float64 `json:"maxEventBytes,omitzero"`
	Description   *string  `json:"description,omitzero"`
	// Enable/disable the rendering of localized event message strings (Applicable for 4.8.0 nodes and newer that use the Native API)
	DisableJSONRendering *bool `json:"disableJsonRendering,omitzero"`
	// Enable/disable the rendering of localized event message strings (Applicable for 4.8.0 nodes and newer that use the Native API)
	DisableXMLRendering *bool `json:"disableXmlRendering,omitzero"`
}

func (i InputWinEventLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWinEventLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputWinEventLogs) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputWinEventLogs) GetType() TypeWinEventLogs {
	if i == nil {
		return TypeWinEventLogs("")
	}
	return i.Type
}

func (i *InputWinEventLogs) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputWinEventLogs) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputWinEventLogs) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputWinEventLogs) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputWinEventLogs) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputWinEventLogs) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputWinEventLogs) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputWinEventLogs) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputWinEventLogs) GetLogNames() []string {
	if i == nil {
		return []string{}
	}
	return i.LogNames
}

func (i *InputWinEventLogs) GetReadMode() *ReadMode {
	if i == nil {
		return nil
	}
	return i.ReadMode
}

func (i *InputWinEventLogs) GetEventFormat() *EventFormat {
	if i == nil {
		return nil
	}
	return i.EventFormat
}

func (i *InputWinEventLogs) GetDisableNativeModule() *bool {
	if i == nil {
		return nil
	}
	return i.DisableNativeModule
}

func (i *InputWinEventLogs) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputWinEventLogs) GetBatchSize() *float64 {
	if i == nil {
		return nil
	}
	return i.BatchSize
}

func (i *InputWinEventLogs) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputWinEventLogs) GetMaxEventBytes() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxEventBytes
}

func (i *InputWinEventLogs) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputWinEventLogs) GetDisableJSONRendering() *bool {
	if i == nil {
		return nil
	}
	return i.DisableJSONRendering
}

func (i *InputWinEventLogs) GetDisableXMLRendering() *bool {
	if i == nil {
		return nil
	}
	return i.DisableXMLRendering
}

type TypeWef string

const (
	TypeWefWef TypeWef = "wef"
)

func (e TypeWef) ToPointer() *TypeWef {
	return &e
}
func (e *TypeWef) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "wef":
		*e = TypeWef(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeWef: %v", v)
	}
}

// AuthMethodAuthenticationMethod - How to authenticate incoming client connections
type AuthMethodAuthenticationMethod string

const (
	// AuthMethodAuthenticationMethodClientCert Client certificate
	AuthMethodAuthenticationMethodClientCert AuthMethodAuthenticationMethod = "clientCert"
	// AuthMethodAuthenticationMethodKerberos Kerberos
	AuthMethodAuthenticationMethodKerberos AuthMethodAuthenticationMethod = "kerberos"
)

func (e AuthMethodAuthenticationMethod) ToPointer() *AuthMethodAuthenticationMethod {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *AuthMethodAuthenticationMethod) IsExact() bool {
	if e != nil {
		switch *e {
		case "clientCert", "kerberos":
			return true
		}
	}
	return false
}

type MTLSSettings struct {
	// Enable TLS
	Disabled *bool `json:"disabled,omitzero"`
	// Required for WEF certificate authentication
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitzero"`
	// Required for WEF certificate authentication
	RequestCert *bool `json:"requestCert,omitzero"`
	// Name of the predefined certificate
	CertificateName *string `json:"certificateName,omitzero"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath string `json:"privKeyPath"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitzero"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath string `json:"certPath"`
	// Server path containing CA certificates (in PEM format) to use. Can reference $ENV_VARS. If multiple certificates are present in a .pem, each must directly certify the one preceding it.
	CaPath string `json:"caPath"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string                                                    `json:"commonNameRegex,omitzero"`
	MinVersion      *components.MinimumTLSVersionOptionsKafkaSchemaRegistryTLS `json:"minVersion,omitzero"`
	MaxVersion      *components.MaximumTLSVersionOptionsKafkaSchemaRegistryTLS `json:"maxVersion,omitzero"`
	// Enable OCSP check of certificate
	OcspCheck *bool `json:"ocspCheck,omitzero"`
	Keytab    any   `json:"keytab,omitzero"`
	Principal any   `json:"principal,omitzero"`
	// If enabled, checks will fail on any OCSP error. Otherwise, checks will fail only when a certificate is revoked, ignoring other errors.
	OcspCheckFailClose *bool `json:"ocspCheckFailClose,omitzero"`
}

func (m MTLSSettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MTLSSettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (m *MTLSSettings) GetDisabled() *bool {
	if m == nil {
		return nil
	}
	return m.Disabled
}

func (m *MTLSSettings) GetRejectUnauthorized() *bool {
	if m == nil {
		return nil
	}
	return m.RejectUnauthorized
}

func (m *MTLSSettings) GetRequestCert() *bool {
	if m == nil {
		return nil
	}
	return m.RequestCert
}

func (m *MTLSSettings) GetCertificateName() *string {
	if m == nil {
		return nil
	}
	return m.CertificateName
}

func (m *MTLSSettings) GetPrivKeyPath() string {
	if m == nil {
		return ""
	}
	return m.PrivKeyPath
}

func (m *MTLSSettings) GetPassphrase() *string {
	if m == nil {
		return nil
	}
	return m.Passphrase
}

func (m *MTLSSettings) GetCertPath() string {
	if m == nil {
		return ""
	}
	return m.CertPath
}

func (m *MTLSSettings) GetCaPath() string {
	if m == nil {
		return ""
	}
	return m.CaPath
}

func (m *MTLSSettings) GetCommonNameRegex() *string {
	if m == nil {
		return nil
	}
	return m.CommonNameRegex
}

func (m *MTLSSettings) GetMinVersion() *components.MinimumTLSVersionOptionsKafkaSchemaRegistryTLS {
	if m == nil {
		return nil
	}
	return m.MinVersion
}

func (m *MTLSSettings) GetMaxVersion() *components.MaximumTLSVersionOptionsKafkaSchemaRegistryTLS {
	if m == nil {
		return nil
	}
	return m.MaxVersion
}

func (m *MTLSSettings) GetOcspCheck() *bool {
	if m == nil {
		return nil
	}
	return m.OcspCheck
}

func (m *MTLSSettings) GetKeytab() any {
	if m == nil {
		return nil
	}
	return m.Keytab
}

func (m *MTLSSettings) GetPrincipal() any {
	if m == nil {
		return nil
	}
	return m.Principal
}

func (m *MTLSSettings) GetOcspCheckFailClose() *bool {
	if m == nil {
		return nil
	}
	return m.OcspCheckFailClose
}

// CreateInputFormat - Content format in which the endpoint should deliver events
type CreateInputFormat string

const (
	CreateInputFormatRaw          CreateInputFormat = "Raw"
	CreateInputFormatRenderedText CreateInputFormat = "RenderedText"
)

func (e CreateInputFormat) ToPointer() *CreateInputFormat {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateInputFormat) IsExact() bool {
	if e != nil {
		switch *e {
		case "Raw", "RenderedText":
			return true
		}
	}
	return false
}

type QueryBuilderMode string

const (
	QueryBuilderModeSimple QueryBuilderMode = "simple"
	QueryBuilderModeXML    QueryBuilderMode = "xml"
)

func (e QueryBuilderMode) ToPointer() *QueryBuilderMode {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *QueryBuilderMode) IsExact() bool {
	if e != nil {
		switch *e {
		case "simple", "xml":
			return true
		}
	}
	return false
}

type Query struct {
	// The Path attribute from the relevant XML Select element
	Path string `json:"path"`
	// The XPath query inside the relevant XML Select element
	QueryExpression string `json:"queryExpression"`
}

func (q Query) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(q, "", false)
}

func (q *Query) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &q, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (q *Query) GetPath() string {
	if q == nil {
		return ""
	}
	return q.Path
}

func (q *Query) GetQueryExpression() string {
	if q == nil {
		return ""
	}
	return q.QueryExpression
}

type Subscription struct {
	SubscriptionName string `json:"subscriptionName"`
	// Version UUID for this subscription. If any subscription parameters are modified, this value will change.
	Version *string `json:"version,omitzero"`
	// Content format in which the endpoint should deliver events
	ContentFormat CreateInputFormat `json:"contentFormat"`
	// Maximum time (in seconds) between endpoint checkins before considering it unavailable
	HeartbeatInterval float64 `json:"heartbeatInterval"`
	// Interval (in seconds) over which the endpoint should collect events before sending them to Stream
	BatchTimeout float64 `json:"batchTimeout"`
	// Newly subscribed endpoints will send previously existing events. Disable to receive new events only.
	ReadExistingEvents *bool `json:"readExistingEvents,omitzero"`
	// Keep track of which events have been received, resuming from that point after a re-subscription. This setting takes precedence over 'Read existing events'. See [Cribl Docs](https://docs.cribl.io/stream/sources-wef/#subscriptions) for more details.
	SendBookmarks *bool `json:"sendBookmarks,omitzero"`
	// Receive compressed events from the source
	Compress *bool `json:"compress,omitzero"`
	// The DNS names of the endpoints that should forward these events. You may use wildcards, such as *.mydomain.com
	Targets []string `json:"targets"`
	// The RFC-3066 locale the Windows clients should use when sending events. Defaults to "en-US".
	Locale        *string           `json:"locale,omitzero"`
	QuerySelector *QueryBuilderMode `json:"querySelector,omitzero"`
	// Fields to add to events ingested under this subscription
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Queries  []Query                                    `json:"queries,omitzero"`
	// The XPath query to use for selecting events
	XMLQuery *string `json:"xmlQuery,omitzero"`
}

func (s Subscription) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *Subscription) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (s *Subscription) GetSubscriptionName() string {
	if s == nil {
		return ""
	}
	return s.SubscriptionName
}

func (s *Subscription) GetVersion() *string {
	if s == nil {
		return nil
	}
	return s.Version
}

func (s *Subscription) GetContentFormat() CreateInputFormat {
	if s == nil {
		return CreateInputFormat("")
	}
	return s.ContentFormat
}

func (s *Subscription) GetHeartbeatInterval() float64 {
	if s == nil {
		return 0.0
	}
	return s.HeartbeatInterval
}

func (s *Subscription) GetBatchTimeout() float64 {
	if s == nil {
		return 0.0
	}
	return s.BatchTimeout
}

func (s *Subscription) GetReadExistingEvents() *bool {
	if s == nil {
		return nil
	}
	return s.ReadExistingEvents
}

func (s *Subscription) GetSendBookmarks() *bool {
	if s == nil {
		return nil
	}
	return s.SendBookmarks
}

func (s *Subscription) GetCompress() *bool {
	if s == nil {
		return nil
	}
	return s.Compress
}

func (s *Subscription) GetTargets() []string {
	if s == nil {
		return []string{}
	}
	return s.Targets
}

func (s *Subscription) GetLocale() *string {
	if s == nil {
		return nil
	}
	return s.Locale
}

func (s *Subscription) GetQuerySelector() *QueryBuilderMode {
	if s == nil {
		return nil
	}
	return s.QuerySelector
}

func (s *Subscription) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if s == nil {
		return nil
	}
	return s.Metadata
}

func (s *Subscription) GetQueries() []Query {
	if s == nil {
		return nil
	}
	return s.Queries
}

func (s *Subscription) GetXMLQuery() *string {
	if s == nil {
		return nil
	}
	return s.XMLQuery
}

type InputWef struct {
	// Unique ID for this input
	ID       string  `json:"id"`
	Type     TypeWef `json:"type"`
	Disabled *bool   `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// How to authenticate incoming client connections
	AuthMethod *AuthMethodAuthenticationMethod `json:"authMethod,omitzero"`
	TLS        *MTLSSettings                   `json:"tls,omitzero"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `json:"maxActiveReq,omitzero"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `json:"maxRequestsPerSocket,omitzero"`
	// Preserve the clients original IP address in the __srcIpPort field when connecting through an HTTP proxy that supports the X-Forwarded-For header. This does not apply to TCP-layer Proxy Protocol v1/v2.
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Add request headers to events in the __headers field
	CaptureHeaders *bool `json:"captureHeaders,omitzero"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitzero"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `json:"enableHealthCheck,omitzero"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `json:"ipAllowlistRegex,omitzero"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `json:"ipDenylistRegex,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// SHA1 fingerprint expected by the client, if it does not match the first certificate in the configured CA chain
	CaFingerprint *string `json:"caFingerprint,omitzero"`
	// Path to the keytab file containing the service principal credentials. @{product} will use `/etc/krb5.keytab` if not provided.
	Keytab *string `json:"keytab,omitzero"`
	// Kerberos principal used for authentication, typically in the form HTTP/<hostname>@<REALM>
	Principal *string `json:"principal,omitzero"`
	// Allow events to be ingested even if their MachineID does not match the client certificate CN
	AllowMachineIDMismatch *bool `json:"allowMachineIdMismatch,omitzero"`
	// Subscriptions to events on forwarding endpoints
	Subscriptions []Subscription `json:"subscriptions"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
	// Log a warning if the client certificate authority (CA) fingerprint does not match the expected value. A mismatch prevents Cribl from receiving events from the Windows Event Forwarder.
	LogFingerprintMismatch *bool `json:"logFingerprintMismatch,omitzero"`
}

func (i InputWef) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWef) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputWef) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputWef) GetType() TypeWef {
	if i == nil {
		return TypeWef("")
	}
	return i.Type
}

func (i *InputWef) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputWef) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputWef) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputWef) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputWef) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputWef) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputWef) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputWef) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputWef) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputWef) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputWef) GetAuthMethod() *AuthMethodAuthenticationMethod {
	if i == nil {
		return nil
	}
	return i.AuthMethod
}

func (i *InputWef) GetTLS() *MTLSSettings {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputWef) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputWef) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputWef) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputWef) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputWef) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputWef) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputWef) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputWef) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputWef) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputWef) GetCaFingerprint() *string {
	if i == nil {
		return nil
	}
	return i.CaFingerprint
}

func (i *InputWef) GetKeytab() *string {
	if i == nil {
		return nil
	}
	return i.Keytab
}

func (i *InputWef) GetPrincipal() *string {
	if i == nil {
		return nil
	}
	return i.Principal
}

func (i *InputWef) GetAllowMachineIDMismatch() *bool {
	if i == nil {
		return nil
	}
	return i.AllowMachineIDMismatch
}

func (i *InputWef) GetSubscriptions() []Subscription {
	if i == nil {
		return []Subscription{}
	}
	return i.Subscriptions
}

func (i *InputWef) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputWef) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputWef) GetLogFingerprintMismatch() *bool {
	if i == nil {
		return nil
	}
	return i.LogFingerprintMismatch
}

type TypeAppscope string

const (
	TypeAppscopeAppscope TypeAppscope = "appscope"
)

func (e TypeAppscope) ToPointer() *TypeAppscope {
	return &e
}
func (e *TypeAppscope) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "appscope":
		*e = TypeAppscope(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeAppscope: %v", v)
	}
}

type Allow struct {
	// Specify the name of a process or family of processes.
	Procname string `json:"procname"`
	// Specify a string to substring-match against process command-line.
	Arg *string `json:"arg,omitzero"`
	// Choose a config to apply to processes that match the process name and/or argument.
	Config string `json:"config"`
}

func (a Allow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *Allow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *Allow) GetProcname() string {
	if a == nil {
		return ""
	}
	return a.Procname
}

func (a *Allow) GetArg() *string {
	if a == nil {
		return nil
	}
	return a.Arg
}

func (a *Allow) GetConfig() string {
	if a == nil {
		return ""
	}
	return a.Config
}

type FilterAppscope struct {
	// Specify processes that AppScope should be loaded into, and the config to use.
	Allow []Allow `json:"allow,omitzero"`
	// To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL.
	TransportURL *string `json:"transportURL,omitzero"`
}

func (f FilterAppscope) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(f, "", false)
}

func (f *FilterAppscope) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &f, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (f *FilterAppscope) GetAllow() []Allow {
	if f == nil {
		return nil
	}
	return f.Allow
}

func (f *FilterAppscope) GetTransportURL() *string {
	if f == nil {
		return nil
	}
	return f.TransportURL
}

type PersistenceAppscope struct {
	// Spool events and metrics on disk for Cribl Edge and Search
	Enable *bool `json:"enable,omitzero"`
	// Time span for each file bucket
	TimeWindow *string `json:"timeWindow,omitzero"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `json:"maxDataSize,omitzero"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                                             `json:"maxDataTime,omitzero"`
	Compress    *components.DataCompressionFormatOptionsPersistence `json:"compress,omitzero"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/appscope
	DestPath *string `json:"destPath,omitzero"`
}

func (p PersistenceAppscope) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PersistenceAppscope) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PersistenceAppscope) GetEnable() *bool {
	if p == nil {
		return nil
	}
	return p.Enable
}

func (p *PersistenceAppscope) GetTimeWindow() *string {
	if p == nil {
		return nil
	}
	return p.TimeWindow
}

func (p *PersistenceAppscope) GetMaxDataSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataSize
}

func (p *PersistenceAppscope) GetMaxDataTime() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataTime
}

func (p *PersistenceAppscope) GetCompress() *components.DataCompressionFormatOptionsPersistence {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PersistenceAppscope) GetDestPath() *string {
	if p == nil {
		return nil
	}
	return p.DestPath
}

type InputAppscope struct {
	// Unique ID for this input
	ID       string       `json:"id"`
	Type     TypeAppscope `json:"type"`
	Disabled *bool        `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Regex matching IP addresses that are allowed to establish a connection
	IPWhitelistRegex *string `json:"ipWhitelistRegex,omitzero"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `json:"maxActiveCxn,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `json:"socketIdleTimeout,omitzero"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `json:"socketEndingMaxWait,omitzero"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `json:"socketMaxLifespan,omitzero"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitzero"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `json:"staleChannelFlushMs,omitzero"`
	// Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port.
	EnableUnixPath *bool                `json:"enableUnixPath,omitzero"`
	Filter         *FilterAppscope      `json:"filter,omitzero"`
	Persistence    *PersistenceAppscope `json:"persistence,omitzero"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitzero"`
	Description *string                                                `json:"description,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `json:"host,omitzero"`
	// Port to listen on
	Port *float64                              `json:"port,omitzero"`
	TLS  *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Path to the UNIX domain socket to listen on.
	UnixSocketPath *string `json:"unixSocketPath,omitzero"`
	// Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions.
	UnixSocketPerms *string `json:"unixSocketPerms,omitzero"`
	// Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
	AuthToken *string `json:"authToken,omitzero"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitzero"`
}

func (i InputAppscope) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAppscope) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputAppscope) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputAppscope) GetType() TypeAppscope {
	if i == nil {
		return TypeAppscope("")
	}
	return i.Type
}

func (i *InputAppscope) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputAppscope) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputAppscope) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputAppscope) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputAppscope) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputAppscope) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputAppscope) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputAppscope) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputAppscope) GetIPWhitelistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPWhitelistRegex
}

func (i *InputAppscope) GetMaxActiveCxn() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveCxn
}

func (i *InputAppscope) GetSocketIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketIdleTimeout
}

func (i *InputAppscope) GetSocketEndingMaxWait() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketEndingMaxWait
}

func (i *InputAppscope) GetSocketMaxLifespan() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketMaxLifespan
}

func (i *InputAppscope) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputAppscope) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputAppscope) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputAppscope) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputAppscope) GetEnableUnixPath() *bool {
	if i == nil {
		return nil
	}
	return i.EnableUnixPath
}

func (i *InputAppscope) GetFilter() *FilterAppscope {
	if i == nil {
		return nil
	}
	return i.Filter
}

func (i *InputAppscope) GetPersistence() *PersistenceAppscope {
	if i == nil {
		return nil
	}
	return i.Persistence
}

func (i *InputAppscope) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputAppscope) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputAppscope) GetHost() *string {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputAppscope) GetPort() *float64 {
	if i == nil {
		return nil
	}
	return i.Port
}

func (i *InputAppscope) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputAppscope) GetUnixSocketPath() *string {
	if i == nil {
		return nil
	}
	return i.UnixSocketPath
}

func (i *InputAppscope) GetUnixSocketPerms() *string {
	if i == nil {
		return nil
	}
	return i.UnixSocketPerms
}

func (i *InputAppscope) GetAuthToken() *string {
	if i == nil {
		return nil
	}
	return i.AuthToken
}

func (i *InputAppscope) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

type TypeTCP string

const (
	TypeTCPTCP TypeTCP = "tcp"
)

func (e TypeTCP) ToPointer() *TypeTCP {
	return &e
}
func (e *TypeTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "tcp":
		*e = TypeTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeTCP: %v", v)
	}
}

type InputTCP struct {
	// Unique ID for this input
	ID       string  `json:"id"`
	Type     TypeTCP `json:"type"`
	Disabled *bool   `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64                               `json:"port"`
	TLS  *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Regex matching IP addresses that are allowed to establish a connection
	IPWhitelistRegex *string `json:"ipWhitelistRegex,omitzero"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `json:"maxActiveCxn,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `json:"socketIdleTimeout,omitzero"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `json:"socketEndingMaxWait,omitzero"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `json:"socketMaxLifespan,omitzero"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitzero"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `json:"staleChannelFlushMs,omitzero"`
	// Client will pass the header record with every new connection. The header can contain an authToken, and an object with a list of fields and values to add to every event. These fields can be used to simplify Event Breaker selection, routing, etc. Header has this format, and must be followed by a newline: { "authToken" : "myToken", "fields": { "field1": "value1", "field2": "value2" } }
	EnableHeader *bool                                             `json:"enableHeader,omitzero"`
	Preprocess   *components.PreprocessTypeSavedJobCollectionInput `json:"preprocess,omitzero"`
	Description  *string                                           `json:"description,omitzero"`
	// Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
	AuthToken *string `json:"authToken,omitzero"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitzero"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitzero"`
}

func (i InputTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputTCP) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputTCP) GetType() TypeTCP {
	if i == nil {
		return TypeTCP("")
	}
	return i.Type
}

func (i *InputTCP) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputTCP) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputTCP) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputTCP) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputTCP) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputTCP) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputTCP) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputTCP) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputTCP) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputTCP) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputTCP) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputTCP) GetIPWhitelistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPWhitelistRegex
}

func (i *InputTCP) GetMaxActiveCxn() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveCxn
}

func (i *InputTCP) GetSocketIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketIdleTimeout
}

func (i *InputTCP) GetSocketEndingMaxWait() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketEndingMaxWait
}

func (i *InputTCP) GetSocketMaxLifespan() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketMaxLifespan
}

func (i *InputTCP) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputTCP) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputTCP) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputTCP) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputTCP) GetEnableHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHeader
}

func (i *InputTCP) GetPreprocess() *components.PreprocessTypeSavedJobCollectionInput {
	if i == nil {
		return nil
	}
	return i.Preprocess
}

func (i *InputTCP) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputTCP) GetAuthToken() *string {
	if i == nil {
		return nil
	}
	return i.AuthToken
}

func (i *InputTCP) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputTCP) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

type InputFileType string

const (
	InputFileTypeFile InputFileType = "file"
)

func (e InputFileType) ToPointer() *InputFileType {
	return &e
}
func (e *InputFileType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "file":
		*e = InputFileType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFileType: %v", v)
	}
}

// InputFileMode - Choose how to discover files to monitor
type InputFileMode string

const (
	// InputFileModeManual Manual
	InputFileModeManual InputFileMode = "manual"
	// InputFileModeAuto Auto
	InputFileModeAuto InputFileMode = "auto"
)

func (e InputFileMode) ToPointer() *InputFileMode {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *InputFileMode) IsExact() bool {
	if e != nil {
		switch *e {
		case "manual", "auto":
			return true
		}
	}
	return false
}

type InputFile struct {
	// Unique ID for this input
	ID       string        `json:"id"`
	Type     InputFileType `json:"type"`
	Disabled *bool         `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Choose how to discover files to monitor
	Mode *InputFileMode `json:"mode,omitzero"`
	// Time, in seconds, between scanning for files
	Interval *float64 `json:"interval,omitzero"`
	// The full path of discovered files are matched against this wildcard list
	Filenames []string `json:"filenames,omitzero"`
	// Apply filename allowlist to file entries in archive file types, like tar or zip.
	FilterArchivedFiles *bool `json:"filterArchivedFiles,omitzero"`
	// Read only new entries at the end of all files discovered at next startup. @{product} will then read newly discovered files from the head. Disable this to resume reading all files from head.
	TailOnly *bool `json:"tailOnly,omitzero"`
	// Time, in seconds, before an idle file is closed
	IdleTimeout *float64 `json:"idleTimeout,omitzero"`
	// The minimum age of files to monitor. Format examples: 30s, 15m, 1h. Age is relative to file modification time. Leave empty to apply no age filters.
	MinAgeDur *string `json:"minAgeDur,omitzero"`
	// The maximum age of event timestamps to collect. Format examples: 60s, 4h, 3d, 1w. Can be used in conjuction with "Check file modification times". Leave empty to apply no age filters.
	MaxAgeDur *string `json:"maxAgeDur,omitzero"`
	// Skip files with modification times earlier than the maximum age duration
	CheckFileModTime *bool `json:"checkFileModTime,omitzero"`
	// Forces files containing binary data to be streamed as text
	ForceText *bool `json:"forceText,omitzero"`
	// Length of file header bytes to use in hash for unique file identification
	HashLen *float64 `json:"hashLen,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitzero"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `json:"staleChannelFlushMs,omitzero"`
	Description         *string  `json:"description,omitzero"`
	// Directory path to search for files. Environment variables will be resolved, e.g. $CRIBL_HOME/log/.
	Path *string `json:"path,omitzero"`
	// Set how many subdirectories deep to search. Use 0 to search only files in the given path, 1 to also look in its immediate subdirectories, etc. Leave it empty for unlimited depth.
	Depth                     *float64 `json:"depth,omitzero"`
	SuppressMissingPathErrors *bool    `json:"suppressMissingPathErrors,omitzero"`
	// Delete files after they have been collected
	DeleteFiles *bool `json:"deleteFiles,omitzero"`
	// Salt the file hash with the Source file path. Ensures that all files with the same header hash, such as CSV files, are ingested. Moving or renaming the file, or toggling this after starting the Source will cause re-ingestion.
	SaltHash *bool `json:"saltHash,omitzero"`
	// Stream binary files as Base64-encoded chunks.
	IncludeUnidentifiableBinary *bool `json:"includeUnidentifiableBinary,omitzero"`
}

func (i InputFile) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFile) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputFile) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputFile) GetType() InputFileType {
	if i == nil {
		return InputFileType("")
	}
	return i.Type
}

func (i *InputFile) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputFile) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputFile) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputFile) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputFile) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputFile) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputFile) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputFile) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputFile) GetMode() *InputFileMode {
	if i == nil {
		return nil
	}
	return i.Mode
}

func (i *InputFile) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputFile) GetFilenames() []string {
	if i == nil {
		return nil
	}
	return i.Filenames
}

func (i *InputFile) GetFilterArchivedFiles() *bool {
	if i == nil {
		return nil
	}
	return i.FilterArchivedFiles
}

func (i *InputFile) GetTailOnly() *bool {
	if i == nil {
		return nil
	}
	return i.TailOnly
}

func (i *InputFile) GetIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.IdleTimeout
}

func (i *InputFile) GetMinAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MinAgeDur
}

func (i *InputFile) GetMaxAgeDur() *string {
	if i == nil {
		return nil
	}
	return i.MaxAgeDur
}

func (i *InputFile) GetCheckFileModTime() *bool {
	if i == nil {
		return nil
	}
	return i.CheckFileModTime
}

func (i *InputFile) GetForceText() *bool {
	if i == nil {
		return nil
	}
	return i.ForceText
}

func (i *InputFile) GetHashLen() *float64 {
	if i == nil {
		return nil
	}
	return i.HashLen
}

func (i *InputFile) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputFile) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputFile) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputFile) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputFile) GetPath() *string {
	if i == nil {
		return nil
	}
	return i.Path
}

func (i *InputFile) GetDepth() *float64 {
	if i == nil {
		return nil
	}
	return i.Depth
}

func (i *InputFile) GetSuppressMissingPathErrors() *bool {
	if i == nil {
		return nil
	}
	return i.SuppressMissingPathErrors
}

func (i *InputFile) GetDeleteFiles() *bool {
	if i == nil {
		return nil
	}
	return i.DeleteFiles
}

func (i *InputFile) GetSaltHash() *bool {
	if i == nil {
		return nil
	}
	return i.SaltHash
}

func (i *InputFile) GetIncludeUnidentifiableBinary() *bool {
	if i == nil {
		return nil
	}
	return i.IncludeUnidentifiableBinary
}

type InputSyslogType2 string

const (
	InputSyslogType2Syslog InputSyslogType2 = "syslog"
)

func (e InputSyslogType2) ToPointer() *InputSyslogType2 {
	return &e
}
func (e *InputSyslogType2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "syslog":
		*e = InputSyslogType2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogType2: %v", v)
	}
}

type InputSyslogSyslog2 struct {
	// Unique ID for this input
	ID       string           `json:"id"`
	Type     InputSyslogType2 `json:"type"`
	Disabled *bool            `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host string `json:"host"`
	// Enter UDP port number to listen on. Not required if listening on TCP.
	UDPPort *float64 `json:"udpPort,omitzero"`
	// Enter TCP port number to listen on. Not required if listening on UDP.
	TCPPort float64 `json:"tcpPort"`
	// Maximum number of events to buffer when downstream is blocking. Only applies to UDP.
	MaxBufferSize *float64 `json:"maxBufferSize,omitzero"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `json:"ipWhitelistRegex,omitzero"`
	// Timezone to assign to timestamps without timezone info
	TimestampTimezone *string `json:"timestampTimezone,omitzero"`
	// Treat UDP packet data received as full syslog message
	SingleMsgUDPPackets *bool `json:"singleMsgUdpPackets,omitzero"`
	// Enable if the connection is proxied by a device that supports Proxy Protocol V1 or V2
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Wildcard list of fields to keep from source data; * = ALL (default)
	KeepFieldsList []string `json:"keepFieldsList,omitzero"`
	// Enable if incoming messages use octet counting per RFC 6587.
	OctetCounting *bool `json:"octetCounting,omitzero"`
	// Enable if we should infer the syslog framing of the incoming messages.
	InferFraming *bool `json:"inferFraming,omitzero"`
	// Enable if we should infer octet counting only if the messages comply with RFC 5424.
	StrictlyInferOctetCounting *bool `json:"strictlyInferOctetCounting,omitzero"`
	// Enable if RFC 3164-formatted messages have hyphens in the app name portion of the TAG section. If disabled, only alphanumeric characters and underscores are allowed. Ignored for RFC 5424-formatted messages.
	AllowNonStandardAppName *bool `json:"allowNonStandardAppName,omitzero"`
	// Maximum number of active connections allowed per Worker Process for TCP connections. Use 0 for unlimited.
	MaxActiveCxn *float64 `json:"maxActiveCxn,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `json:"socketIdleTimeout,omitzero"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `json:"socketEndingMaxWait,omitzero"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64                              `json:"socketMaxLifespan,omitzero"`
	TLS               *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitzero"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool   `json:"enableLoadBalancing,omitzero"`
	Description         *string `json:"description,omitzero"`
	// When enabled, parses PROXY protocol headers during the TLS handshake. Disable if compatibility issues arise.
	EnableEnhancedProxyHeaderParsing *bool `json:"enableEnhancedProxyHeaderParsing,omitzero"`
}

func (i InputSyslogSyslog2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogSyslog2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputSyslogSyslog2) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputSyslogSyslog2) GetType() InputSyslogType2 {
	if i == nil {
		return InputSyslogType2("")
	}
	return i.Type
}

func (i *InputSyslogSyslog2) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSyslogSyslog2) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSyslogSyslog2) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputSyslogSyslog2) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputSyslogSyslog2) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputSyslogSyslog2) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputSyslogSyslog2) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputSyslogSyslog2) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputSyslogSyslog2) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputSyslogSyslog2) GetUDPPort() *float64 {
	if i == nil {
		return nil
	}
	return i.UDPPort
}

func (i *InputSyslogSyslog2) GetTCPPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.TCPPort
}

func (i *InputSyslogSyslog2) GetMaxBufferSize() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBufferSize
}

func (i *InputSyslogSyslog2) GetIPWhitelistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPWhitelistRegex
}

func (i *InputSyslogSyslog2) GetTimestampTimezone() *string {
	if i == nil {
		return nil
	}
	return i.TimestampTimezone
}

func (i *InputSyslogSyslog2) GetSingleMsgUDPPackets() *bool {
	if i == nil {
		return nil
	}
	return i.SingleMsgUDPPackets
}

func (i *InputSyslogSyslog2) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputSyslogSyslog2) GetKeepFieldsList() []string {
	if i == nil {
		return nil
	}
	return i.KeepFieldsList
}

func (i *InputSyslogSyslog2) GetOctetCounting() *bool {
	if i == nil {
		return nil
	}
	return i.OctetCounting
}

func (i *InputSyslogSyslog2) GetInferFraming() *bool {
	if i == nil {
		return nil
	}
	return i.InferFraming
}

func (i *InputSyslogSyslog2) GetStrictlyInferOctetCounting() *bool {
	if i == nil {
		return nil
	}
	return i.StrictlyInferOctetCounting
}

func (i *InputSyslogSyslog2) GetAllowNonStandardAppName() *bool {
	if i == nil {
		return nil
	}
	return i.AllowNonStandardAppName
}

func (i *InputSyslogSyslog2) GetMaxActiveCxn() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveCxn
}

func (i *InputSyslogSyslog2) GetSocketIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketIdleTimeout
}

func (i *InputSyslogSyslog2) GetSocketEndingMaxWait() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketEndingMaxWait
}

func (i *InputSyslogSyslog2) GetSocketMaxLifespan() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketMaxLifespan
}

func (i *InputSyslogSyslog2) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputSyslogSyslog2) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputSyslogSyslog2) GetUDPSocketRxBufSize() *float64 {
	if i == nil {
		return nil
	}
	return i.UDPSocketRxBufSize
}

func (i *InputSyslogSyslog2) GetEnableLoadBalancing() *bool {
	if i == nil {
		return nil
	}
	return i.EnableLoadBalancing
}

func (i *InputSyslogSyslog2) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputSyslogSyslog2) GetEnableEnhancedProxyHeaderParsing() *bool {
	if i == nil {
		return nil
	}
	return i.EnableEnhancedProxyHeaderParsing
}

type InputSyslogType1 string

const (
	InputSyslogType1Syslog InputSyslogType1 = "syslog"
)

func (e InputSyslogType1) ToPointer() *InputSyslogType1 {
	return &e
}
func (e *InputSyslogType1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "syslog":
		*e = InputSyslogType1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogType1: %v", v)
	}
}

type InputSyslogSyslog1 struct {
	// Unique ID for this input
	ID       string           `json:"id"`
	Type     InputSyslogType1 `json:"type"`
	Disabled *bool            `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host string `json:"host"`
	// Enter UDP port number to listen on. Not required if listening on TCP.
	UDPPort float64 `json:"udpPort"`
	// Enter TCP port number to listen on. Not required if listening on UDP.
	TCPPort *float64 `json:"tcpPort,omitzero"`
	// Maximum number of events to buffer when downstream is blocking. Only applies to UDP.
	MaxBufferSize *float64 `json:"maxBufferSize,omitzero"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `json:"ipWhitelistRegex,omitzero"`
	// Timezone to assign to timestamps without timezone info
	TimestampTimezone *string `json:"timestampTimezone,omitzero"`
	// Treat UDP packet data received as full syslog message
	SingleMsgUDPPackets *bool `json:"singleMsgUdpPackets,omitzero"`
	// Enable if the connection is proxied by a device that supports Proxy Protocol V1 or V2
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Wildcard list of fields to keep from source data; * = ALL (default)
	KeepFieldsList []string `json:"keepFieldsList,omitzero"`
	// Enable if incoming messages use octet counting per RFC 6587.
	OctetCounting *bool `json:"octetCounting,omitzero"`
	// Enable if we should infer the syslog framing of the incoming messages.
	InferFraming *bool `json:"inferFraming,omitzero"`
	// Enable if we should infer octet counting only if the messages comply with RFC 5424.
	StrictlyInferOctetCounting *bool `json:"strictlyInferOctetCounting,omitzero"`
	// Enable if RFC 3164-formatted messages have hyphens in the app name portion of the TAG section. If disabled, only alphanumeric characters and underscores are allowed. Ignored for RFC 5424-formatted messages.
	AllowNonStandardAppName *bool `json:"allowNonStandardAppName,omitzero"`
	// Maximum number of active connections allowed per Worker Process for TCP connections. Use 0 for unlimited.
	MaxActiveCxn *float64 `json:"maxActiveCxn,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `json:"socketIdleTimeout,omitzero"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `json:"socketEndingMaxWait,omitzero"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64                              `json:"socketMaxLifespan,omitzero"`
	TLS               *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitzero"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool   `json:"enableLoadBalancing,omitzero"`
	Description         *string `json:"description,omitzero"`
	// When enabled, parses PROXY protocol headers during the TLS handshake. Disable if compatibility issues arise.
	EnableEnhancedProxyHeaderParsing *bool `json:"enableEnhancedProxyHeaderParsing,omitzero"`
}

func (i InputSyslogSyslog1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogSyslog1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputSyslogSyslog1) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputSyslogSyslog1) GetType() InputSyslogType1 {
	if i == nil {
		return InputSyslogType1("")
	}
	return i.Type
}

func (i *InputSyslogSyslog1) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSyslogSyslog1) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSyslogSyslog1) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputSyslogSyslog1) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputSyslogSyslog1) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputSyslogSyslog1) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputSyslogSyslog1) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputSyslogSyslog1) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputSyslogSyslog1) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputSyslogSyslog1) GetUDPPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.UDPPort
}

func (i *InputSyslogSyslog1) GetTCPPort() *float64 {
	if i == nil {
		return nil
	}
	return i.TCPPort
}

func (i *InputSyslogSyslog1) GetMaxBufferSize() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBufferSize
}

func (i *InputSyslogSyslog1) GetIPWhitelistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPWhitelistRegex
}

func (i *InputSyslogSyslog1) GetTimestampTimezone() *string {
	if i == nil {
		return nil
	}
	return i.TimestampTimezone
}

func (i *InputSyslogSyslog1) GetSingleMsgUDPPackets() *bool {
	if i == nil {
		return nil
	}
	return i.SingleMsgUDPPackets
}

func (i *InputSyslogSyslog1) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputSyslogSyslog1) GetKeepFieldsList() []string {
	if i == nil {
		return nil
	}
	return i.KeepFieldsList
}

func (i *InputSyslogSyslog1) GetOctetCounting() *bool {
	if i == nil {
		return nil
	}
	return i.OctetCounting
}

func (i *InputSyslogSyslog1) GetInferFraming() *bool {
	if i == nil {
		return nil
	}
	return i.InferFraming
}

func (i *InputSyslogSyslog1) GetStrictlyInferOctetCounting() *bool {
	if i == nil {
		return nil
	}
	return i.StrictlyInferOctetCounting
}

func (i *InputSyslogSyslog1) GetAllowNonStandardAppName() *bool {
	if i == nil {
		return nil
	}
	return i.AllowNonStandardAppName
}

func (i *InputSyslogSyslog1) GetMaxActiveCxn() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveCxn
}

func (i *InputSyslogSyslog1) GetSocketIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketIdleTimeout
}

func (i *InputSyslogSyslog1) GetSocketEndingMaxWait() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketEndingMaxWait
}

func (i *InputSyslogSyslog1) GetSocketMaxLifespan() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketMaxLifespan
}

func (i *InputSyslogSyslog1) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputSyslogSyslog1) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputSyslogSyslog1) GetUDPSocketRxBufSize() *float64 {
	if i == nil {
		return nil
	}
	return i.UDPSocketRxBufSize
}

func (i *InputSyslogSyslog1) GetEnableLoadBalancing() *bool {
	if i == nil {
		return nil
	}
	return i.EnableLoadBalancing
}

func (i *InputSyslogSyslog1) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputSyslogSyslog1) GetEnableEnhancedProxyHeaderParsing() *bool {
	if i == nil {
		return nil
	}
	return i.EnableEnhancedProxyHeaderParsing
}

type InputSyslogType string

const (
	InputSyslogTypeInputSyslogSyslog1 InputSyslogType = "InputSyslog_Syslog_1"
	InputSyslogTypeInputSyslogSyslog2 InputSyslogType = "InputSyslog_Syslog_2"
)

type InputSyslog struct {
	InputSyslogSyslog1 *InputSyslogSyslog1 `queryParam:"inline" union:"member"`
	InputSyslogSyslog2 *InputSyslogSyslog2 `queryParam:"inline" union:"member"`

	Type InputSyslogType
}

func CreateInputSyslogInputSyslogSyslog1(inputSyslogSyslog1 InputSyslogSyslog1) InputSyslog {
	typ := InputSyslogTypeInputSyslogSyslog1

	return InputSyslog{
		InputSyslogSyslog1: &inputSyslogSyslog1,
		Type:               typ,
	}
}

func CreateInputSyslogInputSyslogSyslog2(inputSyslogSyslog2 InputSyslogSyslog2) InputSyslog {
	typ := InputSyslogTypeInputSyslogSyslog2

	return InputSyslog{
		InputSyslogSyslog2: &inputSyslogSyslog2,
		Type:               typ,
	}
}

func (u *InputSyslog) UnmarshalJSON(data []byte) error {

	var candidates []utils.UnionCandidate

	// Collect all valid candidates
	var inputSyslogSyslog1 InputSyslogSyslog1 = InputSyslogSyslog1{}
	if err := utils.UnmarshalJSON(data, &inputSyslogSyslog1, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  InputSyslogTypeInputSyslogSyslog1,
			Value: &inputSyslogSyslog1,
		})
	}

	var inputSyslogSyslog2 InputSyslogSyslog2 = InputSyslogSyslog2{}
	if err := utils.UnmarshalJSON(data, &inputSyslogSyslog2, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  InputSyslogTypeInputSyslogSyslog2,
			Value: &inputSyslogSyslog2,
		})
	}

	if len(candidates) == 0 {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for InputSyslog", string(data))
	}

	// Pick the best candidate using multi-stage filtering
	best := utils.PickBestUnionCandidate(candidates, data)
	if best == nil {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for InputSyslog", string(data))
	}

	// Set the union type and value based on the best candidate
	u.Type = best.Type.(InputSyslogType)
	switch best.Type {
	case InputSyslogTypeInputSyslogSyslog1:
		u.InputSyslogSyslog1 = best.Value.(*InputSyslogSyslog1)
		return nil
	case InputSyslogTypeInputSyslogSyslog2:
		u.InputSyslogSyslog2 = best.Value.(*InputSyslogSyslog2)
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for InputSyslog", string(data))
}

func (u InputSyslog) MarshalJSON() ([]byte, error) {
	if u.InputSyslogSyslog1 != nil {
		return utils.MarshalJSON(u.InputSyslogSyslog1, "", true)
	}

	if u.InputSyslogSyslog2 != nil {
		return utils.MarshalJSON(u.InputSyslogSyslog2, "", true)
	}

	return nil, errors.New("could not marshal union type InputSyslog: all fields are null")
}

type CreateInputTypeSqs string

const (
	CreateInputTypeSqsSqs CreateInputTypeSqs = "sqs"
)

func (e CreateInputTypeSqs) ToPointer() *CreateInputTypeSqs {
	return &e
}
func (e *CreateInputTypeSqs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sqs":
		*e = CreateInputTypeSqs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeSqs: %v", v)
	}
}

// CreateInputQueueType - The queue type used (or created)
type CreateInputQueueType string

const (
	// CreateInputQueueTypeStandard Standard
	CreateInputQueueTypeStandard CreateInputQueueType = "standard"
	// CreateInputQueueTypeFifo FIFO
	CreateInputQueueTypeFifo CreateInputQueueType = "fifo"
)

func (e CreateInputQueueType) ToPointer() *CreateInputQueueType {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateInputQueueType) IsExact() bool {
	if e != nil {
		switch *e {
		case "standard", "fifo":
			return true
		}
	}
	return false
}

type InputSqs struct {
	// Unique ID for this input
	ID       string             `json:"id"`
	Type     CreateInputTypeSqs `json:"type"`
	Disabled *bool              `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// The name, URL, or ARN of the SQS queue to read events from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can only be evaluated at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// The queue type used (or created)
	QueueType CreateInputQueueType `json:"queueType"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitzero"`
	// Create queue if it does not exist
	CreateQueue *bool `json:"createQueue,omitzero"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitzero"`
	AwsSecretKey            *string                                                `json:"awsSecretKey,omitzero"`
	// AWS Region where the SQS queue is located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitzero"`
	// SQS service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to SQS-compatible endpoint.
	Endpoint *string `json:"endpoint,omitzero"`
	// Signature version to use for signing SQS requests
	SignatureVersion *components.SignatureVersionOptions3 `json:"signatureVersion,omitzero"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitzero"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitzero"`
	// Use Assume Role credentials to access SQS
	EnableAssumeRole *bool `json:"enableAssumeRole,omitzero"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitzero"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitzero"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitzero"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `json:"maxMessages,omitzero"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `json:"visibilityTimeout,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `json:"pollTimeout,omitzero"`
	Description *string  `json:"description,omitzero"`
	AwsAPIKey   *string  `json:"awsApiKey,omitzero"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitzero"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `json:"numReceivers,omitzero"`
}

func (i InputSqs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSqs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputSqs) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputSqs) GetType() CreateInputTypeSqs {
	if i == nil {
		return CreateInputTypeSqs("")
	}
	return i.Type
}

func (i *InputSqs) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSqs) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSqs) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputSqs) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputSqs) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputSqs) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputSqs) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputSqs) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputSqs) GetQueueName() string {
	if i == nil {
		return ""
	}
	return i.QueueName
}

func (i *InputSqs) GetQueueType() CreateInputQueueType {
	if i == nil {
		return CreateInputQueueType("")
	}
	return i.QueueType
}

func (i *InputSqs) GetAwsAccountID() *string {
	if i == nil {
		return nil
	}
	return i.AwsAccountID
}

func (i *InputSqs) GetCreateQueue() *bool {
	if i == nil {
		return nil
	}
	return i.CreateQueue
}

func (i *InputSqs) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if i == nil {
		return nil
	}
	return i.AwsAuthenticationMethod
}

func (i *InputSqs) GetAwsSecretKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecretKey
}

func (i *InputSqs) GetRegion() *string {
	if i == nil {
		return nil
	}
	return i.Region
}

func (i *InputSqs) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputSqs) GetSignatureVersion() *components.SignatureVersionOptions3 {
	if i == nil {
		return nil
	}
	return i.SignatureVersion
}

func (i *InputSqs) GetReuseConnections() *bool {
	if i == nil {
		return nil
	}
	return i.ReuseConnections
}

func (i *InputSqs) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputSqs) GetEnableAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableAssumeRole
}

func (i *InputSqs) GetAssumeRoleArn() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleArn
}

func (i *InputSqs) GetAssumeRoleExternalID() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleExternalID
}

func (i *InputSqs) GetDurationSeconds() *float64 {
	if i == nil {
		return nil
	}
	return i.DurationSeconds
}

func (i *InputSqs) GetMaxMessages() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMessages
}

func (i *InputSqs) GetVisibilityTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.VisibilityTimeout
}

func (i *InputSqs) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputSqs) GetPollTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.PollTimeout
}

func (i *InputSqs) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputSqs) GetAwsAPIKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsAPIKey
}

func (i *InputSqs) GetAwsSecret() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecret
}

func (i *InputSqs) GetNumReceivers() *float64 {
	if i == nil {
		return nil
	}
	return i.NumReceivers
}

type TypeModelDrivenTelemetry string

const (
	TypeModelDrivenTelemetryModelDrivenTelemetry TypeModelDrivenTelemetry = "model_driven_telemetry"
)

func (e TypeModelDrivenTelemetry) ToPointer() *TypeModelDrivenTelemetry {
	return &e
}
func (e *TypeModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "model_driven_telemetry":
		*e = TypeModelDrivenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeModelDrivenTelemetry: %v", v)
	}
}

type InputModelDrivenTelemetry struct {
	// Unique ID for this input
	ID       string                   `json:"id"`
	Type     TypeModelDrivenTelemetry `json:"type"`
	Disabled *bool                    `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64                               `json:"port"`
	TLS  *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `json:"maxActiveCxn,omitzero"`
	// Time in milliseconds to allow the server to shutdown gracefully before forcing shutdown. Defaults to 5000.
	ShutdownTimeoutMs *float64 `json:"shutdownTimeoutMs,omitzero"`
	Description       *string  `json:"description,omitzero"`
}

func (i InputModelDrivenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputModelDrivenTelemetry) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputModelDrivenTelemetry) GetType() TypeModelDrivenTelemetry {
	if i == nil {
		return TypeModelDrivenTelemetry("")
	}
	return i.Type
}

func (i *InputModelDrivenTelemetry) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputModelDrivenTelemetry) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputModelDrivenTelemetry) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputModelDrivenTelemetry) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputModelDrivenTelemetry) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputModelDrivenTelemetry) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputModelDrivenTelemetry) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputModelDrivenTelemetry) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputModelDrivenTelemetry) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputModelDrivenTelemetry) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputModelDrivenTelemetry) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputModelDrivenTelemetry) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputModelDrivenTelemetry) GetMaxActiveCxn() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveCxn
}

func (i *InputModelDrivenTelemetry) GetShutdownTimeoutMs() *float64 {
	if i == nil {
		return nil
	}
	return i.ShutdownTimeoutMs
}

func (i *InputModelDrivenTelemetry) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type CreateInputTypeOpenTelemetry string

const (
	CreateInputTypeOpenTelemetryOpenTelemetry CreateInputTypeOpenTelemetry = "open_telemetry"
)

func (e CreateInputTypeOpenTelemetry) ToPointer() *CreateInputTypeOpenTelemetry {
	return &e
}
func (e *CreateInputTypeOpenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "open_telemetry":
		*e = CreateInputTypeOpenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeOpenTelemetry: %v", v)
	}
}

// CreateInputProtocol - Select whether to leverage gRPC or HTTP for OpenTelemetry
type CreateInputProtocol string

const (
	// CreateInputProtocolGrpc gRPC
	CreateInputProtocolGrpc CreateInputProtocol = "grpc"
	// CreateInputProtocolHTTP HTTP
	CreateInputProtocolHTTP CreateInputProtocol = "http"
)

func (e CreateInputProtocol) ToPointer() *CreateInputProtocol {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateInputProtocol) IsExact() bool {
	if e != nil {
		switch *e {
		case "grpc", "http":
			return true
		}
	}
	return false
}

// CreateInputOTLPVersion - The version of OTLP Protobuf definitions to use when interpreting received data
type CreateInputOTLPVersion string

const (
	// CreateInputOTLPVersionZeroDot10Dot0 0.10.0
	CreateInputOTLPVersionZeroDot10Dot0 CreateInputOTLPVersion = "0.10.0"
	// CreateInputOTLPVersionOneDot3Dot1 1.3.1
	CreateInputOTLPVersionOneDot3Dot1 CreateInputOTLPVersion = "1.3.1"
)

func (e CreateInputOTLPVersion) ToPointer() *CreateInputOTLPVersion {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateInputOTLPVersion) IsExact() bool {
	if e != nil {
		switch *e {
		case "0.10.0", "1.3.1":
			return true
		}
	}
	return false
}

type InputOpenTelemetry struct {
	// Unique ID for this input
	ID       string                       `json:"id"`
	Type     CreateInputTypeOpenTelemetry `json:"type"`
	Disabled *bool                        `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64                               `json:"port"`
	TLS  *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `json:"maxActiveReq,omitzero"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket  *int64 `json:"maxRequestsPerSocket,omitzero"`
	EnableProxyHeader     any    `json:"enableProxyHeader,omitzero"`
	CaptureHeaders        any    `json:"captureHeaders,omitzero"`
	ActivityLogSampleRate any    `json:"activityLogSampleRate,omitzero"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitzero"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `json:"enableHealthCheck,omitzero"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist.
	IPAllowlistRegex *string `json:"ipAllowlistRegex,omitzero"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `json:"ipDenylistRegex,omitzero"`
	// Select whether to leverage gRPC or HTTP for OpenTelemetry
	Protocol *CreateInputProtocol `json:"protocol,omitzero"`
	// Enable to extract each incoming span to a separate event
	ExtractSpans *bool `json:"extractSpans,omitzero"`
	// Enable to extract each incoming Gauge or IntGauge metric to multiple events, one per data point
	ExtractMetrics *bool `json:"extractMetrics,omitzero"`
	// The version of OTLP Protobuf definitions to use when interpreting received data
	OtlpVersion *CreateInputOTLPVersion `json:"otlpVersion,omitzero"`
	// OpenTelemetry authentication type
	AuthType *components.AuthenticationTypeOptions `json:"authType,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `json:"maxActiveCxn,omitzero"`
	Description  *string  `json:"description,omitzero"`
	Username     *string  `json:"username,omitzero"`
	Password     *string  `json:"password,omitzero"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitzero"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitzero"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitzero"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitzero"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitzero"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitzero"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitzero"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `json:"authHeaderExpr,omitzero"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `json:"tokenTimeoutSecs,omitzero"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []components.ItemsTypeOauthParams `json:"oauthParams,omitzero"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []components.ItemsTypeOauthHeaders `json:"oauthHeaders,omitzero"`
	// Enable to extract each incoming log record to a separate event
	ExtractLogs *bool `json:"extractLogs,omitzero"`
}

func (i InputOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputOpenTelemetry) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputOpenTelemetry) GetType() CreateInputTypeOpenTelemetry {
	if i == nil {
		return CreateInputTypeOpenTelemetry("")
	}
	return i.Type
}

func (i *InputOpenTelemetry) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputOpenTelemetry) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputOpenTelemetry) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputOpenTelemetry) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputOpenTelemetry) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputOpenTelemetry) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputOpenTelemetry) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputOpenTelemetry) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputOpenTelemetry) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputOpenTelemetry) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputOpenTelemetry) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputOpenTelemetry) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputOpenTelemetry) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputOpenTelemetry) GetEnableProxyHeader() any {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputOpenTelemetry) GetCaptureHeaders() any {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputOpenTelemetry) GetActivityLogSampleRate() any {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputOpenTelemetry) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputOpenTelemetry) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputOpenTelemetry) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputOpenTelemetry) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputOpenTelemetry) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputOpenTelemetry) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputOpenTelemetry) GetProtocol() *CreateInputProtocol {
	if i == nil {
		return nil
	}
	return i.Protocol
}

func (i *InputOpenTelemetry) GetExtractSpans() *bool {
	if i == nil {
		return nil
	}
	return i.ExtractSpans
}

func (i *InputOpenTelemetry) GetExtractMetrics() *bool {
	if i == nil {
		return nil
	}
	return i.ExtractMetrics
}

func (i *InputOpenTelemetry) GetOtlpVersion() *CreateInputOTLPVersion {
	if i == nil {
		return nil
	}
	return i.OtlpVersion
}

func (i *InputOpenTelemetry) GetAuthType() *components.AuthenticationTypeOptions {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputOpenTelemetry) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputOpenTelemetry) GetMaxActiveCxn() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveCxn
}

func (i *InputOpenTelemetry) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputOpenTelemetry) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputOpenTelemetry) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputOpenTelemetry) GetToken() *string {
	if i == nil {
		return nil
	}
	return i.Token
}

func (i *InputOpenTelemetry) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputOpenTelemetry) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputOpenTelemetry) GetLoginURL() *string {
	if i == nil {
		return nil
	}
	return i.LoginURL
}

func (i *InputOpenTelemetry) GetSecretParamName() *string {
	if i == nil {
		return nil
	}
	return i.SecretParamName
}

func (i *InputOpenTelemetry) GetSecret() *string {
	if i == nil {
		return nil
	}
	return i.Secret
}

func (i *InputOpenTelemetry) GetTokenAttributeName() *string {
	if i == nil {
		return nil
	}
	return i.TokenAttributeName
}

func (i *InputOpenTelemetry) GetAuthHeaderExpr() *string {
	if i == nil {
		return nil
	}
	return i.AuthHeaderExpr
}

func (i *InputOpenTelemetry) GetTokenTimeoutSecs() *float64 {
	if i == nil {
		return nil
	}
	return i.TokenTimeoutSecs
}

func (i *InputOpenTelemetry) GetOauthParams() []components.ItemsTypeOauthParams {
	if i == nil {
		return nil
	}
	return i.OauthParams
}

func (i *InputOpenTelemetry) GetOauthHeaders() []components.ItemsTypeOauthHeaders {
	if i == nil {
		return nil
	}
	return i.OauthHeaders
}

func (i *InputOpenTelemetry) GetExtractLogs() *bool {
	if i == nil {
		return nil
	}
	return i.ExtractLogs
}

type CreateInputTypeSnmp string

const (
	CreateInputTypeSnmpSnmp CreateInputTypeSnmp = "snmp"
)

func (e CreateInputTypeSnmp) ToPointer() *CreateInputTypeSnmp {
	return &e
}
func (e *CreateInputTypeSnmp) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "snmp":
		*e = CreateInputTypeSnmp(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeSnmp: %v", v)
	}
}

type PrivacyProtocol string

const (
	// PrivacyProtocolNone None
	PrivacyProtocolNone PrivacyProtocol = "none"
	// PrivacyProtocolDes DES
	PrivacyProtocolDes PrivacyProtocol = "des"
	// PrivacyProtocolAes AES128
	PrivacyProtocolAes PrivacyProtocol = "aes"
	// PrivacyProtocolAes256b AES256b (Blumenthal)
	PrivacyProtocolAes256b PrivacyProtocol = "aes256b"
	// PrivacyProtocolAes256r AES256r (Reeder)
	PrivacyProtocolAes256r PrivacyProtocol = "aes256r"
)

func (e PrivacyProtocol) ToPointer() *PrivacyProtocol {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *PrivacyProtocol) IsExact() bool {
	if e != nil {
		switch *e {
		case "none", "des", "aes", "aes256b", "aes256r":
			return true
		}
	}
	return false
}

type V3User struct {
	Name         string                                          `json:"name"`
	AuthProtocol *components.AuthenticationProtocolOptionsV3User `json:"authProtocol,omitzero"`
	AuthKey      *string                                         `json:"authKey,omitzero"`
	PrivProtocol *PrivacyProtocol                                `json:"privProtocol,omitzero"`
	PrivKey      *string                                         `json:"privKey,omitzero"`
}

func (v V3User) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(v, "", false)
}

func (v *V3User) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &v, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (v *V3User) GetName() string {
	if v == nil {
		return ""
	}
	return v.Name
}

func (v *V3User) GetAuthProtocol() *components.AuthenticationProtocolOptionsV3User {
	if v == nil {
		return nil
	}
	return v.AuthProtocol
}

func (v *V3User) GetAuthKey() *string {
	if v == nil {
		return nil
	}
	return v.AuthKey
}

func (v *V3User) GetPrivProtocol() *PrivacyProtocol {
	if v == nil {
		return nil
	}
	return v.PrivProtocol
}

func (v *V3User) GetPrivKey() *string {
	if v == nil {
		return nil
	}
	return v.PrivKey
}

// SNMPv3Authentication - Authentication parameters for SNMPv3 trap. Set the log level to debug if you are experiencing authentication or decryption issues.
type SNMPv3Authentication struct {
	V3AuthEnabled bool `json:"v3AuthEnabled"`
	// Pass through traps that don't match any of the configured users. @{product} will not attempt to decrypt these traps.
	AllowUnmatchedTrap *bool `json:"allowUnmatchedTrap,omitzero"`
	// User credentials for receiving v3 traps
	V3Users []V3User `json:"v3Users,omitzero"`
}

func (s SNMPv3Authentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SNMPv3Authentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (s *SNMPv3Authentication) GetV3AuthEnabled() bool {
	if s == nil {
		return false
	}
	return s.V3AuthEnabled
}

func (s *SNMPv3Authentication) GetAllowUnmatchedTrap() *bool {
	if s == nil {
		return nil
	}
	return s.AllowUnmatchedTrap
}

func (s *SNMPv3Authentication) GetV3Users() []V3User {
	if s == nil {
		return nil
	}
	return s.V3Users
}

type InputSnmp struct {
	// Unique ID for this input
	ID       string              `json:"id"`
	Type     CreateInputTypeSnmp `json:"type"`
	Disabled *bool               `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host string `json:"host"`
	// UDP port to receive SNMP traps on. Defaults to 162.
	Port float64 `json:"port"`
	// Authentication parameters for SNMPv3 trap. Set the log level to debug if you are experiencing authentication or decryption issues.
	SnmpV3Auth *SNMPv3Authentication `json:"snmpV3Auth,omitzero"`
	// Maximum number of events to buffer when downstream is blocking.
	MaxBufferSize *float64 `json:"maxBufferSize,omitzero"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `json:"ipWhitelistRegex,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitzero"`
	// If enabled, parses varbinds as an array of objects that include OID, value, and type
	VarbindsWithTypes *bool `json:"varbindsWithTypes,omitzero"`
	// If enabled, the parser will attempt to parse varbind octet strings as UTF-8, first, otherwise will fallback to other methods
	BestEffortParsing *bool   `json:"bestEffortParsing,omitzero"`
	Description       *string `json:"description,omitzero"`
}

func (i InputSnmp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSnmp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputSnmp) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputSnmp) GetType() CreateInputTypeSnmp {
	if i == nil {
		return CreateInputTypeSnmp("")
	}
	return i.Type
}

func (i *InputSnmp) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSnmp) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSnmp) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputSnmp) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputSnmp) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputSnmp) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputSnmp) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputSnmp) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputSnmp) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputSnmp) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputSnmp) GetSnmpV3Auth() *SNMPv3Authentication {
	if i == nil {
		return nil
	}
	return i.SnmpV3Auth
}

func (i *InputSnmp) GetMaxBufferSize() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBufferSize
}

func (i *InputSnmp) GetIPWhitelistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPWhitelistRegex
}

func (i *InputSnmp) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputSnmp) GetUDPSocketRxBufSize() *float64 {
	if i == nil {
		return nil
	}
	return i.UDPSocketRxBufSize
}

func (i *InputSnmp) GetVarbindsWithTypes() *bool {
	if i == nil {
		return nil
	}
	return i.VarbindsWithTypes
}

func (i *InputSnmp) GetBestEffortParsing() *bool {
	if i == nil {
		return nil
	}
	return i.BestEffortParsing
}

func (i *InputSnmp) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type TypeS3Inventory string

const (
	TypeS3InventoryS3Inventory TypeS3Inventory = "s3_inventory"
)

func (e TypeS3Inventory) ToPointer() *TypeS3Inventory {
	return &e
}
func (e *TypeS3Inventory) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "s3_inventory":
		*e = TypeS3Inventory(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeS3Inventory: %v", v)
	}
}

type InputS3Inventory struct {
	// Unique ID for this input
	ID       string          `json:"id"`
	Type     TypeS3Inventory `json:"type"`
	Disabled *bool           `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `json:"fileFilter,omitzero"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitzero"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitzero"`
	AwsSecretKey            *string                                                `json:"awsSecretKey,omitzero"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitzero"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitzero"`
	// Signature version to use for signing S3 requests
	SignatureVersion *components.SignatureVersionOptionsS3CollectorConf `json:"signatureVersion,omitzero"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitzero"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitzero"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitzero"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `json:"staleChannelFlushMs,omitzero"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `json:"maxMessages,omitzero"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `json:"visibilityTimeout,omitzero"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `json:"numReceivers,omitzero"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `json:"skipOnError,omitzero"`
	// Attach SQS notification metadata to a __sqsMetadata field on each event
	IncludeSqsMetadata *bool `json:"includeSqsMetadata,omitzero"`
	// Use Assume Role credentials to access Amazon S3
	EnableAssumeRole *bool `json:"enableAssumeRole,omitzero"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitzero"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitzero"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitzero"`
	// Use Assume Role credentials when accessing Amazon SQS
	EnableSQSAssumeRole *bool                                             `json:"enableSQSAssumeRole,omitzero"`
	Preprocess          *components.PreprocessTypeSavedJobCollectionInput `json:"preprocess,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `json:"parquetChunkSizeMB,omitzero"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64                      `json:"parquetChunkDownloadTimeout,omitzero"`
	Checkpointing               *components.CheckpointingType `json:"checkpointing,omitzero"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `json:"pollTimeout,omitzero"`
	// Filename suffix of the manifest checksum file. If a filename matching this suffix is received        in the queue, the matching manifest file will be downloaded and validated against its value. Defaults to "checksum"
	ChecksumSuffix *string `json:"checksumSuffix,omitzero"`
	// Maximum download size (KB) of each manifest or checksum file. Manifest files larger than this size will not be read.        Defaults to 4096.
	MaxManifestSizeKB *int64 `json:"maxManifestSizeKB,omitzero"`
	// If set to Yes, each inventory file in the manifest will be validated against its checksum. Defaults to false
	ValidateInventoryFiles *bool   `json:"validateInventoryFiles,omitzero"`
	Description            *string `json:"description,omitzero"`
	AwsAPIKey              *string `json:"awsApiKey,omitzero"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret          *string                               `json:"awsSecret,omitzero"`
	TagAfterProcessing *components.TagAfterProcessingOptions `json:"tagAfterProcessing,omitzero"`
	// The key for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagKey *string `json:"processedTagKey,omitzero"`
	// The value for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagValue *string `json:"processedTagValue,omitzero"`
}

func (i InputS3Inventory) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputS3Inventory) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputS3Inventory) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputS3Inventory) GetType() TypeS3Inventory {
	if i == nil {
		return TypeS3Inventory("")
	}
	return i.Type
}

func (i *InputS3Inventory) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputS3Inventory) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputS3Inventory) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputS3Inventory) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputS3Inventory) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputS3Inventory) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputS3Inventory) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputS3Inventory) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputS3Inventory) GetQueueName() string {
	if i == nil {
		return ""
	}
	return i.QueueName
}

func (i *InputS3Inventory) GetFileFilter() *string {
	if i == nil {
		return nil
	}
	return i.FileFilter
}

func (i *InputS3Inventory) GetAwsAccountID() *string {
	if i == nil {
		return nil
	}
	return i.AwsAccountID
}

func (i *InputS3Inventory) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if i == nil {
		return nil
	}
	return i.AwsAuthenticationMethod
}

func (i *InputS3Inventory) GetAwsSecretKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecretKey
}

func (i *InputS3Inventory) GetRegion() *string {
	if i == nil {
		return nil
	}
	return i.Region
}

func (i *InputS3Inventory) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputS3Inventory) GetSignatureVersion() *components.SignatureVersionOptionsS3CollectorConf {
	if i == nil {
		return nil
	}
	return i.SignatureVersion
}

func (i *InputS3Inventory) GetReuseConnections() *bool {
	if i == nil {
		return nil
	}
	return i.ReuseConnections
}

func (i *InputS3Inventory) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputS3Inventory) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputS3Inventory) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputS3Inventory) GetMaxMessages() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMessages
}

func (i *InputS3Inventory) GetVisibilityTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.VisibilityTimeout
}

func (i *InputS3Inventory) GetNumReceivers() *float64 {
	if i == nil {
		return nil
	}
	return i.NumReceivers
}

func (i *InputS3Inventory) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputS3Inventory) GetSkipOnError() *bool {
	if i == nil {
		return nil
	}
	return i.SkipOnError
}

func (i *InputS3Inventory) GetIncludeSqsMetadata() *bool {
	if i == nil {
		return nil
	}
	return i.IncludeSqsMetadata
}

func (i *InputS3Inventory) GetEnableAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableAssumeRole
}

func (i *InputS3Inventory) GetAssumeRoleArn() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleArn
}

func (i *InputS3Inventory) GetAssumeRoleExternalID() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleExternalID
}

func (i *InputS3Inventory) GetDurationSeconds() *float64 {
	if i == nil {
		return nil
	}
	return i.DurationSeconds
}

func (i *InputS3Inventory) GetEnableSQSAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableSQSAssumeRole
}

func (i *InputS3Inventory) GetPreprocess() *components.PreprocessTypeSavedJobCollectionInput {
	if i == nil {
		return nil
	}
	return i.Preprocess
}

func (i *InputS3Inventory) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputS3Inventory) GetParquetChunkSizeMB() *float64 {
	if i == nil {
		return nil
	}
	return i.ParquetChunkSizeMB
}

func (i *InputS3Inventory) GetParquetChunkDownloadTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.ParquetChunkDownloadTimeout
}

func (i *InputS3Inventory) GetCheckpointing() *components.CheckpointingType {
	if i == nil {
		return nil
	}
	return i.Checkpointing
}

func (i *InputS3Inventory) GetPollTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.PollTimeout
}

func (i *InputS3Inventory) GetChecksumSuffix() *string {
	if i == nil {
		return nil
	}
	return i.ChecksumSuffix
}

func (i *InputS3Inventory) GetMaxManifestSizeKB() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxManifestSizeKB
}

func (i *InputS3Inventory) GetValidateInventoryFiles() *bool {
	if i == nil {
		return nil
	}
	return i.ValidateInventoryFiles
}

func (i *InputS3Inventory) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputS3Inventory) GetAwsAPIKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsAPIKey
}

func (i *InputS3Inventory) GetAwsSecret() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecret
}

func (i *InputS3Inventory) GetTagAfterProcessing() *components.TagAfterProcessingOptions {
	if i == nil {
		return nil
	}
	return i.TagAfterProcessing
}

func (i *InputS3Inventory) GetProcessedTagKey() *string {
	if i == nil {
		return nil
	}
	return i.ProcessedTagKey
}

func (i *InputS3Inventory) GetProcessedTagValue() *string {
	if i == nil {
		return nil
	}
	return i.ProcessedTagValue
}

type CreateInputTypeS3 string

const (
	CreateInputTypeS3S3 CreateInputTypeS3 = "s3"
)

func (e CreateInputTypeS3) ToPointer() *CreateInputTypeS3 {
	return &e
}
func (e *CreateInputTypeS3) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "s3":
		*e = CreateInputTypeS3(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeS3: %v", v)
	}
}

type InputS3 struct {
	// Unique ID for this input
	ID       string            `json:"id"`
	Type     CreateInputTypeS3 `json:"type"`
	Disabled *bool             `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `json:"fileFilter,omitzero"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitzero"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitzero"`
	AwsSecretKey            *string                                                `json:"awsSecretKey,omitzero"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitzero"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitzero"`
	// Signature version to use for signing S3 requests
	SignatureVersion *components.SignatureVersionOptionsS3CollectorConf `json:"signatureVersion,omitzero"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitzero"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitzero"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitzero"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `json:"staleChannelFlushMs,omitzero"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `json:"maxMessages,omitzero"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `json:"visibilityTimeout,omitzero"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `json:"numReceivers,omitzero"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `json:"skipOnError,omitzero"`
	// Attach SQS notification metadata to a __sqsMetadata field on each event
	IncludeSqsMetadata *bool `json:"includeSqsMetadata,omitzero"`
	// Use Assume Role credentials to access Amazon S3
	EnableAssumeRole *bool `json:"enableAssumeRole,omitzero"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitzero"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitzero"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitzero"`
	// Use Assume Role credentials when accessing Amazon SQS
	EnableSQSAssumeRole *bool                                             `json:"enableSQSAssumeRole,omitzero"`
	Preprocess          *components.PreprocessTypeSavedJobCollectionInput `json:"preprocess,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `json:"parquetChunkSizeMB,omitzero"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64                      `json:"parquetChunkDownloadTimeout,omitzero"`
	Checkpointing               *components.CheckpointingType `json:"checkpointing,omitzero"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `json:"pollTimeout,omitzero"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding *string `json:"encoding,omitzero"`
	// Add a tag to processed S3 objects. Requires s3:GetObjectTagging and s3:PutObjectTagging AWS permissions.
	TagAfterProcessing *bool   `json:"tagAfterProcessing,omitzero"`
	Description        *string `json:"description,omitzero"`
	AwsAPIKey          *string `json:"awsApiKey,omitzero"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitzero"`
	// The key for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagKey *string `json:"processedTagKey,omitzero"`
	// The value for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagValue *string `json:"processedTagValue,omitzero"`
}

func (i InputS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputS3) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputS3) GetType() CreateInputTypeS3 {
	if i == nil {
		return CreateInputTypeS3("")
	}
	return i.Type
}

func (i *InputS3) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputS3) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputS3) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputS3) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputS3) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputS3) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputS3) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputS3) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputS3) GetQueueName() string {
	if i == nil {
		return ""
	}
	return i.QueueName
}

func (i *InputS3) GetFileFilter() *string {
	if i == nil {
		return nil
	}
	return i.FileFilter
}

func (i *InputS3) GetAwsAccountID() *string {
	if i == nil {
		return nil
	}
	return i.AwsAccountID
}

func (i *InputS3) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if i == nil {
		return nil
	}
	return i.AwsAuthenticationMethod
}

func (i *InputS3) GetAwsSecretKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecretKey
}

func (i *InputS3) GetRegion() *string {
	if i == nil {
		return nil
	}
	return i.Region
}

func (i *InputS3) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputS3) GetSignatureVersion() *components.SignatureVersionOptionsS3CollectorConf {
	if i == nil {
		return nil
	}
	return i.SignatureVersion
}

func (i *InputS3) GetReuseConnections() *bool {
	if i == nil {
		return nil
	}
	return i.ReuseConnections
}

func (i *InputS3) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputS3) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputS3) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputS3) GetMaxMessages() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMessages
}

func (i *InputS3) GetVisibilityTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.VisibilityTimeout
}

func (i *InputS3) GetNumReceivers() *float64 {
	if i == nil {
		return nil
	}
	return i.NumReceivers
}

func (i *InputS3) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputS3) GetSkipOnError() *bool {
	if i == nil {
		return nil
	}
	return i.SkipOnError
}

func (i *InputS3) GetIncludeSqsMetadata() *bool {
	if i == nil {
		return nil
	}
	return i.IncludeSqsMetadata
}

func (i *InputS3) GetEnableAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableAssumeRole
}

func (i *InputS3) GetAssumeRoleArn() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleArn
}

func (i *InputS3) GetAssumeRoleExternalID() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleExternalID
}

func (i *InputS3) GetDurationSeconds() *float64 {
	if i == nil {
		return nil
	}
	return i.DurationSeconds
}

func (i *InputS3) GetEnableSQSAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableSQSAssumeRole
}

func (i *InputS3) GetPreprocess() *components.PreprocessTypeSavedJobCollectionInput {
	if i == nil {
		return nil
	}
	return i.Preprocess
}

func (i *InputS3) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputS3) GetParquetChunkSizeMB() *float64 {
	if i == nil {
		return nil
	}
	return i.ParquetChunkSizeMB
}

func (i *InputS3) GetParquetChunkDownloadTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.ParquetChunkDownloadTimeout
}

func (i *InputS3) GetCheckpointing() *components.CheckpointingType {
	if i == nil {
		return nil
	}
	return i.Checkpointing
}

func (i *InputS3) GetPollTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.PollTimeout
}

func (i *InputS3) GetEncoding() *string {
	if i == nil {
		return nil
	}
	return i.Encoding
}

func (i *InputS3) GetTagAfterProcessing() *bool {
	if i == nil {
		return nil
	}
	return i.TagAfterProcessing
}

func (i *InputS3) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputS3) GetAwsAPIKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsAPIKey
}

func (i *InputS3) GetAwsSecret() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecret
}

func (i *InputS3) GetProcessedTagKey() *string {
	if i == nil {
		return nil
	}
	return i.ProcessedTagKey
}

func (i *InputS3) GetProcessedTagValue() *string {
	if i == nil {
		return nil
	}
	return i.ProcessedTagValue
}

type TypeMetrics string

const (
	TypeMetricsMetrics TypeMetrics = "metrics"
)

func (e TypeMetrics) ToPointer() *TypeMetrics {
	return &e
}
func (e *TypeMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "metrics":
		*e = TypeMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeMetrics: %v", v)
	}
}

type InputMetrics struct {
	// Unique ID for this input
	ID       string      `json:"id"`
	Type     TypeMetrics `json:"type"`
	Disabled *bool       `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host string `json:"host"`
	// Enter UDP port number to listen on. Not required if listening on TCP.
	UDPPort *float64 `json:"udpPort,omitzero"`
	// Enter TCP port number to listen on. Not required if listening on UDP.
	TCPPort *float64 `json:"tcpPort,omitzero"`
	// Maximum number of events to buffer when downstream is blocking. Only applies to UDP.
	MaxBufferSize *float64 `json:"maxBufferSize,omitzero"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `json:"ipWhitelistRegex,omitzero"`
	// Enable if the connection is proxied by a device that supports Proxy Protocol V1 or V2
	EnableProxyHeader *bool                                 `json:"enableProxyHeader,omitzero"`
	TLS               *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitzero"`
	Description        *string  `json:"description,omitzero"`
}

func (i InputMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputMetrics) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputMetrics) GetType() TypeMetrics {
	if i == nil {
		return TypeMetrics("")
	}
	return i.Type
}

func (i *InputMetrics) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputMetrics) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputMetrics) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputMetrics) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputMetrics) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputMetrics) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputMetrics) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputMetrics) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputMetrics) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputMetrics) GetUDPPort() *float64 {
	if i == nil {
		return nil
	}
	return i.UDPPort
}

func (i *InputMetrics) GetTCPPort() *float64 {
	if i == nil {
		return nil
	}
	return i.TCPPort
}

func (i *InputMetrics) GetMaxBufferSize() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBufferSize
}

func (i *InputMetrics) GetIPWhitelistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPWhitelistRegex
}

func (i *InputMetrics) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputMetrics) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputMetrics) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputMetrics) GetUDPSocketRxBufSize() *float64 {
	if i == nil {
		return nil
	}
	return i.UDPSocketRxBufSize
}

func (i *InputMetrics) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type TypeCriblmetrics string

const (
	TypeCriblmetricsCriblmetrics TypeCriblmetrics = "criblmetrics"
)

func (e TypeCriblmetrics) ToPointer() *TypeCriblmetrics {
	return &e
}
func (e *TypeCriblmetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "criblmetrics":
		*e = TypeCriblmetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCriblmetrics: %v", v)
	}
}

type InputCriblmetrics struct {
	// Unique ID for this input
	ID       string           `json:"id"`
	Type     TypeCriblmetrics `json:"type"`
	Disabled *bool            `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// A prefix that is applied to the metrics provided by Cribl Stream
	Prefix *string `json:"prefix,omitzero"`
	// Include granular metrics. Disabling this will drop the following metrics events: `cribl.logstream.host.(in_bytes,in_events,out_bytes,out_events)`, `cribl.logstream.index.(in_bytes,in_events,out_bytes,out_events)`, `cribl.logstream.source.(in_bytes,in_events,out_bytes,out_events)`, `cribl.logstream.sourcetype.(in_bytes,in_events,out_bytes,out_events)`.
	FullFidelity *bool `json:"fullFidelity,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
}

func (i InputCriblmetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblmetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputCriblmetrics) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputCriblmetrics) GetType() TypeCriblmetrics {
	if i == nil {
		return TypeCriblmetrics("")
	}
	return i.Type
}

func (i *InputCriblmetrics) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputCriblmetrics) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputCriblmetrics) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputCriblmetrics) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputCriblmetrics) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputCriblmetrics) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputCriblmetrics) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputCriblmetrics) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputCriblmetrics) GetPrefix() *string {
	if i == nil {
		return nil
	}
	return i.Prefix
}

func (i *InputCriblmetrics) GetFullFidelity() *bool {
	if i == nil {
		return nil
	}
	return i.FullFidelity
}

func (i *InputCriblmetrics) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputCriblmetrics) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type CreateInputTypeKinesis string

const (
	CreateInputTypeKinesisKinesis CreateInputTypeKinesis = "kinesis"
)

func (e CreateInputTypeKinesis) ToPointer() *CreateInputTypeKinesis {
	return &e
}
func (e *CreateInputTypeKinesis) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kinesis":
		*e = CreateInputTypeKinesis(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeKinesis: %v", v)
	}
}

// ShardIteratorStart - Location at which to start reading a shard for the first time
type ShardIteratorStart string

const (
	// ShardIteratorStartTrimHorizon Earliest record
	ShardIteratorStartTrimHorizon ShardIteratorStart = "TRIM_HORIZON"
	// ShardIteratorStartLatest Latest record
	ShardIteratorStartLatest ShardIteratorStart = "LATEST"
)

func (e ShardIteratorStart) ToPointer() *ShardIteratorStart {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *ShardIteratorStart) IsExact() bool {
	if e != nil {
		switch *e {
		case "TRIM_HORIZON", "LATEST":
			return true
		}
	}
	return false
}

// RecordDataFormat - Format of data inside the Kinesis Stream records. Gzip compression is automatically detected.
type RecordDataFormat string

const (
	// RecordDataFormatCribl Cribl
	RecordDataFormatCribl RecordDataFormat = "cribl"
	// RecordDataFormatNdjson Newline JSON
	RecordDataFormatNdjson RecordDataFormat = "ndjson"
	// RecordDataFormatCloudwatch Cloudwatch Logs
	RecordDataFormatCloudwatch RecordDataFormat = "cloudwatch"
	// RecordDataFormatLine Event per line
	RecordDataFormatLine RecordDataFormat = "line"
)

func (e RecordDataFormat) ToPointer() *RecordDataFormat {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *RecordDataFormat) IsExact() bool {
	if e != nil {
		switch *e {
		case "cribl", "ndjson", "cloudwatch", "line":
			return true
		}
	}
	return false
}

// ShardLoadBalancing - The load-balancing algorithm to use for spreading out shards across Workers and Worker Processes
type ShardLoadBalancing string

const (
	// ShardLoadBalancingConsistentHashing Consistent Hashing
	ShardLoadBalancingConsistentHashing ShardLoadBalancing = "ConsistentHashing"
	// ShardLoadBalancingRoundRobin Round Robin
	ShardLoadBalancingRoundRobin ShardLoadBalancing = "RoundRobin"
)

func (e ShardLoadBalancing) ToPointer() *ShardLoadBalancing {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *ShardLoadBalancing) IsExact() bool {
	if e != nil {
		switch *e {
		case "ConsistentHashing", "RoundRobin":
			return true
		}
	}
	return false
}

type InputKinesis struct {
	// Unique ID for this input
	ID       string                 `json:"id"`
	Type     CreateInputTypeKinesis `json:"type"`
	Disabled *bool                  `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Kinesis Data Stream to read data from
	StreamName string `json:"streamName"`
	// Time interval in minutes between consecutive service calls
	ServiceInterval *float64 `json:"serviceInterval,omitzero"`
	// A JavaScript expression to be called with each shardId for the stream. If the expression evaluates to a truthy value, the shard will be processed.
	ShardExpr *string `json:"shardExpr,omitzero"`
	// Location at which to start reading a shard for the first time
	ShardIteratorType *ShardIteratorStart `json:"shardIteratorType,omitzero"`
	// Format of data inside the Kinesis Stream records. Gzip compression is automatically detected.
	PayloadFormat *RecordDataFormat `json:"payloadFormat,omitzero"`
	// Maximum number of records per getRecords call
	GetRecordsLimit *float64 `json:"getRecordsLimit,omitzero"`
	// Maximum number of records, across all shards, to pull down at once per Worker Process
	GetRecordsLimitTotal *float64 `json:"getRecordsLimitTotal,omitzero"`
	// The load-balancing algorithm to use for spreading out shards across Workers and Worker Processes
	LoadBalancingAlgorithm *ShardLoadBalancing `json:"loadBalancingAlgorithm,omitzero"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitzero"`
	AwsSecretKey            *string                                                `json:"awsSecretKey,omitzero"`
	// Region where the Kinesis stream is located
	Region string `json:"region"`
	// Kinesis stream service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to Kinesis stream-compatible endpoint.
	Endpoint *string `json:"endpoint,omitzero"`
	// Signature version to use for signing Kinesis stream requests
	SignatureVersion *components.SignatureVersionOptions2 `json:"signatureVersion,omitzero"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitzero"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitzero"`
	// Use Assume Role credentials to access Kinesis stream
	EnableAssumeRole *bool `json:"enableAssumeRole,omitzero"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitzero"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitzero"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitzero"`
	// Verify Kinesis Producer Library (KPL) event checksums
	VerifyKPLCheckSums *bool `json:"verifyKPLCheckSums,omitzero"`
	// When resuming streaming from a stored state, Stream will read the next available record, rather than rereading the last-read record. Enabling this setting can cause data loss after a Worker Node's unexpected shutdown or restart.
	AvoidDuplicates *bool `json:"avoidDuplicates,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
	AwsAPIKey   *string                                    `json:"awsApiKey,omitzero"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitzero"`
}

func (i InputKinesis) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKinesis) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputKinesis) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputKinesis) GetType() CreateInputTypeKinesis {
	if i == nil {
		return CreateInputTypeKinesis("")
	}
	return i.Type
}

func (i *InputKinesis) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKinesis) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputKinesis) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputKinesis) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputKinesis) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputKinesis) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputKinesis) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputKinesis) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputKinesis) GetStreamName() string {
	if i == nil {
		return ""
	}
	return i.StreamName
}

func (i *InputKinesis) GetServiceInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.ServiceInterval
}

func (i *InputKinesis) GetShardExpr() *string {
	if i == nil {
		return nil
	}
	return i.ShardExpr
}

func (i *InputKinesis) GetShardIteratorType() *ShardIteratorStart {
	if i == nil {
		return nil
	}
	return i.ShardIteratorType
}

func (i *InputKinesis) GetPayloadFormat() *RecordDataFormat {
	if i == nil {
		return nil
	}
	return i.PayloadFormat
}

func (i *InputKinesis) GetGetRecordsLimit() *float64 {
	if i == nil {
		return nil
	}
	return i.GetRecordsLimit
}

func (i *InputKinesis) GetGetRecordsLimitTotal() *float64 {
	if i == nil {
		return nil
	}
	return i.GetRecordsLimitTotal
}

func (i *InputKinesis) GetLoadBalancingAlgorithm() *ShardLoadBalancing {
	if i == nil {
		return nil
	}
	return i.LoadBalancingAlgorithm
}

func (i *InputKinesis) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if i == nil {
		return nil
	}
	return i.AwsAuthenticationMethod
}

func (i *InputKinesis) GetAwsSecretKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecretKey
}

func (i *InputKinesis) GetRegion() string {
	if i == nil {
		return ""
	}
	return i.Region
}

func (i *InputKinesis) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputKinesis) GetSignatureVersion() *components.SignatureVersionOptions2 {
	if i == nil {
		return nil
	}
	return i.SignatureVersion
}

func (i *InputKinesis) GetReuseConnections() *bool {
	if i == nil {
		return nil
	}
	return i.ReuseConnections
}

func (i *InputKinesis) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputKinesis) GetEnableAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableAssumeRole
}

func (i *InputKinesis) GetAssumeRoleArn() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleArn
}

func (i *InputKinesis) GetAssumeRoleExternalID() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleExternalID
}

func (i *InputKinesis) GetDurationSeconds() *float64 {
	if i == nil {
		return nil
	}
	return i.DurationSeconds
}

func (i *InputKinesis) GetVerifyKPLCheckSums() *bool {
	if i == nil {
		return nil
	}
	return i.VerifyKPLCheckSums
}

func (i *InputKinesis) GetAvoidDuplicates() *bool {
	if i == nil {
		return nil
	}
	return i.AvoidDuplicates
}

func (i *InputKinesis) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputKinesis) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputKinesis) GetAwsAPIKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsAPIKey
}

func (i *InputKinesis) GetAwsSecret() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecret
}

type TypeHTTPRaw string

const (
	TypeHTTPRawHTTPRaw TypeHTTPRaw = "http_raw"
)

func (e TypeHTTPRaw) ToPointer() *TypeHTTPRaw {
	return &e
}
func (e *TypeHTTPRaw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http_raw":
		*e = TypeHTTPRaw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeHTTPRaw: %v", v)
	}
}

type InputHTTPRaw struct {
	// Unique ID for this input
	ID       string      `json:"id"`
	Type     TypeHTTPRaw `json:"type"`
	Disabled *bool       `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                              `json:"authTokens,omitzero"`
	TLS        *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `json:"maxActiveReq,omitzero"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `json:"maxRequestsPerSocket,omitzero"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `json:"captureHeaders,omitzero"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `json:"activityLogSampleRate,omitzero"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitzero"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `json:"enableHealthCheck,omitzero"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `json:"ipAllowlistRegex,omitzero"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `json:"ipDenylistRegex,omitzero"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitzero"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `json:"staleChannelFlushMs,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// List of URI paths accepted by this input, wildcards are supported, e.g /api/v*/hook. Defaults to allow all.
	AllowedPaths []string `json:"allowedPaths,omitzero"`
	// List of HTTP methods accepted by this input. Wildcards are supported (such as P*, GET). Defaults to allow all.
	AllowedMethods []string `json:"allowedMethods,omitzero"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokensExt []components.ItemsTypeAuthTokensExt `json:"authTokensExt,omitzero"`
	Description   *string                             `json:"description,omitzero"`
}

func (i InputHTTPRaw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputHTTPRaw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputHTTPRaw) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputHTTPRaw) GetType() TypeHTTPRaw {
	if i == nil {
		return TypeHTTPRaw("")
	}
	return i.Type
}

func (i *InputHTTPRaw) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputHTTPRaw) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputHTTPRaw) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputHTTPRaw) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputHTTPRaw) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputHTTPRaw) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputHTTPRaw) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputHTTPRaw) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputHTTPRaw) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputHTTPRaw) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputHTTPRaw) GetAuthTokens() []string {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputHTTPRaw) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputHTTPRaw) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputHTTPRaw) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputHTTPRaw) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputHTTPRaw) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputHTTPRaw) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputHTTPRaw) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputHTTPRaw) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputHTTPRaw) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputHTTPRaw) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputHTTPRaw) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputHTTPRaw) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputHTTPRaw) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputHTTPRaw) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputHTTPRaw) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputHTTPRaw) GetAllowedPaths() []string {
	if i == nil {
		return nil
	}
	return i.AllowedPaths
}

func (i *InputHTTPRaw) GetAllowedMethods() []string {
	if i == nil {
		return nil
	}
	return i.AllowedMethods
}

func (i *InputHTTPRaw) GetAuthTokensExt() []components.ItemsTypeAuthTokensExt {
	if i == nil {
		return nil
	}
	return i.AuthTokensExt
}

func (i *InputHTTPRaw) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type TypeDatagen string

const (
	TypeDatagenDatagen TypeDatagen = "datagen"
)

func (e TypeDatagen) ToPointer() *TypeDatagen {
	return &e
}
func (e *TypeDatagen) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "datagen":
		*e = TypeDatagen(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeDatagen: %v", v)
	}
}

type Sample struct {
	Sample string `json:"sample"`
	// Maximum number of events to generate per second per Worker Node. Defaults to 10.
	EventsPerSec float64 `json:"eventsPerSec"`
}

func (s Sample) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *Sample) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (s *Sample) GetSample() string {
	if s == nil {
		return ""
	}
	return s.Sample
}

func (s *Sample) GetEventsPerSec() float64 {
	if s == nil {
		return 0.0
	}
	return s.EventsPerSec
}

type InputDatagen struct {
	// Unique ID for this input
	ID       string      `json:"id"`
	Type     TypeDatagen `json:"type"`
	Disabled *bool       `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	Samples     []Sample                                  `json:"samples"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
}

func (i InputDatagen) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputDatagen) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputDatagen) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputDatagen) GetType() TypeDatagen {
	if i == nil {
		return TypeDatagen("")
	}
	return i.Type
}

func (i *InputDatagen) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputDatagen) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputDatagen) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputDatagen) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputDatagen) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputDatagen) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputDatagen) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputDatagen) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputDatagen) GetSamples() []Sample {
	if i == nil {
		return []Sample{}
	}
	return i.Samples
}

func (i *InputDatagen) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputDatagen) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type TypeDatadogAgent string

const (
	TypeDatadogAgentDatadogAgent TypeDatadogAgent = "datadog_agent"
)

func (e TypeDatadogAgent) ToPointer() *TypeDatadogAgent {
	return &e
}
func (e *TypeDatadogAgent) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "datadog_agent":
		*e = TypeDatadogAgent(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeDatadogAgent: %v", v)
	}
}

type ProxyModeDatadogAgent struct {
	// Toggle to Yes to send key validation requests from Datadog Agent to the Datadog API. If toggled to No (the default), Stream handles key validation requests by always responding that the key is valid.
	Enabled bool `json:"enabled"`
	// Whether to reject certificates that cannot be verified against a valid CA (e.g., self-signed certificates).
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitzero"`
}

func (p ProxyModeDatadogAgent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *ProxyModeDatadogAgent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *ProxyModeDatadogAgent) GetEnabled() bool {
	if p == nil {
		return false
	}
	return p.Enabled
}

func (p *ProxyModeDatadogAgent) GetRejectUnauthorized() *bool {
	if p == nil {
		return nil
	}
	return p.RejectUnauthorized
}

type InputDatadogAgent struct {
	// Unique ID for this input
	ID       string           `json:"id"`
	Type     TypeDatadogAgent `json:"type"`
	Disabled *bool            `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64                               `json:"port"`
	TLS  *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `json:"maxActiveReq,omitzero"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `json:"maxRequestsPerSocket,omitzero"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `json:"captureHeaders,omitzero"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `json:"activityLogSampleRate,omitzero"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitzero"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `json:"enableHealthCheck,omitzero"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `json:"ipAllowlistRegex,omitzero"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `json:"ipDenylistRegex,omitzero"`
	// Toggle to Yes to extract each incoming metric to multiple events, one per data point. This works well when sending metrics to a statsd-type output. If sending metrics to DatadogHQ or any destination that accepts arbitrary JSON, leave toggled to No (the default).
	ExtractMetrics *bool `json:"extractMetrics,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	ProxyMode   *ProxyModeDatadogAgent                     `json:"proxyMode,omitzero"`
	Description *string                                    `json:"description,omitzero"`
}

func (i InputDatadogAgent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputDatadogAgent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputDatadogAgent) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputDatadogAgent) GetType() TypeDatadogAgent {
	if i == nil {
		return TypeDatadogAgent("")
	}
	return i.Type
}

func (i *InputDatadogAgent) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputDatadogAgent) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputDatadogAgent) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputDatadogAgent) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputDatadogAgent) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputDatadogAgent) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputDatadogAgent) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputDatadogAgent) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputDatadogAgent) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputDatadogAgent) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputDatadogAgent) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputDatadogAgent) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputDatadogAgent) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputDatadogAgent) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputDatadogAgent) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputDatadogAgent) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputDatadogAgent) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputDatadogAgent) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputDatadogAgent) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputDatadogAgent) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputDatadogAgent) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputDatadogAgent) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputDatadogAgent) GetExtractMetrics() *bool {
	if i == nil {
		return nil
	}
	return i.ExtractMetrics
}

func (i *InputDatadogAgent) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputDatadogAgent) GetProxyMode() *ProxyModeDatadogAgent {
	if i == nil {
		return nil
	}
	return i.ProxyMode
}

func (i *InputDatadogAgent) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type TypeCrowdstrike string

const (
	TypeCrowdstrikeCrowdstrike TypeCrowdstrike = "crowdstrike"
)

func (e TypeCrowdstrike) ToPointer() *TypeCrowdstrike {
	return &e
}
func (e *TypeCrowdstrike) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "crowdstrike":
		*e = TypeCrowdstrike(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCrowdstrike: %v", v)
	}
}

type InputCrowdstrike struct {
	// Unique ID for this input
	ID       string          `json:"id"`
	Type     TypeCrowdstrike `json:"type"`
	Disabled *bool           `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `json:"fileFilter,omitzero"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitzero"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitzero"`
	AwsSecretKey            *string                                                `json:"awsSecretKey,omitzero"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitzero"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitzero"`
	// Signature version to use for signing S3 requests
	SignatureVersion *components.SignatureVersionOptionsS3CollectorConf `json:"signatureVersion,omitzero"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitzero"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitzero"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitzero"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `json:"staleChannelFlushMs,omitzero"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `json:"maxMessages,omitzero"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `json:"visibilityTimeout,omitzero"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `json:"numReceivers,omitzero"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `json:"skipOnError,omitzero"`
	// Attach SQS notification metadata to a __sqsMetadata field on each event
	IncludeSqsMetadata *bool `json:"includeSqsMetadata,omitzero"`
	// Use Assume Role credentials to access Amazon S3
	EnableAssumeRole *bool `json:"enableAssumeRole,omitzero"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitzero"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitzero"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitzero"`
	// Use Assume Role credentials when accessing Amazon SQS
	EnableSQSAssumeRole *bool                                             `json:"enableSQSAssumeRole,omitzero"`
	Preprocess          *components.PreprocessTypeSavedJobCollectionInput `json:"preprocess,omitzero"`
	// Fields to add to events from this input
	Metadata      []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Checkpointing *components.CheckpointingType              `json:"checkpointing,omitzero"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `json:"pollTimeout,omitzero"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding    *string `json:"encoding,omitzero"`
	Description *string `json:"description,omitzero"`
	AwsAPIKey   *string `json:"awsApiKey,omitzero"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret          *string                               `json:"awsSecret,omitzero"`
	TagAfterProcessing *components.TagAfterProcessingOptions `json:"tagAfterProcessing,omitzero"`
	// The key for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagKey *string `json:"processedTagKey,omitzero"`
	// The value for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagValue *string `json:"processedTagValue,omitzero"`
}

func (i InputCrowdstrike) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCrowdstrike) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputCrowdstrike) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputCrowdstrike) GetType() TypeCrowdstrike {
	if i == nil {
		return TypeCrowdstrike("")
	}
	return i.Type
}

func (i *InputCrowdstrike) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputCrowdstrike) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputCrowdstrike) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputCrowdstrike) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputCrowdstrike) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputCrowdstrike) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputCrowdstrike) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputCrowdstrike) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputCrowdstrike) GetQueueName() string {
	if i == nil {
		return ""
	}
	return i.QueueName
}

func (i *InputCrowdstrike) GetFileFilter() *string {
	if i == nil {
		return nil
	}
	return i.FileFilter
}

func (i *InputCrowdstrike) GetAwsAccountID() *string {
	if i == nil {
		return nil
	}
	return i.AwsAccountID
}

func (i *InputCrowdstrike) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if i == nil {
		return nil
	}
	return i.AwsAuthenticationMethod
}

func (i *InputCrowdstrike) GetAwsSecretKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecretKey
}

func (i *InputCrowdstrike) GetRegion() *string {
	if i == nil {
		return nil
	}
	return i.Region
}

func (i *InputCrowdstrike) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputCrowdstrike) GetSignatureVersion() *components.SignatureVersionOptionsS3CollectorConf {
	if i == nil {
		return nil
	}
	return i.SignatureVersion
}

func (i *InputCrowdstrike) GetReuseConnections() *bool {
	if i == nil {
		return nil
	}
	return i.ReuseConnections
}

func (i *InputCrowdstrike) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputCrowdstrike) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputCrowdstrike) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputCrowdstrike) GetMaxMessages() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMessages
}

func (i *InputCrowdstrike) GetVisibilityTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.VisibilityTimeout
}

func (i *InputCrowdstrike) GetNumReceivers() *float64 {
	if i == nil {
		return nil
	}
	return i.NumReceivers
}

func (i *InputCrowdstrike) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputCrowdstrike) GetSkipOnError() *bool {
	if i == nil {
		return nil
	}
	return i.SkipOnError
}

func (i *InputCrowdstrike) GetIncludeSqsMetadata() *bool {
	if i == nil {
		return nil
	}
	return i.IncludeSqsMetadata
}

func (i *InputCrowdstrike) GetEnableAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableAssumeRole
}

func (i *InputCrowdstrike) GetAssumeRoleArn() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleArn
}

func (i *InputCrowdstrike) GetAssumeRoleExternalID() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleExternalID
}

func (i *InputCrowdstrike) GetDurationSeconds() *float64 {
	if i == nil {
		return nil
	}
	return i.DurationSeconds
}

func (i *InputCrowdstrike) GetEnableSQSAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableSQSAssumeRole
}

func (i *InputCrowdstrike) GetPreprocess() *components.PreprocessTypeSavedJobCollectionInput {
	if i == nil {
		return nil
	}
	return i.Preprocess
}

func (i *InputCrowdstrike) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputCrowdstrike) GetCheckpointing() *components.CheckpointingType {
	if i == nil {
		return nil
	}
	return i.Checkpointing
}

func (i *InputCrowdstrike) GetPollTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.PollTimeout
}

func (i *InputCrowdstrike) GetEncoding() *string {
	if i == nil {
		return nil
	}
	return i.Encoding
}

func (i *InputCrowdstrike) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputCrowdstrike) GetAwsAPIKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsAPIKey
}

func (i *InputCrowdstrike) GetAwsSecret() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecret
}

func (i *InputCrowdstrike) GetTagAfterProcessing() *components.TagAfterProcessingOptions {
	if i == nil {
		return nil
	}
	return i.TagAfterProcessing
}

func (i *InputCrowdstrike) GetProcessedTagKey() *string {
	if i == nil {
		return nil
	}
	return i.ProcessedTagKey
}

func (i *InputCrowdstrike) GetProcessedTagValue() *string {
	if i == nil {
		return nil
	}
	return i.ProcessedTagValue
}

type TypeWindowsMetrics string

const (
	TypeWindowsMetricsWindowsMetrics TypeWindowsMetrics = "windows_metrics"
)

func (e TypeWindowsMetrics) ToPointer() *TypeWindowsMetrics {
	return &e
}
func (e *TypeWindowsMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "windows_metrics":
		*e = TypeWindowsMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeWindowsMetrics: %v", v)
	}
}

// SystemModeWindowsMetrics - Select the level of details for system metrics
type SystemModeWindowsMetrics string

const (
	// SystemModeWindowsMetricsBasic Basic
	SystemModeWindowsMetricsBasic SystemModeWindowsMetrics = "basic"
	// SystemModeWindowsMetricsAll All
	SystemModeWindowsMetricsAll SystemModeWindowsMetrics = "all"
	// SystemModeWindowsMetricsCustom Custom
	SystemModeWindowsMetricsCustom SystemModeWindowsMetrics = "custom"
	// SystemModeWindowsMetricsDisabled Disabled
	SystemModeWindowsMetricsDisabled SystemModeWindowsMetrics = "disabled"
)

func (e SystemModeWindowsMetrics) ToPointer() *SystemModeWindowsMetrics {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *SystemModeWindowsMetrics) IsExact() bool {
	if e != nil {
		switch *e {
		case "basic", "all", "custom", "disabled":
			return true
		}
	}
	return false
}

type SystemWindowsMetrics struct {
	// Select the level of details for system metrics
	Mode *SystemModeWindowsMetrics `json:"mode,omitzero"`
	// Generate metrics for all system information
	Detail *bool `json:"detail,omitzero"`
}

func (s SystemWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SystemWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (s *SystemWindowsMetrics) GetMode() *SystemModeWindowsMetrics {
	if s == nil {
		return nil
	}
	return s.Mode
}

func (s *SystemWindowsMetrics) GetDetail() *bool {
	if s == nil {
		return nil
	}
	return s.Detail
}

// CPUModeWindowsMetrics - Select the level of details for CPU metrics
type CPUModeWindowsMetrics string

const (
	// CPUModeWindowsMetricsBasic Basic
	CPUModeWindowsMetricsBasic CPUModeWindowsMetrics = "basic"
	// CPUModeWindowsMetricsAll All
	CPUModeWindowsMetricsAll CPUModeWindowsMetrics = "all"
	// CPUModeWindowsMetricsCustom Custom
	CPUModeWindowsMetricsCustom CPUModeWindowsMetrics = "custom"
	// CPUModeWindowsMetricsDisabled Disabled
	CPUModeWindowsMetricsDisabled CPUModeWindowsMetrics = "disabled"
)

func (e CPUModeWindowsMetrics) ToPointer() *CPUModeWindowsMetrics {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CPUModeWindowsMetrics) IsExact() bool {
	if e != nil {
		switch *e {
		case "basic", "all", "custom", "disabled":
			return true
		}
	}
	return false
}

type CPUWindowsMetrics struct {
	// Select the level of details for CPU metrics
	Mode *CPUModeWindowsMetrics `json:"mode,omitzero"`
	// Generate metrics for each CPU
	PerCPU *bool `json:"perCpu,omitzero"`
	// Generate metrics for all CPU states
	Detail *bool `json:"detail,omitzero"`
	// Generate raw, monotonic CPU time counters
	Time *bool `json:"time,omitzero"`
}

func (c CPUWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CPUWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *CPUWindowsMetrics) GetMode() *CPUModeWindowsMetrics {
	if c == nil {
		return nil
	}
	return c.Mode
}

func (c *CPUWindowsMetrics) GetPerCPU() *bool {
	if c == nil {
		return nil
	}
	return c.PerCPU
}

func (c *CPUWindowsMetrics) GetDetail() *bool {
	if c == nil {
		return nil
	}
	return c.Detail
}

func (c *CPUWindowsMetrics) GetTime() *bool {
	if c == nil {
		return nil
	}
	return c.Time
}

// MemoryModeWindowsMetrics - Select the level of details for memory metrics
type MemoryModeWindowsMetrics string

const (
	// MemoryModeWindowsMetricsBasic Basic
	MemoryModeWindowsMetricsBasic MemoryModeWindowsMetrics = "basic"
	// MemoryModeWindowsMetricsAll All
	MemoryModeWindowsMetricsAll MemoryModeWindowsMetrics = "all"
	// MemoryModeWindowsMetricsCustom Custom
	MemoryModeWindowsMetricsCustom MemoryModeWindowsMetrics = "custom"
	// MemoryModeWindowsMetricsDisabled Disabled
	MemoryModeWindowsMetricsDisabled MemoryModeWindowsMetrics = "disabled"
)

func (e MemoryModeWindowsMetrics) ToPointer() *MemoryModeWindowsMetrics {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *MemoryModeWindowsMetrics) IsExact() bool {
	if e != nil {
		switch *e {
		case "basic", "all", "custom", "disabled":
			return true
		}
	}
	return false
}

type MemoryWindowsMetrics struct {
	// Select the level of details for memory metrics
	Mode *MemoryModeWindowsMetrics `json:"mode,omitzero"`
	// Generate metrics for all memory states
	Detail *bool `json:"detail,omitzero"`
}

func (m MemoryWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MemoryWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (m *MemoryWindowsMetrics) GetMode() *MemoryModeWindowsMetrics {
	if m == nil {
		return nil
	}
	return m.Mode
}

func (m *MemoryWindowsMetrics) GetDetail() *bool {
	if m == nil {
		return nil
	}
	return m.Detail
}

// NetworkModeWindowsMetrics - Select the level of details for network metrics
type NetworkModeWindowsMetrics string

const (
	// NetworkModeWindowsMetricsBasic Basic
	NetworkModeWindowsMetricsBasic NetworkModeWindowsMetrics = "basic"
	// NetworkModeWindowsMetricsAll All
	NetworkModeWindowsMetricsAll NetworkModeWindowsMetrics = "all"
	// NetworkModeWindowsMetricsCustom Custom
	NetworkModeWindowsMetricsCustom NetworkModeWindowsMetrics = "custom"
	// NetworkModeWindowsMetricsDisabled Disabled
	NetworkModeWindowsMetricsDisabled NetworkModeWindowsMetrics = "disabled"
)

func (e NetworkModeWindowsMetrics) ToPointer() *NetworkModeWindowsMetrics {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *NetworkModeWindowsMetrics) IsExact() bool {
	if e != nil {
		switch *e {
		case "basic", "all", "custom", "disabled":
			return true
		}
	}
	return false
}

type NetworkWindowsMetrics struct {
	// Select the level of details for network metrics
	Mode *NetworkModeWindowsMetrics `json:"mode,omitzero"`
	// Generate full network metrics
	Detail *bool `json:"detail,omitzero"`
	// Generate protocol metrics for ICMP, ICMPMsg, IP, TCP, UDP and UDPLite
	Protocols *bool `json:"protocols,omitzero"`
	// Network interfaces to include/exclude. All interfaces are included if this list is empty.
	Devices []string `json:"devices,omitzero"`
	// Generate separate metrics for each interface
	PerInterface *bool `json:"perInterface,omitzero"`
}

func (n NetworkWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(n, "", false)
}

func (n *NetworkWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &n, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (n *NetworkWindowsMetrics) GetMode() *NetworkModeWindowsMetrics {
	if n == nil {
		return nil
	}
	return n.Mode
}

func (n *NetworkWindowsMetrics) GetDetail() *bool {
	if n == nil {
		return nil
	}
	return n.Detail
}

func (n *NetworkWindowsMetrics) GetProtocols() *bool {
	if n == nil {
		return nil
	}
	return n.Protocols
}

func (n *NetworkWindowsMetrics) GetDevices() []string {
	if n == nil {
		return nil
	}
	return n.Devices
}

func (n *NetworkWindowsMetrics) GetPerInterface() *bool {
	if n == nil {
		return nil
	}
	return n.PerInterface
}

// DiskModeWindowsMetrics - Select the level of details for disk metrics
type DiskModeWindowsMetrics string

const (
	// DiskModeWindowsMetricsBasic Basic
	DiskModeWindowsMetricsBasic DiskModeWindowsMetrics = "basic"
	// DiskModeWindowsMetricsAll All
	DiskModeWindowsMetricsAll DiskModeWindowsMetrics = "all"
	// DiskModeWindowsMetricsCustom Custom
	DiskModeWindowsMetricsCustom DiskModeWindowsMetrics = "custom"
	// DiskModeWindowsMetricsDisabled Disabled
	DiskModeWindowsMetricsDisabled DiskModeWindowsMetrics = "disabled"
)

func (e DiskModeWindowsMetrics) ToPointer() *DiskModeWindowsMetrics {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *DiskModeWindowsMetrics) IsExact() bool {
	if e != nil {
		switch *e {
		case "basic", "all", "custom", "disabled":
			return true
		}
	}
	return false
}

type DiskWindowsMetrics struct {
	// Select the level of details for disk metrics
	Mode *DiskModeWindowsMetrics `json:"mode,omitzero"`
	// Generate separate metrics for each volume
	PerVolume *bool `json:"perVolume,omitzero"`
	// Generate full disk metrics
	Detail *bool `json:"detail,omitzero"`
	// Windows volumes to include/exclude. E.g.: C:, !E:, etc. Wildcards and ! (not) operators are supported. All volumes are included if this list is empty.
	Volumes []string `json:"volumes,omitzero"`
}

func (d DiskWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DiskWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DiskWindowsMetrics) GetMode() *DiskModeWindowsMetrics {
	if d == nil {
		return nil
	}
	return d.Mode
}

func (d *DiskWindowsMetrics) GetPerVolume() *bool {
	if d == nil {
		return nil
	}
	return d.PerVolume
}

func (d *DiskWindowsMetrics) GetDetail() *bool {
	if d == nil {
		return nil
	}
	return d.Detail
}

func (d *DiskWindowsMetrics) GetVolumes() []string {
	if d == nil {
		return nil
	}
	return d.Volumes
}

type CustomWindowsMetrics struct {
	System  *SystemWindowsMetrics  `json:"system,omitzero"`
	CPU     *CPUWindowsMetrics     `json:"cpu,omitzero"`
	Memory  *MemoryWindowsMetrics  `json:"memory,omitzero"`
	Network *NetworkWindowsMetrics `json:"network,omitzero"`
	Disk    *DiskWindowsMetrics    `json:"disk,omitzero"`
}

func (c CustomWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CustomWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *CustomWindowsMetrics) GetSystem() *SystemWindowsMetrics {
	if c == nil {
		return nil
	}
	return c.System
}

func (c *CustomWindowsMetrics) GetCPU() *CPUWindowsMetrics {
	if c == nil {
		return nil
	}
	return c.CPU
}

func (c *CustomWindowsMetrics) GetMemory() *MemoryWindowsMetrics {
	if c == nil {
		return nil
	}
	return c.Memory
}

func (c *CustomWindowsMetrics) GetNetwork() *NetworkWindowsMetrics {
	if c == nil {
		return nil
	}
	return c.Network
}

func (c *CustomWindowsMetrics) GetDisk() *DiskWindowsMetrics {
	if c == nil {
		return nil
	}
	return c.Disk
}

type HostWindowsMetrics struct {
	// Select level of detail for host metrics
	Mode   *components.ModeOptionsHost `json:"mode,omitzero"`
	Custom *CustomWindowsMetrics       `json:"custom,omitzero"`
}

func (h HostWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *HostWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (h *HostWindowsMetrics) GetMode() *components.ModeOptionsHost {
	if h == nil {
		return nil
	}
	return h.Mode
}

func (h *HostWindowsMetrics) GetCustom() *CustomWindowsMetrics {
	if h == nil {
		return nil
	}
	return h.Custom
}

type PersistenceWindowsMetrics struct {
	// Spool metrics to disk for Cribl Edge and Search
	Enable *bool `json:"enable,omitzero"`
	// Time span for each file bucket
	TimeWindow *string `json:"timeWindow,omitzero"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `json:"maxDataSize,omitzero"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                                             `json:"maxDataTime,omitzero"`
	Compress    *components.DataCompressionFormatOptionsPersistence `json:"compress,omitzero"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/windows_metrics
	DestPath *string `json:"destPath,omitzero"`
}

func (p PersistenceWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PersistenceWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PersistenceWindowsMetrics) GetEnable() *bool {
	if p == nil {
		return nil
	}
	return p.Enable
}

func (p *PersistenceWindowsMetrics) GetTimeWindow() *string {
	if p == nil {
		return nil
	}
	return p.TimeWindow
}

func (p *PersistenceWindowsMetrics) GetMaxDataSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataSize
}

func (p *PersistenceWindowsMetrics) GetMaxDataTime() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataTime
}

func (p *PersistenceWindowsMetrics) GetCompress() *components.DataCompressionFormatOptionsPersistence {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PersistenceWindowsMetrics) GetDestPath() *string {
	if p == nil {
		return nil
	}
	return p.DestPath
}

type InputWindowsMetrics struct {
	// Unique ID for this input
	ID       string             `json:"id"`
	Type     TypeWindowsMetrics `json:"type"`
	Disabled *bool              `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Time, in seconds, between consecutive metric collections. Default is 10 seconds.
	Interval *float64                `json:"interval,omitzero"`
	Host     *HostWindowsMetrics     `json:"host,omitzero"`
	Process  *components.ProcessType `json:"process,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Persistence *PersistenceWindowsMetrics                 `json:"persistence,omitzero"`
	// Enable to use built-in tools (PowerShell) to collect metrics instead of native API (default) [Learn more](https://docs.cribl.io/edge/sources-windows-metrics/#advanced-tab)
	DisableNativeModule *bool   `json:"disableNativeModule,omitzero"`
	Description         *string `json:"description,omitzero"`
}

func (i InputWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputWindowsMetrics) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputWindowsMetrics) GetType() TypeWindowsMetrics {
	if i == nil {
		return TypeWindowsMetrics("")
	}
	return i.Type
}

func (i *InputWindowsMetrics) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputWindowsMetrics) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputWindowsMetrics) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputWindowsMetrics) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputWindowsMetrics) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputWindowsMetrics) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputWindowsMetrics) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputWindowsMetrics) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputWindowsMetrics) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputWindowsMetrics) GetHost() *HostWindowsMetrics {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputWindowsMetrics) GetProcess() *components.ProcessType {
	if i == nil {
		return nil
	}
	return i.Process
}

func (i *InputWindowsMetrics) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputWindowsMetrics) GetPersistence() *PersistenceWindowsMetrics {
	if i == nil {
		return nil
	}
	return i.Persistence
}

func (i *InputWindowsMetrics) GetDisableNativeModule() *bool {
	if i == nil {
		return nil
	}
	return i.DisableNativeModule
}

func (i *InputWindowsMetrics) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type TypeKubeEvents string

const (
	TypeKubeEventsKubeEvents TypeKubeEvents = "kube_events"
)

func (e TypeKubeEvents) ToPointer() *TypeKubeEvents {
	return &e
}
func (e *TypeKubeEvents) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kube_events":
		*e = TypeKubeEvents(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeKubeEvents: %v", v)
	}
}

type InputKubeEvents struct {
	// Unique ID for this input
	ID       string         `json:"id"`
	Type     TypeKubeEvents `json:"type"`
	Disabled *bool          `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Filtering on event fields
	Rules []components.ItemsTypeRules `json:"rules,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
}

func (i InputKubeEvents) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeEvents) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputKubeEvents) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputKubeEvents) GetType() TypeKubeEvents {
	if i == nil {
		return TypeKubeEvents("")
	}
	return i.Type
}

func (i *InputKubeEvents) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKubeEvents) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputKubeEvents) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputKubeEvents) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputKubeEvents) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputKubeEvents) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputKubeEvents) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputKubeEvents) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputKubeEvents) GetRules() []components.ItemsTypeRules {
	if i == nil {
		return nil
	}
	return i.Rules
}

func (i *InputKubeEvents) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputKubeEvents) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type TypeKubeLogs string

const (
	TypeKubeLogsKubeLogs TypeKubeLogs = "kube_logs"
)

func (e TypeKubeLogs) ToPointer() *TypeKubeLogs {
	return &e
}
func (e *TypeKubeLogs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kube_logs":
		*e = TypeKubeLogs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeKubeLogs: %v", v)
	}
}

type RuleKubeLogs struct {
	// JavaScript expression applied to Pod objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitzero"`
}

func (r RuleKubeLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RuleKubeLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (r *RuleKubeLogs) GetFilter() string {
	if r == nil {
		return ""
	}
	return r.Filter
}

func (r *RuleKubeLogs) GetDescription() *string {
	if r == nil {
		return nil
	}
	return r.Description
}

type InputKubeLogs struct {
	// Unique ID for this input
	ID       string       `json:"id"`
	Type     TypeKubeLogs `json:"type"`
	Disabled *bool        `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Time, in seconds, between checks for new containers. Default is 15 secs.
	Interval *float64 `json:"interval,omitzero"`
	// Add rules to decide which Pods to collect logs from. Logs are collected if no rules are given or if all the rules' expressions evaluate to true.
	Rules []RuleKubeLogs `json:"rules,omitzero"`
	// For use when containers do not emit a timestamp, prefix each line of output with a timestamp. If you enable this setting, you can use the Kubernetes Logs Event Breaker and the kubernetes_logs Pre-processing Pipeline to remove them from the events after the timestamps are extracted.
	Timestamps *bool `json:"timestamps,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Persistence *components.DiskSpoolingType               `json:"persistence,omitzero"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitzero"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `json:"staleChannelFlushMs,omitzero"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool   `json:"enableLoadBalancing,omitzero"`
	Description         *string `json:"description,omitzero"`
}

func (i InputKubeLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputKubeLogs) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputKubeLogs) GetType() TypeKubeLogs {
	if i == nil {
		return TypeKubeLogs("")
	}
	return i.Type
}

func (i *InputKubeLogs) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKubeLogs) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputKubeLogs) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputKubeLogs) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputKubeLogs) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputKubeLogs) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputKubeLogs) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputKubeLogs) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputKubeLogs) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputKubeLogs) GetRules() []RuleKubeLogs {
	if i == nil {
		return nil
	}
	return i.Rules
}

func (i *InputKubeLogs) GetTimestamps() *bool {
	if i == nil {
		return nil
	}
	return i.Timestamps
}

func (i *InputKubeLogs) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputKubeLogs) GetPersistence() *components.DiskSpoolingType {
	if i == nil {
		return nil
	}
	return i.Persistence
}

func (i *InputKubeLogs) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputKubeLogs) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputKubeLogs) GetEnableLoadBalancing() *bool {
	if i == nil {
		return nil
	}
	return i.EnableLoadBalancing
}

func (i *InputKubeLogs) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type TypeKubeMetrics string

const (
	TypeKubeMetricsKubeMetrics TypeKubeMetrics = "kube_metrics"
)

func (e TypeKubeMetrics) ToPointer() *TypeKubeMetrics {
	return &e
}
func (e *TypeKubeMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kube_metrics":
		*e = TypeKubeMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeKubeMetrics: %v", v)
	}
}

type PersistenceKubeMetrics struct {
	// Spool metrics on disk for Cribl Search
	Enable *bool `json:"enable,omitzero"`
	// Time span for each file bucket
	TimeWindow *string `json:"timeWindow,omitzero"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `json:"maxDataSize,omitzero"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                                             `json:"maxDataTime,omitzero"`
	Compress    *components.DataCompressionFormatOptionsPersistence `json:"compress,omitzero"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/<id>
	DestPath *string `json:"destPath,omitzero"`
}

func (p PersistenceKubeMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PersistenceKubeMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PersistenceKubeMetrics) GetEnable() *bool {
	if p == nil {
		return nil
	}
	return p.Enable
}

func (p *PersistenceKubeMetrics) GetTimeWindow() *string {
	if p == nil {
		return nil
	}
	return p.TimeWindow
}

func (p *PersistenceKubeMetrics) GetMaxDataSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataSize
}

func (p *PersistenceKubeMetrics) GetMaxDataTime() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataTime
}

func (p *PersistenceKubeMetrics) GetCompress() *components.DataCompressionFormatOptionsPersistence {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PersistenceKubeMetrics) GetDestPath() *string {
	if p == nil {
		return nil
	}
	return p.DestPath
}

type InputKubeMetrics struct {
	// Unique ID for this input
	ID       string          `json:"id"`
	Type     TypeKubeMetrics `json:"type"`
	Disabled *bool           `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Time, in seconds, between consecutive metrics collections. Default is 15 secs.
	Interval *float64 `json:"interval,omitzero"`
	// Add rules to decide which Kubernetes objects to generate metrics for. Events are generated if no rules are given or of all the rules' expressions evaluate to true.
	Rules []components.ItemsTypeRules `json:"rules,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Persistence *PersistenceKubeMetrics                    `json:"persistence,omitzero"`
	Description *string                                    `json:"description,omitzero"`
}

func (i InputKubeMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputKubeMetrics) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputKubeMetrics) GetType() TypeKubeMetrics {
	if i == nil {
		return TypeKubeMetrics("")
	}
	return i.Type
}

func (i *InputKubeMetrics) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKubeMetrics) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputKubeMetrics) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputKubeMetrics) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputKubeMetrics) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputKubeMetrics) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputKubeMetrics) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputKubeMetrics) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputKubeMetrics) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputKubeMetrics) GetRules() []components.ItemsTypeRules {
	if i == nil {
		return nil
	}
	return i.Rules
}

func (i *InputKubeMetrics) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputKubeMetrics) GetPersistence() *PersistenceKubeMetrics {
	if i == nil {
		return nil
	}
	return i.Persistence
}

func (i *InputKubeMetrics) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type TypeSystemState string

const (
	TypeSystemStateSystemState TypeSystemState = "system_state"
)

func (e TypeSystemState) ToPointer() *TypeSystemState {
	return &e
}
func (e *TypeSystemState) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "system_state":
		*e = TypeSystemState(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeSystemState: %v", v)
	}
}

// HostsFile - Creates events based on entries collected from the hosts file
type HostsFile struct {
	Enable *bool `json:"enable,omitzero"`
}

func (h HostsFile) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *HostsFile) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (h *HostsFile) GetEnable() *bool {
	if h == nil {
		return nil
	}
	return h.Enable
}

// Interfaces - Creates events for each of the hosts network interfaces
type Interfaces struct {
	Enable *bool `json:"enable,omitzero"`
}

func (i Interfaces) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *Interfaces) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *Interfaces) GetEnable() *bool {
	if i == nil {
		return nil
	}
	return i.Enable
}

// DisksAndFileSystems - Creates events for physical disks, partitions, and file systems
type DisksAndFileSystems struct {
	Enable *bool `json:"enable,omitzero"`
}

func (d DisksAndFileSystems) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DisksAndFileSystems) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DisksAndFileSystems) GetEnable() *bool {
	if d == nil {
		return nil
	}
	return d.Enable
}

// HostInfo - Creates events based on the host systems current state
type HostInfo struct {
	Enable *bool `json:"enable,omitzero"`
}

func (h HostInfo) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *HostInfo) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (h *HostInfo) GetEnable() *bool {
	if h == nil {
		return nil
	}
	return h.Enable
}

// Routes - Creates events based on entries collected from the hosts network routes
type Routes struct {
	Enable *bool `json:"enable,omitzero"`
}

func (r Routes) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *Routes) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (r *Routes) GetEnable() *bool {
	if r == nil {
		return nil
	}
	return r.Enable
}

// DNS - Creates events for DNS resolvers and search entries
type DNS struct {
	Enable *bool `json:"enable,omitzero"`
}

func (d DNS) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DNS) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DNS) GetEnable() *bool {
	if d == nil {
		return nil
	}
	return d.Enable
}

// UsersAndGroups - Creates events for local users and groups
type UsersAndGroups struct {
	Enable *bool `json:"enable,omitzero"`
}

func (u UsersAndGroups) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(u, "", false)
}

func (u *UsersAndGroups) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &u, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (u *UsersAndGroups) GetEnable() *bool {
	if u == nil {
		return nil
	}
	return u.Enable
}

// Firewall - Creates events for Firewall rules entries
type Firewall struct {
	Enable *bool `json:"enable,omitzero"`
}

func (f Firewall) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(f, "", false)
}

func (f *Firewall) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &f, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (f *Firewall) GetEnable() *bool {
	if f == nil {
		return nil
	}
	return f.Enable
}

// Services - Creates events from the list of services
type Services struct {
	Enable *bool `json:"enable,omitzero"`
}

func (s Services) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *Services) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (s *Services) GetEnable() *bool {
	if s == nil {
		return nil
	}
	return s.Enable
}

// ListeningPorts - Creates events from list of listening ports
type ListeningPorts struct {
	Enable *bool `json:"enable,omitzero"`
}

func (l ListeningPorts) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(l, "", false)
}

func (l *ListeningPorts) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &l, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (l *ListeningPorts) GetEnable() *bool {
	if l == nil {
		return nil
	}
	return l.Enable
}

// LoggedInUsers - Creates events from list of logged-in users
type LoggedInUsers struct {
	Enable *bool `json:"enable,omitzero"`
}

func (l LoggedInUsers) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(l, "", false)
}

func (l *LoggedInUsers) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &l, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (l *LoggedInUsers) GetEnable() *bool {
	if l == nil {
		return nil
	}
	return l.Enable
}

type Collectors struct {
	// Creates events based on entries collected from the hosts file
	Hostsfile *HostsFile `json:"hostsfile,omitzero"`
	// Creates events for each of the hosts network interfaces
	Interfaces *Interfaces `json:"interfaces,omitzero"`
	// Creates events for physical disks, partitions, and file systems
	Disk *DisksAndFileSystems `json:"disk,omitzero"`
	// Creates events based on the host systems current state
	Metadata *HostInfo `json:"metadata,omitzero"`
	// Creates events based on entries collected from the hosts network routes
	Routes *Routes `json:"routes,omitzero"`
	// Creates events for DNS resolvers and search entries
	DNS *DNS `json:"dns,omitzero"`
	// Creates events for local users and groups
	User *UsersAndGroups `json:"user,omitzero"`
	// Creates events for Firewall rules entries
	Firewall *Firewall `json:"firewall,omitzero"`
	// Creates events from the list of services
	Services *Services `json:"services,omitzero"`
	// Creates events from list of listening ports
	Ports *ListeningPorts `json:"ports,omitzero"`
	// Creates events from list of logged-in users
	LoginUsers *LoggedInUsers `json:"loginUsers,omitzero"`
}

func (c Collectors) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *Collectors) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *Collectors) GetHostsfile() *HostsFile {
	if c == nil {
		return nil
	}
	return c.Hostsfile
}

func (c *Collectors) GetInterfaces() *Interfaces {
	if c == nil {
		return nil
	}
	return c.Interfaces
}

func (c *Collectors) GetDisk() *DisksAndFileSystems {
	if c == nil {
		return nil
	}
	return c.Disk
}

func (c *Collectors) GetMetadata() *HostInfo {
	if c == nil {
		return nil
	}
	return c.Metadata
}

func (c *Collectors) GetRoutes() *Routes {
	if c == nil {
		return nil
	}
	return c.Routes
}

func (c *Collectors) GetDNS() *DNS {
	if c == nil {
		return nil
	}
	return c.DNS
}

func (c *Collectors) GetUser() *UsersAndGroups {
	if c == nil {
		return nil
	}
	return c.User
}

func (c *Collectors) GetFirewall() *Firewall {
	if c == nil {
		return nil
	}
	return c.Firewall
}

func (c *Collectors) GetServices() *Services {
	if c == nil {
		return nil
	}
	return c.Services
}

func (c *Collectors) GetPorts() *ListeningPorts {
	if c == nil {
		return nil
	}
	return c.Ports
}

func (c *Collectors) GetLoginUsers() *LoggedInUsers {
	if c == nil {
		return nil
	}
	return c.LoginUsers
}

type PersistenceSystemState struct {
	// Spool metrics to disk for Cribl Edge and Search
	Enable *bool `json:"enable,omitzero"`
	// Time span for each file bucket
	TimeWindow *string `json:"timeWindow,omitzero"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `json:"maxDataSize,omitzero"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                                             `json:"maxDataTime,omitzero"`
	Compress    *components.DataCompressionFormatOptionsPersistence `json:"compress,omitzero"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/system_state
	DestPath *string `json:"destPath,omitzero"`
}

func (p PersistenceSystemState) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PersistenceSystemState) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PersistenceSystemState) GetEnable() *bool {
	if p == nil {
		return nil
	}
	return p.Enable
}

func (p *PersistenceSystemState) GetTimeWindow() *string {
	if p == nil {
		return nil
	}
	return p.TimeWindow
}

func (p *PersistenceSystemState) GetMaxDataSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataSize
}

func (p *PersistenceSystemState) GetMaxDataTime() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataTime
}

func (p *PersistenceSystemState) GetCompress() *components.DataCompressionFormatOptionsPersistence {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PersistenceSystemState) GetDestPath() *string {
	if p == nil {
		return nil
	}
	return p.DestPath
}

type InputSystemState struct {
	// Unique ID for this input
	ID       string          `json:"id"`
	Type     TypeSystemState `json:"type"`
	Disabled *bool           `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Time, in seconds, between consecutive state collections. Default is 300 seconds (5 minutes).
	Interval *float64 `json:"interval,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Collectors  *Collectors                                `json:"collectors,omitzero"`
	Persistence *PersistenceSystemState                    `json:"persistence,omitzero"`
	// Enable to use built-in tools (PowerShell) to collect events instead of native API (default) [Learn more](https://docs.cribl.io/edge/sources-system-state/#advanced-tab)
	DisableNativeModule *bool `json:"disableNativeModule,omitzero"`
	// Enable only to collect LastLog data via legacy implementation. This option will be removed in a future release. Please contact Support before enabling. [Learn more](https://docs.cribl.io/edge/sources-system-state/#advanced-tab)
	DisableNativeLastLogModule *bool   `json:"disableNativeLastLogModule,omitzero"`
	Description                *string `json:"description,omitzero"`
}

func (i InputSystemState) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSystemState) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputSystemState) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputSystemState) GetType() TypeSystemState {
	if i == nil {
		return TypeSystemState("")
	}
	return i.Type
}

func (i *InputSystemState) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSystemState) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSystemState) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputSystemState) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputSystemState) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputSystemState) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputSystemState) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputSystemState) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputSystemState) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputSystemState) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputSystemState) GetCollectors() *Collectors {
	if i == nil {
		return nil
	}
	return i.Collectors
}

func (i *InputSystemState) GetPersistence() *PersistenceSystemState {
	if i == nil {
		return nil
	}
	return i.Persistence
}

func (i *InputSystemState) GetDisableNativeModule() *bool {
	if i == nil {
		return nil
	}
	return i.DisableNativeModule
}

func (i *InputSystemState) GetDisableNativeLastLogModule() *bool {
	if i == nil {
		return nil
	}
	return i.DisableNativeLastLogModule
}

func (i *InputSystemState) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type TypeSystemMetrics string

const (
	TypeSystemMetricsSystemMetrics TypeSystemMetrics = "system_metrics"
)

func (e TypeSystemMetrics) ToPointer() *TypeSystemMetrics {
	return &e
}
func (e *TypeSystemMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "system_metrics":
		*e = TypeSystemMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeSystemMetrics: %v", v)
	}
}

// SystemModeSystemMetrics - Select the level of detail for system metrics
type SystemModeSystemMetrics string

const (
	// SystemModeSystemMetricsBasic Basic
	SystemModeSystemMetricsBasic SystemModeSystemMetrics = "basic"
	// SystemModeSystemMetricsAll All
	SystemModeSystemMetricsAll SystemModeSystemMetrics = "all"
	// SystemModeSystemMetricsCustom Custom
	SystemModeSystemMetricsCustom SystemModeSystemMetrics = "custom"
	// SystemModeSystemMetricsDisabled Disabled
	SystemModeSystemMetricsDisabled SystemModeSystemMetrics = "disabled"
)

func (e SystemModeSystemMetrics) ToPointer() *SystemModeSystemMetrics {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *SystemModeSystemMetrics) IsExact() bool {
	if e != nil {
		switch *e {
		case "basic", "all", "custom", "disabled":
			return true
		}
	}
	return false
}

type SystemSystemMetrics struct {
	// Select the level of detail for system metrics
	Mode *SystemModeSystemMetrics `json:"mode,omitzero"`
	// Generate metrics for the numbers of processes in various states
	Processes *bool `json:"processes,omitzero"`
}

func (s SystemSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SystemSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (s *SystemSystemMetrics) GetMode() *SystemModeSystemMetrics {
	if s == nil {
		return nil
	}
	return s.Mode
}

func (s *SystemSystemMetrics) GetProcesses() *bool {
	if s == nil {
		return nil
	}
	return s.Processes
}

// CPUModeSystemMetrics - Select the level of detail for CPU metrics
type CPUModeSystemMetrics string

const (
	// CPUModeSystemMetricsBasic Basic
	CPUModeSystemMetricsBasic CPUModeSystemMetrics = "basic"
	// CPUModeSystemMetricsAll All
	CPUModeSystemMetricsAll CPUModeSystemMetrics = "all"
	// CPUModeSystemMetricsCustom Custom
	CPUModeSystemMetricsCustom CPUModeSystemMetrics = "custom"
	// CPUModeSystemMetricsDisabled Disabled
	CPUModeSystemMetricsDisabled CPUModeSystemMetrics = "disabled"
)

func (e CPUModeSystemMetrics) ToPointer() *CPUModeSystemMetrics {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CPUModeSystemMetrics) IsExact() bool {
	if e != nil {
		switch *e {
		case "basic", "all", "custom", "disabled":
			return true
		}
	}
	return false
}

type CPUSystemMetrics struct {
	// Select the level of detail for CPU metrics
	Mode *CPUModeSystemMetrics `json:"mode,omitzero"`
	// Generate metrics for each CPU
	PerCPU *bool `json:"perCpu,omitzero"`
	// Generate metrics for all CPU states
	Detail *bool `json:"detail,omitzero"`
	// Generate raw, monotonic CPU time counters
	Time *bool `json:"time,omitzero"`
}

func (c CPUSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CPUSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *CPUSystemMetrics) GetMode() *CPUModeSystemMetrics {
	if c == nil {
		return nil
	}
	return c.Mode
}

func (c *CPUSystemMetrics) GetPerCPU() *bool {
	if c == nil {
		return nil
	}
	return c.PerCPU
}

func (c *CPUSystemMetrics) GetDetail() *bool {
	if c == nil {
		return nil
	}
	return c.Detail
}

func (c *CPUSystemMetrics) GetTime() *bool {
	if c == nil {
		return nil
	}
	return c.Time
}

// MemoryModeSystemMetrics - Select the level of detail for memory metrics
type MemoryModeSystemMetrics string

const (
	// MemoryModeSystemMetricsBasic Basic
	MemoryModeSystemMetricsBasic MemoryModeSystemMetrics = "basic"
	// MemoryModeSystemMetricsAll All
	MemoryModeSystemMetricsAll MemoryModeSystemMetrics = "all"
	// MemoryModeSystemMetricsCustom Custom
	MemoryModeSystemMetricsCustom MemoryModeSystemMetrics = "custom"
	// MemoryModeSystemMetricsDisabled Disabled
	MemoryModeSystemMetricsDisabled MemoryModeSystemMetrics = "disabled"
)

func (e MemoryModeSystemMetrics) ToPointer() *MemoryModeSystemMetrics {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *MemoryModeSystemMetrics) IsExact() bool {
	if e != nil {
		switch *e {
		case "basic", "all", "custom", "disabled":
			return true
		}
	}
	return false
}

type MemorySystemMetrics struct {
	// Select the level of detail for memory metrics
	Mode *MemoryModeSystemMetrics `json:"mode,omitzero"`
	// Generate metrics for all memory states
	Detail *bool `json:"detail,omitzero"`
}

func (m MemorySystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MemorySystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (m *MemorySystemMetrics) GetMode() *MemoryModeSystemMetrics {
	if m == nil {
		return nil
	}
	return m.Mode
}

func (m *MemorySystemMetrics) GetDetail() *bool {
	if m == nil {
		return nil
	}
	return m.Detail
}

// NetworkModeSystemMetrics - Select the level of detail for network metrics
type NetworkModeSystemMetrics string

const (
	// NetworkModeSystemMetricsBasic Basic
	NetworkModeSystemMetricsBasic NetworkModeSystemMetrics = "basic"
	// NetworkModeSystemMetricsAll All
	NetworkModeSystemMetricsAll NetworkModeSystemMetrics = "all"
	// NetworkModeSystemMetricsCustom Custom
	NetworkModeSystemMetricsCustom NetworkModeSystemMetrics = "custom"
	// NetworkModeSystemMetricsDisabled Disabled
	NetworkModeSystemMetricsDisabled NetworkModeSystemMetrics = "disabled"
)

func (e NetworkModeSystemMetrics) ToPointer() *NetworkModeSystemMetrics {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *NetworkModeSystemMetrics) IsExact() bool {
	if e != nil {
		switch *e {
		case "basic", "all", "custom", "disabled":
			return true
		}
	}
	return false
}

type NetworkSystemMetrics struct {
	// Select the level of detail for network metrics
	Mode *NetworkModeSystemMetrics `json:"mode,omitzero"`
	// Generate full network metrics
	Detail *bool `json:"detail,omitzero"`
	// Generate protocol metrics for ICMP, ICMPMsg, IP, TCP, UDP and UDPLite
	Protocols *bool `json:"protocols,omitzero"`
	// Network interfaces to include/exclude. Examples: eth0, !lo. All interfaces are included if this list is empty.
	Devices []string `json:"devices,omitzero"`
	// Generate separate metrics for each interface
	PerInterface *bool `json:"perInterface,omitzero"`
}

func (n NetworkSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(n, "", false)
}

func (n *NetworkSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &n, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (n *NetworkSystemMetrics) GetMode() *NetworkModeSystemMetrics {
	if n == nil {
		return nil
	}
	return n.Mode
}

func (n *NetworkSystemMetrics) GetDetail() *bool {
	if n == nil {
		return nil
	}
	return n.Detail
}

func (n *NetworkSystemMetrics) GetProtocols() *bool {
	if n == nil {
		return nil
	}
	return n.Protocols
}

func (n *NetworkSystemMetrics) GetDevices() []string {
	if n == nil {
		return nil
	}
	return n.Devices
}

func (n *NetworkSystemMetrics) GetPerInterface() *bool {
	if n == nil {
		return nil
	}
	return n.PerInterface
}

// DiskModeSystemMetrics - Select the level of detail for disk metrics
type DiskModeSystemMetrics string

const (
	// DiskModeSystemMetricsBasic Basic
	DiskModeSystemMetricsBasic DiskModeSystemMetrics = "basic"
	// DiskModeSystemMetricsAll All
	DiskModeSystemMetricsAll DiskModeSystemMetrics = "all"
	// DiskModeSystemMetricsCustom Custom
	DiskModeSystemMetricsCustom DiskModeSystemMetrics = "custom"
	// DiskModeSystemMetricsDisabled Disabled
	DiskModeSystemMetricsDisabled DiskModeSystemMetrics = "disabled"
)

func (e DiskModeSystemMetrics) ToPointer() *DiskModeSystemMetrics {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *DiskModeSystemMetrics) IsExact() bool {
	if e != nil {
		switch *e {
		case "basic", "all", "custom", "disabled":
			return true
		}
	}
	return false
}

type DiskSystemMetrics struct {
	// Select the level of detail for disk metrics
	Mode *DiskModeSystemMetrics `json:"mode,omitzero"`
	// Generate full disk metrics
	Detail *bool `json:"detail,omitzero"`
	// Generate filesystem inode metrics
	Inodes *bool `json:"inodes,omitzero"`
	// Block devices to include/exclude. Examples: sda*, !loop*. Wildcards and ! (not) operators are supported. All devices are included if this list is empty.
	Devices []string `json:"devices,omitzero"`
	// Filesystem mountpoints to include/exclude. Examples: /, /home, !/proc*, !/tmp. Wildcards and ! (not) operators are supported. All mountpoints are included if this list is empty.
	Mountpoints []string `json:"mountpoints,omitzero"`
	// Filesystem types to include/exclude. Examples: ext4, !*tmpfs, !squashfs. Wildcards and ! (not) operators are supported. All types are included if this list is empty.
	Fstypes []string `json:"fstypes,omitzero"`
	// Generate separate metrics for each device
	PerDevice *bool `json:"perDevice,omitzero"`
}

func (d DiskSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DiskSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (d *DiskSystemMetrics) GetMode() *DiskModeSystemMetrics {
	if d == nil {
		return nil
	}
	return d.Mode
}

func (d *DiskSystemMetrics) GetDetail() *bool {
	if d == nil {
		return nil
	}
	return d.Detail
}

func (d *DiskSystemMetrics) GetInodes() *bool {
	if d == nil {
		return nil
	}
	return d.Inodes
}

func (d *DiskSystemMetrics) GetDevices() []string {
	if d == nil {
		return nil
	}
	return d.Devices
}

func (d *DiskSystemMetrics) GetMountpoints() []string {
	if d == nil {
		return nil
	}
	return d.Mountpoints
}

func (d *DiskSystemMetrics) GetFstypes() []string {
	if d == nil {
		return nil
	}
	return d.Fstypes
}

func (d *DiskSystemMetrics) GetPerDevice() *bool {
	if d == nil {
		return nil
	}
	return d.PerDevice
}

type CustomSystemMetrics struct {
	System  *SystemSystemMetrics  `json:"system,omitzero"`
	CPU     *CPUSystemMetrics     `json:"cpu,omitzero"`
	Memory  *MemorySystemMetrics  `json:"memory,omitzero"`
	Network *NetworkSystemMetrics `json:"network,omitzero"`
	Disk    *DiskSystemMetrics    `json:"disk,omitzero"`
}

func (c CustomSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CustomSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *CustomSystemMetrics) GetSystem() *SystemSystemMetrics {
	if c == nil {
		return nil
	}
	return c.System
}

func (c *CustomSystemMetrics) GetCPU() *CPUSystemMetrics {
	if c == nil {
		return nil
	}
	return c.CPU
}

func (c *CustomSystemMetrics) GetMemory() *MemorySystemMetrics {
	if c == nil {
		return nil
	}
	return c.Memory
}

func (c *CustomSystemMetrics) GetNetwork() *NetworkSystemMetrics {
	if c == nil {
		return nil
	}
	return c.Network
}

func (c *CustomSystemMetrics) GetDisk() *DiskSystemMetrics {
	if c == nil {
		return nil
	}
	return c.Disk
}

type HostSystemMetrics struct {
	// Select level of detail for host metrics
	Mode   *components.ModeOptionsHost `json:"mode,omitzero"`
	Custom *CustomSystemMetrics        `json:"custom,omitzero"`
}

func (h HostSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *HostSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (h *HostSystemMetrics) GetMode() *components.ModeOptionsHost {
	if h == nil {
		return nil
	}
	return h.Mode
}

func (h *HostSystemMetrics) GetCustom() *CustomSystemMetrics {
	if h == nil {
		return nil
	}
	return h.Custom
}

// ContainerMode - Select the level of detail for container metrics
type ContainerMode string

const (
	// ContainerModeBasic Basic
	ContainerModeBasic ContainerMode = "basic"
	// ContainerModeAll All
	ContainerModeAll ContainerMode = "all"
	// ContainerModeCustom Custom
	ContainerModeCustom ContainerMode = "custom"
	// ContainerModeDisabled Disabled
	ContainerModeDisabled ContainerMode = "disabled"
)

func (e ContainerMode) ToPointer() *ContainerMode {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *ContainerMode) IsExact() bool {
	if e != nil {
		switch *e {
		case "basic", "all", "custom", "disabled":
			return true
		}
	}
	return false
}

type ContainerFilter struct {
	Expr string `json:"expr"`
}

func (c ContainerFilter) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ContainerFilter) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *ContainerFilter) GetExpr() string {
	if c == nil {
		return ""
	}
	return c.Expr
}

type Container struct {
	// Select the level of detail for container metrics
	Mode *ContainerMode `json:"mode,omitzero"`
	// Full paths for Docker's UNIX-domain socket
	DockerSocket []string `json:"dockerSocket,omitzero"`
	// Timeout, in seconds, for the Docker API
	DockerTimeout *float64 `json:"dockerTimeout,omitzero"`
	// Containers matching any of these will be included. All are included if no filters are added.
	Filters []ContainerFilter `json:"filters,omitzero"`
	// Include stopped and paused containers
	AllContainers *bool `json:"allContainers,omitzero"`
	// Generate separate metrics for each device
	PerDevice *bool `json:"perDevice,omitzero"`
	// Generate full container metrics
	Detail *bool `json:"detail,omitzero"`
}

func (c Container) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *Container) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *Container) GetMode() *ContainerMode {
	if c == nil {
		return nil
	}
	return c.Mode
}

func (c *Container) GetDockerSocket() []string {
	if c == nil {
		return nil
	}
	return c.DockerSocket
}

func (c *Container) GetDockerTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.DockerTimeout
}

func (c *Container) GetFilters() []ContainerFilter {
	if c == nil {
		return nil
	}
	return c.Filters
}

func (c *Container) GetAllContainers() *bool {
	if c == nil {
		return nil
	}
	return c.AllContainers
}

func (c *Container) GetPerDevice() *bool {
	if c == nil {
		return nil
	}
	return c.PerDevice
}

func (c *Container) GetDetail() *bool {
	if c == nil {
		return nil
	}
	return c.Detail
}

type PersistenceSystemMetrics struct {
	// Spool metrics to disk for Cribl Edge and Search
	Enable *bool `json:"enable,omitzero"`
	// Time span for each file bucket
	TimeWindow *string `json:"timeWindow,omitzero"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `json:"maxDataSize,omitzero"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                                             `json:"maxDataTime,omitzero"`
	Compress    *components.DataCompressionFormatOptionsPersistence `json:"compress,omitzero"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/system_metrics
	DestPath *string `json:"destPath,omitzero"`
}

func (p PersistenceSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PersistenceSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PersistenceSystemMetrics) GetEnable() *bool {
	if p == nil {
		return nil
	}
	return p.Enable
}

func (p *PersistenceSystemMetrics) GetTimeWindow() *string {
	if p == nil {
		return nil
	}
	return p.TimeWindow
}

func (p *PersistenceSystemMetrics) GetMaxDataSize() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataSize
}

func (p *PersistenceSystemMetrics) GetMaxDataTime() *string {
	if p == nil {
		return nil
	}
	return p.MaxDataTime
}

func (p *PersistenceSystemMetrics) GetCompress() *components.DataCompressionFormatOptionsPersistence {
	if p == nil {
		return nil
	}
	return p.Compress
}

func (p *PersistenceSystemMetrics) GetDestPath() *string {
	if p == nil {
		return nil
	}
	return p.DestPath
}

type InputSystemMetrics struct {
	// Unique ID for this input
	ID       string            `json:"id"`
	Type     TypeSystemMetrics `json:"type"`
	Disabled *bool             `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Time, in seconds, between consecutive metric collections. Default is 10 seconds.
	Interval  *float64                `json:"interval,omitzero"`
	Host      *HostSystemMetrics      `json:"host,omitzero"`
	Process   *components.ProcessType `json:"process,omitzero"`
	Container *Container              `json:"container,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Persistence *PersistenceSystemMetrics                  `json:"persistence,omitzero"`
	Description *string                                    `json:"description,omitzero"`
}

func (i InputSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputSystemMetrics) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputSystemMetrics) GetType() TypeSystemMetrics {
	if i == nil {
		return TypeSystemMetrics("")
	}
	return i.Type
}

func (i *InputSystemMetrics) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSystemMetrics) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSystemMetrics) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputSystemMetrics) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputSystemMetrics) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputSystemMetrics) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputSystemMetrics) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputSystemMetrics) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputSystemMetrics) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputSystemMetrics) GetHost() *HostSystemMetrics {
	if i == nil {
		return nil
	}
	return i.Host
}

func (i *InputSystemMetrics) GetProcess() *components.ProcessType {
	if i == nil {
		return nil
	}
	return i.Process
}

func (i *InputSystemMetrics) GetContainer() *Container {
	if i == nil {
		return nil
	}
	return i.Container
}

func (i *InputSystemMetrics) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputSystemMetrics) GetPersistence() *PersistenceSystemMetrics {
	if i == nil {
		return nil
	}
	return i.Persistence
}

func (i *InputSystemMetrics) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type CreateInputTypeTcpjson string

const (
	CreateInputTypeTcpjsonTcpjson CreateInputTypeTcpjson = "tcpjson"
)

func (e CreateInputTypeTcpjson) ToPointer() *CreateInputTypeTcpjson {
	return &e
}
func (e *CreateInputTypeTcpjson) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "tcpjson":
		*e = CreateInputTypeTcpjson(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeTcpjson: %v", v)
	}
}

type InputTcpjson struct {
	// Unique ID for this input
	ID       string                 `json:"id"`
	Type     CreateInputTypeTcpjson `json:"type"`
	Disabled *bool                  `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64                               `json:"port"`
	TLS  *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Regex matching IP addresses that are allowed to establish a connection
	IPWhitelistRegex *string `json:"ipWhitelistRegex,omitzero"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `json:"maxActiveCxn,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `json:"socketIdleTimeout,omitzero"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `json:"socketEndingMaxWait,omitzero"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `json:"socketMaxLifespan,omitzero"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool `json:"enableLoadBalancing,omitzero"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitzero"`
	Description *string                                                `json:"description,omitzero"`
	// Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
	AuthToken *string `json:"authToken,omitzero"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitzero"`
}

func (i InputTcpjson) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTcpjson) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputTcpjson) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputTcpjson) GetType() CreateInputTypeTcpjson {
	if i == nil {
		return CreateInputTypeTcpjson("")
	}
	return i.Type
}

func (i *InputTcpjson) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputTcpjson) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputTcpjson) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputTcpjson) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputTcpjson) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputTcpjson) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputTcpjson) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputTcpjson) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputTcpjson) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputTcpjson) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputTcpjson) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputTcpjson) GetIPWhitelistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPWhitelistRegex
}

func (i *InputTcpjson) GetMaxActiveCxn() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveCxn
}

func (i *InputTcpjson) GetSocketIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketIdleTimeout
}

func (i *InputTcpjson) GetSocketEndingMaxWait() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketEndingMaxWait
}

func (i *InputTcpjson) GetSocketMaxLifespan() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketMaxLifespan
}

func (i *InputTcpjson) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputTcpjson) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputTcpjson) GetEnableLoadBalancing() *bool {
	if i == nil {
		return nil
	}
	return i.EnableLoadBalancing
}

func (i *InputTcpjson) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputTcpjson) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputTcpjson) GetAuthToken() *string {
	if i == nil {
		return nil
	}
	return i.AuthToken
}

func (i *InputTcpjson) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

type TypeCriblLakeHTTP string

const (
	TypeCriblLakeHTTPCriblLakeHTTP TypeCriblLakeHTTP = "cribl_lake_http"
)

func (e TypeCriblLakeHTTP) ToPointer() *TypeCriblLakeHTTP {
	return &e
}
func (e *TypeCriblLakeHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_lake_http":
		*e = TypeCriblLakeHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCriblLakeHTTP: %v", v)
	}
}

type SplunkHecMetadata struct {
	Enabled               *bool    `json:"enabled,omitzero"`
	DefaultDataset        *string  `json:"defaultDataset,omitzero"`
	AllowedIndexesAtToken []string `json:"allowedIndexesAtToken,omitzero"`
}

func (s SplunkHecMetadata) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SplunkHecMetadata) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (s *SplunkHecMetadata) GetEnabled() *bool {
	if s == nil {
		return nil
	}
	return s.Enabled
}

func (s *SplunkHecMetadata) GetDefaultDataset() *string {
	if s == nil {
		return nil
	}
	return s.DefaultDataset
}

func (s *SplunkHecMetadata) GetAllowedIndexesAtToken() []string {
	if s == nil {
		return nil
	}
	return s.AllowedIndexesAtToken
}

type ElasticsearchMetadata struct {
	Enabled        *bool   `json:"enabled,omitzero"`
	DefaultDataset *string `json:"defaultDataset,omitzero"`
}

func (e ElasticsearchMetadata) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(e, "", false)
}

func (e *ElasticsearchMetadata) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &e, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (e *ElasticsearchMetadata) GetEnabled() *bool {
	if e == nil {
		return nil
	}
	return e.Enabled
}

func (e *ElasticsearchMetadata) GetDefaultDataset() *string {
	if e == nil {
		return nil
	}
	return e.DefaultDataset
}

type AuthTokensExt struct {
	Token       string  `json:"token"`
	Description *string `json:"description,omitzero"`
	// Fields to add to events referencing this token
	Metadata              []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	SplunkHecMetadata     *SplunkHecMetadata                         `json:"splunkHecMetadata,omitzero"`
	ElasticsearchMetadata *ElasticsearchMetadata                     `json:"elasticsearchMetadata,omitzero"`
}

func (a AuthTokensExt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokensExt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokensExt) GetToken() string {
	if a == nil {
		return ""
	}
	return a.Token
}

func (a *AuthTokensExt) GetDescription() *string {
	if a == nil {
		return nil
	}
	return a.Description
}

func (a *AuthTokensExt) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if a == nil {
		return nil
	}
	return a.Metadata
}

func (a *AuthTokensExt) GetSplunkHecMetadata() *SplunkHecMetadata {
	if a == nil {
		return nil
	}
	return a.SplunkHecMetadata
}

func (a *AuthTokensExt) GetElasticsearchMetadata() *ElasticsearchMetadata {
	if a == nil {
		return nil
	}
	return a.ElasticsearchMetadata
}

type InputCriblLakeHTTP struct {
	// Unique ID for this input
	ID       string            `json:"id"`
	Type     TypeCriblLakeHTTP `json:"type"`
	Disabled *bool             `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                              `json:"authTokens,omitzero"`
	TLS        *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `json:"maxActiveReq,omitzero"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `json:"maxRequestsPerSocket,omitzero"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `json:"captureHeaders,omitzero"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `json:"activityLogSampleRate,omitzero"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitzero"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `json:"enableHealthCheck,omitzero"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `json:"ipAllowlistRegex,omitzero"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `json:"ipDenylistRegex,omitzero"`
	// Absolute path on which to listen for the Cribl HTTP API requests. Only _bulk (default /cribl/_bulk) is available. Use empty string to disable.
	CriblAPI *string `json:"criblAPI,omitzero"`
	// Absolute path on which to listen for the Elasticsearch API requests. Only _bulk (default /elastic/_bulk) is available. Use empty string to disable.
	ElasticAPI *string `json:"elasticAPI,omitzero"`
	// Absolute path on which listen for the Splunk HTTP Event Collector API requests. Use empty string to disable.
	SplunkHecAPI  *string `json:"splunkHecAPI,omitzero"`
	SplunkHecAcks *bool   `json:"splunkHecAcks,omitzero"`
	// Fields to add to events from this input
	Metadata      []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	AuthTokensExt []AuthTokensExt                            `json:"authTokensExt,omitzero"`
	Description   *string                                    `json:"description,omitzero"`
}

func (i InputCriblLakeHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblLakeHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputCriblLakeHTTP) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputCriblLakeHTTP) GetType() TypeCriblLakeHTTP {
	if i == nil {
		return TypeCriblLakeHTTP("")
	}
	return i.Type
}

func (i *InputCriblLakeHTTP) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputCriblLakeHTTP) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputCriblLakeHTTP) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputCriblLakeHTTP) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputCriblLakeHTTP) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputCriblLakeHTTP) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputCriblLakeHTTP) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputCriblLakeHTTP) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputCriblLakeHTTP) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputCriblLakeHTTP) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputCriblLakeHTTP) GetAuthTokens() []string {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputCriblLakeHTTP) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputCriblLakeHTTP) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputCriblLakeHTTP) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputCriblLakeHTTP) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputCriblLakeHTTP) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputCriblLakeHTTP) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputCriblLakeHTTP) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputCriblLakeHTTP) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputCriblLakeHTTP) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputCriblLakeHTTP) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputCriblLakeHTTP) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputCriblLakeHTTP) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputCriblLakeHTTP) GetCriblAPI() *string {
	if i == nil {
		return nil
	}
	return i.CriblAPI
}

func (i *InputCriblLakeHTTP) GetElasticAPI() *string {
	if i == nil {
		return nil
	}
	return i.ElasticAPI
}

func (i *InputCriblLakeHTTP) GetSplunkHecAPI() *string {
	if i == nil {
		return nil
	}
	return i.SplunkHecAPI
}

func (i *InputCriblLakeHTTP) GetSplunkHecAcks() *bool {
	if i == nil {
		return nil
	}
	return i.SplunkHecAcks
}

func (i *InputCriblLakeHTTP) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputCriblLakeHTTP) GetAuthTokensExt() []AuthTokensExt {
	if i == nil {
		return nil
	}
	return i.AuthTokensExt
}

func (i *InputCriblLakeHTTP) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}
