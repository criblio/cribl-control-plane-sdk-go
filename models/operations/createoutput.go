// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package operations

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/criblio/cribl-control-plane-sdk-go/internal/utils"
	"github.com/criblio/cribl-control-plane-sdk-go/models/components"
)

type CreateOutputTypeCloudflareR2 string

const (
	CreateOutputTypeCloudflareR2CloudflareR2 CreateOutputTypeCloudflareR2 = "cloudflare_r2"
)

func (e CreateOutputTypeCloudflareR2) ToPointer() *CreateOutputTypeCloudflareR2 {
	return &e
}
func (e *CreateOutputTypeCloudflareR2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cloudflare_r2":
		*e = CreateOutputTypeCloudflareR2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeCloudflareR2: %v", v)
	}
}

// CreateOutputAuthenticationMethodCloudflareR2 - AWS authentication method. Choose Auto to use IAM roles.
type CreateOutputAuthenticationMethodCloudflareR2 string

const (
	// CreateOutputAuthenticationMethodCloudflareR2Auto Auto
	CreateOutputAuthenticationMethodCloudflareR2Auto CreateOutputAuthenticationMethodCloudflareR2 = "auto"
	// CreateOutputAuthenticationMethodCloudflareR2Secret Secret Key pair
	CreateOutputAuthenticationMethodCloudflareR2Secret CreateOutputAuthenticationMethodCloudflareR2 = "secret"
)

func (e CreateOutputAuthenticationMethodCloudflareR2) ToPointer() *CreateOutputAuthenticationMethodCloudflareR2 {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputAuthenticationMethodCloudflareR2) IsExact() bool {
	if e != nil {
		switch *e {
		case "auto", "secret":
			return true
		}
	}
	return false
}

type CreateOutputOutputCloudflareR2 struct {
	// Unique ID for this output
	ID   string                       `json:"id"`
	Type CreateOutputTypeCloudflareR2 `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Cloudflare R2 service URL (example: https://<ACCOUNT_ID>.r2.cloudflarestorage.com)
	Endpoint string `json:"endpoint"`
	// Name of the destination R2 bucket. This value can be a constant or a JavaScript expression that can only be evaluated at init time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
	Bucket string `json:"bucket"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *CreateOutputAuthenticationMethodCloudflareR2 `json:"awsAuthenticationMethod,omitempty"`
	// Secret key. This value can be a constant or a JavaScript expression, such as `${C.env.SOME_SECRET}`).
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	Region       any     `json:"region,omitempty"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
	StagePath string `json:"stagePath"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Root directory to prepend to path before uploading. Enter a constant, or a JavaScript expression enclosed in quotes or backticks.
	DestPath *string `json:"destPath,omitempty"`
	// Signature version to use for signing MinIO requests
	SignatureVersion *components.SignatureVersionOptions5 `json:"signatureVersion,omitempty"`
	ObjectACL        any                                  `json:"objectACL,omitempty"`
	// Storage class to select for uploaded objects
	StorageClass *components.StorageClassOptions2 `json:"storageClass,omitempty"`
	// Server-side encryption for uploaded objects
	ServerSideEncryption *components.ServerSideEncryptionOptions `json:"serverSideEncryption,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates)
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Disable if you can access files within the bucket but not the bucket itself
	VerifyPermissions *bool `json:"verifyPermissions,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
	PartitionExpr *string `json:"partitionExpr,omitempty"`
	// Format of the output data
	Format *components.DataFormatOptions `json:"format,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `json:"baseFileName,omitempty"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `json:"fileNameSuffix,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `json:"maxFileSizeMB,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `json:"maxOpenFiles,omitempty"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `json:"headerLine,omitempty"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `json:"writeHighWaterMark,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `json:"deadletterEnabled,omitempty"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *components.DiskSpaceProtectionOptions `json:"onDiskFullBackpressure,omitempty"`
	// Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
	ForceCloseOnShutdown *bool                         `json:"forceCloseOnShutdown,omitempty"`
	RetrySettings        *components.RetrySettingsType `json:"retrySettings,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *float64 `json:"maxConcurrentFileParts,omitempty"`
	Description            *string  `json:"description,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Data compression format to apply to HTTP content before it is delivered
	Compress *components.CompressionOptions2 `json:"compress,omitempty"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *components.CompressionLevelOptions `json:"compressionLevel,omitempty"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `json:"automaticSchema,omitempty"`
	// To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
	ParquetSchema *string `json:"parquetSchema,omitempty"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *components.ParquetVersionOptions `json:"parquetVersion,omitempty"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *components.DataPageVersionOptions `json:"parquetDataPageVersion,omitempty"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `json:"parquetRowGroupLength,omitempty"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
	KeyValueMetadata []components.ItemsTypeKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `json:"enableStatistics,omitempty"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `json:"enableWritePageIndex,omitempty"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `json:"enablePageChecksum,omitempty"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `json:"emptyDirCleanupSec,omitempty"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `json:"directoryBatchSize,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `json:"deadletterPath,omitempty"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `json:"maxRetryNum,omitempty"`
	// Binds 'bucket' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'bucket' at runtime.
	TemplateBucket *string `json:"__template_bucket,omitempty"`
	// Binds 'format' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'format' at runtime.
	TemplateFormat *string `json:"__template_format,omitempty"`
}

func (c CreateOutputOutputCloudflareR2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputCloudflareR2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "endpoint", "bucket", "stagePath"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputCloudflareR2) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputCloudflareR2) GetType() CreateOutputTypeCloudflareR2 {
	if c == nil {
		return CreateOutputTypeCloudflareR2("")
	}
	return c.Type
}

func (c *CreateOutputOutputCloudflareR2) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputCloudflareR2) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputCloudflareR2) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputCloudflareR2) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputCloudflareR2) GetEndpoint() string {
	if c == nil {
		return ""
	}
	return c.Endpoint
}

func (c *CreateOutputOutputCloudflareR2) GetBucket() string {
	if c == nil {
		return ""
	}
	return c.Bucket
}

func (c *CreateOutputOutputCloudflareR2) GetAwsAuthenticationMethod() *CreateOutputAuthenticationMethodCloudflareR2 {
	if c == nil {
		return nil
	}
	return c.AwsAuthenticationMethod
}

func (c *CreateOutputOutputCloudflareR2) GetAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecretKey
}

func (c *CreateOutputOutputCloudflareR2) GetRegion() any {
	if c == nil {
		return nil
	}
	return c.Region
}

func (c *CreateOutputOutputCloudflareR2) GetStagePath() string {
	if c == nil {
		return ""
	}
	return c.StagePath
}

func (c *CreateOutputOutputCloudflareR2) GetAddIDToStagePath() *bool {
	if c == nil {
		return nil
	}
	return c.AddIDToStagePath
}

func (c *CreateOutputOutputCloudflareR2) GetDestPath() *string {
	if c == nil {
		return nil
	}
	return c.DestPath
}

func (c *CreateOutputOutputCloudflareR2) GetSignatureVersion() *components.SignatureVersionOptions5 {
	if c == nil {
		return nil
	}
	return c.SignatureVersion
}

func (c *CreateOutputOutputCloudflareR2) GetObjectACL() any {
	if c == nil {
		return nil
	}
	return c.ObjectACL
}

func (c *CreateOutputOutputCloudflareR2) GetStorageClass() *components.StorageClassOptions2 {
	if c == nil {
		return nil
	}
	return c.StorageClass
}

func (c *CreateOutputOutputCloudflareR2) GetServerSideEncryption() *components.ServerSideEncryptionOptions {
	if c == nil {
		return nil
	}
	return c.ServerSideEncryption
}

func (c *CreateOutputOutputCloudflareR2) GetReuseConnections() *bool {
	if c == nil {
		return nil
	}
	return c.ReuseConnections
}

func (c *CreateOutputOutputCloudflareR2) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputCloudflareR2) GetVerifyPermissions() *bool {
	if c == nil {
		return nil
	}
	return c.VerifyPermissions
}

func (c *CreateOutputOutputCloudflareR2) GetRemoveEmptyDirs() *bool {
	if c == nil {
		return nil
	}
	return c.RemoveEmptyDirs
}

func (c *CreateOutputOutputCloudflareR2) GetPartitionExpr() *string {
	if c == nil {
		return nil
	}
	return c.PartitionExpr
}

func (c *CreateOutputOutputCloudflareR2) GetFormat() *components.DataFormatOptions {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputCloudflareR2) GetBaseFileName() *string {
	if c == nil {
		return nil
	}
	return c.BaseFileName
}

func (c *CreateOutputOutputCloudflareR2) GetFileNameSuffix() *string {
	if c == nil {
		return nil
	}
	return c.FileNameSuffix
}

func (c *CreateOutputOutputCloudflareR2) GetMaxFileSizeMB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileSizeMB
}

func (c *CreateOutputOutputCloudflareR2) GetMaxOpenFiles() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxOpenFiles
}

func (c *CreateOutputOutputCloudflareR2) GetHeaderLine() *string {
	if c == nil {
		return nil
	}
	return c.HeaderLine
}

func (c *CreateOutputOutputCloudflareR2) GetWriteHighWaterMark() *float64 {
	if c == nil {
		return nil
	}
	return c.WriteHighWaterMark
}

func (c *CreateOutputOutputCloudflareR2) GetOnBackpressure() *components.BackpressureBehaviorOptions1 {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputCloudflareR2) GetDeadletterEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.DeadletterEnabled
}

func (c *CreateOutputOutputCloudflareR2) GetOnDiskFullBackpressure() *components.DiskSpaceProtectionOptions {
	if c == nil {
		return nil
	}
	return c.OnDiskFullBackpressure
}

func (c *CreateOutputOutputCloudflareR2) GetForceCloseOnShutdown() *bool {
	if c == nil {
		return nil
	}
	return c.ForceCloseOnShutdown
}

func (c *CreateOutputOutputCloudflareR2) GetRetrySettings() *components.RetrySettingsType {
	if c == nil {
		return nil
	}
	return c.RetrySettings
}

func (c *CreateOutputOutputCloudflareR2) GetMaxFileOpenTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileOpenTimeSec
}

func (c *CreateOutputOutputCloudflareR2) GetMaxFileIdleTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileIdleTimeSec
}

func (c *CreateOutputOutputCloudflareR2) GetMaxConcurrentFileParts() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxConcurrentFileParts
}

func (c *CreateOutputOutputCloudflareR2) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputCloudflareR2) GetAwsSecret() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecret
}

func (c *CreateOutputOutputCloudflareR2) GetCompress() *components.CompressionOptions2 {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputCloudflareR2) GetCompressionLevel() *components.CompressionLevelOptions {
	if c == nil {
		return nil
	}
	return c.CompressionLevel
}

func (c *CreateOutputOutputCloudflareR2) GetAutomaticSchema() *bool {
	if c == nil {
		return nil
	}
	return c.AutomaticSchema
}

func (c *CreateOutputOutputCloudflareR2) GetParquetSchema() *string {
	if c == nil {
		return nil
	}
	return c.ParquetSchema
}

func (c *CreateOutputOutputCloudflareR2) GetParquetVersion() *components.ParquetVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetVersion
}

func (c *CreateOutputOutputCloudflareR2) GetParquetDataPageVersion() *components.DataPageVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetDataPageVersion
}

func (c *CreateOutputOutputCloudflareR2) GetParquetRowGroupLength() *float64 {
	if c == nil {
		return nil
	}
	return c.ParquetRowGroupLength
}

func (c *CreateOutputOutputCloudflareR2) GetParquetPageSize() *string {
	if c == nil {
		return nil
	}
	return c.ParquetPageSize
}

func (c *CreateOutputOutputCloudflareR2) GetShouldLogInvalidRows() *bool {
	if c == nil {
		return nil
	}
	return c.ShouldLogInvalidRows
}

func (c *CreateOutputOutputCloudflareR2) GetKeyValueMetadata() []components.ItemsTypeKeyValueMetadata {
	if c == nil {
		return nil
	}
	return c.KeyValueMetadata
}

func (c *CreateOutputOutputCloudflareR2) GetEnableStatistics() *bool {
	if c == nil {
		return nil
	}
	return c.EnableStatistics
}

func (c *CreateOutputOutputCloudflareR2) GetEnableWritePageIndex() *bool {
	if c == nil {
		return nil
	}
	return c.EnableWritePageIndex
}

func (c *CreateOutputOutputCloudflareR2) GetEnablePageChecksum() *bool {
	if c == nil {
		return nil
	}
	return c.EnablePageChecksum
}

func (c *CreateOutputOutputCloudflareR2) GetEmptyDirCleanupSec() *float64 {
	if c == nil {
		return nil
	}
	return c.EmptyDirCleanupSec
}

func (c *CreateOutputOutputCloudflareR2) GetDirectoryBatchSize() *float64 {
	if c == nil {
		return nil
	}
	return c.DirectoryBatchSize
}

func (c *CreateOutputOutputCloudflareR2) GetDeadletterPath() *string {
	if c == nil {
		return nil
	}
	return c.DeadletterPath
}

func (c *CreateOutputOutputCloudflareR2) GetMaxRetryNum() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRetryNum
}

func (c *CreateOutputOutputCloudflareR2) GetTemplateBucket() *string {
	if c == nil {
		return nil
	}
	return c.TemplateBucket
}

func (c *CreateOutputOutputCloudflareR2) GetTemplateFormat() *string {
	if c == nil {
		return nil
	}
	return c.TemplateFormat
}

type CreateOutputTypeMicrosoftFabric string

const (
	CreateOutputTypeMicrosoftFabricMicrosoftFabric CreateOutputTypeMicrosoftFabric = "microsoft_fabric"
)

func (e CreateOutputTypeMicrosoftFabric) ToPointer() *CreateOutputTypeMicrosoftFabric {
	return &e
}
func (e *CreateOutputTypeMicrosoftFabric) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "microsoft_fabric":
		*e = CreateOutputTypeMicrosoftFabric(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeMicrosoftFabric: %v", v)
	}
}

type CreateOutputClientSecretAuthTypeAuthenticationMethod string

const (
	CreateOutputClientSecretAuthTypeAuthenticationMethodSecret      CreateOutputClientSecretAuthTypeAuthenticationMethod = "secret"
	CreateOutputClientSecretAuthTypeAuthenticationMethodCertificate CreateOutputClientSecretAuthTypeAuthenticationMethod = "certificate"
)

func (e CreateOutputClientSecretAuthTypeAuthenticationMethod) ToPointer() *CreateOutputClientSecretAuthTypeAuthenticationMethod {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputClientSecretAuthTypeAuthenticationMethod) IsExact() bool {
	if e != nil {
		switch *e {
		case "secret", "certificate":
			return true
		}
	}
	return false
}

// CreateOutputAuthentication - Authentication parameters to use when connecting to bootstrap server. Using TLS is highly recommended.
type CreateOutputAuthentication struct {
	Disabled  bool                                  `json:"disabled"`
	Mechanism *components.SaslMechanismOptionsSasl1 `json:"mechanism,omitempty"`
	// The username for authentication. This should always be $ConnectionString.
	Username *string `json:"username,omitempty"`
	// Select or create a stored text secret corresponding to the SASL JASS Password Primary or Password Secondary
	TextSecret           *string                                               `json:"textSecret,omitempty"`
	ClientSecretAuthType *CreateOutputClientSecretAuthTypeAuthenticationMethod `json:"clientSecretAuthType,omitempty"`
	// Select or create a stored text secret
	ClientTextSecret *string `json:"clientTextSecret,omitempty"`
	// Select or create a stored certificate
	CertificateName *string `json:"certificateName,omitempty"`
	CertPath        *string `json:"certPath,omitempty"`
	PrivKeyPath     *string `json:"privKeyPath,omitempty"`
	Passphrase      *string `json:"passphrase,omitempty"`
	// Endpoint used to acquire authentication tokens from Azure
	OauthEndpoint *components.MicrosoftEntraIDAuthenticationEndpointOptionsSasl `json:"oauthEndpoint,omitempty"`
	// client_id to pass in the OAuth request parameter
	ClientID *string `json:"clientId,omitempty"`
	// Directory ID (tenant identifier) in Azure Active Directory
	TenantID *string `json:"tenantId,omitempty"`
	// Scope to pass in the OAuth request parameter
	Scope *string `json:"scope,omitempty"`
}

func (c CreateOutputAuthentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputAuthentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"disabled"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputAuthentication) GetDisabled() bool {
	if c == nil {
		return false
	}
	return c.Disabled
}

func (c *CreateOutputAuthentication) GetMechanism() *components.SaslMechanismOptionsSasl1 {
	if c == nil {
		return nil
	}
	return c.Mechanism
}

func (c *CreateOutputAuthentication) GetUsername() *string {
	if c == nil {
		return nil
	}
	return c.Username
}

func (c *CreateOutputAuthentication) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputAuthentication) GetClientSecretAuthType() *CreateOutputClientSecretAuthTypeAuthenticationMethod {
	if c == nil {
		return nil
	}
	return c.ClientSecretAuthType
}

func (c *CreateOutputAuthentication) GetClientTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.ClientTextSecret
}

func (c *CreateOutputAuthentication) GetCertificateName() *string {
	if c == nil {
		return nil
	}
	return c.CertificateName
}

func (c *CreateOutputAuthentication) GetCertPath() *string {
	if c == nil {
		return nil
	}
	return c.CertPath
}

func (c *CreateOutputAuthentication) GetPrivKeyPath() *string {
	if c == nil {
		return nil
	}
	return c.PrivKeyPath
}

func (c *CreateOutputAuthentication) GetPassphrase() *string {
	if c == nil {
		return nil
	}
	return c.Passphrase
}

func (c *CreateOutputAuthentication) GetOauthEndpoint() *components.MicrosoftEntraIDAuthenticationEndpointOptionsSasl {
	if c == nil {
		return nil
	}
	return c.OauthEndpoint
}

func (c *CreateOutputAuthentication) GetClientID() *string {
	if c == nil {
		return nil
	}
	return c.ClientID
}

func (c *CreateOutputAuthentication) GetTenantID() *string {
	if c == nil {
		return nil
	}
	return c.TenantID
}

func (c *CreateOutputAuthentication) GetScope() *string {
	if c == nil {
		return nil
	}
	return c.Scope
}

type CreateOutputPqControlsMicrosoftFabric struct {
}

func (c CreateOutputPqControlsMicrosoftFabric) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsMicrosoftFabric) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputMicrosoftFabric struct {
	// Unique ID for this output
	ID   string                          `json:"id"`
	Type CreateOutputTypeMicrosoftFabric `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Topic name from Fabric Eventstream's endpoint
	Topic string `json:"topic"`
	// Control the number of required acknowledgments
	Ack *components.AcknowledgmentsOptions `json:"ack,omitempty"`
	// Format to use to serialize events before writing to the Event Hubs Kafka brokers
	Format *components.RecordDataFormatOptions `json:"format,omitempty"`
	// Maximum size of each record batch before compression. Setting should be < message.max.bytes settings in Event Hubs brokers.
	MaxRecordSizeKB *float64 `json:"maxRecordSizeKB,omitempty"`
	// Maximum number of events in a batch before forcing a flush
	FlushEventCount *float64 `json:"flushEventCount,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `json:"requestTimeout,omitempty"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `json:"maxRetries,omitempty"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `json:"maxBackOff,omitempty"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `json:"initialBackoff,omitempty"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `json:"backoffRate,omitempty"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `json:"authenticationTimeout,omitempty"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `json:"reauthenticationThreshold,omitempty"`
	// Authentication parameters to use when connecting to bootstrap server. Using TLS is highly recommended.
	Sasl *CreateOutputAuthentication           `json:"sasl,omitempty"`
	TLS  *components.TLSSettingsClientSideType `json:"tls,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Bootstrap server from Fabric Eventstream's endpoint
	BootstrapServer string  `json:"bootstrap_server"`
	Description     *string `json:"description,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions   `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsMicrosoftFabric `json:"pqControls,omitempty"`
	// Binds 'topic' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'topic' at runtime.
	TemplateTopic *string `json:"__template_topic,omitempty"`
	// Binds 'bootstrap_server' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'bootstrap_server' at runtime.
	TemplateBootstrapServer *string `json:"__template_bootstrap_server,omitempty"`
}

func (c CreateOutputOutputMicrosoftFabric) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputMicrosoftFabric) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "topic", "bootstrap_server"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputMicrosoftFabric) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputMicrosoftFabric) GetType() CreateOutputTypeMicrosoftFabric {
	if c == nil {
		return CreateOutputTypeMicrosoftFabric("")
	}
	return c.Type
}

func (c *CreateOutputOutputMicrosoftFabric) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputMicrosoftFabric) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputMicrosoftFabric) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputMicrosoftFabric) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputMicrosoftFabric) GetTopic() string {
	if c == nil {
		return ""
	}
	return c.Topic
}

func (c *CreateOutputOutputMicrosoftFabric) GetAck() *components.AcknowledgmentsOptions {
	if c == nil {
		return nil
	}
	return c.Ack
}

func (c *CreateOutputOutputMicrosoftFabric) GetFormat() *components.RecordDataFormatOptions {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputMicrosoftFabric) GetMaxRecordSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRecordSizeKB
}

func (c *CreateOutputOutputMicrosoftFabric) GetFlushEventCount() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushEventCount
}

func (c *CreateOutputOutputMicrosoftFabric) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputMicrosoftFabric) GetConnectionTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.ConnectionTimeout
}

func (c *CreateOutputOutputMicrosoftFabric) GetRequestTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.RequestTimeout
}

func (c *CreateOutputOutputMicrosoftFabric) GetMaxRetries() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRetries
}

func (c *CreateOutputOutputMicrosoftFabric) GetMaxBackOff() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxBackOff
}

func (c *CreateOutputOutputMicrosoftFabric) GetInitialBackoff() *float64 {
	if c == nil {
		return nil
	}
	return c.InitialBackoff
}

func (c *CreateOutputOutputMicrosoftFabric) GetBackoffRate() *float64 {
	if c == nil {
		return nil
	}
	return c.BackoffRate
}

func (c *CreateOutputOutputMicrosoftFabric) GetAuthenticationTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.AuthenticationTimeout
}

func (c *CreateOutputOutputMicrosoftFabric) GetReauthenticationThreshold() *float64 {
	if c == nil {
		return nil
	}
	return c.ReauthenticationThreshold
}

func (c *CreateOutputOutputMicrosoftFabric) GetSasl() *CreateOutputAuthentication {
	if c == nil {
		return nil
	}
	return c.Sasl
}

func (c *CreateOutputOutputMicrosoftFabric) GetTLS() *components.TLSSettingsClientSideType {
	if c == nil {
		return nil
	}
	return c.TLS
}

func (c *CreateOutputOutputMicrosoftFabric) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputMicrosoftFabric) GetBootstrapServer() string {
	if c == nil {
		return ""
	}
	return c.BootstrapServer
}

func (c *CreateOutputOutputMicrosoftFabric) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputMicrosoftFabric) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputMicrosoftFabric) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputMicrosoftFabric) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputMicrosoftFabric) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputMicrosoftFabric) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputMicrosoftFabric) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputMicrosoftFabric) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputMicrosoftFabric) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputMicrosoftFabric) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputMicrosoftFabric) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputMicrosoftFabric) GetPqControls() *CreateOutputPqControlsMicrosoftFabric {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputMicrosoftFabric) GetTemplateTopic() *string {
	if c == nil {
		return nil
	}
	return c.TemplateTopic
}

func (c *CreateOutputOutputMicrosoftFabric) GetTemplateBootstrapServer() *string {
	if c == nil {
		return nil
	}
	return c.TemplateBootstrapServer
}

type CreateOutputTypeDatabricks string

const (
	CreateOutputTypeDatabricksDatabricks CreateOutputTypeDatabricks = "databricks"
)

func (e CreateOutputTypeDatabricks) ToPointer() *CreateOutputTypeDatabricks {
	return &e
}
func (e *CreateOutputTypeDatabricks) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "databricks":
		*e = CreateOutputTypeDatabricks(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeDatabricks: %v", v)
	}
}

type CreateOutputOutputDatabricks struct {
	// Unique ID for this output
	ID   string                     `json:"id"`
	Type CreateOutputTypeDatabricks `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Optional path to prepend to files before uploading.
	DestPath *string `json:"destPath,omitempty"`
	// Filesystem location in which to buffer files before compressing and moving to final destination. Use performant, stable storage.
	StagePath *string `json:"stagePath,omitempty"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
	PartitionExpr *string `json:"partitionExpr,omitempty"`
	// Format of the output data
	Format *components.DataFormatOptions `json:"format,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `json:"baseFileName,omitempty"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `json:"fileNameSuffix,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `json:"maxFileSizeMB,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `json:"maxOpenFiles,omitempty"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `json:"headerLine,omitempty"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `json:"writeHighWaterMark,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `json:"deadletterEnabled,omitempty"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *components.DiskSpaceProtectionOptions `json:"onDiskFullBackpressure,omitempty"`
	// Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
	ForceCloseOnShutdown *bool                         `json:"forceCloseOnShutdown,omitempty"`
	RetrySettings        *components.RetrySettingsType `json:"retrySettings,omitempty"`
	// Databricks workspace ID
	WorkspaceID string `json:"workspaceId"`
	// OAuth scope for Unity Catalog authentication
	Scope string `json:"scope"`
	// OAuth client ID for Unity Catalog authentication
	ClientID string `json:"clientId"`
	// Name of the catalog to use for the output
	Catalog string `json:"catalog"`
	// Name of the catalog schema to use for the output
	Schema string `json:"schema"`
	// Name of the events volume in Databricks
	EventsVolumeName string `json:"eventsVolumeName"`
	// OAuth client secret for Unity Catalog authentication
	ClientTextSecret string `json:"clientTextSecret"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec  *float64 `json:"timeoutSec,omitempty"`
	Description *string  `json:"description,omitempty"`
	// Data compression format to apply to HTTP content before it is delivered
	Compress *components.CompressionOptions2 `json:"compress,omitempty"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *components.CompressionLevelOptions `json:"compressionLevel,omitempty"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `json:"automaticSchema,omitempty"`
	// To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
	ParquetSchema *string `json:"parquetSchema,omitempty"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *components.ParquetVersionOptions `json:"parquetVersion,omitempty"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *components.DataPageVersionOptions `json:"parquetDataPageVersion,omitempty"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `json:"parquetRowGroupLength,omitempty"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
	KeyValueMetadata []components.ItemsTypeKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `json:"enableStatistics,omitempty"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `json:"enableWritePageIndex,omitempty"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `json:"enablePageChecksum,omitempty"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `json:"emptyDirCleanupSec,omitempty"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `json:"directoryBatchSize,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `json:"deadletterPath,omitempty"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `json:"maxRetryNum,omitempty"`
	// Binds 'format' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'format' at runtime.
	TemplateFormat *string `json:"__template_format,omitempty"`
}

func (c CreateOutputOutputDatabricks) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputDatabricks) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "workspaceId", "scope", "clientId", "catalog", "schema", "eventsVolumeName", "clientTextSecret"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputDatabricks) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputDatabricks) GetType() CreateOutputTypeDatabricks {
	if c == nil {
		return CreateOutputTypeDatabricks("")
	}
	return c.Type
}

func (c *CreateOutputOutputDatabricks) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputDatabricks) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputDatabricks) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputDatabricks) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputDatabricks) GetDestPath() *string {
	if c == nil {
		return nil
	}
	return c.DestPath
}

func (c *CreateOutputOutputDatabricks) GetStagePath() *string {
	if c == nil {
		return nil
	}
	return c.StagePath
}

func (c *CreateOutputOutputDatabricks) GetAddIDToStagePath() *bool {
	if c == nil {
		return nil
	}
	return c.AddIDToStagePath
}

func (c *CreateOutputOutputDatabricks) GetRemoveEmptyDirs() *bool {
	if c == nil {
		return nil
	}
	return c.RemoveEmptyDirs
}

func (c *CreateOutputOutputDatabricks) GetPartitionExpr() *string {
	if c == nil {
		return nil
	}
	return c.PartitionExpr
}

func (c *CreateOutputOutputDatabricks) GetFormat() *components.DataFormatOptions {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputDatabricks) GetBaseFileName() *string {
	if c == nil {
		return nil
	}
	return c.BaseFileName
}

func (c *CreateOutputOutputDatabricks) GetFileNameSuffix() *string {
	if c == nil {
		return nil
	}
	return c.FileNameSuffix
}

func (c *CreateOutputOutputDatabricks) GetMaxFileSizeMB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileSizeMB
}

func (c *CreateOutputOutputDatabricks) GetMaxFileOpenTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileOpenTimeSec
}

func (c *CreateOutputOutputDatabricks) GetMaxFileIdleTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileIdleTimeSec
}

func (c *CreateOutputOutputDatabricks) GetMaxOpenFiles() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxOpenFiles
}

func (c *CreateOutputOutputDatabricks) GetHeaderLine() *string {
	if c == nil {
		return nil
	}
	return c.HeaderLine
}

func (c *CreateOutputOutputDatabricks) GetWriteHighWaterMark() *float64 {
	if c == nil {
		return nil
	}
	return c.WriteHighWaterMark
}

func (c *CreateOutputOutputDatabricks) GetOnBackpressure() *components.BackpressureBehaviorOptions1 {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputDatabricks) GetDeadletterEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.DeadletterEnabled
}

func (c *CreateOutputOutputDatabricks) GetOnDiskFullBackpressure() *components.DiskSpaceProtectionOptions {
	if c == nil {
		return nil
	}
	return c.OnDiskFullBackpressure
}

func (c *CreateOutputOutputDatabricks) GetForceCloseOnShutdown() *bool {
	if c == nil {
		return nil
	}
	return c.ForceCloseOnShutdown
}

func (c *CreateOutputOutputDatabricks) GetRetrySettings() *components.RetrySettingsType {
	if c == nil {
		return nil
	}
	return c.RetrySettings
}

func (c *CreateOutputOutputDatabricks) GetWorkspaceID() string {
	if c == nil {
		return ""
	}
	return c.WorkspaceID
}

func (c *CreateOutputOutputDatabricks) GetScope() string {
	if c == nil {
		return ""
	}
	return c.Scope
}

func (c *CreateOutputOutputDatabricks) GetClientID() string {
	if c == nil {
		return ""
	}
	return c.ClientID
}

func (c *CreateOutputOutputDatabricks) GetCatalog() string {
	if c == nil {
		return ""
	}
	return c.Catalog
}

func (c *CreateOutputOutputDatabricks) GetSchema() string {
	if c == nil {
		return ""
	}
	return c.Schema
}

func (c *CreateOutputOutputDatabricks) GetEventsVolumeName() string {
	if c == nil {
		return ""
	}
	return c.EventsVolumeName
}

func (c *CreateOutputOutputDatabricks) GetClientTextSecret() string {
	if c == nil {
		return ""
	}
	return c.ClientTextSecret
}

func (c *CreateOutputOutputDatabricks) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputDatabricks) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputDatabricks) GetCompress() *components.CompressionOptions2 {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputDatabricks) GetCompressionLevel() *components.CompressionLevelOptions {
	if c == nil {
		return nil
	}
	return c.CompressionLevel
}

func (c *CreateOutputOutputDatabricks) GetAutomaticSchema() *bool {
	if c == nil {
		return nil
	}
	return c.AutomaticSchema
}

func (c *CreateOutputOutputDatabricks) GetParquetSchema() *string {
	if c == nil {
		return nil
	}
	return c.ParquetSchema
}

func (c *CreateOutputOutputDatabricks) GetParquetVersion() *components.ParquetVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetVersion
}

func (c *CreateOutputOutputDatabricks) GetParquetDataPageVersion() *components.DataPageVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetDataPageVersion
}

func (c *CreateOutputOutputDatabricks) GetParquetRowGroupLength() *float64 {
	if c == nil {
		return nil
	}
	return c.ParquetRowGroupLength
}

func (c *CreateOutputOutputDatabricks) GetParquetPageSize() *string {
	if c == nil {
		return nil
	}
	return c.ParquetPageSize
}

func (c *CreateOutputOutputDatabricks) GetShouldLogInvalidRows() *bool {
	if c == nil {
		return nil
	}
	return c.ShouldLogInvalidRows
}

func (c *CreateOutputOutputDatabricks) GetKeyValueMetadata() []components.ItemsTypeKeyValueMetadata {
	if c == nil {
		return nil
	}
	return c.KeyValueMetadata
}

func (c *CreateOutputOutputDatabricks) GetEnableStatistics() *bool {
	if c == nil {
		return nil
	}
	return c.EnableStatistics
}

func (c *CreateOutputOutputDatabricks) GetEnableWritePageIndex() *bool {
	if c == nil {
		return nil
	}
	return c.EnableWritePageIndex
}

func (c *CreateOutputOutputDatabricks) GetEnablePageChecksum() *bool {
	if c == nil {
		return nil
	}
	return c.EnablePageChecksum
}

func (c *CreateOutputOutputDatabricks) GetEmptyDirCleanupSec() *float64 {
	if c == nil {
		return nil
	}
	return c.EmptyDirCleanupSec
}

func (c *CreateOutputOutputDatabricks) GetDirectoryBatchSize() *float64 {
	if c == nil {
		return nil
	}
	return c.DirectoryBatchSize
}

func (c *CreateOutputOutputDatabricks) GetDeadletterPath() *string {
	if c == nil {
		return nil
	}
	return c.DeadletterPath
}

func (c *CreateOutputOutputDatabricks) GetMaxRetryNum() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRetryNum
}

func (c *CreateOutputOutputDatabricks) GetTemplateFormat() *string {
	if c == nil {
		return nil
	}
	return c.TemplateFormat
}

type CreateOutputTypeChronicle string

const (
	CreateOutputTypeChronicleChronicle CreateOutputTypeChronicle = "chronicle"
)

func (e CreateOutputTypeChronicle) ToPointer() *CreateOutputTypeChronicle {
	return &e
}
func (e *CreateOutputTypeChronicle) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "chronicle":
		*e = CreateOutputTypeChronicle(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeChronicle: %v", v)
	}
}

type CreateOutputAuthenticationMethodChronicle string

const (
	CreateOutputAuthenticationMethodChronicleServiceAccount       CreateOutputAuthenticationMethodChronicle = "serviceAccount"
	CreateOutputAuthenticationMethodChronicleServiceAccountSecret CreateOutputAuthenticationMethodChronicle = "serviceAccountSecret"
)

func (e CreateOutputAuthenticationMethodChronicle) ToPointer() *CreateOutputAuthenticationMethodChronicle {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputAuthenticationMethodChronicle) IsExact() bool {
	if e != nil {
		switch *e {
		case "serviceAccount", "serviceAccountSecret":
			return true
		}
	}
	return false
}

type CreateOutputCustomLabel struct {
	Key   string `json:"key"`
	Value string `json:"value"`
	// Designate this label for role-based access control and filtering
	RbacEnabled *bool `json:"rbacEnabled,omitempty"`
}

func (c CreateOutputCustomLabel) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputCustomLabel) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"key", "value"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputCustomLabel) GetKey() string {
	if c == nil {
		return ""
	}
	return c.Key
}

func (c *CreateOutputCustomLabel) GetValue() string {
	if c == nil {
		return ""
	}
	return c.Value
}

func (c *CreateOutputCustomLabel) GetRbacEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.RbacEnabled
}

type CreateOutputPqControlsChronicle struct {
}

func (c CreateOutputPqControlsChronicle) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsChronicle) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputChronicle struct {
	// Unique ID for this output
	ID   string                    `json:"id"`
	Type CreateOutputTypeChronicle `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags           []string                                   `json:"streamtags,omitempty"`
	APIVersion           *string                                    `json:"apiVersion,omitempty"`
	AuthenticationMethod *CreateOutputAuthenticationMethodChronicle `json:"authenticationMethod,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// Regional endpoint to send events to
	Region string `json:"region"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	IngestionMethod    *string  `json:"ingestionMethod,omitempty"`
	// User-configured environment namespace to identify the data domain the logs originated from. This namespace is used as a tag to identify the appropriate data domain for indexing and enrichment functionality. Can be overwritten by event field __namespace.
	Namespace *string `json:"namespace,omitempty"`
	// Default log type value to send to SecOps. Can be overwritten by event field __logType.
	LogType string `json:"logType"`
	// Name of the event field that contains the log text to send. If not specified, Stream sends a JSON representation of the whole event.
	LogTextField *string `json:"logTextField,omitempty"`
	// The Google Cloud Platform (GCP) project ID to send events to
	GcpProjectID string `json:"gcpProjectId"`
	// The Google Cloud Platform (GCP) instance to send events to. This is the Chronicle customer uuid.
	GcpInstance string `json:"gcpInstance"`
	// Custom labels to be added to every event
	CustomLabels []CreateOutputCustomLabel `json:"customLabels,omitempty"`
	Description  *string                   `json:"description,omitempty"`
	// Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
	ServiceAccountCredentials *string `json:"serviceAccountCredentials,omitempty"`
	// Select or create a stored text secret
	ServiceAccountCredentialsSecret *string `json:"serviceAccountCredentialsSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsChronicle     `json:"pqControls,omitempty"`
	// Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime.
	TemplateRegion *string `json:"__template_region,omitempty"`
}

func (c CreateOutputOutputChronicle) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputChronicle) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "region", "logType", "gcpProjectId", "gcpInstance"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputChronicle) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputChronicle) GetType() CreateOutputTypeChronicle {
	if c == nil {
		return CreateOutputTypeChronicle("")
	}
	return c.Type
}

func (c *CreateOutputOutputChronicle) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputChronicle) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputChronicle) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputChronicle) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputChronicle) GetAPIVersion() *string {
	if c == nil {
		return nil
	}
	return c.APIVersion
}

func (c *CreateOutputOutputChronicle) GetAuthenticationMethod() *CreateOutputAuthenticationMethodChronicle {
	if c == nil {
		return nil
	}
	return c.AuthenticationMethod
}

func (c *CreateOutputOutputChronicle) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputChronicle) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputChronicle) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputChronicle) GetRegion() string {
	if c == nil {
		return ""
	}
	return c.Region
}

func (c *CreateOutputOutputChronicle) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputChronicle) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputChronicle) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputChronicle) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputChronicle) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputChronicle) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputChronicle) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputChronicle) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputChronicle) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputChronicle) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputChronicle) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputChronicle) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputChronicle) GetTotalMemoryLimitKB() *float64 {
	if c == nil {
		return nil
	}
	return c.TotalMemoryLimitKB
}

func (c *CreateOutputOutputChronicle) GetIngestionMethod() *string {
	if c == nil {
		return nil
	}
	return c.IngestionMethod
}

func (c *CreateOutputOutputChronicle) GetNamespace() *string {
	if c == nil {
		return nil
	}
	return c.Namespace
}

func (c *CreateOutputOutputChronicle) GetLogType() string {
	if c == nil {
		return ""
	}
	return c.LogType
}

func (c *CreateOutputOutputChronicle) GetLogTextField() *string {
	if c == nil {
		return nil
	}
	return c.LogTextField
}

func (c *CreateOutputOutputChronicle) GetGcpProjectID() string {
	if c == nil {
		return ""
	}
	return c.GcpProjectID
}

func (c *CreateOutputOutputChronicle) GetGcpInstance() string {
	if c == nil {
		return ""
	}
	return c.GcpInstance
}

func (c *CreateOutputOutputChronicle) GetCustomLabels() []CreateOutputCustomLabel {
	if c == nil {
		return nil
	}
	return c.CustomLabels
}

func (c *CreateOutputOutputChronicle) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputChronicle) GetServiceAccountCredentials() *string {
	if c == nil {
		return nil
	}
	return c.ServiceAccountCredentials
}

func (c *CreateOutputOutputChronicle) GetServiceAccountCredentialsSecret() *string {
	if c == nil {
		return nil
	}
	return c.ServiceAccountCredentialsSecret
}

func (c *CreateOutputOutputChronicle) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputChronicle) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputChronicle) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputChronicle) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputChronicle) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputChronicle) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputChronicle) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputChronicle) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputChronicle) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputChronicle) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputChronicle) GetPqControls() *CreateOutputPqControlsChronicle {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputChronicle) GetTemplateRegion() *string {
	if c == nil {
		return nil
	}
	return c.TemplateRegion
}

type CreateOutputTypeSentinelOneAiSiem string

const (
	CreateOutputTypeSentinelOneAiSiemSentinelOneAiSiem CreateOutputTypeSentinelOneAiSiem = "sentinel_one_ai_siem"
)

func (e CreateOutputTypeSentinelOneAiSiem) ToPointer() *CreateOutputTypeSentinelOneAiSiem {
	return &e
}
func (e *CreateOutputTypeSentinelOneAiSiem) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sentinel_one_ai_siem":
		*e = CreateOutputTypeSentinelOneAiSiem(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeSentinelOneAiSiem: %v", v)
	}
}

// CreateOutputRegion - The SentinelOne region to send events to. In most cases you can find the region by either looking at your SentinelOne URL or knowing what geographic region your SentinelOne instance is contained in.
type CreateOutputRegion string

const (
	CreateOutputRegionUs     CreateOutputRegion = "US"
	CreateOutputRegionCa     CreateOutputRegion = "CA"
	CreateOutputRegionEmea   CreateOutputRegion = "EMEA"
	CreateOutputRegionAp     CreateOutputRegion = "AP"
	CreateOutputRegionAps    CreateOutputRegion = "APS"
	CreateOutputRegionAu     CreateOutputRegion = "AU"
	CreateOutputRegionCustom CreateOutputRegion = "Custom"
)

func (e CreateOutputRegion) ToPointer() *CreateOutputRegion {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputRegion) IsExact() bool {
	if e != nil {
		switch *e {
		case "US", "CA", "EMEA", "AP", "APS", "AU", "Custom":
			return true
		}
	}
	return false
}

// CreateOutputAISIEMEndpointPath - Endpoint to send events to. Use /services/collector/event for structured JSON payloads with standard HEC top-level fields. Use /services/collector/raw for unstructured log lines (plain text).
type CreateOutputAISIEMEndpointPath string

const (
	CreateOutputAISIEMEndpointPathRootServicesCollectorEvent CreateOutputAISIEMEndpointPath = "/services/collector/event"
	CreateOutputAISIEMEndpointPathRootServicesCollectorRaw   CreateOutputAISIEMEndpointPath = "/services/collector/raw"
)

func (e CreateOutputAISIEMEndpointPath) ToPointer() *CreateOutputAISIEMEndpointPath {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputAISIEMEndpointPath) IsExact() bool {
	if e != nil {
		switch *e {
		case "/services/collector/event", "/services/collector/raw":
			return true
		}
	}
	return false
}

type CreateOutputPqControlsSentinelOneAiSiem struct {
}

func (c CreateOutputPqControlsSentinelOneAiSiem) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsSentinelOneAiSiem) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputSentinelOneAiSiem struct {
	// Unique ID for this output
	ID   string                            `json:"id"`
	Type CreateOutputTypeSentinelOneAiSiem `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The SentinelOne region to send events to. In most cases you can find the region by either looking at your SentinelOne URL or knowing what geographic region your SentinelOne instance is contained in.
	Region CreateOutputRegion `json:"region"`
	// Endpoint to send events to. Use /services/collector/event for structured JSON payloads with standard HEC top-level fields. Use /services/collector/raw for unstructured log lines (plain text).
	Endpoint CreateOutputAISIEMEndpointPath `json:"endpoint"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// In the SentinelOne Console select Policy & Settings then select the Singularity AI SIEM section, API Keys will be at the bottom. Under Log Access Keys select a Write token and copy it here
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Base URL of the endpoint used to send events to, such as https://<Your-S1-Tenant>.sentinelone.net. Must begin with http:// or https://, can include a port number, and no trailing slashes. Matches pattern: ^https?://[a-zA-Z0-9.-]+(:[0-9]+)?$.
	BaseURL *string `json:"baseUrl,omitempty"`
	// Define serverHost for events using a JavaScript expression. You must enclose text constants in quotes (such as, 'myServer').
	HostExpression *string `json:"hostExpression,omitempty"`
	// Define logFile for events using a JavaScript expression. You must enclose text constants in quotes (such as, 'myLogFile.txt').
	SourceExpression *string `json:"sourceExpression,omitempty"`
	// Define the parser for events using a JavaScript expression. This value helps parse data into AI SIEM. You must enclose text constants in quotes (such as, 'dottedJson'). For custom parsers, substitute 'dottedJson' with your parser's name.
	SourceTypeExpression *string `json:"sourceTypeExpression,omitempty"`
	// Define the dataSource.category for events using a JavaScript expression. This value helps categorize data and helps enable extra features in SentinelOne AI SIEM. You must enclose text constants in quotes. The default value is 'security'.
	DataSourceCategoryExpression *string `json:"dataSourceCategoryExpression,omitempty"`
	// Define the dataSource.name for events using a JavaScript expression. This value should reflect the type of data being inserted into AI SIEM. You must enclose text constants in quotes (such as, 'networkActivity' or 'authLogs').
	DataSourceNameExpression *string `json:"dataSourceNameExpression,omitempty"`
	// Define the dataSource.vendor for events using a JavaScript expression. This value should reflect the vendor of the data being inserted into AI SIEM. You must enclose text constants in quotes (such as, 'Cisco' or 'Microsoft').
	DataSourceVendorExpression *string `json:"dataSourceVendorExpression,omitempty"`
	// Optionally, define the event.type for events using a JavaScript expression. This value acts as a label, grouping events into meaningful categories. You must enclose text constants in quotes (such as, 'Process Creation' or 'Network Connection').
	EventTypeExpression *string `json:"eventTypeExpression,omitempty"`
	// Define the serverHost for events using a JavaScript expression. This value will be passed to AI SIEM. You must enclose text constants in quotes (such as, 'myServerName').
	Host *string `json:"host,omitempty"`
	// Specify the logFile value to pass as a parameter to SentinelOne AI SIEM. Don't quote this value. The default is cribl.
	Source *string `json:"source,omitempty"`
	// Specify the sourcetype parameter for SentinelOne AI SIEM, which determines the parser. Don't quote this value. For custom parsers, substitute hecRawParser with your parser's name. The default is hecRawParser.
	SourceType *string `json:"sourceType,omitempty"`
	// Specify the dataSource.category value to pass as a parameter to SentinelOne AI SIEM. This value helps categorize data and enables additional features. Don't quote this value. The default is security.
	DataSourceCategory *string `json:"dataSourceCategory,omitempty"`
	// Specify the dataSource.name value to pass as a parameter to AI SIEM. This value should reflect the type of data being inserted. Don't quote this value. The default is cribl.
	DataSourceName *string `json:"dataSourceName,omitempty"`
	// Specify the dataSource.vendorvalue to pass as a parameter to AI SIEM. This value should reflect the vendor of the data being inserted. Don't quote this value. The default is cribl.
	DataSourceVendor *string `json:"dataSourceVendor,omitempty"`
	// Specify the event.type value to pass as an optional parameter to AI SIEM. This value acts as a label, grouping events into meaningful categories like Process Creation, File Modification, or Network Connection. Don't quote this value. By default, this field is empty.
	EventType *string `json:"eventType,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions     `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsSentinelOneAiSiem `json:"pqControls,omitempty"`
}

func (c CreateOutputOutputSentinelOneAiSiem) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputSentinelOneAiSiem) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "region", "endpoint"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetType() CreateOutputTypeSentinelOneAiSiem {
	if c == nil {
		return CreateOutputTypeSentinelOneAiSiem("")
	}
	return c.Type
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetRegion() CreateOutputRegion {
	if c == nil {
		return CreateOutputRegion("")
	}
	return c.Region
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetEndpoint() CreateOutputAISIEMEndpointPath {
	if c == nil {
		return CreateOutputAISIEMEndpointPath("")
	}
	return c.Endpoint
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetToken() *string {
	if c == nil {
		return nil
	}
	return c.Token
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetBaseURL() *string {
	if c == nil {
		return nil
	}
	return c.BaseURL
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetHostExpression() *string {
	if c == nil {
		return nil
	}
	return c.HostExpression
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetSourceExpression() *string {
	if c == nil {
		return nil
	}
	return c.SourceExpression
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetSourceTypeExpression() *string {
	if c == nil {
		return nil
	}
	return c.SourceTypeExpression
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetDataSourceCategoryExpression() *string {
	if c == nil {
		return nil
	}
	return c.DataSourceCategoryExpression
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetDataSourceNameExpression() *string {
	if c == nil {
		return nil
	}
	return c.DataSourceNameExpression
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetDataSourceVendorExpression() *string {
	if c == nil {
		return nil
	}
	return c.DataSourceVendorExpression
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetEventTypeExpression() *string {
	if c == nil {
		return nil
	}
	return c.EventTypeExpression
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetHost() *string {
	if c == nil {
		return nil
	}
	return c.Host
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetSource() *string {
	if c == nil {
		return nil
	}
	return c.Source
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetSourceType() *string {
	if c == nil {
		return nil
	}
	return c.SourceType
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetDataSourceCategory() *string {
	if c == nil {
		return nil
	}
	return c.DataSourceCategory
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetDataSourceName() *string {
	if c == nil {
		return nil
	}
	return c.DataSourceName
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetDataSourceVendor() *string {
	if c == nil {
		return nil
	}
	return c.DataSourceVendor
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetEventType() *string {
	if c == nil {
		return nil
	}
	return c.EventType
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputSentinelOneAiSiem) GetPqControls() *CreateOutputPqControlsSentinelOneAiSiem {
	if c == nil {
		return nil
	}
	return c.PqControls
}

type CreateOutputTypeDynatraceOtlp string

const (
	CreateOutputTypeDynatraceOtlpDynatraceOtlp CreateOutputTypeDynatraceOtlp = "dynatrace_otlp"
)

func (e CreateOutputTypeDynatraceOtlp) ToPointer() *CreateOutputTypeDynatraceOtlp {
	return &e
}
func (e *CreateOutputTypeDynatraceOtlp) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "dynatrace_otlp":
		*e = CreateOutputTypeDynatraceOtlp(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeDynatraceOtlp: %v", v)
	}
}

// CreateOutputProtocolDynatraceOtlp - Select a transport option for Dynatrace
type CreateOutputProtocolDynatraceOtlp string

const (
	// CreateOutputProtocolDynatraceOtlpHTTP HTTP
	CreateOutputProtocolDynatraceOtlpHTTP CreateOutputProtocolDynatraceOtlp = "http"
)

func (e CreateOutputProtocolDynatraceOtlp) ToPointer() *CreateOutputProtocolDynatraceOtlp {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputProtocolDynatraceOtlp) IsExact() bool {
	if e != nil {
		switch *e {
		case "http":
			return true
		}
	}
	return false
}

// CreateOutputEndpointType - Select the type of Dynatrace endpoint configured
type CreateOutputEndpointType string

const (
	// CreateOutputEndpointTypeSaas SaaS
	CreateOutputEndpointTypeSaas CreateOutputEndpointType = "saas"
	// CreateOutputEndpointTypeAg ActiveGate
	CreateOutputEndpointTypeAg CreateOutputEndpointType = "ag"
)

func (e CreateOutputEndpointType) ToPointer() *CreateOutputEndpointType {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputEndpointType) IsExact() bool {
	if e != nil {
		switch *e {
		case "saas", "ag":
			return true
		}
	}
	return false
}

type CreateOutputPqControlsDynatraceOtlp struct {
}

func (c CreateOutputPqControlsDynatraceOtlp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsDynatraceOtlp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputDynatraceOtlp struct {
	// Unique ID for this output
	ID   string                        `json:"id"`
	Type CreateOutputTypeDynatraceOtlp `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Select a transport option for Dynatrace
	Protocol CreateOutputProtocolDynatraceOtlp `json:"protocol"`
	// The endpoint where Dynatrace events will be sent. Enter any valid URL or an IP address (IPv4 or IPv6; enclose IPv6 addresses in square brackets)
	Endpoint string `json:"endpoint"`
	// The version of OTLP Protobuf definitions to use when structuring data to send
	OtlpVersion components.OtlpVersionOptions1 `json:"otlpVersion"`
	// Type of compression to apply to messages sent to the OpenTelemetry endpoint
	Compress *components.CompressionOptions4 `json:"compress,omitempty"`
	// Type of compression to apply to messages sent to the OpenTelemetry endpoint
	HTTPCompress *components.CompressionOptions5 `json:"httpCompress,omitempty"`
	// If you want to send traces to the default `{endpoint}/v1/traces` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPTracesEndpointOverride *string `json:"httpTracesEndpointOverride,omitempty"`
	// If you want to send metrics to the default `{endpoint}/v1/metrics` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPMetricsEndpointOverride *string `json:"httpMetricsEndpointOverride,omitempty"`
	// If you want to send logs to the default `{endpoint}/v1/logs` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPLogsEndpointOverride *string `json:"httpLogsEndpointOverride,omitempty"`
	// List of key-value pairs to send with each gRPC request. Value supports JavaScript expressions that are evaluated just once, when the destination gets started. To pass credentials as metadata, use 'C.Secret'.
	Metadata []components.ItemsTypeKeyValueMetadata `json:"metadata,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size (in KB) of the request body. The maximum payload size is 4 MB. If this limit is exceeded, the entire OTLP message is dropped
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// How often the sender should ping the peer to keep the connection open
	KeepAliveTime *float64 `json:"keepAliveTime,omitempty"`
	// Disable to close the connection immediately after sending the outgoing request
	KeepAlive *bool `json:"keepAlive,omitempty"`
	// Select the type of Dynatrace endpoint configured
	EndpointType CreateOutputEndpointType `json:"endpointType"`
	// Select or create a stored text secret
	TokenSecret   string  `json:"tokenSecret"`
	AuthTokenName *string `json:"authTokenName,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsDynatraceOtlp `json:"pqControls,omitempty"`
}

func (c CreateOutputOutputDynatraceOtlp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputDynatraceOtlp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "protocol", "endpoint", "otlpVersion", "endpointType", "tokenSecret"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputDynatraceOtlp) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputDynatraceOtlp) GetType() CreateOutputTypeDynatraceOtlp {
	if c == nil {
		return CreateOutputTypeDynatraceOtlp("")
	}
	return c.Type
}

func (c *CreateOutputOutputDynatraceOtlp) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputDynatraceOtlp) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputDynatraceOtlp) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputDynatraceOtlp) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputDynatraceOtlp) GetProtocol() CreateOutputProtocolDynatraceOtlp {
	if c == nil {
		return CreateOutputProtocolDynatraceOtlp("")
	}
	return c.Protocol
}

func (c *CreateOutputOutputDynatraceOtlp) GetEndpoint() string {
	if c == nil {
		return ""
	}
	return c.Endpoint
}

func (c *CreateOutputOutputDynatraceOtlp) GetOtlpVersion() components.OtlpVersionOptions1 {
	if c == nil {
		return components.OtlpVersionOptions1("")
	}
	return c.OtlpVersion
}

func (c *CreateOutputOutputDynatraceOtlp) GetCompress() *components.CompressionOptions4 {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputDynatraceOtlp) GetHTTPCompress() *components.CompressionOptions5 {
	if c == nil {
		return nil
	}
	return c.HTTPCompress
}

func (c *CreateOutputOutputDynatraceOtlp) GetHTTPTracesEndpointOverride() *string {
	if c == nil {
		return nil
	}
	return c.HTTPTracesEndpointOverride
}

func (c *CreateOutputOutputDynatraceOtlp) GetHTTPMetricsEndpointOverride() *string {
	if c == nil {
		return nil
	}
	return c.HTTPMetricsEndpointOverride
}

func (c *CreateOutputOutputDynatraceOtlp) GetHTTPLogsEndpointOverride() *string {
	if c == nil {
		return nil
	}
	return c.HTTPLogsEndpointOverride
}

func (c *CreateOutputOutputDynatraceOtlp) GetMetadata() []components.ItemsTypeKeyValueMetadata {
	if c == nil {
		return nil
	}
	return c.Metadata
}

func (c *CreateOutputOutputDynatraceOtlp) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputDynatraceOtlp) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputDynatraceOtlp) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputDynatraceOtlp) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputDynatraceOtlp) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputDynatraceOtlp) GetConnectionTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.ConnectionTimeout
}

func (c *CreateOutputOutputDynatraceOtlp) GetKeepAliveTime() *float64 {
	if c == nil {
		return nil
	}
	return c.KeepAliveTime
}

func (c *CreateOutputOutputDynatraceOtlp) GetKeepAlive() *bool {
	if c == nil {
		return nil
	}
	return c.KeepAlive
}

func (c *CreateOutputOutputDynatraceOtlp) GetEndpointType() CreateOutputEndpointType {
	if c == nil {
		return CreateOutputEndpointType("")
	}
	return c.EndpointType
}

func (c *CreateOutputOutputDynatraceOtlp) GetTokenSecret() string {
	if c == nil {
		return ""
	}
	return c.TokenSecret
}

func (c *CreateOutputOutputDynatraceOtlp) GetAuthTokenName() *string {
	if c == nil {
		return nil
	}
	return c.AuthTokenName
}

func (c *CreateOutputOutputDynatraceOtlp) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputDynatraceOtlp) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputDynatraceOtlp) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputDynatraceOtlp) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputDynatraceOtlp) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputDynatraceOtlp) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputDynatraceOtlp) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputDynatraceOtlp) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputDynatraceOtlp) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputDynatraceOtlp) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputDynatraceOtlp) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputDynatraceOtlp) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputDynatraceOtlp) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputDynatraceOtlp) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputDynatraceOtlp) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputDynatraceOtlp) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputDynatraceOtlp) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputDynatraceOtlp) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputDynatraceOtlp) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputDynatraceOtlp) GetPqControls() *CreateOutputPqControlsDynatraceOtlp {
	if c == nil {
		return nil
	}
	return c.PqControls
}

type CreateOutputTypeDynatraceHTTP string

const (
	CreateOutputTypeDynatraceHTTPDynatraceHTTP CreateOutputTypeDynatraceHTTP = "dynatrace_http"
)

func (e CreateOutputTypeDynatraceHTTP) ToPointer() *CreateOutputTypeDynatraceHTTP {
	return &e
}
func (e *CreateOutputTypeDynatraceHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "dynatrace_http":
		*e = CreateOutputTypeDynatraceHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeDynatraceHTTP: %v", v)
	}
}

type CreateOutputAuthenticationTypeDynatraceHTTP string

const (
	// CreateOutputAuthenticationTypeDynatraceHTTPToken Auth token
	CreateOutputAuthenticationTypeDynatraceHTTPToken CreateOutputAuthenticationTypeDynatraceHTTP = "token"
	// CreateOutputAuthenticationTypeDynatraceHTTPTextSecret Token (text secret)
	CreateOutputAuthenticationTypeDynatraceHTTPTextSecret CreateOutputAuthenticationTypeDynatraceHTTP = "textSecret"
)

func (e CreateOutputAuthenticationTypeDynatraceHTTP) ToPointer() *CreateOutputAuthenticationTypeDynatraceHTTP {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputAuthenticationTypeDynatraceHTTP) IsExact() bool {
	if e != nil {
		switch *e {
		case "token", "textSecret":
			return true
		}
	}
	return false
}

// CreateOutputFormatDynatraceHTTP - How to format events before sending. Defaults to JSON. Plaintext is not currently supported.
type CreateOutputFormatDynatraceHTTP string

const (
	// CreateOutputFormatDynatraceHTTPJSONArray JSON
	CreateOutputFormatDynatraceHTTPJSONArray CreateOutputFormatDynatraceHTTP = "json_array"
	// CreateOutputFormatDynatraceHTTPPlaintext Plaintext
	CreateOutputFormatDynatraceHTTPPlaintext CreateOutputFormatDynatraceHTTP = "plaintext"
)

func (e CreateOutputFormatDynatraceHTTP) ToPointer() *CreateOutputFormatDynatraceHTTP {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputFormatDynatraceHTTP) IsExact() bool {
	if e != nil {
		switch *e {
		case "json_array", "plaintext":
			return true
		}
	}
	return false
}

type CreateOutputEndpoint string

const (
	// CreateOutputEndpointCloud Cloud
	CreateOutputEndpointCloud CreateOutputEndpoint = "cloud"
	// CreateOutputEndpointActiveGate ActiveGate
	CreateOutputEndpointActiveGate CreateOutputEndpoint = "activeGate"
	// CreateOutputEndpointManual Manual
	CreateOutputEndpointManual CreateOutputEndpoint = "manual"
)

func (e CreateOutputEndpoint) ToPointer() *CreateOutputEndpoint {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputEndpoint) IsExact() bool {
	if e != nil {
		switch *e {
		case "cloud", "activeGate", "manual":
			return true
		}
	}
	return false
}

type CreateOutputTelemetryType string

const (
	// CreateOutputTelemetryTypeLogs Logs
	CreateOutputTelemetryTypeLogs CreateOutputTelemetryType = "logs"
	// CreateOutputTelemetryTypeMetrics Metrics
	CreateOutputTelemetryTypeMetrics CreateOutputTelemetryType = "metrics"
)

func (e CreateOutputTelemetryType) ToPointer() *CreateOutputTelemetryType {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputTelemetryType) IsExact() bool {
	if e != nil {
		switch *e {
		case "logs", "metrics":
			return true
		}
	}
	return false
}

type CreateOutputPqControlsDynatraceHTTP struct {
}

func (c CreateOutputPqControlsDynatraceHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsDynatraceHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputDynatraceHTTP struct {
	// Unique ID for this output
	ID   string                        `json:"id"`
	Type CreateOutputTypeDynatraceHTTP `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The method to use when sending events
	Method *components.MethodOptions `json:"method,omitempty"`
	// Disable to close the connection immediately after sending the outgoing request
	KeepAlive *bool `json:"keepAlive,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events. You can also add headers dynamically on a per-event basis in the __headers field, as explained in [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook/#internal-fields).
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions      `json:"onBackpressure,omitempty"`
	AuthType       *CreateOutputAuthenticationTypeDynatraceHTTP `json:"authType,omitempty"`
	// How to format events before sending. Defaults to JSON. Plaintext is not currently supported.
	Format        CreateOutputFormatDynatraceHTTP `json:"format"`
	Endpoint      CreateOutputEndpoint            `json:"endpoint"`
	TelemetryType CreateOutputTelemetryType       `json:"telemetryType"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsDynatraceHTTP `json:"pqControls,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// ID of the environment to send to
	EnvironmentID *string `json:"environmentId,omitempty"`
	// ActiveGate domain with Log analytics collector module enabled. For example https://{activeGate-domain}:9999/e/{environment-id}/api/v2/logs/ingest.
	ActiveGateDomain *string `json:"activeGateDomain,omitempty"`
	// URL to send events to. Can be overwritten by an event's __url field.
	URL *string `json:"url,omitempty"`
	// Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
	TemplateURL *string `json:"__template_url,omitempty"`
}

func (c CreateOutputOutputDynatraceHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputDynatraceHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "format", "endpoint", "telemetryType"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputDynatraceHTTP) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputDynatraceHTTP) GetType() CreateOutputTypeDynatraceHTTP {
	if c == nil {
		return CreateOutputTypeDynatraceHTTP("")
	}
	return c.Type
}

func (c *CreateOutputOutputDynatraceHTTP) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputDynatraceHTTP) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputDynatraceHTTP) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputDynatraceHTTP) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputDynatraceHTTP) GetMethod() *components.MethodOptions {
	if c == nil {
		return nil
	}
	return c.Method
}

func (c *CreateOutputOutputDynatraceHTTP) GetKeepAlive() *bool {
	if c == nil {
		return nil
	}
	return c.KeepAlive
}

func (c *CreateOutputOutputDynatraceHTTP) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputDynatraceHTTP) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputDynatraceHTTP) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputDynatraceHTTP) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputDynatraceHTTP) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputDynatraceHTTP) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputDynatraceHTTP) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputDynatraceHTTP) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputDynatraceHTTP) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputDynatraceHTTP) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputDynatraceHTTP) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputDynatraceHTTP) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputDynatraceHTTP) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputDynatraceHTTP) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputDynatraceHTTP) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputDynatraceHTTP) GetAuthType() *CreateOutputAuthenticationTypeDynatraceHTTP {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputDynatraceHTTP) GetFormat() CreateOutputFormatDynatraceHTTP {
	if c == nil {
		return CreateOutputFormatDynatraceHTTP("")
	}
	return c.Format
}

func (c *CreateOutputOutputDynatraceHTTP) GetEndpoint() CreateOutputEndpoint {
	if c == nil {
		return CreateOutputEndpoint("")
	}
	return c.Endpoint
}

func (c *CreateOutputOutputDynatraceHTTP) GetTelemetryType() CreateOutputTelemetryType {
	if c == nil {
		return CreateOutputTelemetryType("")
	}
	return c.TelemetryType
}

func (c *CreateOutputOutputDynatraceHTTP) GetTotalMemoryLimitKB() *float64 {
	if c == nil {
		return nil
	}
	return c.TotalMemoryLimitKB
}

func (c *CreateOutputOutputDynatraceHTTP) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputDynatraceHTTP) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputDynatraceHTTP) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputDynatraceHTTP) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputDynatraceHTTP) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputDynatraceHTTP) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputDynatraceHTTP) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputDynatraceHTTP) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputDynatraceHTTP) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputDynatraceHTTP) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputDynatraceHTTP) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputDynatraceHTTP) GetPqControls() *CreateOutputPqControlsDynatraceHTTP {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputDynatraceHTTP) GetToken() *string {
	if c == nil {
		return nil
	}
	return c.Token
}

func (c *CreateOutputOutputDynatraceHTTP) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputDynatraceHTTP) GetEnvironmentID() *string {
	if c == nil {
		return nil
	}
	return c.EnvironmentID
}

func (c *CreateOutputOutputDynatraceHTTP) GetActiveGateDomain() *string {
	if c == nil {
		return nil
	}
	return c.ActiveGateDomain
}

func (c *CreateOutputOutputDynatraceHTTP) GetURL() *string {
	if c == nil {
		return nil
	}
	return c.URL
}

func (c *CreateOutputOutputDynatraceHTTP) GetTemplateURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateURL
}

type CreateOutputTypeNetflow string

const (
	CreateOutputTypeNetflowNetflow CreateOutputTypeNetflow = "netflow"
)

func (e CreateOutputTypeNetflow) ToPointer() *CreateOutputTypeNetflow {
	return &e
}
func (e *CreateOutputTypeNetflow) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "netflow":
		*e = CreateOutputTypeNetflow(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeNetflow: %v", v)
	}
}

type CreateOutputHostNetflow struct {
	// Destination host
	Host string `json:"host"`
	// Destination port, default is 2055
	Port float64 `json:"port"`
	// Binds 'host' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'host' at runtime.
	TemplateHost *string `json:"__template_host,omitempty"`
	// Binds 'port' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'port' at runtime.
	TemplatePort *string `json:"__template_port,omitempty"`
}

func (c CreateOutputHostNetflow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputHostNetflow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"host", "port"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputHostNetflow) GetHost() string {
	if c == nil {
		return ""
	}
	return c.Host
}

func (c *CreateOutputHostNetflow) GetPort() float64 {
	if c == nil {
		return 0.0
	}
	return c.Port
}

func (c *CreateOutputHostNetflow) GetTemplateHost() *string {
	if c == nil {
		return nil
	}
	return c.TemplateHost
}

func (c *CreateOutputHostNetflow) GetTemplatePort() *string {
	if c == nil {
		return nil
	}
	return c.TemplatePort
}

type CreateOutputOutputNetflow struct {
	// Unique ID for this output
	ID   string                  `json:"id"`
	Type CreateOutputTypeNetflow `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// One or more NetFlow Destinations to forward events to
	Hosts []CreateOutputHostNetflow `json:"hosts"`
	// How often to resolve the destination hostname to an IP address. Ignored if all destinations are IP addresses. A value of 0 means every datagram sent will incur a DNS lookup.
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	// Send NetFlow traffic using the original event's Source IP and port. To enable this, you must install the external `udp-sender` helper binary at `/usr/bin/udp-sender` on all Worker Nodes and grant it the `CAP_NET_RAW` capability.
	EnableIPSpoofing *bool   `json:"enableIpSpoofing,omitempty"`
	Description      *string `json:"description,omitempty"`
	// MTU in bytes. The actual maximum NetFlow payload size will be MTU minus IP and UDP headers (28 bytes for IPv4, 48 bytes for IPv6). For example, with the default MTU of 1500, the max payload is 1472 bytes for IPv4. Payloads exceeding this limit will be dropped.
	MaxRecordSize *float64 `json:"maxRecordSize,omitempty"`
}

func (c CreateOutputOutputNetflow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputNetflow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "hosts"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputNetflow) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputNetflow) GetType() CreateOutputTypeNetflow {
	if c == nil {
		return CreateOutputTypeNetflow("")
	}
	return c.Type
}

func (c *CreateOutputOutputNetflow) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputNetflow) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputNetflow) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputNetflow) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputNetflow) GetHosts() []CreateOutputHostNetflow {
	if c == nil {
		return []CreateOutputHostNetflow{}
	}
	return c.Hosts
}

func (c *CreateOutputOutputNetflow) GetDNSResolvePeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.DNSResolvePeriodSec
}

func (c *CreateOutputOutputNetflow) GetEnableIPSpoofing() *bool {
	if c == nil {
		return nil
	}
	return c.EnableIPSpoofing
}

func (c *CreateOutputOutputNetflow) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputNetflow) GetMaxRecordSize() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRecordSize
}

type CreateOutputTypeXsiam string

const (
	CreateOutputTypeXsiamXsiam CreateOutputTypeXsiam = "xsiam"
)

func (e CreateOutputTypeXsiam) ToPointer() *CreateOutputTypeXsiam {
	return &e
}
func (e *CreateOutputTypeXsiam) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "xsiam":
		*e = CreateOutputTypeXsiam(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeXsiam: %v", v)
	}
}

// CreateOutputAuthenticationMethodXsiam - Enter a token directly, or provide a secret referencing a token
type CreateOutputAuthenticationMethodXsiam string

const (
	CreateOutputAuthenticationMethodXsiamToken  CreateOutputAuthenticationMethodXsiam = "token"
	CreateOutputAuthenticationMethodXsiamSecret CreateOutputAuthenticationMethodXsiam = "secret"
)

func (e CreateOutputAuthenticationMethodXsiam) ToPointer() *CreateOutputAuthenticationMethodXsiam {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputAuthenticationMethodXsiam) IsExact() bool {
	if e != nil {
		switch *e {
		case "token", "secret":
			return true
		}
	}
	return false
}

type CreateOutputURLXsiam struct {
	URL any `json:"url"`
	// Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
	Weight *float64 `json:"weight,omitempty"`
}

func (c CreateOutputURLXsiam) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputURLXsiam) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"url"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputURLXsiam) GetURL() any {
	if c == nil {
		return nil
	}
	return c.URL
}

func (c *CreateOutputURLXsiam) GetWeight() *float64 {
	if c == nil {
		return nil
	}
	return c.Weight
}

type CreateOutputPqControlsXsiam struct {
}

func (c CreateOutputPqControlsXsiam) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsXsiam) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputXsiam struct {
	// Unique ID for this output
	ID   string                `json:"id"`
	Type CreateOutputTypeXsiam `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Enable for optimal performance. Even if you have one hostname, it can expand to multiple IPs. If disabled, consider enabling round-robin DNS.
	LoadBalanced *bool `json:"loadBalanced,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Enter a token directly, or provide a secret referencing a token
	AuthType *CreateOutputAuthenticationMethodXsiam `json:"authType,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// Maximum number of requests to limit to per second
	ThrottleRateReqPerSec *int64 `json:"throttleRateReqPerSec,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	// XSIAM endpoint URL to send events to, such as https://api-{tenant external URL}/logs/v1/event
	URL *string `json:"url,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Exclude all IPs of the current host from the list of any resolved hostnames
	ExcludeSelf *bool                  `json:"excludeSelf,omitempty"`
	Urls        []CreateOutputURLXsiam `json:"urls,omitempty"`
	// The interval in which to re-resolve any hostnames and pick up destinations from A records
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	// How far back in time to keep traffic stats for load balancing purposes
	LoadBalanceStatsPeriodSec *float64 `json:"loadBalanceStatsPeriodSec,omitempty"`
	// XSIAM authentication token
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsXsiam         `json:"pqControls,omitempty"`
	// Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
	TemplateURL *string `json:"__template_url,omitempty"`
}

func (c CreateOutputOutputXsiam) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputXsiam) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputXsiam) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputXsiam) GetType() CreateOutputTypeXsiam {
	if c == nil {
		return CreateOutputTypeXsiam("")
	}
	return c.Type
}

func (c *CreateOutputOutputXsiam) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputXsiam) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputXsiam) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputXsiam) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputXsiam) GetLoadBalanced() *bool {
	if c == nil {
		return nil
	}
	return c.LoadBalanced
}

func (c *CreateOutputOutputXsiam) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputXsiam) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputXsiam) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputXsiam) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputXsiam) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputXsiam) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputXsiam) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputXsiam) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputXsiam) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputXsiam) GetAuthType() *CreateOutputAuthenticationMethodXsiam {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputXsiam) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputXsiam) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputXsiam) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputXsiam) GetThrottleRateReqPerSec() *int64 {
	if c == nil {
		return nil
	}
	return c.ThrottleRateReqPerSec
}

func (c *CreateOutputOutputXsiam) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputXsiam) GetTotalMemoryLimitKB() *float64 {
	if c == nil {
		return nil
	}
	return c.TotalMemoryLimitKB
}

func (c *CreateOutputOutputXsiam) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputXsiam) GetURL() *string {
	if c == nil {
		return nil
	}
	return c.URL
}

func (c *CreateOutputOutputXsiam) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputXsiam) GetExcludeSelf() *bool {
	if c == nil {
		return nil
	}
	return c.ExcludeSelf
}

func (c *CreateOutputOutputXsiam) GetUrls() []CreateOutputURLXsiam {
	if c == nil {
		return nil
	}
	return c.Urls
}

func (c *CreateOutputOutputXsiam) GetDNSResolvePeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.DNSResolvePeriodSec
}

func (c *CreateOutputOutputXsiam) GetLoadBalanceStatsPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.LoadBalanceStatsPeriodSec
}

func (c *CreateOutputOutputXsiam) GetToken() *string {
	if c == nil {
		return nil
	}
	return c.Token
}

func (c *CreateOutputOutputXsiam) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputXsiam) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputXsiam) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputXsiam) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputXsiam) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputXsiam) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputXsiam) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputXsiam) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputXsiam) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputXsiam) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputXsiam) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputXsiam) GetPqControls() *CreateOutputPqControlsXsiam {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputXsiam) GetTemplateURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateURL
}

type CreateOutputTypeClickHouse string

const (
	CreateOutputTypeClickHouseClickHouse CreateOutputTypeClickHouse = "click_house"
)

func (e CreateOutputTypeClickHouse) ToPointer() *CreateOutputTypeClickHouse {
	return &e
}
func (e *CreateOutputTypeClickHouse) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "click_house":
		*e = CreateOutputTypeClickHouse(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeClickHouse: %v", v)
	}
}

type CreateOutputAuthenticationTypeClickHouse string

const (
	// CreateOutputAuthenticationTypeClickHouseNone None
	CreateOutputAuthenticationTypeClickHouseNone CreateOutputAuthenticationTypeClickHouse = "none"
	// CreateOutputAuthenticationTypeClickHouseBasic Basic
	CreateOutputAuthenticationTypeClickHouseBasic CreateOutputAuthenticationTypeClickHouse = "basic"
	// CreateOutputAuthenticationTypeClickHouseCredentialsSecret Basic (credentials secret)
	CreateOutputAuthenticationTypeClickHouseCredentialsSecret CreateOutputAuthenticationTypeClickHouse = "credentialsSecret"
	// CreateOutputAuthenticationTypeClickHouseSslUserCertificate SSL User Certificate
	CreateOutputAuthenticationTypeClickHouseSslUserCertificate CreateOutputAuthenticationTypeClickHouse = "sslUserCertificate"
)

func (e CreateOutputAuthenticationTypeClickHouse) ToPointer() *CreateOutputAuthenticationTypeClickHouse {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputAuthenticationTypeClickHouse) IsExact() bool {
	if e != nil {
		switch *e {
		case "none", "basic", "credentialsSecret", "sslUserCertificate":
			return true
		}
	}
	return false
}

// CreateOutputFormatClickHouse - Data format to use when sending data to ClickHouse. Defaults to JSON Compact.
type CreateOutputFormatClickHouse string

const (
	// CreateOutputFormatClickHouseJSONCompactEachRowWithNames JSONCompactEachRowWithNames
	CreateOutputFormatClickHouseJSONCompactEachRowWithNames CreateOutputFormatClickHouse = "json-compact-each-row-with-names"
	// CreateOutputFormatClickHouseJSONEachRow JSONEachRow
	CreateOutputFormatClickHouseJSONEachRow CreateOutputFormatClickHouse = "json-each-row"
)

func (e CreateOutputFormatClickHouse) ToPointer() *CreateOutputFormatClickHouse {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputFormatClickHouse) IsExact() bool {
	if e != nil {
		switch *e {
		case "json-compact-each-row-with-names", "json-each-row":
			return true
		}
	}
	return false
}

// CreateOutputMappingType - How event fields are mapped to ClickHouse columns.
type CreateOutputMappingType string

const (
	// CreateOutputMappingTypeAutomatic Automatic
	CreateOutputMappingTypeAutomatic CreateOutputMappingType = "automatic"
	// CreateOutputMappingTypeCustom Custom
	CreateOutputMappingTypeCustom CreateOutputMappingType = "custom"
)

func (e CreateOutputMappingType) ToPointer() *CreateOutputMappingType {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputMappingType) IsExact() bool {
	if e != nil {
		switch *e {
		case "automatic", "custom":
			return true
		}
	}
	return false
}

type CreateOutputStatsDestination struct {
	URL         *string `json:"url,omitempty"`
	Database    *string `json:"database,omitempty"`
	TableName   *string `json:"tableName,omitempty"`
	AuthType    *string `json:"authType,omitempty"`
	Username    *string `json:"username,omitempty"`
	SQLUsername *string `json:"sqlUsername,omitempty"`
	Password    *string `json:"password,omitempty"`
}

func (c CreateOutputStatsDestination) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputStatsDestination) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputStatsDestination) GetURL() *string {
	if c == nil {
		return nil
	}
	return c.URL
}

func (c *CreateOutputStatsDestination) GetDatabase() *string {
	if c == nil {
		return nil
	}
	return c.Database
}

func (c *CreateOutputStatsDestination) GetTableName() *string {
	if c == nil {
		return nil
	}
	return c.TableName
}

func (c *CreateOutputStatsDestination) GetAuthType() *string {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputStatsDestination) GetUsername() *string {
	if c == nil {
		return nil
	}
	return c.Username
}

func (c *CreateOutputStatsDestination) GetSQLUsername() *string {
	if c == nil {
		return nil
	}
	return c.SQLUsername
}

func (c *CreateOutputStatsDestination) GetPassword() *string {
	if c == nil {
		return nil
	}
	return c.Password
}

type CreateOutputColumnMapping struct {
	// Name of the column in ClickHouse that will store field value
	ColumnName string `json:"columnName"`
	// Type of the column in the ClickHouse database
	ColumnType *string `json:"columnType,omitempty"`
	// JavaScript expression to compute value to be inserted into ClickHouse table
	ColumnValueExpression string `json:"columnValueExpression"`
}

func (c CreateOutputColumnMapping) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputColumnMapping) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"columnName", "columnValueExpression"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputColumnMapping) GetColumnName() string {
	if c == nil {
		return ""
	}
	return c.ColumnName
}

func (c *CreateOutputColumnMapping) GetColumnType() *string {
	if c == nil {
		return nil
	}
	return c.ColumnType
}

func (c *CreateOutputColumnMapping) GetColumnValueExpression() string {
	if c == nil {
		return ""
	}
	return c.ColumnValueExpression
}

type CreateOutputPqControlsClickHouse struct {
}

func (c CreateOutputPqControlsClickHouse) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsClickHouse) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputClickHouse struct {
	// Unique ID for this output
	ID   string                     `json:"id"`
	Type CreateOutputTypeClickHouse `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// URL of the ClickHouse instance. Example: http://localhost:8123/
	URL      string                                    `json:"url"`
	AuthType *CreateOutputAuthenticationTypeClickHouse `json:"authType,omitempty"`
	Database string                                    `json:"database"`
	// Name of the ClickHouse table where data will be inserted. Name can contain letters (A-Z, a-z), numbers (0-9), and the character "_", and must start with either a letter or the character "_".
	TableName string `json:"tableName"`
	// Data format to use when sending data to ClickHouse. Defaults to JSON Compact.
	Format *CreateOutputFormatClickHouse `json:"format,omitempty"`
	// How event fields are mapped to ClickHouse columns.
	MappingType *CreateOutputMappingType `json:"mappingType,omitempty"`
	// Collect data into batches for later processing. Disable to write to a ClickHouse table immediately.
	AsyncInserts *bool                                  `json:"asyncInserts,omitempty"`
	TLS          *components.TLSSettingsClientSideType1 `json:"tls,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// Log the most recent event that fails to match the table schema
	DumpFormatErrorsToDisk *bool                         `json:"dumpFormatErrorsToDisk,omitempty"`
	StatsDestination       *CreateOutputStatsDestination `json:"statsDestination,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	Username       *string                                 `json:"username,omitempty"`
	Password       *string                                 `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Username for certificate authentication
	SQLUsername *string `json:"sqlUsername,omitempty"`
	// Cribl will wait for confirmation that data has been fully inserted into the ClickHouse database before proceeding. Disabling this option can increase throughput, but Cribl won’t be able to verify data has been completely inserted.
	WaitForAsyncInserts *bool `json:"waitForAsyncInserts,omitempty"`
	// Fields to exclude from sending to ClickHouse
	ExcludeMappingFields []string `json:"excludeMappingFields,omitempty"`
	// Retrieves the table schema from ClickHouse and populates the Column Mapping table
	DescribeTable  *string                     `json:"describeTable,omitempty"`
	ColumnMappings []CreateOutputColumnMapping `json:"columnMappings,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsClickHouse    `json:"pqControls,omitempty"`
	// Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
	TemplateURL *string `json:"__template_url,omitempty"`
	// Binds 'database' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'database' at runtime.
	TemplateDatabase *string `json:"__template_database,omitempty"`
	// Binds 'tableName' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'tableName' at runtime.
	TemplateTableName *string `json:"__template_tableName,omitempty"`
}

func (c CreateOutputOutputClickHouse) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputClickHouse) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "url", "database", "tableName"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputClickHouse) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputClickHouse) GetType() CreateOutputTypeClickHouse {
	if c == nil {
		return CreateOutputTypeClickHouse("")
	}
	return c.Type
}

func (c *CreateOutputOutputClickHouse) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputClickHouse) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputClickHouse) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputClickHouse) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputClickHouse) GetURL() string {
	if c == nil {
		return ""
	}
	return c.URL
}

func (c *CreateOutputOutputClickHouse) GetAuthType() *CreateOutputAuthenticationTypeClickHouse {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputClickHouse) GetDatabase() string {
	if c == nil {
		return ""
	}
	return c.Database
}

func (c *CreateOutputOutputClickHouse) GetTableName() string {
	if c == nil {
		return ""
	}
	return c.TableName
}

func (c *CreateOutputOutputClickHouse) GetFormat() *CreateOutputFormatClickHouse {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputClickHouse) GetMappingType() *CreateOutputMappingType {
	if c == nil {
		return nil
	}
	return c.MappingType
}

func (c *CreateOutputOutputClickHouse) GetAsyncInserts() *bool {
	if c == nil {
		return nil
	}
	return c.AsyncInserts
}

func (c *CreateOutputOutputClickHouse) GetTLS() *components.TLSSettingsClientSideType1 {
	if c == nil {
		return nil
	}
	return c.TLS
}

func (c *CreateOutputOutputClickHouse) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputClickHouse) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputClickHouse) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputClickHouse) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputClickHouse) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputClickHouse) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputClickHouse) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputClickHouse) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputClickHouse) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputClickHouse) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputClickHouse) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputClickHouse) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputClickHouse) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputClickHouse) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputClickHouse) GetDumpFormatErrorsToDisk() *bool {
	if c == nil {
		return nil
	}
	return c.DumpFormatErrorsToDisk
}

func (c *CreateOutputOutputClickHouse) GetStatsDestination() *CreateOutputStatsDestination {
	if c == nil {
		return nil
	}
	return c.StatsDestination
}

func (c *CreateOutputOutputClickHouse) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputClickHouse) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputClickHouse) GetUsername() *string {
	if c == nil {
		return nil
	}
	return c.Username
}

func (c *CreateOutputOutputClickHouse) GetPassword() *string {
	if c == nil {
		return nil
	}
	return c.Password
}

func (c *CreateOutputOutputClickHouse) GetCredentialsSecret() *string {
	if c == nil {
		return nil
	}
	return c.CredentialsSecret
}

func (c *CreateOutputOutputClickHouse) GetSQLUsername() *string {
	if c == nil {
		return nil
	}
	return c.SQLUsername
}

func (c *CreateOutputOutputClickHouse) GetWaitForAsyncInserts() *bool {
	if c == nil {
		return nil
	}
	return c.WaitForAsyncInserts
}

func (c *CreateOutputOutputClickHouse) GetExcludeMappingFields() []string {
	if c == nil {
		return nil
	}
	return c.ExcludeMappingFields
}

func (c *CreateOutputOutputClickHouse) GetDescribeTable() *string {
	if c == nil {
		return nil
	}
	return c.DescribeTable
}

func (c *CreateOutputOutputClickHouse) GetColumnMappings() []CreateOutputColumnMapping {
	if c == nil {
		return nil
	}
	return c.ColumnMappings
}

func (c *CreateOutputOutputClickHouse) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputClickHouse) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputClickHouse) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputClickHouse) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputClickHouse) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputClickHouse) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputClickHouse) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputClickHouse) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputClickHouse) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputClickHouse) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputClickHouse) GetPqControls() *CreateOutputPqControlsClickHouse {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputClickHouse) GetTemplateURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateURL
}

func (c *CreateOutputOutputClickHouse) GetTemplateDatabase() *string {
	if c == nil {
		return nil
	}
	return c.TemplateDatabase
}

func (c *CreateOutputOutputClickHouse) GetTemplateTableName() *string {
	if c == nil {
		return nil
	}
	return c.TemplateTableName
}

type CreateOutputTypeDiskSpool string

const (
	CreateOutputTypeDiskSpoolDiskSpool CreateOutputTypeDiskSpool = "disk_spool"
)

func (e CreateOutputTypeDiskSpool) ToPointer() *CreateOutputTypeDiskSpool {
	return &e
}
func (e *CreateOutputTypeDiskSpool) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "disk_spool":
		*e = CreateOutputTypeDiskSpool(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeDiskSpool: %v", v)
	}
}

type CreateOutputOutputDiskSpool struct {
	// Unique ID for this output
	ID   string                    `json:"id"`
	Type CreateOutputTypeDiskSpool `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Time period for grouping spooled events. Default is 10m.
	TimeWindow *string `json:"timeWindow,omitempty"`
	// Maximum disk space that can be consumed before older buckets are deleted. Examples: 420MB, 4GB. Default is 1GB.
	MaxDataSize *string `json:"maxDataSize,omitempty"`
	// Maximum amount of time to retain data before older buckets are deleted. Examples: 2h, 4d. Default is 24h.
	MaxDataTime *string `json:"maxDataTime,omitempty"`
	// Data compression format. Default is gzip.
	Compress *components.CompressionOptionsPersistence `json:"compress,omitempty"`
	// JavaScript expression defining how files are partitioned and organized within the time-buckets. If blank, the event's __partition property is used and otherwise, events go directly into the time-bucket directory.
	PartitionExpr *string `json:"partitionExpr,omitempty"`
	Description   *string `json:"description,omitempty"`
}

func (c CreateOutputOutputDiskSpool) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputDiskSpool) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputDiskSpool) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputDiskSpool) GetType() CreateOutputTypeDiskSpool {
	if c == nil {
		return CreateOutputTypeDiskSpool("")
	}
	return c.Type
}

func (c *CreateOutputOutputDiskSpool) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputDiskSpool) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputDiskSpool) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputDiskSpool) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputDiskSpool) GetTimeWindow() *string {
	if c == nil {
		return nil
	}
	return c.TimeWindow
}

func (c *CreateOutputOutputDiskSpool) GetMaxDataSize() *string {
	if c == nil {
		return nil
	}
	return c.MaxDataSize
}

func (c *CreateOutputOutputDiskSpool) GetMaxDataTime() *string {
	if c == nil {
		return nil
	}
	return c.MaxDataTime
}

func (c *CreateOutputOutputDiskSpool) GetCompress() *components.CompressionOptionsPersistence {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputDiskSpool) GetPartitionExpr() *string {
	if c == nil {
		return nil
	}
	return c.PartitionExpr
}

func (c *CreateOutputOutputDiskSpool) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

type CreateOutputTypeCriblLake string

const (
	CreateOutputTypeCriblLakeCriblLake CreateOutputTypeCriblLake = "cribl_lake"
)

func (e CreateOutputTypeCriblLake) ToPointer() *CreateOutputTypeCriblLake {
	return &e
}
func (e *CreateOutputTypeCriblLake) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_lake":
		*e = CreateOutputTypeCriblLake(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeCriblLake: %v", v)
	}
}

type CreateOutputOutputCriblLake struct {
	// Unique ID for this output
	ID   string                    `json:"id"`
	Type CreateOutputTypeCriblLake `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
	Bucket *string `json:"bucket,omitempty"`
	// Region where the S3 bucket is located
	Region *string `json:"region,omitempty"`
	// Secret key. This value can be a constant or a JavaScript expression. Example: `${C.env.SOME_SECRET}`)
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *components.SignatureVersionOptionsS3CollectorConf `json:"signatureVersion,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `json:"enableAssumeRole,omitempty"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitempty"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
	StagePath *string `json:"stagePath,omitempty"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Lake dataset to send the data to.
	DestPath *string `json:"destPath,omitempty"`
	// Object ACL to assign to uploaded objects
	ObjectACL *components.ObjectACLOptions `json:"objectACL,omitempty"`
	// Storage class to select for uploaded objects
	StorageClass         *components.StorageClassOptions                           `json:"storageClass,omitempty"`
	ServerSideEncryption *components.ServerSideEncryptionForUploadedObjectsOptions `json:"serverSideEncryption,omitempty"`
	// ID or ARN of the KMS customer-managed key to use for encryption
	KmsKeyID *string `json:"kmsKeyId,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `json:"baseFileName,omitempty"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `json:"fileNameSuffix,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `json:"maxFileSizeMB,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `json:"maxOpenFiles,omitempty"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `json:"headerLine,omitempty"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `json:"writeHighWaterMark,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `json:"deadletterEnabled,omitempty"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *components.DiskSpaceProtectionOptions `json:"onDiskFullBackpressure,omitempty"`
	// Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
	ForceCloseOnShutdown *bool                         `json:"forceCloseOnShutdown,omitempty"`
	RetrySettings        *components.RetrySettingsType `json:"retrySettings,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `json:"maxFileIdleTimeSec,omitempty"`
	// Disable if you can access files within the bucket but not the bucket itself
	VerifyPermissions *bool `json:"verifyPermissions,omitempty"`
	// Maximum number of files that can be waiting for upload before backpressure is applied
	MaxClosingFilesToBackpressure *float64                                   `json:"maxClosingFilesToBackpressure,omitempty"`
	AwsAuthenticationMethod       *components.AwsAuthenticationMethodOptions `json:"awsAuthenticationMethod,omitempty"`
	Format                        *components.FormatOptions                  `json:"format,omitempty"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *float64 `json:"maxConcurrentFileParts,omitempty"`
	Description            *string  `json:"description,omitempty"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `json:"emptyDirCleanupSec,omitempty"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `json:"directoryBatchSize,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `json:"deadletterPath,omitempty"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `json:"maxRetryNum,omitempty"`
	// Binds 'bucket' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'bucket' at runtime.
	TemplateBucket *string `json:"__template_bucket,omitempty"`
	// Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime.
	TemplateRegion *string `json:"__template_region,omitempty"`
	// Binds 'awsSecretKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsSecretKey' at runtime.
	TemplateAwsSecretKey *string `json:"__template_awsSecretKey,omitempty"`
	// Binds 'assumeRoleArn' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleArn' at runtime.
	TemplateAssumeRoleArn *string `json:"__template_assumeRoleArn,omitempty"`
	// Binds 'assumeRoleExternalId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleExternalId' at runtime.
	TemplateAssumeRoleExternalID *string `json:"__template_assumeRoleExternalId,omitempty"`
	// Binds 'destPath' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'destPath' at runtime.
	TemplateDestPath *string `json:"__template_destPath,omitempty"`
}

func (c CreateOutputOutputCriblLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputCriblLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputCriblLake) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputCriblLake) GetType() CreateOutputTypeCriblLake {
	if c == nil {
		return CreateOutputTypeCriblLake("")
	}
	return c.Type
}

func (c *CreateOutputOutputCriblLake) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputCriblLake) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputCriblLake) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputCriblLake) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputCriblLake) GetBucket() *string {
	if c == nil {
		return nil
	}
	return c.Bucket
}

func (c *CreateOutputOutputCriblLake) GetRegion() *string {
	if c == nil {
		return nil
	}
	return c.Region
}

func (c *CreateOutputOutputCriblLake) GetAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecretKey
}

func (c *CreateOutputOutputCriblLake) GetEndpoint() *string {
	if c == nil {
		return nil
	}
	return c.Endpoint
}

func (c *CreateOutputOutputCriblLake) GetSignatureVersion() *components.SignatureVersionOptionsS3CollectorConf {
	if c == nil {
		return nil
	}
	return c.SignatureVersion
}

func (c *CreateOutputOutputCriblLake) GetReuseConnections() *bool {
	if c == nil {
		return nil
	}
	return c.ReuseConnections
}

func (c *CreateOutputOutputCriblLake) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputCriblLake) GetEnableAssumeRole() *bool {
	if c == nil {
		return nil
	}
	return c.EnableAssumeRole
}

func (c *CreateOutputOutputCriblLake) GetAssumeRoleArn() *string {
	if c == nil {
		return nil
	}
	return c.AssumeRoleArn
}

func (c *CreateOutputOutputCriblLake) GetAssumeRoleExternalID() *string {
	if c == nil {
		return nil
	}
	return c.AssumeRoleExternalID
}

func (c *CreateOutputOutputCriblLake) GetDurationSeconds() *float64 {
	if c == nil {
		return nil
	}
	return c.DurationSeconds
}

func (c *CreateOutputOutputCriblLake) GetStagePath() *string {
	if c == nil {
		return nil
	}
	return c.StagePath
}

func (c *CreateOutputOutputCriblLake) GetAddIDToStagePath() *bool {
	if c == nil {
		return nil
	}
	return c.AddIDToStagePath
}

func (c *CreateOutputOutputCriblLake) GetDestPath() *string {
	if c == nil {
		return nil
	}
	return c.DestPath
}

func (c *CreateOutputOutputCriblLake) GetObjectACL() *components.ObjectACLOptions {
	if c == nil {
		return nil
	}
	return c.ObjectACL
}

func (c *CreateOutputOutputCriblLake) GetStorageClass() *components.StorageClassOptions {
	if c == nil {
		return nil
	}
	return c.StorageClass
}

func (c *CreateOutputOutputCriblLake) GetServerSideEncryption() *components.ServerSideEncryptionForUploadedObjectsOptions {
	if c == nil {
		return nil
	}
	return c.ServerSideEncryption
}

func (c *CreateOutputOutputCriblLake) GetKmsKeyID() *string {
	if c == nil {
		return nil
	}
	return c.KmsKeyID
}

func (c *CreateOutputOutputCriblLake) GetRemoveEmptyDirs() *bool {
	if c == nil {
		return nil
	}
	return c.RemoveEmptyDirs
}

func (c *CreateOutputOutputCriblLake) GetBaseFileName() *string {
	if c == nil {
		return nil
	}
	return c.BaseFileName
}

func (c *CreateOutputOutputCriblLake) GetFileNameSuffix() *string {
	if c == nil {
		return nil
	}
	return c.FileNameSuffix
}

func (c *CreateOutputOutputCriblLake) GetMaxFileSizeMB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileSizeMB
}

func (c *CreateOutputOutputCriblLake) GetMaxOpenFiles() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxOpenFiles
}

func (c *CreateOutputOutputCriblLake) GetHeaderLine() *string {
	if c == nil {
		return nil
	}
	return c.HeaderLine
}

func (c *CreateOutputOutputCriblLake) GetWriteHighWaterMark() *float64 {
	if c == nil {
		return nil
	}
	return c.WriteHighWaterMark
}

func (c *CreateOutputOutputCriblLake) GetOnBackpressure() *components.BackpressureBehaviorOptions1 {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputCriblLake) GetDeadletterEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.DeadletterEnabled
}

func (c *CreateOutputOutputCriblLake) GetOnDiskFullBackpressure() *components.DiskSpaceProtectionOptions {
	if c == nil {
		return nil
	}
	return c.OnDiskFullBackpressure
}

func (c *CreateOutputOutputCriblLake) GetForceCloseOnShutdown() *bool {
	if c == nil {
		return nil
	}
	return c.ForceCloseOnShutdown
}

func (c *CreateOutputOutputCriblLake) GetRetrySettings() *components.RetrySettingsType {
	if c == nil {
		return nil
	}
	return c.RetrySettings
}

func (c *CreateOutputOutputCriblLake) GetMaxFileOpenTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileOpenTimeSec
}

func (c *CreateOutputOutputCriblLake) GetMaxFileIdleTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileIdleTimeSec
}

func (c *CreateOutputOutputCriblLake) GetVerifyPermissions() *bool {
	if c == nil {
		return nil
	}
	return c.VerifyPermissions
}

func (c *CreateOutputOutputCriblLake) GetMaxClosingFilesToBackpressure() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxClosingFilesToBackpressure
}

func (c *CreateOutputOutputCriblLake) GetAwsAuthenticationMethod() *components.AwsAuthenticationMethodOptions {
	if c == nil {
		return nil
	}
	return c.AwsAuthenticationMethod
}

func (c *CreateOutputOutputCriblLake) GetFormat() *components.FormatOptions {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputCriblLake) GetMaxConcurrentFileParts() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxConcurrentFileParts
}

func (c *CreateOutputOutputCriblLake) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputCriblLake) GetEmptyDirCleanupSec() *float64 {
	if c == nil {
		return nil
	}
	return c.EmptyDirCleanupSec
}

func (c *CreateOutputOutputCriblLake) GetDirectoryBatchSize() *float64 {
	if c == nil {
		return nil
	}
	return c.DirectoryBatchSize
}

func (c *CreateOutputOutputCriblLake) GetDeadletterPath() *string {
	if c == nil {
		return nil
	}
	return c.DeadletterPath
}

func (c *CreateOutputOutputCriblLake) GetMaxRetryNum() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRetryNum
}

func (c *CreateOutputOutputCriblLake) GetTemplateBucket() *string {
	if c == nil {
		return nil
	}
	return c.TemplateBucket
}

func (c *CreateOutputOutputCriblLake) GetTemplateRegion() *string {
	if c == nil {
		return nil
	}
	return c.TemplateRegion
}

func (c *CreateOutputOutputCriblLake) GetTemplateAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAwsSecretKey
}

func (c *CreateOutputOutputCriblLake) GetTemplateAssumeRoleArn() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAssumeRoleArn
}

func (c *CreateOutputOutputCriblLake) GetTemplateAssumeRoleExternalID() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAssumeRoleExternalID
}

func (c *CreateOutputOutputCriblLake) GetTemplateDestPath() *string {
	if c == nil {
		return nil
	}
	return c.TemplateDestPath
}

type CreateOutputTypeSecurityLake string

const (
	CreateOutputTypeSecurityLakeSecurityLake CreateOutputTypeSecurityLake = "security_lake"
)

func (e CreateOutputTypeSecurityLake) ToPointer() *CreateOutputTypeSecurityLake {
	return &e
}
func (e *CreateOutputTypeSecurityLake) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "security_lake":
		*e = CreateOutputTypeSecurityLake(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeSecurityLake: %v", v)
	}
}

// CreateOutputSignatureVersionSecurityLake - Signature version to use for signing Amazon Security Lake requests
type CreateOutputSignatureVersionSecurityLake string

const (
	CreateOutputSignatureVersionSecurityLakeV2 CreateOutputSignatureVersionSecurityLake = "v2"
	CreateOutputSignatureVersionSecurityLakeV4 CreateOutputSignatureVersionSecurityLake = "v4"
)

func (e CreateOutputSignatureVersionSecurityLake) ToPointer() *CreateOutputSignatureVersionSecurityLake {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputSignatureVersionSecurityLake) IsExact() bool {
	if e != nil {
		switch *e {
		case "v2", "v4":
			return true
		}
	}
	return false
}

type CreateOutputOutputSecurityLake struct {
	// Unique ID for this output
	ID   string                       `json:"id"`
	Type CreateOutputTypeSecurityLake `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions and labels to generated metrics and logs, respectively.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
	Bucket string `json:"bucket"`
	// Region where the Amazon Security Lake is located.
	Region       string  `json:"region"`
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitempty"`
	// Amazon Security Lake service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to Amazon Security Lake-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing Amazon Security Lake requests
	SignatureVersion *CreateOutputSignatureVersionSecurityLake `json:"signatureVersion,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `json:"enableAssumeRole,omitempty"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn string `json:"assumeRoleArn"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitempty"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
	StagePath string `json:"stagePath"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Object ACL to assign to uploaded objects
	ObjectACL *components.ObjectACLOptions `json:"objectACL,omitempty"`
	// Storage class to select for uploaded objects
	StorageClass         *components.StorageClassOptions                           `json:"storageClass,omitempty"`
	ServerSideEncryption *components.ServerSideEncryptionForUploadedObjectsOptions `json:"serverSideEncryption,omitempty"`
	// ID or ARN of the KMS customer-managed key to use for encryption
	KmsKeyID *string `json:"kmsKeyId,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `json:"baseFileName,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `json:"maxFileSizeMB,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `json:"maxOpenFiles,omitempty"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `json:"headerLine,omitempty"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `json:"writeHighWaterMark,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `json:"deadletterEnabled,omitempty"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *components.DiskSpaceProtectionOptions `json:"onDiskFullBackpressure,omitempty"`
	// Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
	ForceCloseOnShutdown *bool                         `json:"forceCloseOnShutdown,omitempty"`
	RetrySettings        *components.RetrySettingsType `json:"retrySettings,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *float64 `json:"maxConcurrentFileParts,omitempty"`
	// Disable if you can access files within the bucket but not the bucket itself
	VerifyPermissions *bool `json:"verifyPermissions,omitempty"`
	// Maximum number of files that can be waiting for upload before backpressure is applied
	MaxClosingFilesToBackpressure *float64 `json:"maxClosingFilesToBackpressure,omitempty"`
	// ID of the AWS account whose data the Destination will write to Security Lake. This should have been configured when creating the Amazon Security Lake custom source.
	AccountID string `json:"accountId"`
	// Name of the custom source configured in Amazon Security Lake
	CustomSource string `json:"customSource"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `json:"automaticSchema,omitempty"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *components.ParquetVersionOptions `json:"parquetVersion,omitempty"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *components.DataPageVersionOptions `json:"parquetDataPageVersion,omitempty"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `json:"parquetRowGroupLength,omitempty"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
	KeyValueMetadata []components.ItemsTypeKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `json:"enableStatistics,omitempty"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `json:"enableWritePageIndex,omitempty"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool   `json:"enablePageChecksum,omitempty"`
	Description        *string `json:"description,omitempty"`
	// This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `json:"emptyDirCleanupSec,omitempty"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `json:"directoryBatchSize,omitempty"`
	// To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
	ParquetSchema *string `json:"parquetSchema,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `json:"deadletterPath,omitempty"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `json:"maxRetryNum,omitempty"`
	// Binds 'bucket' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'bucket' at runtime.
	TemplateBucket *string `json:"__template_bucket,omitempty"`
	// Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime.
	TemplateRegion *string `json:"__template_region,omitempty"`
	// Binds 'awsSecretKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsSecretKey' at runtime.
	TemplateAwsSecretKey *string `json:"__template_awsSecretKey,omitempty"`
	// Binds 'assumeRoleArn' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleArn' at runtime.
	TemplateAssumeRoleArn *string `json:"__template_assumeRoleArn,omitempty"`
	// Binds 'assumeRoleExternalId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleExternalId' at runtime.
	TemplateAssumeRoleExternalID *string `json:"__template_assumeRoleExternalId,omitempty"`
	// Binds 'awsApiKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsApiKey' at runtime.
	TemplateAwsAPIKey *string `json:"__template_awsApiKey,omitempty"`
}

func (c CreateOutputOutputSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "bucket", "region", "assumeRoleArn", "stagePath", "accountId", "customSource"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputSecurityLake) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputSecurityLake) GetType() CreateOutputTypeSecurityLake {
	if c == nil {
		return CreateOutputTypeSecurityLake("")
	}
	return c.Type
}

func (c *CreateOutputOutputSecurityLake) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputSecurityLake) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputSecurityLake) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputSecurityLake) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputSecurityLake) GetBucket() string {
	if c == nil {
		return ""
	}
	return c.Bucket
}

func (c *CreateOutputOutputSecurityLake) GetRegion() string {
	if c == nil {
		return ""
	}
	return c.Region
}

func (c *CreateOutputOutputSecurityLake) GetAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecretKey
}

func (c *CreateOutputOutputSecurityLake) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if c == nil {
		return nil
	}
	return c.AwsAuthenticationMethod
}

func (c *CreateOutputOutputSecurityLake) GetEndpoint() *string {
	if c == nil {
		return nil
	}
	return c.Endpoint
}

func (c *CreateOutputOutputSecurityLake) GetSignatureVersion() *CreateOutputSignatureVersionSecurityLake {
	if c == nil {
		return nil
	}
	return c.SignatureVersion
}

func (c *CreateOutputOutputSecurityLake) GetReuseConnections() *bool {
	if c == nil {
		return nil
	}
	return c.ReuseConnections
}

func (c *CreateOutputOutputSecurityLake) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputSecurityLake) GetEnableAssumeRole() *bool {
	if c == nil {
		return nil
	}
	return c.EnableAssumeRole
}

func (c *CreateOutputOutputSecurityLake) GetAssumeRoleArn() string {
	if c == nil {
		return ""
	}
	return c.AssumeRoleArn
}

func (c *CreateOutputOutputSecurityLake) GetAssumeRoleExternalID() *string {
	if c == nil {
		return nil
	}
	return c.AssumeRoleExternalID
}

func (c *CreateOutputOutputSecurityLake) GetDurationSeconds() *float64 {
	if c == nil {
		return nil
	}
	return c.DurationSeconds
}

func (c *CreateOutputOutputSecurityLake) GetStagePath() string {
	if c == nil {
		return ""
	}
	return c.StagePath
}

func (c *CreateOutputOutputSecurityLake) GetAddIDToStagePath() *bool {
	if c == nil {
		return nil
	}
	return c.AddIDToStagePath
}

func (c *CreateOutputOutputSecurityLake) GetObjectACL() *components.ObjectACLOptions {
	if c == nil {
		return nil
	}
	return c.ObjectACL
}

func (c *CreateOutputOutputSecurityLake) GetStorageClass() *components.StorageClassOptions {
	if c == nil {
		return nil
	}
	return c.StorageClass
}

func (c *CreateOutputOutputSecurityLake) GetServerSideEncryption() *components.ServerSideEncryptionForUploadedObjectsOptions {
	if c == nil {
		return nil
	}
	return c.ServerSideEncryption
}

func (c *CreateOutputOutputSecurityLake) GetKmsKeyID() *string {
	if c == nil {
		return nil
	}
	return c.KmsKeyID
}

func (c *CreateOutputOutputSecurityLake) GetRemoveEmptyDirs() *bool {
	if c == nil {
		return nil
	}
	return c.RemoveEmptyDirs
}

func (c *CreateOutputOutputSecurityLake) GetBaseFileName() *string {
	if c == nil {
		return nil
	}
	return c.BaseFileName
}

func (c *CreateOutputOutputSecurityLake) GetMaxFileSizeMB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileSizeMB
}

func (c *CreateOutputOutputSecurityLake) GetMaxOpenFiles() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxOpenFiles
}

func (c *CreateOutputOutputSecurityLake) GetHeaderLine() *string {
	if c == nil {
		return nil
	}
	return c.HeaderLine
}

func (c *CreateOutputOutputSecurityLake) GetWriteHighWaterMark() *float64 {
	if c == nil {
		return nil
	}
	return c.WriteHighWaterMark
}

func (c *CreateOutputOutputSecurityLake) GetOnBackpressure() *components.BackpressureBehaviorOptions1 {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputSecurityLake) GetDeadletterEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.DeadletterEnabled
}

func (c *CreateOutputOutputSecurityLake) GetOnDiskFullBackpressure() *components.DiskSpaceProtectionOptions {
	if c == nil {
		return nil
	}
	return c.OnDiskFullBackpressure
}

func (c *CreateOutputOutputSecurityLake) GetForceCloseOnShutdown() *bool {
	if c == nil {
		return nil
	}
	return c.ForceCloseOnShutdown
}

func (c *CreateOutputOutputSecurityLake) GetRetrySettings() *components.RetrySettingsType {
	if c == nil {
		return nil
	}
	return c.RetrySettings
}

func (c *CreateOutputOutputSecurityLake) GetMaxFileOpenTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileOpenTimeSec
}

func (c *CreateOutputOutputSecurityLake) GetMaxFileIdleTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileIdleTimeSec
}

func (c *CreateOutputOutputSecurityLake) GetMaxConcurrentFileParts() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxConcurrentFileParts
}

func (c *CreateOutputOutputSecurityLake) GetVerifyPermissions() *bool {
	if c == nil {
		return nil
	}
	return c.VerifyPermissions
}

func (c *CreateOutputOutputSecurityLake) GetMaxClosingFilesToBackpressure() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxClosingFilesToBackpressure
}

func (c *CreateOutputOutputSecurityLake) GetAccountID() string {
	if c == nil {
		return ""
	}
	return c.AccountID
}

func (c *CreateOutputOutputSecurityLake) GetCustomSource() string {
	if c == nil {
		return ""
	}
	return c.CustomSource
}

func (c *CreateOutputOutputSecurityLake) GetAutomaticSchema() *bool {
	if c == nil {
		return nil
	}
	return c.AutomaticSchema
}

func (c *CreateOutputOutputSecurityLake) GetParquetVersion() *components.ParquetVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetVersion
}

func (c *CreateOutputOutputSecurityLake) GetParquetDataPageVersion() *components.DataPageVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetDataPageVersion
}

func (c *CreateOutputOutputSecurityLake) GetParquetRowGroupLength() *float64 {
	if c == nil {
		return nil
	}
	return c.ParquetRowGroupLength
}

func (c *CreateOutputOutputSecurityLake) GetParquetPageSize() *string {
	if c == nil {
		return nil
	}
	return c.ParquetPageSize
}

func (c *CreateOutputOutputSecurityLake) GetShouldLogInvalidRows() *bool {
	if c == nil {
		return nil
	}
	return c.ShouldLogInvalidRows
}

func (c *CreateOutputOutputSecurityLake) GetKeyValueMetadata() []components.ItemsTypeKeyValueMetadata {
	if c == nil {
		return nil
	}
	return c.KeyValueMetadata
}

func (c *CreateOutputOutputSecurityLake) GetEnableStatistics() *bool {
	if c == nil {
		return nil
	}
	return c.EnableStatistics
}

func (c *CreateOutputOutputSecurityLake) GetEnableWritePageIndex() *bool {
	if c == nil {
		return nil
	}
	return c.EnableWritePageIndex
}

func (c *CreateOutputOutputSecurityLake) GetEnablePageChecksum() *bool {
	if c == nil {
		return nil
	}
	return c.EnablePageChecksum
}

func (c *CreateOutputOutputSecurityLake) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputSecurityLake) GetAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsAPIKey
}

func (c *CreateOutputOutputSecurityLake) GetAwsSecret() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecret
}

func (c *CreateOutputOutputSecurityLake) GetEmptyDirCleanupSec() *float64 {
	if c == nil {
		return nil
	}
	return c.EmptyDirCleanupSec
}

func (c *CreateOutputOutputSecurityLake) GetDirectoryBatchSize() *float64 {
	if c == nil {
		return nil
	}
	return c.DirectoryBatchSize
}

func (c *CreateOutputOutputSecurityLake) GetParquetSchema() *string {
	if c == nil {
		return nil
	}
	return c.ParquetSchema
}

func (c *CreateOutputOutputSecurityLake) GetDeadletterPath() *string {
	if c == nil {
		return nil
	}
	return c.DeadletterPath
}

func (c *CreateOutputOutputSecurityLake) GetMaxRetryNum() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRetryNum
}

func (c *CreateOutputOutputSecurityLake) GetTemplateBucket() *string {
	if c == nil {
		return nil
	}
	return c.TemplateBucket
}

func (c *CreateOutputOutputSecurityLake) GetTemplateRegion() *string {
	if c == nil {
		return nil
	}
	return c.TemplateRegion
}

func (c *CreateOutputOutputSecurityLake) GetTemplateAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAwsSecretKey
}

func (c *CreateOutputOutputSecurityLake) GetTemplateAssumeRoleArn() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAssumeRoleArn
}

func (c *CreateOutputOutputSecurityLake) GetTemplateAssumeRoleExternalID() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAssumeRoleExternalID
}

func (c *CreateOutputOutputSecurityLake) GetTemplateAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAwsAPIKey
}

type CreateOutputTypeDlS3 string

const (
	CreateOutputTypeDlS3DlS3 CreateOutputTypeDlS3 = "dl_s3"
)

func (e CreateOutputTypeDlS3) ToPointer() *CreateOutputTypeDlS3 {
	return &e
}
func (e *CreateOutputTypeDlS3) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "dl_s3":
		*e = CreateOutputTypeDlS3(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeDlS3: %v", v)
	}
}

type CreateOutputOutputDlS3 struct {
	// Unique ID for this output
	ID   string               `json:"id"`
	Type CreateOutputTypeDlS3 `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
	Bucket string `json:"bucket"`
	// Region where the S3 bucket is located
	Region *string `json:"region,omitempty"`
	// Secret key. This value can be a constant or a JavaScript expression. Example: `${C.env.SOME_SECRET}`)
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *components.SignatureVersionOptionsS3CollectorConf `json:"signatureVersion,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `json:"enableAssumeRole,omitempty"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitempty"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
	StagePath string `json:"stagePath"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Prefix to prepend to files before uploading. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `myKeyPrefix-${C.vars.myVar}`
	DestPath *string `json:"destPath,omitempty"`
	// Object ACL to assign to uploaded objects
	ObjectACL *components.ObjectACLOptions `json:"objectACL,omitempty"`
	// Storage class to select for uploaded objects
	StorageClass         *components.StorageClassOptions                           `json:"storageClass,omitempty"`
	ServerSideEncryption *components.ServerSideEncryptionForUploadedObjectsOptions `json:"serverSideEncryption,omitempty"`
	// ID or ARN of the KMS customer-managed key to use for encryption
	KmsKeyID *string `json:"kmsKeyId,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// Format of the output data
	Format *components.DataFormatOptions `json:"format,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `json:"baseFileName,omitempty"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `json:"fileNameSuffix,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `json:"maxFileSizeMB,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `json:"maxOpenFiles,omitempty"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `json:"headerLine,omitempty"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `json:"writeHighWaterMark,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `json:"deadletterEnabled,omitempty"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *components.DiskSpaceProtectionOptions `json:"onDiskFullBackpressure,omitempty"`
	// Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
	ForceCloseOnShutdown *bool                         `json:"forceCloseOnShutdown,omitempty"`
	RetrySettings        *components.RetrySettingsType `json:"retrySettings,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *float64 `json:"maxConcurrentFileParts,omitempty"`
	// Disable if you can access files within the bucket but not the bucket itself
	VerifyPermissions *bool `json:"verifyPermissions,omitempty"`
	// Maximum number of files that can be waiting for upload before backpressure is applied
	MaxClosingFilesToBackpressure *float64 `json:"maxClosingFilesToBackpressure,omitempty"`
	// List of fields to partition the path by, in addition to time, which is included automatically. The effective partition will be YYYY/MM/DD/HH/<list/of/fields>.
	PartitioningFields []string `json:"partitioningFields,omitempty"`
	Description        *string  `json:"description,omitempty"`
	// This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Data compression format to apply to HTTP content before it is delivered
	Compress *components.CompressionOptions2 `json:"compress,omitempty"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *components.CompressionLevelOptions `json:"compressionLevel,omitempty"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `json:"automaticSchema,omitempty"`
	// To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
	ParquetSchema *string `json:"parquetSchema,omitempty"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *components.ParquetVersionOptions `json:"parquetVersion,omitempty"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *components.DataPageVersionOptions `json:"parquetDataPageVersion,omitempty"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `json:"parquetRowGroupLength,omitempty"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
	KeyValueMetadata []components.ItemsTypeKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `json:"enableStatistics,omitempty"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `json:"enableWritePageIndex,omitempty"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `json:"enablePageChecksum,omitempty"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `json:"emptyDirCleanupSec,omitempty"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `json:"directoryBatchSize,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `json:"deadletterPath,omitempty"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `json:"maxRetryNum,omitempty"`
	// Binds 'bucket' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'bucket' at runtime.
	TemplateBucket *string `json:"__template_bucket,omitempty"`
	// Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime.
	TemplateRegion *string `json:"__template_region,omitempty"`
	// Binds 'awsSecretKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsSecretKey' at runtime.
	TemplateAwsSecretKey *string `json:"__template_awsSecretKey,omitempty"`
	// Binds 'assumeRoleArn' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleArn' at runtime.
	TemplateAssumeRoleArn *string `json:"__template_assumeRoleArn,omitempty"`
	// Binds 'assumeRoleExternalId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleExternalId' at runtime.
	TemplateAssumeRoleExternalID *string `json:"__template_assumeRoleExternalId,omitempty"`
	// Binds 'format' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'format' at runtime.
	TemplateFormat *string `json:"__template_format,omitempty"`
	// Binds 'awsApiKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsApiKey' at runtime.
	TemplateAwsAPIKey *string `json:"__template_awsApiKey,omitempty"`
}

func (c CreateOutputOutputDlS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputDlS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "bucket", "stagePath"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputDlS3) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputDlS3) GetType() CreateOutputTypeDlS3 {
	if c == nil {
		return CreateOutputTypeDlS3("")
	}
	return c.Type
}

func (c *CreateOutputOutputDlS3) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputDlS3) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputDlS3) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputDlS3) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputDlS3) GetBucket() string {
	if c == nil {
		return ""
	}
	return c.Bucket
}

func (c *CreateOutputOutputDlS3) GetRegion() *string {
	if c == nil {
		return nil
	}
	return c.Region
}

func (c *CreateOutputOutputDlS3) GetAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecretKey
}

func (c *CreateOutputOutputDlS3) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if c == nil {
		return nil
	}
	return c.AwsAuthenticationMethod
}

func (c *CreateOutputOutputDlS3) GetEndpoint() *string {
	if c == nil {
		return nil
	}
	return c.Endpoint
}

func (c *CreateOutputOutputDlS3) GetSignatureVersion() *components.SignatureVersionOptionsS3CollectorConf {
	if c == nil {
		return nil
	}
	return c.SignatureVersion
}

func (c *CreateOutputOutputDlS3) GetReuseConnections() *bool {
	if c == nil {
		return nil
	}
	return c.ReuseConnections
}

func (c *CreateOutputOutputDlS3) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputDlS3) GetEnableAssumeRole() *bool {
	if c == nil {
		return nil
	}
	return c.EnableAssumeRole
}

func (c *CreateOutputOutputDlS3) GetAssumeRoleArn() *string {
	if c == nil {
		return nil
	}
	return c.AssumeRoleArn
}

func (c *CreateOutputOutputDlS3) GetAssumeRoleExternalID() *string {
	if c == nil {
		return nil
	}
	return c.AssumeRoleExternalID
}

func (c *CreateOutputOutputDlS3) GetDurationSeconds() *float64 {
	if c == nil {
		return nil
	}
	return c.DurationSeconds
}

func (c *CreateOutputOutputDlS3) GetStagePath() string {
	if c == nil {
		return ""
	}
	return c.StagePath
}

func (c *CreateOutputOutputDlS3) GetAddIDToStagePath() *bool {
	if c == nil {
		return nil
	}
	return c.AddIDToStagePath
}

func (c *CreateOutputOutputDlS3) GetDestPath() *string {
	if c == nil {
		return nil
	}
	return c.DestPath
}

func (c *CreateOutputOutputDlS3) GetObjectACL() *components.ObjectACLOptions {
	if c == nil {
		return nil
	}
	return c.ObjectACL
}

func (c *CreateOutputOutputDlS3) GetStorageClass() *components.StorageClassOptions {
	if c == nil {
		return nil
	}
	return c.StorageClass
}

func (c *CreateOutputOutputDlS3) GetServerSideEncryption() *components.ServerSideEncryptionForUploadedObjectsOptions {
	if c == nil {
		return nil
	}
	return c.ServerSideEncryption
}

func (c *CreateOutputOutputDlS3) GetKmsKeyID() *string {
	if c == nil {
		return nil
	}
	return c.KmsKeyID
}

func (c *CreateOutputOutputDlS3) GetRemoveEmptyDirs() *bool {
	if c == nil {
		return nil
	}
	return c.RemoveEmptyDirs
}

func (c *CreateOutputOutputDlS3) GetFormat() *components.DataFormatOptions {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputDlS3) GetBaseFileName() *string {
	if c == nil {
		return nil
	}
	return c.BaseFileName
}

func (c *CreateOutputOutputDlS3) GetFileNameSuffix() *string {
	if c == nil {
		return nil
	}
	return c.FileNameSuffix
}

func (c *CreateOutputOutputDlS3) GetMaxFileSizeMB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileSizeMB
}

func (c *CreateOutputOutputDlS3) GetMaxOpenFiles() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxOpenFiles
}

func (c *CreateOutputOutputDlS3) GetHeaderLine() *string {
	if c == nil {
		return nil
	}
	return c.HeaderLine
}

func (c *CreateOutputOutputDlS3) GetWriteHighWaterMark() *float64 {
	if c == nil {
		return nil
	}
	return c.WriteHighWaterMark
}

func (c *CreateOutputOutputDlS3) GetOnBackpressure() *components.BackpressureBehaviorOptions1 {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputDlS3) GetDeadletterEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.DeadletterEnabled
}

func (c *CreateOutputOutputDlS3) GetOnDiskFullBackpressure() *components.DiskSpaceProtectionOptions {
	if c == nil {
		return nil
	}
	return c.OnDiskFullBackpressure
}

func (c *CreateOutputOutputDlS3) GetForceCloseOnShutdown() *bool {
	if c == nil {
		return nil
	}
	return c.ForceCloseOnShutdown
}

func (c *CreateOutputOutputDlS3) GetRetrySettings() *components.RetrySettingsType {
	if c == nil {
		return nil
	}
	return c.RetrySettings
}

func (c *CreateOutputOutputDlS3) GetMaxFileOpenTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileOpenTimeSec
}

func (c *CreateOutputOutputDlS3) GetMaxFileIdleTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileIdleTimeSec
}

func (c *CreateOutputOutputDlS3) GetMaxConcurrentFileParts() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxConcurrentFileParts
}

func (c *CreateOutputOutputDlS3) GetVerifyPermissions() *bool {
	if c == nil {
		return nil
	}
	return c.VerifyPermissions
}

func (c *CreateOutputOutputDlS3) GetMaxClosingFilesToBackpressure() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxClosingFilesToBackpressure
}

func (c *CreateOutputOutputDlS3) GetPartitioningFields() []string {
	if c == nil {
		return nil
	}
	return c.PartitioningFields
}

func (c *CreateOutputOutputDlS3) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputDlS3) GetAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsAPIKey
}

func (c *CreateOutputOutputDlS3) GetAwsSecret() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecret
}

func (c *CreateOutputOutputDlS3) GetCompress() *components.CompressionOptions2 {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputDlS3) GetCompressionLevel() *components.CompressionLevelOptions {
	if c == nil {
		return nil
	}
	return c.CompressionLevel
}

func (c *CreateOutputOutputDlS3) GetAutomaticSchema() *bool {
	if c == nil {
		return nil
	}
	return c.AutomaticSchema
}

func (c *CreateOutputOutputDlS3) GetParquetSchema() *string {
	if c == nil {
		return nil
	}
	return c.ParquetSchema
}

func (c *CreateOutputOutputDlS3) GetParquetVersion() *components.ParquetVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetVersion
}

func (c *CreateOutputOutputDlS3) GetParquetDataPageVersion() *components.DataPageVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetDataPageVersion
}

func (c *CreateOutputOutputDlS3) GetParquetRowGroupLength() *float64 {
	if c == nil {
		return nil
	}
	return c.ParquetRowGroupLength
}

func (c *CreateOutputOutputDlS3) GetParquetPageSize() *string {
	if c == nil {
		return nil
	}
	return c.ParquetPageSize
}

func (c *CreateOutputOutputDlS3) GetShouldLogInvalidRows() *bool {
	if c == nil {
		return nil
	}
	return c.ShouldLogInvalidRows
}

func (c *CreateOutputOutputDlS3) GetKeyValueMetadata() []components.ItemsTypeKeyValueMetadata {
	if c == nil {
		return nil
	}
	return c.KeyValueMetadata
}

func (c *CreateOutputOutputDlS3) GetEnableStatistics() *bool {
	if c == nil {
		return nil
	}
	return c.EnableStatistics
}

func (c *CreateOutputOutputDlS3) GetEnableWritePageIndex() *bool {
	if c == nil {
		return nil
	}
	return c.EnableWritePageIndex
}

func (c *CreateOutputOutputDlS3) GetEnablePageChecksum() *bool {
	if c == nil {
		return nil
	}
	return c.EnablePageChecksum
}

func (c *CreateOutputOutputDlS3) GetEmptyDirCleanupSec() *float64 {
	if c == nil {
		return nil
	}
	return c.EmptyDirCleanupSec
}

func (c *CreateOutputOutputDlS3) GetDirectoryBatchSize() *float64 {
	if c == nil {
		return nil
	}
	return c.DirectoryBatchSize
}

func (c *CreateOutputOutputDlS3) GetDeadletterPath() *string {
	if c == nil {
		return nil
	}
	return c.DeadletterPath
}

func (c *CreateOutputOutputDlS3) GetMaxRetryNum() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRetryNum
}

func (c *CreateOutputOutputDlS3) GetTemplateBucket() *string {
	if c == nil {
		return nil
	}
	return c.TemplateBucket
}

func (c *CreateOutputOutputDlS3) GetTemplateRegion() *string {
	if c == nil {
		return nil
	}
	return c.TemplateRegion
}

func (c *CreateOutputOutputDlS3) GetTemplateAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAwsSecretKey
}

func (c *CreateOutputOutputDlS3) GetTemplateAssumeRoleArn() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAssumeRoleArn
}

func (c *CreateOutputOutputDlS3) GetTemplateAssumeRoleExternalID() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAssumeRoleExternalID
}

func (c *CreateOutputOutputDlS3) GetTemplateFormat() *string {
	if c == nil {
		return nil
	}
	return c.TemplateFormat
}

func (c *CreateOutputOutputDlS3) GetTemplateAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAwsAPIKey
}

type CreateOutputTypeCrowdstrikeNextGenSiem string

const (
	CreateOutputTypeCrowdstrikeNextGenSiemCrowdstrikeNextGenSiem CreateOutputTypeCrowdstrikeNextGenSiem = "crowdstrike_next_gen_siem"
)

func (e CreateOutputTypeCrowdstrikeNextGenSiem) ToPointer() *CreateOutputTypeCrowdstrikeNextGenSiem {
	return &e
}
func (e *CreateOutputTypeCrowdstrikeNextGenSiem) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "crowdstrike_next_gen_siem":
		*e = CreateOutputTypeCrowdstrikeNextGenSiem(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeCrowdstrikeNextGenSiem: %v", v)
	}
}

type CreateOutputPqControlsCrowdstrikeNextGenSiem struct {
}

func (c CreateOutputPqControlsCrowdstrikeNextGenSiem) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsCrowdstrikeNextGenSiem) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputCrowdstrikeNextGenSiem struct {
	// Unique ID for this output
	ID   string                                 `json:"id"`
	Type CreateOutputTypeCrowdstrikeNextGenSiem `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// URL provided from a CrowdStrike data connector.
	// Example: https://ingest.<region>.crowdstrike.com/api/ingest/hec/<connection-id>/v1/services/collector
	URL string `json:"url"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// When set to JSON, the event is automatically formatted with required fields before sending. When set to Raw, only the event's `_raw` value is sent.
	Format components.RequestFormatOptions `json:"format"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	Token          *string                                 `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions          `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsCrowdstrikeNextGenSiem `json:"pqControls,omitempty"`
	// Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
	TemplateURL *string `json:"__template_url,omitempty"`
}

func (c CreateOutputOutputCrowdstrikeNextGenSiem) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "url", "format"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetType() CreateOutputTypeCrowdstrikeNextGenSiem {
	if c == nil {
		return CreateOutputTypeCrowdstrikeNextGenSiem("")
	}
	return c.Type
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetURL() string {
	if c == nil {
		return ""
	}
	return c.URL
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetFormat() components.RequestFormatOptions {
	if c == nil {
		return components.RequestFormatOptions("")
	}
	return c.Format
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetToken() *string {
	if c == nil {
		return nil
	}
	return c.Token
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetPqControls() *CreateOutputPqControlsCrowdstrikeNextGenSiem {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputCrowdstrikeNextGenSiem) GetTemplateURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateURL
}

type CreateOutputTypeHumioHec string

const (
	CreateOutputTypeHumioHecHumioHec CreateOutputTypeHumioHec = "humio_hec"
)

func (e CreateOutputTypeHumioHec) ToPointer() *CreateOutputTypeHumioHec {
	return &e
}
func (e *CreateOutputTypeHumioHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "humio_hec":
		*e = CreateOutputTypeHumioHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeHumioHec: %v", v)
	}
}

type CreateOutputPqControlsHumioHec struct {
}

func (c CreateOutputPqControlsHumioHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsHumioHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputHumioHec struct {
	// Unique ID for this output
	ID   string                   `json:"id"`
	Type CreateOutputTypeHumioHec `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// URL to a CrowdStrike Falcon LogScale endpoint to send events to. Examples: https://cloud.us.humio.com/api/v1/ingest/hec for JSON and https://cloud.us.humio.com/api/v1/ingest/hec/raw for raw
	URL string `json:"url"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// When set to JSON, the event is automatically formatted with required fields before sending. When set to Raw, only the event's `_raw` value is sent.
	Format components.RequestFormatOptions `json:"format"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// CrowdStrike Falcon LogScale authentication token
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsHumioHec      `json:"pqControls,omitempty"`
	// Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
	TemplateURL *string `json:"__template_url,omitempty"`
}

func (c CreateOutputOutputHumioHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputHumioHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "url", "format"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputHumioHec) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputHumioHec) GetType() CreateOutputTypeHumioHec {
	if c == nil {
		return CreateOutputTypeHumioHec("")
	}
	return c.Type
}

func (c *CreateOutputOutputHumioHec) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputHumioHec) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputHumioHec) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputHumioHec) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputHumioHec) GetURL() string {
	if c == nil {
		return ""
	}
	return c.URL
}

func (c *CreateOutputOutputHumioHec) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputHumioHec) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputHumioHec) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputHumioHec) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputHumioHec) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputHumioHec) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputHumioHec) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputHumioHec) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputHumioHec) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputHumioHec) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputHumioHec) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputHumioHec) GetFormat() components.RequestFormatOptions {
	if c == nil {
		return components.RequestFormatOptions("")
	}
	return c.Format
}

func (c *CreateOutputOutputHumioHec) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputHumioHec) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputHumioHec) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputHumioHec) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputHumioHec) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputHumioHec) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputHumioHec) GetToken() *string {
	if c == nil {
		return nil
	}
	return c.Token
}

func (c *CreateOutputOutputHumioHec) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputHumioHec) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputHumioHec) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputHumioHec) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputHumioHec) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputHumioHec) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputHumioHec) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputHumioHec) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputHumioHec) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputHumioHec) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputHumioHec) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputHumioHec) GetPqControls() *CreateOutputPqControlsHumioHec {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputHumioHec) GetTemplateURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateURL
}

type CreateOutputTypeCriblSearchEngine string

const (
	CreateOutputTypeCriblSearchEngineCriblSearchEngine CreateOutputTypeCriblSearchEngine = "cribl_search_engine"
)

func (e CreateOutputTypeCriblSearchEngine) ToPointer() *CreateOutputTypeCriblSearchEngine {
	return &e
}
func (e *CreateOutputTypeCriblSearchEngine) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_search_engine":
		*e = CreateOutputTypeCriblSearchEngine(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeCriblSearchEngine: %v", v)
	}
}

type CreateOutputPqControlsCriblSearchEngine struct {
}

func (c CreateOutputPqControlsCriblSearchEngine) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsCriblSearchEngine) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputCriblSearchEngine struct {
	// Unique ID for this output
	ID   string                            `json:"id"`
	Type CreateOutputTypeCriblSearchEngine `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// For optimal performance, enable load balancing even if you have one hostname, as it can expand to multiple IPs. If this setting is disabled, consider enabling round-robin DNS.
	LoadBalanced *bool                                                    `json:"loadBalanced,omitempty"`
	TLS          *components.TLSSettingsClientSideTypeKafkaSchemaRegistry `json:"tls,omitempty"`
	// The number of minutes before the internally generated authentication token expires. Valid values are between 1 and 60.
	TokenTTLMinutes *float64 `json:"tokenTTLMinutes,omitempty"`
	// Fields to exclude from the event. By default, all internal fields except `__output` are sent. Example: `cribl_pipe`, `c*`. Wildcards supported.
	ExcludeFields []string `json:"excludeFields,omitempty"`
	// Codec to use to compress the data before sending
	Compression *components.CompressionOptions1 `json:"compression,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `json:"throttleRatePerSec,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// Shared secrets to be used by connected environments to authorize connections. These tokens should also be installed in Cribl HTTP Source in Cribl.Cloud.
	AuthTokens []components.ItemsTypeAuthTokens1 `json:"authTokens,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool   `json:"useRoundRobinDns,omitempty"`
	Description      *string `json:"description,omitempty"`
	// URL of a Cribl Worker to send events to, such as http://localhost:10200
	URL *string `json:"url,omitempty"`
	// Exclude all IPs of the current host from the list of any resolved hostnames
	ExcludeSelf *bool                      `json:"excludeSelf,omitempty"`
	Urls        []components.ItemsTypeUrls `json:"urls,omitempty"`
	// The interval in which to re-resolve any hostnames and pick up destinations from A records
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	// How far back in time to keep traffic stats for load balancing purposes
	LoadBalanceStatsPeriodSec *float64 `json:"loadBalanceStatsPeriodSec,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions     `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsCriblSearchEngine `json:"pqControls,omitempty"`
	// Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
	TemplateURL *string `json:"__template_url,omitempty"`
}

func (c CreateOutputOutputCriblSearchEngine) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputCriblSearchEngine) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputCriblSearchEngine) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputCriblSearchEngine) GetType() CreateOutputTypeCriblSearchEngine {
	if c == nil {
		return CreateOutputTypeCriblSearchEngine("")
	}
	return c.Type
}

func (c *CreateOutputOutputCriblSearchEngine) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputCriblSearchEngine) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputCriblSearchEngine) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputCriblSearchEngine) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputCriblSearchEngine) GetLoadBalanced() *bool {
	if c == nil {
		return nil
	}
	return c.LoadBalanced
}

func (c *CreateOutputOutputCriblSearchEngine) GetTLS() *components.TLSSettingsClientSideTypeKafkaSchemaRegistry {
	if c == nil {
		return nil
	}
	return c.TLS
}

func (c *CreateOutputOutputCriblSearchEngine) GetTokenTTLMinutes() *float64 {
	if c == nil {
		return nil
	}
	return c.TokenTTLMinutes
}

func (c *CreateOutputOutputCriblSearchEngine) GetExcludeFields() []string {
	if c == nil {
		return nil
	}
	return c.ExcludeFields
}

func (c *CreateOutputOutputCriblSearchEngine) GetCompression() *components.CompressionOptions1 {
	if c == nil {
		return nil
	}
	return c.Compression
}

func (c *CreateOutputOutputCriblSearchEngine) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputCriblSearchEngine) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputCriblSearchEngine) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputCriblSearchEngine) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputCriblSearchEngine) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputCriblSearchEngine) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputCriblSearchEngine) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputCriblSearchEngine) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputCriblSearchEngine) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputCriblSearchEngine) GetThrottleRatePerSec() *string {
	if c == nil {
		return nil
	}
	return c.ThrottleRatePerSec
}

func (c *CreateOutputOutputCriblSearchEngine) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputCriblSearchEngine) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputCriblSearchEngine) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputCriblSearchEngine) GetAuthTokens() []components.ItemsTypeAuthTokens1 {
	if c == nil {
		return nil
	}
	return c.AuthTokens
}

func (c *CreateOutputOutputCriblSearchEngine) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputCriblSearchEngine) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputCriblSearchEngine) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputCriblSearchEngine) GetURL() *string {
	if c == nil {
		return nil
	}
	return c.URL
}

func (c *CreateOutputOutputCriblSearchEngine) GetExcludeSelf() *bool {
	if c == nil {
		return nil
	}
	return c.ExcludeSelf
}

func (c *CreateOutputOutputCriblSearchEngine) GetUrls() []components.ItemsTypeUrls {
	if c == nil {
		return nil
	}
	return c.Urls
}

func (c *CreateOutputOutputCriblSearchEngine) GetDNSResolvePeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.DNSResolvePeriodSec
}

func (c *CreateOutputOutputCriblSearchEngine) GetLoadBalanceStatsPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.LoadBalanceStatsPeriodSec
}

func (c *CreateOutputOutputCriblSearchEngine) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputCriblSearchEngine) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputCriblSearchEngine) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputCriblSearchEngine) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputCriblSearchEngine) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputCriblSearchEngine) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputCriblSearchEngine) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputCriblSearchEngine) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputCriblSearchEngine) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputCriblSearchEngine) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputCriblSearchEngine) GetPqControls() *CreateOutputPqControlsCriblSearchEngine {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputCriblSearchEngine) GetTemplateURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateURL
}

type CreateOutputTypeCriblHTTP string

const (
	CreateOutputTypeCriblHTTPCriblHTTP CreateOutputTypeCriblHTTP = "cribl_http"
)

func (e CreateOutputTypeCriblHTTP) ToPointer() *CreateOutputTypeCriblHTTP {
	return &e
}
func (e *CreateOutputTypeCriblHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_http":
		*e = CreateOutputTypeCriblHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeCriblHTTP: %v", v)
	}
}

type CreateOutputPqControlsCriblHTTP struct {
}

func (c CreateOutputPqControlsCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputCriblHTTP struct {
	// Unique ID for this output
	ID   string                    `json:"id"`
	Type CreateOutputTypeCriblHTTP `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// For optimal performance, enable load balancing even if you have one hostname, as it can expand to multiple IPs. If this setting is disabled, consider enabling round-robin DNS.
	LoadBalanced *bool                                                    `json:"loadBalanced,omitempty"`
	TLS          *components.TLSSettingsClientSideTypeKafkaSchemaRegistry `json:"tls,omitempty"`
	// The number of minutes before the internally generated authentication token expires. Valid values are between 1 and 60.
	TokenTTLMinutes *float64 `json:"tokenTTLMinutes,omitempty"`
	// Fields to exclude from the event. By default, all internal fields except `__output` are sent. Example: `cribl_pipe`, `c*`. Wildcards supported.
	ExcludeFields []string `json:"excludeFields,omitempty"`
	// Codec to use to compress the data before sending
	Compression *components.CompressionOptions1 `json:"compression,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `json:"throttleRatePerSec,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// Shared secrets to be used by connected environments to authorize connections. These tokens should also be installed in Cribl HTTP Source in Cribl.Cloud.
	AuthTokens []components.ItemsTypeAuthTokens1 `json:"authTokens,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// URL of a Cribl Worker to send events to, such as http://localhost:10200
	URL *string `json:"url,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Exclude all IPs of the current host from the list of any resolved hostnames
	ExcludeSelf *bool                      `json:"excludeSelf,omitempty"`
	Urls        []components.ItemsTypeUrls `json:"urls,omitempty"`
	// The interval in which to re-resolve any hostnames and pick up destinations from A records
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	// How far back in time to keep traffic stats for load balancing purposes
	LoadBalanceStatsPeriodSec *float64 `json:"loadBalanceStatsPeriodSec,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsCriblHTTP     `json:"pqControls,omitempty"`
	// Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
	TemplateURL *string `json:"__template_url,omitempty"`
}

func (c CreateOutputOutputCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputCriblHTTP) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputCriblHTTP) GetType() CreateOutputTypeCriblHTTP {
	if c == nil {
		return CreateOutputTypeCriblHTTP("")
	}
	return c.Type
}

func (c *CreateOutputOutputCriblHTTP) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputCriblHTTP) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputCriblHTTP) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputCriblHTTP) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputCriblHTTP) GetLoadBalanced() *bool {
	if c == nil {
		return nil
	}
	return c.LoadBalanced
}

func (c *CreateOutputOutputCriblHTTP) GetTLS() *components.TLSSettingsClientSideTypeKafkaSchemaRegistry {
	if c == nil {
		return nil
	}
	return c.TLS
}

func (c *CreateOutputOutputCriblHTTP) GetTokenTTLMinutes() *float64 {
	if c == nil {
		return nil
	}
	return c.TokenTTLMinutes
}

func (c *CreateOutputOutputCriblHTTP) GetExcludeFields() []string {
	if c == nil {
		return nil
	}
	return c.ExcludeFields
}

func (c *CreateOutputOutputCriblHTTP) GetCompression() *components.CompressionOptions1 {
	if c == nil {
		return nil
	}
	return c.Compression
}

func (c *CreateOutputOutputCriblHTTP) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputCriblHTTP) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputCriblHTTP) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputCriblHTTP) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputCriblHTTP) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputCriblHTTP) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputCriblHTTP) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputCriblHTTP) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputCriblHTTP) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputCriblHTTP) GetThrottleRatePerSec() *string {
	if c == nil {
		return nil
	}
	return c.ThrottleRatePerSec
}

func (c *CreateOutputOutputCriblHTTP) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputCriblHTTP) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputCriblHTTP) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputCriblHTTP) GetAuthTokens() []components.ItemsTypeAuthTokens1 {
	if c == nil {
		return nil
	}
	return c.AuthTokens
}

func (c *CreateOutputOutputCriblHTTP) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputCriblHTTP) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputCriblHTTP) GetURL() *string {
	if c == nil {
		return nil
	}
	return c.URL
}

func (c *CreateOutputOutputCriblHTTP) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputCriblHTTP) GetExcludeSelf() *bool {
	if c == nil {
		return nil
	}
	return c.ExcludeSelf
}

func (c *CreateOutputOutputCriblHTTP) GetUrls() []components.ItemsTypeUrls {
	if c == nil {
		return nil
	}
	return c.Urls
}

func (c *CreateOutputOutputCriblHTTP) GetDNSResolvePeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.DNSResolvePeriodSec
}

func (c *CreateOutputOutputCriblHTTP) GetLoadBalanceStatsPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.LoadBalanceStatsPeriodSec
}

func (c *CreateOutputOutputCriblHTTP) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputCriblHTTP) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputCriblHTTP) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputCriblHTTP) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputCriblHTTP) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputCriblHTTP) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputCriblHTTP) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputCriblHTTP) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputCriblHTTP) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputCriblHTTP) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputCriblHTTP) GetPqControls() *CreateOutputPqControlsCriblHTTP {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputCriblHTTP) GetTemplateURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateURL
}

type CreateOutputTypeCriblTCP string

const (
	CreateOutputTypeCriblTCPCriblTCP CreateOutputTypeCriblTCP = "cribl_tcp"
)

func (e CreateOutputTypeCriblTCP) ToPointer() *CreateOutputTypeCriblTCP {
	return &e
}
func (e *CreateOutputTypeCriblTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_tcp":
		*e = CreateOutputTypeCriblTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeCriblTCP: %v", v)
	}
}

type CreateOutputPqControlsCriblTCP struct {
}

func (c CreateOutputPqControlsCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputCriblTCP struct {
	// Unique ID for this output
	ID   string                   `json:"id"`
	Type CreateOutputTypeCriblTCP `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Use load-balanced destinations
	LoadBalanced *bool `json:"loadBalanced,omitempty"`
	// Codec to use to compress the data before sending
	Compression *components.CompressionOptions1 `json:"compression,omitempty"`
	// Use to troubleshoot issues with sending data
	LogFailedRequests *bool `json:"logFailedRequests,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string                                                  `json:"throttleRatePerSec,omitempty"`
	TLS                *components.TLSSettingsClientSideTypeKafkaSchemaRegistry `json:"tls,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64 `json:"writeTimeout,omitempty"`
	// The number of minutes before the internally generated authentication token expires, valid values between 1 and 60
	TokenTTLMinutes *float64 `json:"tokenTTLMinutes,omitempty"`
	// Shared secrets to be used by connected environments to authorize connections. These tokens should also be installed in Cribl TCP Source in Cribl.Cloud.
	AuthTokens []components.ItemsTypeAuthTokens `json:"authTokens,omitempty"`
	// Fields to exclude from the event. By default, all internal fields except `__output` are sent. Example: `cribl_pipe`, `c*`. Wildcards supported.
	ExcludeFields []string `json:"excludeFields,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// The hostname of the receiver
	Host *string `json:"host,omitempty"`
	// The port to connect to on the provided host
	Port *float64 `json:"port,omitempty"`
	// Exclude all IPs of the current host from the list of any resolved hostnames
	ExcludeSelf *bool `json:"excludeSelf,omitempty"`
	// Set of hosts to load-balance data to
	Hosts []components.ItemsTypeHosts `json:"hosts,omitempty"`
	// The interval in which to re-resolve any hostnames and pick up destinations from A records
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	// How far back in time to keep traffic stats for load balancing purposes
	LoadBalanceStatsPeriodSec *float64 `json:"loadBalanceStatsPeriodSec,omitempty"`
	// Maximum number of concurrent connections (per Worker Process). A random set of IPs will be picked on every DNS resolution period. Use 0 for unlimited.
	MaxConcurrentSenders *float64 `json:"maxConcurrentSenders,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsCriblTCP      `json:"pqControls,omitempty"`
	// Binds 'host' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'host' at runtime.
	TemplateHost *string `json:"__template_host,omitempty"`
	// Binds 'port' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'port' at runtime.
	TemplatePort *string `json:"__template_port,omitempty"`
}

func (c CreateOutputOutputCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputCriblTCP) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputCriblTCP) GetType() CreateOutputTypeCriblTCP {
	if c == nil {
		return CreateOutputTypeCriblTCP("")
	}
	return c.Type
}

func (c *CreateOutputOutputCriblTCP) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputCriblTCP) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputCriblTCP) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputCriblTCP) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputCriblTCP) GetLoadBalanced() *bool {
	if c == nil {
		return nil
	}
	return c.LoadBalanced
}

func (c *CreateOutputOutputCriblTCP) GetCompression() *components.CompressionOptions1 {
	if c == nil {
		return nil
	}
	return c.Compression
}

func (c *CreateOutputOutputCriblTCP) GetLogFailedRequests() *bool {
	if c == nil {
		return nil
	}
	return c.LogFailedRequests
}

func (c *CreateOutputOutputCriblTCP) GetThrottleRatePerSec() *string {
	if c == nil {
		return nil
	}
	return c.ThrottleRatePerSec
}

func (c *CreateOutputOutputCriblTCP) GetTLS() *components.TLSSettingsClientSideTypeKafkaSchemaRegistry {
	if c == nil {
		return nil
	}
	return c.TLS
}

func (c *CreateOutputOutputCriblTCP) GetConnectionTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.ConnectionTimeout
}

func (c *CreateOutputOutputCriblTCP) GetWriteTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.WriteTimeout
}

func (c *CreateOutputOutputCriblTCP) GetTokenTTLMinutes() *float64 {
	if c == nil {
		return nil
	}
	return c.TokenTTLMinutes
}

func (c *CreateOutputOutputCriblTCP) GetAuthTokens() []components.ItemsTypeAuthTokens {
	if c == nil {
		return nil
	}
	return c.AuthTokens
}

func (c *CreateOutputOutputCriblTCP) GetExcludeFields() []string {
	if c == nil {
		return nil
	}
	return c.ExcludeFields
}

func (c *CreateOutputOutputCriblTCP) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputCriblTCP) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputCriblTCP) GetHost() *string {
	if c == nil {
		return nil
	}
	return c.Host
}

func (c *CreateOutputOutputCriblTCP) GetPort() *float64 {
	if c == nil {
		return nil
	}
	return c.Port
}

func (c *CreateOutputOutputCriblTCP) GetExcludeSelf() *bool {
	if c == nil {
		return nil
	}
	return c.ExcludeSelf
}

func (c *CreateOutputOutputCriblTCP) GetHosts() []components.ItemsTypeHosts {
	if c == nil {
		return nil
	}
	return c.Hosts
}

func (c *CreateOutputOutputCriblTCP) GetDNSResolvePeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.DNSResolvePeriodSec
}

func (c *CreateOutputOutputCriblTCP) GetLoadBalanceStatsPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.LoadBalanceStatsPeriodSec
}

func (c *CreateOutputOutputCriblTCP) GetMaxConcurrentSenders() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxConcurrentSenders
}

func (c *CreateOutputOutputCriblTCP) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputCriblTCP) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputCriblTCP) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputCriblTCP) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputCriblTCP) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputCriblTCP) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputCriblTCP) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputCriblTCP) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputCriblTCP) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputCriblTCP) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputCriblTCP) GetPqControls() *CreateOutputPqControlsCriblTCP {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputCriblTCP) GetTemplateHost() *string {
	if c == nil {
		return nil
	}
	return c.TemplateHost
}

func (c *CreateOutputOutputCriblTCP) GetTemplatePort() *string {
	if c == nil {
		return nil
	}
	return c.TemplatePort
}

type CreateOutputTypeDataset string

const (
	CreateOutputTypeDatasetDataset CreateOutputTypeDataset = "dataset"
)

func (e CreateOutputTypeDataset) ToPointer() *CreateOutputTypeDataset {
	return &e
}
func (e *CreateOutputTypeDataset) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "dataset":
		*e = CreateOutputTypeDataset(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeDataset: %v", v)
	}
}

// CreateOutputDefaultSeveritySeverity - Default value for event severity. If the `sev` or `__severity` fields are set on an event, the first one matching will override this value.
type CreateOutputDefaultSeveritySeverity string

const (
	// CreateOutputDefaultSeveritySeverityFinest 0 - finest
	CreateOutputDefaultSeveritySeverityFinest CreateOutputDefaultSeveritySeverity = "finest"
	// CreateOutputDefaultSeveritySeverityFiner 1 - finer
	CreateOutputDefaultSeveritySeverityFiner CreateOutputDefaultSeveritySeverity = "finer"
	// CreateOutputDefaultSeveritySeverityFine 2 - fine
	CreateOutputDefaultSeveritySeverityFine CreateOutputDefaultSeveritySeverity = "fine"
	// CreateOutputDefaultSeveritySeverityInfo 3 - info
	CreateOutputDefaultSeveritySeverityInfo CreateOutputDefaultSeveritySeverity = "info"
	// CreateOutputDefaultSeveritySeverityWarning 4 - warning
	CreateOutputDefaultSeveritySeverityWarning CreateOutputDefaultSeveritySeverity = "warning"
	// CreateOutputDefaultSeveritySeverityError 5 - error
	CreateOutputDefaultSeveritySeverityError CreateOutputDefaultSeveritySeverity = "error"
	// CreateOutputDefaultSeveritySeverityFatal 6 - fatal
	CreateOutputDefaultSeveritySeverityFatal CreateOutputDefaultSeveritySeverity = "fatal"
)

func (e CreateOutputDefaultSeveritySeverity) ToPointer() *CreateOutputDefaultSeveritySeverity {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputDefaultSeveritySeverity) IsExact() bool {
	if e != nil {
		switch *e {
		case "finest", "finer", "fine", "info", "warning", "error", "fatal":
			return true
		}
	}
	return false
}

// CreateOutputDataSetSite - DataSet site to which events should be sent
type CreateOutputDataSetSite string

const (
	// CreateOutputDataSetSiteUs US
	CreateOutputDataSetSiteUs CreateOutputDataSetSite = "us"
	// CreateOutputDataSetSiteEu Europe
	CreateOutputDataSetSiteEu CreateOutputDataSetSite = "eu"
	// CreateOutputDataSetSiteCustom Custom
	CreateOutputDataSetSiteCustom CreateOutputDataSetSite = "custom"
)

func (e CreateOutputDataSetSite) ToPointer() *CreateOutputDataSetSite {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputDataSetSite) IsExact() bool {
	if e != nil {
		switch *e {
		case "us", "eu", "custom":
			return true
		}
	}
	return false
}

type CreateOutputPqControlsDataset struct {
}

func (c CreateOutputPqControlsDataset) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsDataset) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputDataset struct {
	// Unique ID for this output
	ID   string                  `json:"id"`
	Type CreateOutputTypeDataset `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the event field that contains the message or attributes to send. If not specified, all of the event's non-internal fields will be sent as attributes.
	MessageField *string `json:"messageField,omitempty"`
	// Fields to exclude from the event if the Message field is either unspecified or refers to an object. Ignored if the Message field is a string. If empty, we send all non-internal fields.
	ExcludeFields []string `json:"excludeFields,omitempty"`
	// Name of the event field that contains the `serverHost` identifier. If not specified, defaults to `cribl_<outputId>`.
	ServerHostField *string `json:"serverHostField,omitempty"`
	// Name of the event field that contains the timestamp. If not specified, defaults to `ts`, `_time`, or `Date.now()`, in that order.
	TimestampField *string `json:"timestampField,omitempty"`
	// Default value for event severity. If the `sev` or `__severity` fields are set on an event, the first one matching will override this value.
	DefaultSeverity *CreateOutputDefaultSeveritySeverity `json:"defaultSeverity,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// DataSet site to which events should be sent
	Site *CreateOutputDataSetSite `json:"site,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Enter API key directly, or select a stored secret
	AuthType *components.AuthenticationMethodOptions2 `json:"authType,omitempty"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	CustomURL          *string  `json:"customUrl,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsDataset       `json:"pqControls,omitempty"`
	// A 'Log Write Access' API key for the DataSet account
	APIKey *string `json:"apiKey,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Binds 'customUrl' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'customUrl' at runtime.
	TemplateCustomURL *string `json:"__template_customUrl,omitempty"`
}

func (c CreateOutputOutputDataset) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputDataset) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputDataset) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputDataset) GetType() CreateOutputTypeDataset {
	if c == nil {
		return CreateOutputTypeDataset("")
	}
	return c.Type
}

func (c *CreateOutputOutputDataset) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputDataset) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputDataset) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputDataset) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputDataset) GetMessageField() *string {
	if c == nil {
		return nil
	}
	return c.MessageField
}

func (c *CreateOutputOutputDataset) GetExcludeFields() []string {
	if c == nil {
		return nil
	}
	return c.ExcludeFields
}

func (c *CreateOutputOutputDataset) GetServerHostField() *string {
	if c == nil {
		return nil
	}
	return c.ServerHostField
}

func (c *CreateOutputOutputDataset) GetTimestampField() *string {
	if c == nil {
		return nil
	}
	return c.TimestampField
}

func (c *CreateOutputOutputDataset) GetDefaultSeverity() *CreateOutputDefaultSeveritySeverity {
	if c == nil {
		return nil
	}
	return c.DefaultSeverity
}

func (c *CreateOutputOutputDataset) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputDataset) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputDataset) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputDataset) GetSite() *CreateOutputDataSetSite {
	if c == nil {
		return nil
	}
	return c.Site
}

func (c *CreateOutputOutputDataset) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputDataset) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputDataset) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputDataset) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputDataset) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputDataset) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputDataset) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputDataset) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputDataset) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputDataset) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputDataset) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputDataset) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputDataset) GetAuthType() *components.AuthenticationMethodOptions2 {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputDataset) GetTotalMemoryLimitKB() *float64 {
	if c == nil {
		return nil
	}
	return c.TotalMemoryLimitKB
}

func (c *CreateOutputOutputDataset) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputDataset) GetCustomURL() *string {
	if c == nil {
		return nil
	}
	return c.CustomURL
}

func (c *CreateOutputOutputDataset) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputDataset) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputDataset) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputDataset) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputDataset) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputDataset) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputDataset) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputDataset) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputDataset) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputDataset) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputDataset) GetPqControls() *CreateOutputPqControlsDataset {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputDataset) GetAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.APIKey
}

func (c *CreateOutputOutputDataset) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputDataset) GetTemplateCustomURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateCustomURL
}

type CreateOutputTypeServiceNow string

const (
	CreateOutputTypeServiceNowServiceNow CreateOutputTypeServiceNow = "service_now"
)

func (e CreateOutputTypeServiceNow) ToPointer() *CreateOutputTypeServiceNow {
	return &e
}
func (e *CreateOutputTypeServiceNow) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "service_now":
		*e = CreateOutputTypeServiceNow(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeServiceNow: %v", v)
	}
}

type CreateOutputPqControlsServiceNow struct {
}

func (c CreateOutputPqControlsServiceNow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsServiceNow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputServiceNow struct {
	// Unique ID for this output
	ID   string                     `json:"id"`
	Type CreateOutputTypeServiceNow `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The endpoint where ServiceNow events will be sent. Enter any valid URL or an IP address (IPv4 or IPv6; enclose IPv6 addresses in square brackets)
	Endpoint string `json:"endpoint"`
	// Select or create a stored text secret
	TokenSecret   string  `json:"tokenSecret"`
	AuthTokenName *string `json:"authTokenName,omitempty"`
	// The version of OTLP Protobuf definitions to use when structuring data to send
	OtlpVersion components.OtlpVersionOptions1 `json:"otlpVersion"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Select a transport option for OpenTelemetry
	Protocol components.ProtocolOptions `json:"protocol"`
	// Type of compression to apply to messages sent to the OpenTelemetry endpoint
	Compress *components.CompressionOptions4 `json:"compress,omitempty"`
	// Type of compression to apply to messages sent to the OpenTelemetry endpoint
	HTTPCompress *components.CompressionOptions5 `json:"httpCompress,omitempty"`
	// If you want to send traces to the default `{endpoint}/v1/traces` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPTracesEndpointOverride *string `json:"httpTracesEndpointOverride,omitempty"`
	// If you want to send metrics to the default `{endpoint}/v1/metrics` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPMetricsEndpointOverride *string `json:"httpMetricsEndpointOverride,omitempty"`
	// If you want to send logs to the default `{endpoint}/v1/logs` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPLogsEndpointOverride *string `json:"httpLogsEndpointOverride,omitempty"`
	// List of key-value pairs to send with each gRPC request. Value supports JavaScript expressions that are evaluated just once, when the destination gets started. To pass credentials as metadata, use 'C.Secret'.
	Metadata []components.ItemsTypeKeyValueMetadata `json:"metadata,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// How often the sender should ping the peer to keep the connection open
	KeepAliveTime *float64 `json:"keepAliveTime,omitempty"`
	// Disable to close the connection immediately after sending the outgoing request
	KeepAlive *bool `json:"keepAlive,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool                                  `json:"responseHonorRetryAfterHeader,omitempty"`
	TLS                           *components.TLSSettingsClientSideType2 `json:"tls,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsServiceNow    `json:"pqControls,omitempty"`
}

func (c CreateOutputOutputServiceNow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputServiceNow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "endpoint", "tokenSecret", "otlpVersion", "protocol"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputServiceNow) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputServiceNow) GetType() CreateOutputTypeServiceNow {
	if c == nil {
		return CreateOutputTypeServiceNow("")
	}
	return c.Type
}

func (c *CreateOutputOutputServiceNow) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputServiceNow) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputServiceNow) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputServiceNow) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputServiceNow) GetEndpoint() string {
	if c == nil {
		return ""
	}
	return c.Endpoint
}

func (c *CreateOutputOutputServiceNow) GetTokenSecret() string {
	if c == nil {
		return ""
	}
	return c.TokenSecret
}

func (c *CreateOutputOutputServiceNow) GetAuthTokenName() *string {
	if c == nil {
		return nil
	}
	return c.AuthTokenName
}

func (c *CreateOutputOutputServiceNow) GetOtlpVersion() components.OtlpVersionOptions1 {
	if c == nil {
		return components.OtlpVersionOptions1("")
	}
	return c.OtlpVersion
}

func (c *CreateOutputOutputServiceNow) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputServiceNow) GetProtocol() components.ProtocolOptions {
	if c == nil {
		return components.ProtocolOptions("")
	}
	return c.Protocol
}

func (c *CreateOutputOutputServiceNow) GetCompress() *components.CompressionOptions4 {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputServiceNow) GetHTTPCompress() *components.CompressionOptions5 {
	if c == nil {
		return nil
	}
	return c.HTTPCompress
}

func (c *CreateOutputOutputServiceNow) GetHTTPTracesEndpointOverride() *string {
	if c == nil {
		return nil
	}
	return c.HTTPTracesEndpointOverride
}

func (c *CreateOutputOutputServiceNow) GetHTTPMetricsEndpointOverride() *string {
	if c == nil {
		return nil
	}
	return c.HTTPMetricsEndpointOverride
}

func (c *CreateOutputOutputServiceNow) GetHTTPLogsEndpointOverride() *string {
	if c == nil {
		return nil
	}
	return c.HTTPLogsEndpointOverride
}

func (c *CreateOutputOutputServiceNow) GetMetadata() []components.ItemsTypeKeyValueMetadata {
	if c == nil {
		return nil
	}
	return c.Metadata
}

func (c *CreateOutputOutputServiceNow) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputServiceNow) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputServiceNow) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputServiceNow) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputServiceNow) GetConnectionTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.ConnectionTimeout
}

func (c *CreateOutputOutputServiceNow) GetKeepAliveTime() *float64 {
	if c == nil {
		return nil
	}
	return c.KeepAliveTime
}

func (c *CreateOutputOutputServiceNow) GetKeepAlive() *bool {
	if c == nil {
		return nil
	}
	return c.KeepAlive
}

func (c *CreateOutputOutputServiceNow) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputServiceNow) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputServiceNow) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputServiceNow) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputServiceNow) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputServiceNow) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputServiceNow) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputServiceNow) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputServiceNow) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputServiceNow) GetTLS() *components.TLSSettingsClientSideType2 {
	if c == nil {
		return nil
	}
	return c.TLS
}

func (c *CreateOutputOutputServiceNow) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputServiceNow) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputServiceNow) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputServiceNow) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputServiceNow) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputServiceNow) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputServiceNow) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputServiceNow) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputServiceNow) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputServiceNow) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputServiceNow) GetPqControls() *CreateOutputPqControlsServiceNow {
	if c == nil {
		return nil
	}
	return c.PqControls
}

type CreateOutputTypeOpenTelemetry string

const (
	CreateOutputTypeOpenTelemetryOpenTelemetry CreateOutputTypeOpenTelemetry = "open_telemetry"
)

func (e CreateOutputTypeOpenTelemetry) ToPointer() *CreateOutputTypeOpenTelemetry {
	return &e
}
func (e *CreateOutputTypeOpenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "open_telemetry":
		*e = CreateOutputTypeOpenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeOpenTelemetry: %v", v)
	}
}

// CreateOutputOTLPVersion - The version of OTLP Protobuf definitions to use when structuring data to send
type CreateOutputOTLPVersion string

const (
	// CreateOutputOTLPVersionZeroDot10Dot0 0.10.0
	CreateOutputOTLPVersionZeroDot10Dot0 CreateOutputOTLPVersion = "0.10.0"
	// CreateOutputOTLPVersionOneDot3Dot1 1.3.1
	CreateOutputOTLPVersionOneDot3Dot1 CreateOutputOTLPVersion = "1.3.1"
)

func (e CreateOutputOTLPVersion) ToPointer() *CreateOutputOTLPVersion {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputOTLPVersion) IsExact() bool {
	if e != nil {
		switch *e {
		case "0.10.0", "1.3.1":
			return true
		}
	}
	return false
}

type CreateOutputPqControlsOpenTelemetry struct {
}

func (c CreateOutputPqControlsOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputOpenTelemetry struct {
	// Unique ID for this output
	ID   string                        `json:"id"`
	Type CreateOutputTypeOpenTelemetry `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Select a transport option for OpenTelemetry
	Protocol *components.ProtocolOptions `json:"protocol,omitempty"`
	// The endpoint where OTel events will be sent. Enter any valid URL or an IP address (IPv4 or IPv6; enclose IPv6 addresses in square brackets). Unspecified ports will default to 4317, unless the endpoint is an HTTPS-based URL or TLS is enabled, in which case 443 will be used.
	Endpoint string `json:"endpoint"`
	// The version of OTLP Protobuf definitions to use when structuring data to send
	OtlpVersion *CreateOutputOTLPVersion `json:"otlpVersion,omitempty"`
	// Type of compression to apply to messages sent to the OpenTelemetry endpoint
	Compress *components.CompressionOptions4 `json:"compress,omitempty"`
	// Type of compression to apply to messages sent to the OpenTelemetry endpoint
	HTTPCompress *components.CompressionOptions5 `json:"httpCompress,omitempty"`
	// OpenTelemetry authentication type
	AuthType *components.AuthenticationTypeOptions `json:"authType,omitempty"`
	// If you want to send traces to the default `{endpoint}/v1/traces` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPTracesEndpointOverride *string `json:"httpTracesEndpointOverride,omitempty"`
	// If you want to send metrics to the default `{endpoint}/v1/metrics` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPMetricsEndpointOverride *string `json:"httpMetricsEndpointOverride,omitempty"`
	// If you want to send logs to the default `{endpoint}/v1/logs` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPLogsEndpointOverride *string `json:"httpLogsEndpointOverride,omitempty"`
	// List of key-value pairs to send with each gRPC request. Value supports JavaScript expressions that are evaluated just once, when the destination gets started. To pass credentials as metadata, use 'C.Secret'.
	Metadata []components.ItemsTypeKeyValueMetadata `json:"metadata,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// How often the sender should ping the peer to keep the connection open
	KeepAliveTime *float64 `json:"keepAliveTime,omitempty"`
	// Disable to close the connection immediately after sending the outgoing request
	KeepAlive *bool `json:"keepAlive,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	Username       *string                                 `json:"username,omitempty"`
	Password       *string                                 `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool                                  `json:"responseHonorRetryAfterHeader,omitempty"`
	TLS                           *components.TLSSettingsClientSideType2 `json:"tls,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsOpenTelemetry `json:"pqControls,omitempty"`
}

func (c CreateOutputOutputOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "endpoint"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputOpenTelemetry) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputOpenTelemetry) GetType() CreateOutputTypeOpenTelemetry {
	if c == nil {
		return CreateOutputTypeOpenTelemetry("")
	}
	return c.Type
}

func (c *CreateOutputOutputOpenTelemetry) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputOpenTelemetry) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputOpenTelemetry) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputOpenTelemetry) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputOpenTelemetry) GetProtocol() *components.ProtocolOptions {
	if c == nil {
		return nil
	}
	return c.Protocol
}

func (c *CreateOutputOutputOpenTelemetry) GetEndpoint() string {
	if c == nil {
		return ""
	}
	return c.Endpoint
}

func (c *CreateOutputOutputOpenTelemetry) GetOtlpVersion() *CreateOutputOTLPVersion {
	if c == nil {
		return nil
	}
	return c.OtlpVersion
}

func (c *CreateOutputOutputOpenTelemetry) GetCompress() *components.CompressionOptions4 {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputOpenTelemetry) GetHTTPCompress() *components.CompressionOptions5 {
	if c == nil {
		return nil
	}
	return c.HTTPCompress
}

func (c *CreateOutputOutputOpenTelemetry) GetAuthType() *components.AuthenticationTypeOptions {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputOpenTelemetry) GetHTTPTracesEndpointOverride() *string {
	if c == nil {
		return nil
	}
	return c.HTTPTracesEndpointOverride
}

func (c *CreateOutputOutputOpenTelemetry) GetHTTPMetricsEndpointOverride() *string {
	if c == nil {
		return nil
	}
	return c.HTTPMetricsEndpointOverride
}

func (c *CreateOutputOutputOpenTelemetry) GetHTTPLogsEndpointOverride() *string {
	if c == nil {
		return nil
	}
	return c.HTTPLogsEndpointOverride
}

func (c *CreateOutputOutputOpenTelemetry) GetMetadata() []components.ItemsTypeKeyValueMetadata {
	if c == nil {
		return nil
	}
	return c.Metadata
}

func (c *CreateOutputOutputOpenTelemetry) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputOpenTelemetry) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputOpenTelemetry) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputOpenTelemetry) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputOpenTelemetry) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputOpenTelemetry) GetConnectionTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.ConnectionTimeout
}

func (c *CreateOutputOutputOpenTelemetry) GetKeepAliveTime() *float64 {
	if c == nil {
		return nil
	}
	return c.KeepAliveTime
}

func (c *CreateOutputOutputOpenTelemetry) GetKeepAlive() *bool {
	if c == nil {
		return nil
	}
	return c.KeepAlive
}

func (c *CreateOutputOutputOpenTelemetry) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputOpenTelemetry) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputOpenTelemetry) GetUsername() *string {
	if c == nil {
		return nil
	}
	return c.Username
}

func (c *CreateOutputOutputOpenTelemetry) GetPassword() *string {
	if c == nil {
		return nil
	}
	return c.Password
}

func (c *CreateOutputOutputOpenTelemetry) GetToken() *string {
	if c == nil {
		return nil
	}
	return c.Token
}

func (c *CreateOutputOutputOpenTelemetry) GetCredentialsSecret() *string {
	if c == nil {
		return nil
	}
	return c.CredentialsSecret
}

func (c *CreateOutputOutputOpenTelemetry) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputOpenTelemetry) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputOpenTelemetry) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputOpenTelemetry) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputOpenTelemetry) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputOpenTelemetry) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputOpenTelemetry) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputOpenTelemetry) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputOpenTelemetry) GetTLS() *components.TLSSettingsClientSideType2 {
	if c == nil {
		return nil
	}
	return c.TLS
}

func (c *CreateOutputOutputOpenTelemetry) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputOpenTelemetry) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputOpenTelemetry) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputOpenTelemetry) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputOpenTelemetry) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputOpenTelemetry) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputOpenTelemetry) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputOpenTelemetry) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputOpenTelemetry) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputOpenTelemetry) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputOpenTelemetry) GetPqControls() *CreateOutputPqControlsOpenTelemetry {
	if c == nil {
		return nil
	}
	return c.PqControls
}

type CreateOutputTypeRing string

const (
	CreateOutputTypeRingRing CreateOutputTypeRing = "ring"
)

func (e CreateOutputTypeRing) ToPointer() *CreateOutputTypeRing {
	return &e
}
func (e *CreateOutputTypeRing) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "ring":
		*e = CreateOutputTypeRing(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeRing: %v", v)
	}
}

// CreateOutputDataFormatRing - Format of the output data.
type CreateOutputDataFormatRing string

const (
	CreateOutputDataFormatRingJSON CreateOutputDataFormatRing = "json"
	CreateOutputDataFormatRingRaw  CreateOutputDataFormatRing = "raw"
)

func (e CreateOutputDataFormatRing) ToPointer() *CreateOutputDataFormatRing {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputDataFormatRing) IsExact() bool {
	if e != nil {
		switch *e {
		case "json", "raw":
			return true
		}
	}
	return false
}

type CreateOutputOutputRing struct {
	// Unique ID for this output
	ID   string               `json:"id"`
	Type CreateOutputTypeRing `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Format of the output data.
	Format *CreateOutputDataFormatRing `json:"format,omitempty"`
	// JS expression to define how files are partitioned and organized. If left blank, Cribl Stream will fallback on event.__partition.
	PartitionExpr *string `json:"partitionExpr,omitempty"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `json:"maxDataSize,omitempty"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                                             `json:"maxDataTime,omitempty"`
	Compress    *components.DataCompressionFormatOptionsPersistence `json:"compress,omitempty"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/<id>
	DestPath *string `json:"destPath,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	Description    *string                                  `json:"description,omitempty"`
}

func (c CreateOutputOutputRing) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputRing) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputRing) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputRing) GetType() CreateOutputTypeRing {
	if c == nil {
		return CreateOutputTypeRing("")
	}
	return c.Type
}

func (c *CreateOutputOutputRing) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputRing) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputRing) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputRing) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputRing) GetFormat() *CreateOutputDataFormatRing {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputRing) GetPartitionExpr() *string {
	if c == nil {
		return nil
	}
	return c.PartitionExpr
}

func (c *CreateOutputOutputRing) GetMaxDataSize() *string {
	if c == nil {
		return nil
	}
	return c.MaxDataSize
}

func (c *CreateOutputOutputRing) GetMaxDataTime() *string {
	if c == nil {
		return nil
	}
	return c.MaxDataTime
}

func (c *CreateOutputOutputRing) GetCompress() *components.DataCompressionFormatOptionsPersistence {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputRing) GetDestPath() *string {
	if c == nil {
		return nil
	}
	return c.DestPath
}

func (c *CreateOutputOutputRing) GetOnBackpressure() *components.BackpressureBehaviorOptions1 {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputRing) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

type CreateOutputTypePrometheus string

const (
	CreateOutputTypePrometheusPrometheus CreateOutputTypePrometheus = "prometheus"
)

func (e CreateOutputTypePrometheus) ToPointer() *CreateOutputTypePrometheus {
	return &e
}
func (e *CreateOutputTypePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "prometheus":
		*e = CreateOutputTypePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypePrometheus: %v", v)
	}
}

type CreateOutputPqControlsPrometheus struct {
}

func (c CreateOutputPqControlsPrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsPrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputPrometheus struct {
	// Unique ID for this output
	ID   string                     `json:"id"`
	Type CreateOutputTypePrometheus `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions to generated metrics.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The endpoint to send metrics to
	URL string `json:"url"`
	// JavaScript expression that can be used to rename metrics. For example, name.replace(/\./g, '_') will replace all '.' characters in a metric's name with the supported '_' character. Use the 'name' global variable to access the metric's name. You can access event fields' values via __e.<fieldName>.
	MetricRenameExpr *string `json:"metricRenameExpr,omitempty"`
	// Generate and send metadata (`type` and `metricFamilyName`) requests
	SendMetadata *bool `json:"sendMetadata,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Remote Write authentication type
	AuthType    *components.AuthenticationTypeOptionsPrometheusAuth `json:"authType,omitempty"`
	Description *string                                             `json:"description,omitempty"`
	// How frequently metrics metadata is sent out. Value cannot be smaller than the base Flush period set above.
	MetricsFlushPeriodSec *float64 `json:"metricsFlushPeriodSec,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsPrometheus    `json:"pqControls,omitempty"`
	Username         *string                              `json:"username,omitempty"`
	Password         *string                              `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
	TemplateURL *string `json:"__template_url,omitempty"`
}

func (c CreateOutputOutputPrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputPrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "url"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputPrometheus) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputPrometheus) GetType() CreateOutputTypePrometheus {
	if c == nil {
		return CreateOutputTypePrometheus("")
	}
	return c.Type
}

func (c *CreateOutputOutputPrometheus) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputPrometheus) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputPrometheus) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputPrometheus) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputPrometheus) GetURL() string {
	if c == nil {
		return ""
	}
	return c.URL
}

func (c *CreateOutputOutputPrometheus) GetMetricRenameExpr() *string {
	if c == nil {
		return nil
	}
	return c.MetricRenameExpr
}

func (c *CreateOutputOutputPrometheus) GetSendMetadata() *bool {
	if c == nil {
		return nil
	}
	return c.SendMetadata
}

func (c *CreateOutputOutputPrometheus) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputPrometheus) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputPrometheus) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputPrometheus) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputPrometheus) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputPrometheus) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputPrometheus) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputPrometheus) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputPrometheus) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputPrometheus) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputPrometheus) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputPrometheus) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputPrometheus) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputPrometheus) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputPrometheus) GetAuthType() *components.AuthenticationTypeOptionsPrometheusAuth {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputPrometheus) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputPrometheus) GetMetricsFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MetricsFlushPeriodSec
}

func (c *CreateOutputOutputPrometheus) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputPrometheus) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputPrometheus) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputPrometheus) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputPrometheus) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputPrometheus) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputPrometheus) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputPrometheus) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputPrometheus) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputPrometheus) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputPrometheus) GetPqControls() *CreateOutputPqControlsPrometheus {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputPrometheus) GetUsername() *string {
	if c == nil {
		return nil
	}
	return c.Username
}

func (c *CreateOutputOutputPrometheus) GetPassword() *string {
	if c == nil {
		return nil
	}
	return c.Password
}

func (c *CreateOutputOutputPrometheus) GetToken() *string {
	if c == nil {
		return nil
	}
	return c.Token
}

func (c *CreateOutputOutputPrometheus) GetCredentialsSecret() *string {
	if c == nil {
		return nil
	}
	return c.CredentialsSecret
}

func (c *CreateOutputOutputPrometheus) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputPrometheus) GetTemplateURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateURL
}

type CreateOutputTypeLoki string

const (
	CreateOutputTypeLokiLoki CreateOutputTypeLoki = "loki"
)

func (e CreateOutputTypeLoki) ToPointer() *CreateOutputTypeLoki {
	return &e
}
func (e *CreateOutputTypeLoki) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "loki":
		*e = CreateOutputTypeLoki(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeLoki: %v", v)
	}
}

type CreateOutputPqControlsLoki struct {
}

func (c CreateOutputPqControlsLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputLoki struct {
	// Unique ID for this output
	ID   string               `json:"id"`
	Type CreateOutputTypeLoki `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as labels to generated logs.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The endpoint to send logs to
	URL string `json:"url"`
	// Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
	Message *string `json:"message,omitempty"`
	// Format to use when sending logs to Loki (Protobuf or JSON)
	MessageFormat *components.MessageFormatOptions `json:"messageFormat,omitempty"`
	// List of labels to send with logs. Labels define Loki streams, so use static labels to avoid proliferating label value combinations and streams. Can be merged and/or overridden by the event's __labels field. Example: '__labels: {host: "cribl.io", level: "error"}'
	Labels   []components.ItemsTypeLabels                         `json:"labels,omitempty"`
	AuthType *components.AuthenticationTypeOptionsPrometheusAuth1 `json:"authType,omitempty"`
	// Maximum number of ongoing requests before blocking. Warning: Setting this value > 1 can cause Loki to complain about entries being delivered out of order.
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki to complain about entries being delivered out of order.
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Defaults to 0 (unlimited). Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki to complain about entries being delivered out of order.
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Maximum time between requests. Small values can reduce the payload size below the configured 'Max record size' and 'Max events per request'. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki to complain about entries being delivered out of order.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// Add per-event HTTP headers from the __headers field to outgoing requests. Events with different headers are batched and sent separately.
	EnableDynamicHeaders *bool `json:"enableDynamicHeaders,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Bearer token to include in the authorization header. In Grafana Cloud, this is generally built by concatenating the username and the API key, separated by a colon. Example: <your-username>:<your-api-key>
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Username for authentication
	Username *string `json:"username,omitempty"`
	// Password (API key in Grafana Cloud domain) for authentication
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsLoki          `json:"pqControls,omitempty"`
}

func (c CreateOutputOutputLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "url"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputLoki) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputLoki) GetType() CreateOutputTypeLoki {
	if c == nil {
		return CreateOutputTypeLoki("")
	}
	return c.Type
}

func (c *CreateOutputOutputLoki) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputLoki) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputLoki) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputLoki) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputLoki) GetURL() string {
	if c == nil {
		return ""
	}
	return c.URL
}

func (c *CreateOutputOutputLoki) GetMessage() *string {
	if c == nil {
		return nil
	}
	return c.Message
}

func (c *CreateOutputOutputLoki) GetMessageFormat() *components.MessageFormatOptions {
	if c == nil {
		return nil
	}
	return c.MessageFormat
}

func (c *CreateOutputOutputLoki) GetLabels() []components.ItemsTypeLabels {
	if c == nil {
		return nil
	}
	return c.Labels
}

func (c *CreateOutputOutputLoki) GetAuthType() *components.AuthenticationTypeOptionsPrometheusAuth1 {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputLoki) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputLoki) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputLoki) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputLoki) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputLoki) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputLoki) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputLoki) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputLoki) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputLoki) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputLoki) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputLoki) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputLoki) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputLoki) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputLoki) GetEnableDynamicHeaders() *bool {
	if c == nil {
		return nil
	}
	return c.EnableDynamicHeaders
}

func (c *CreateOutputOutputLoki) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputLoki) GetTotalMemoryLimitKB() *float64 {
	if c == nil {
		return nil
	}
	return c.TotalMemoryLimitKB
}

func (c *CreateOutputOutputLoki) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputLoki) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputLoki) GetToken() *string {
	if c == nil {
		return nil
	}
	return c.Token
}

func (c *CreateOutputOutputLoki) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputLoki) GetUsername() *string {
	if c == nil {
		return nil
	}
	return c.Username
}

func (c *CreateOutputOutputLoki) GetPassword() *string {
	if c == nil {
		return nil
	}
	return c.Password
}

func (c *CreateOutputOutputLoki) GetCredentialsSecret() *string {
	if c == nil {
		return nil
	}
	return c.CredentialsSecret
}

func (c *CreateOutputOutputLoki) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputLoki) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputLoki) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputLoki) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputLoki) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputLoki) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputLoki) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputLoki) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputLoki) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputLoki) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputLoki) GetPqControls() *CreateOutputPqControlsLoki {
	if c == nil {
		return nil
	}
	return c.PqControls
}

type CreateOutputOutputGrafanaCloudType2 string

const (
	CreateOutputOutputGrafanaCloudType2GrafanaCloud CreateOutputOutputGrafanaCloudType2 = "grafana_cloud"
)

func (e CreateOutputOutputGrafanaCloudType2) ToPointer() *CreateOutputOutputGrafanaCloudType2 {
	return &e
}
func (e *CreateOutputOutputGrafanaCloudType2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grafana_cloud":
		*e = CreateOutputOutputGrafanaCloudType2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputOutputGrafanaCloudType2: %v", v)
	}
}

type CreateOutputOutputGrafanaCloudPqControls2 struct {
}

func (c CreateOutputOutputGrafanaCloudPqControls2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputGrafanaCloudPqControls2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputGrafanaCloudGrafanaCloud2 struct {
	// Unique ID for this output
	ID   string                              `json:"id"`
	Type CreateOutputOutputGrafanaCloudType2 `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions and labels to generated metrics and logs, respectively.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The endpoint to send logs to, such as https://logs-prod-us-central1.grafana.net
	LokiURL *string `json:"lokiUrl,omitempty"`
	// The remote_write endpoint to send Prometheus metrics to, such as https://prometheus-blocks-prod-us-central1.grafana.net/api/prom/push
	PrometheusURL string `json:"prometheusUrl"`
	// Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
	Message *string `json:"message,omitempty"`
	// Format to use when sending logs to Loki (Protobuf or JSON)
	MessageFormat *components.MessageFormatOptions `json:"messageFormat,omitempty"`
	// List of labels to send with logs. Labels define Loki streams, so use static labels to avoid proliferating label value combinations and streams. Can be merged and/or overridden by the event's __labels field. Example: '__labels: {host: "cribl.io", level: "error"}'
	Labels []components.ItemsTypeLabels `json:"labels,omitempty"`
	// JavaScript expression that can be used to rename metrics. For example, name.replace(/\./g, '_') will replace all '.' characters in a metric's name with the supported '_' character. Use the 'name' global variable to access the metric's name. You can access event fields' values via __e.<fieldName>.
	MetricRenameExpr *string                        `json:"metricRenameExpr,omitempty"`
	PrometheusAuth   *components.PrometheusAuthType `json:"prometheusAuth,omitempty"`
	LokiAuth         *components.PrometheusAuthType `json:"lokiAuth,omitempty"`
	// Maximum number of ongoing requests before blocking. Warning: Setting this value > 1 can cause Loki and Prometheus to complain about entries being delivered out of order.
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited). Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Maximum time between requests. Small values can reduce the payload size below the configured 'Max record size' and 'Max events per request'. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// Compress the payload body before sending. Applies only to JSON payloads; the Protobuf variant for both Prometheus and Loki are snappy-compressed by default.
	Compress *bool `json:"compress,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions       `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputOutputGrafanaCloudPqControls2 `json:"pqControls,omitempty"`
	// Binds 'lokiUrl' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'lokiUrl' at runtime.
	TemplateLokiURL *string `json:"__template_lokiUrl,omitempty"`
	// Binds 'prometheusUrl' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'prometheusUrl' at runtime.
	TemplatePrometheusURL *string `json:"__template_prometheusUrl,omitempty"`
}

func (c CreateOutputOutputGrafanaCloudGrafanaCloud2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "prometheusUrl"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetType() CreateOutputOutputGrafanaCloudType2 {
	if c == nil {
		return CreateOutputOutputGrafanaCloudType2("")
	}
	return c.Type
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetLokiURL() *string {
	if c == nil {
		return nil
	}
	return c.LokiURL
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetPrometheusURL() string {
	if c == nil {
		return ""
	}
	return c.PrometheusURL
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetMessage() *string {
	if c == nil {
		return nil
	}
	return c.Message
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetMessageFormat() *components.MessageFormatOptions {
	if c == nil {
		return nil
	}
	return c.MessageFormat
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetLabels() []components.ItemsTypeLabels {
	if c == nil {
		return nil
	}
	return c.Labels
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetMetricRenameExpr() *string {
	if c == nil {
		return nil
	}
	return c.MetricRenameExpr
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetPrometheusAuth() *components.PrometheusAuthType {
	if c == nil {
		return nil
	}
	return c.PrometheusAuth
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetLokiAuth() *components.PrometheusAuthType {
	if c == nil {
		return nil
	}
	return c.LokiAuth
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetPqControls() *CreateOutputOutputGrafanaCloudPqControls2 {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetTemplateLokiURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateLokiURL
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud2) GetTemplatePrometheusURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplatePrometheusURL
}

type CreateOutputOutputGrafanaCloudType1 string

const (
	CreateOutputOutputGrafanaCloudType1GrafanaCloud CreateOutputOutputGrafanaCloudType1 = "grafana_cloud"
)

func (e CreateOutputOutputGrafanaCloudType1) ToPointer() *CreateOutputOutputGrafanaCloudType1 {
	return &e
}
func (e *CreateOutputOutputGrafanaCloudType1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grafana_cloud":
		*e = CreateOutputOutputGrafanaCloudType1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputOutputGrafanaCloudType1: %v", v)
	}
}

type CreateOutputOutputGrafanaCloudPqControls1 struct {
}

func (c CreateOutputOutputGrafanaCloudPqControls1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputGrafanaCloudPqControls1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputGrafanaCloudGrafanaCloud1 struct {
	// Unique ID for this output
	ID   string                              `json:"id"`
	Type CreateOutputOutputGrafanaCloudType1 `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions and labels to generated metrics and logs, respectively.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The endpoint to send logs to, such as https://logs-prod-us-central1.grafana.net
	LokiURL string `json:"lokiUrl"`
	// The remote_write endpoint to send Prometheus metrics to, such as https://prometheus-blocks-prod-us-central1.grafana.net/api/prom/push
	PrometheusURL *string `json:"prometheusUrl,omitempty"`
	// Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
	Message *string `json:"message,omitempty"`
	// Format to use when sending logs to Loki (Protobuf or JSON)
	MessageFormat *components.MessageFormatOptions `json:"messageFormat,omitempty"`
	// List of labels to send with logs. Labels define Loki streams, so use static labels to avoid proliferating label value combinations and streams. Can be merged and/or overridden by the event's __labels field. Example: '__labels: {host: "cribl.io", level: "error"}'
	Labels []components.ItemsTypeLabels `json:"labels,omitempty"`
	// JavaScript expression that can be used to rename metrics. For example, name.replace(/\./g, '_') will replace all '.' characters in a metric's name with the supported '_' character. Use the 'name' global variable to access the metric's name. You can access event fields' values via __e.<fieldName>.
	MetricRenameExpr *string                        `json:"metricRenameExpr,omitempty"`
	PrometheusAuth   *components.PrometheusAuthType `json:"prometheusAuth,omitempty"`
	LokiAuth         *components.PrometheusAuthType `json:"lokiAuth,omitempty"`
	// Maximum number of ongoing requests before blocking. Warning: Setting this value > 1 can cause Loki and Prometheus to complain about entries being delivered out of order.
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited). Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Maximum time between requests. Small values can reduce the payload size below the configured 'Max record size' and 'Max events per request'. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// Compress the payload body before sending. Applies only to JSON payloads; the Protobuf variant for both Prometheus and Loki are snappy-compressed by default.
	Compress *bool `json:"compress,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions       `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputOutputGrafanaCloudPqControls1 `json:"pqControls,omitempty"`
	// Binds 'lokiUrl' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'lokiUrl' at runtime.
	TemplateLokiURL *string `json:"__template_lokiUrl,omitempty"`
	// Binds 'prometheusUrl' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'prometheusUrl' at runtime.
	TemplatePrometheusURL *string `json:"__template_prometheusUrl,omitempty"`
}

func (c CreateOutputOutputGrafanaCloudGrafanaCloud1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "lokiUrl"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetType() CreateOutputOutputGrafanaCloudType1 {
	if c == nil {
		return CreateOutputOutputGrafanaCloudType1("")
	}
	return c.Type
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetLokiURL() string {
	if c == nil {
		return ""
	}
	return c.LokiURL
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetPrometheusURL() *string {
	if c == nil {
		return nil
	}
	return c.PrometheusURL
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetMessage() *string {
	if c == nil {
		return nil
	}
	return c.Message
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetMessageFormat() *components.MessageFormatOptions {
	if c == nil {
		return nil
	}
	return c.MessageFormat
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetLabels() []components.ItemsTypeLabels {
	if c == nil {
		return nil
	}
	return c.Labels
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetMetricRenameExpr() *string {
	if c == nil {
		return nil
	}
	return c.MetricRenameExpr
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetPrometheusAuth() *components.PrometheusAuthType {
	if c == nil {
		return nil
	}
	return c.PrometheusAuth
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetLokiAuth() *components.PrometheusAuthType {
	if c == nil {
		return nil
	}
	return c.LokiAuth
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetPqControls() *CreateOutputOutputGrafanaCloudPqControls1 {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetTemplateLokiURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateLokiURL
}

func (c *CreateOutputOutputGrafanaCloudGrafanaCloud1) GetTemplatePrometheusURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplatePrometheusURL
}

type CreateOutputOutputGrafanaCloudUnionType string

const (
	CreateOutputOutputGrafanaCloudUnionTypeCreateOutputOutputGrafanaCloudGrafanaCloud1 CreateOutputOutputGrafanaCloudUnionType = "createOutput_OutputGrafanaCloud_GrafanaCloud_1"
	CreateOutputOutputGrafanaCloudUnionTypeCreateOutputOutputGrafanaCloudGrafanaCloud2 CreateOutputOutputGrafanaCloudUnionType = "createOutput_OutputGrafanaCloud_GrafanaCloud_2"
)

type CreateOutputOutputGrafanaCloudUnion struct {
	CreateOutputOutputGrafanaCloudGrafanaCloud1 *CreateOutputOutputGrafanaCloudGrafanaCloud1 `queryParam:"inline" union:"member"`
	CreateOutputOutputGrafanaCloudGrafanaCloud2 *CreateOutputOutputGrafanaCloudGrafanaCloud2 `queryParam:"inline" union:"member"`

	Type CreateOutputOutputGrafanaCloudUnionType
}

func CreateCreateOutputOutputGrafanaCloudUnionCreateOutputOutputGrafanaCloudGrafanaCloud1(createOutputOutputGrafanaCloudGrafanaCloud1 CreateOutputOutputGrafanaCloudGrafanaCloud1) CreateOutputOutputGrafanaCloudUnion {
	typ := CreateOutputOutputGrafanaCloudUnionTypeCreateOutputOutputGrafanaCloudGrafanaCloud1

	return CreateOutputOutputGrafanaCloudUnion{
		CreateOutputOutputGrafanaCloudGrafanaCloud1: &createOutputOutputGrafanaCloudGrafanaCloud1,
		Type: typ,
	}
}

func CreateCreateOutputOutputGrafanaCloudUnionCreateOutputOutputGrafanaCloudGrafanaCloud2(createOutputOutputGrafanaCloudGrafanaCloud2 CreateOutputOutputGrafanaCloudGrafanaCloud2) CreateOutputOutputGrafanaCloudUnion {
	typ := CreateOutputOutputGrafanaCloudUnionTypeCreateOutputOutputGrafanaCloudGrafanaCloud2

	return CreateOutputOutputGrafanaCloudUnion{
		CreateOutputOutputGrafanaCloudGrafanaCloud2: &createOutputOutputGrafanaCloudGrafanaCloud2,
		Type: typ,
	}
}

func (u *CreateOutputOutputGrafanaCloudUnion) UnmarshalJSON(data []byte) error {

	var createOutputOutputGrafanaCloudGrafanaCloud1 CreateOutputOutputGrafanaCloudGrafanaCloud1 = CreateOutputOutputGrafanaCloudGrafanaCloud1{}
	if err := utils.UnmarshalJSON(data, &createOutputOutputGrafanaCloudGrafanaCloud1, "", true, nil); err == nil {
		u.CreateOutputOutputGrafanaCloudGrafanaCloud1 = &createOutputOutputGrafanaCloudGrafanaCloud1
		u.Type = CreateOutputOutputGrafanaCloudUnionTypeCreateOutputOutputGrafanaCloudGrafanaCloud1
		return nil
	}

	var createOutputOutputGrafanaCloudGrafanaCloud2 CreateOutputOutputGrafanaCloudGrafanaCloud2 = CreateOutputOutputGrafanaCloudGrafanaCloud2{}
	if err := utils.UnmarshalJSON(data, &createOutputOutputGrafanaCloudGrafanaCloud2, "", true, nil); err == nil {
		u.CreateOutputOutputGrafanaCloudGrafanaCloud2 = &createOutputOutputGrafanaCloudGrafanaCloud2
		u.Type = CreateOutputOutputGrafanaCloudUnionTypeCreateOutputOutputGrafanaCloudGrafanaCloud2
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for CreateOutputOutputGrafanaCloudUnion", string(data))
}

func (u CreateOutputOutputGrafanaCloudUnion) MarshalJSON() ([]byte, error) {
	if u.CreateOutputOutputGrafanaCloudGrafanaCloud1 != nil {
		return utils.MarshalJSON(u.CreateOutputOutputGrafanaCloudGrafanaCloud1, "", true)
	}

	if u.CreateOutputOutputGrafanaCloudGrafanaCloud2 != nil {
		return utils.MarshalJSON(u.CreateOutputOutputGrafanaCloudGrafanaCloud2, "", true)
	}

	return nil, errors.New("could not marshal union type CreateOutputOutputGrafanaCloudUnion: all fields are null")
}

type CreateOutputTypeDatadog string

const (
	CreateOutputTypeDatadogDatadog CreateOutputTypeDatadog = "datadog"
)

func (e CreateOutputTypeDatadog) ToPointer() *CreateOutputTypeDatadog {
	return &e
}
func (e *CreateOutputTypeDatadog) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "datadog":
		*e = CreateOutputTypeDatadog(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeDatadog: %v", v)
	}
}

// CreateOutputSendLogsAs - The content type to use when sending logs
type CreateOutputSendLogsAs string

const (
	// CreateOutputSendLogsAsText text/plain
	CreateOutputSendLogsAsText CreateOutputSendLogsAs = "text"
	// CreateOutputSendLogsAsJSON application/json
	CreateOutputSendLogsAsJSON CreateOutputSendLogsAs = "json"
)

func (e CreateOutputSendLogsAs) ToPointer() *CreateOutputSendLogsAs {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputSendLogsAs) IsExact() bool {
	if e != nil {
		switch *e {
		case "text", "json":
			return true
		}
	}
	return false
}

// CreateOutputSeverityDatadog - Default value for message severity. When you send logs as JSON objects, the event's '__severity' field (if set) will override this value.
type CreateOutputSeverityDatadog string

const (
	// CreateOutputSeverityDatadogEmergency emergency
	CreateOutputSeverityDatadogEmergency CreateOutputSeverityDatadog = "emergency"
	// CreateOutputSeverityDatadogAlert alert
	CreateOutputSeverityDatadogAlert CreateOutputSeverityDatadog = "alert"
	// CreateOutputSeverityDatadogCritical critical
	CreateOutputSeverityDatadogCritical CreateOutputSeverityDatadog = "critical"
	// CreateOutputSeverityDatadogError error
	CreateOutputSeverityDatadogError CreateOutputSeverityDatadog = "error"
	// CreateOutputSeverityDatadogWarning warning
	CreateOutputSeverityDatadogWarning CreateOutputSeverityDatadog = "warning"
	// CreateOutputSeverityDatadogNotice notice
	CreateOutputSeverityDatadogNotice CreateOutputSeverityDatadog = "notice"
	// CreateOutputSeverityDatadogInfo info
	CreateOutputSeverityDatadogInfo CreateOutputSeverityDatadog = "info"
	// CreateOutputSeverityDatadogDebug debug
	CreateOutputSeverityDatadogDebug CreateOutputSeverityDatadog = "debug"
)

func (e CreateOutputSeverityDatadog) ToPointer() *CreateOutputSeverityDatadog {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputSeverityDatadog) IsExact() bool {
	if e != nil {
		switch *e {
		case "emergency", "alert", "critical", "error", "warning", "notice", "info", "debug":
			return true
		}
	}
	return false
}

// CreateOutputDatadogSite - Datadog site to which events should be sent
type CreateOutputDatadogSite string

const (
	// CreateOutputDatadogSiteUs US
	CreateOutputDatadogSiteUs CreateOutputDatadogSite = "us"
	// CreateOutputDatadogSiteUs3 US3
	CreateOutputDatadogSiteUs3 CreateOutputDatadogSite = "us3"
	// CreateOutputDatadogSiteUs5 US5
	CreateOutputDatadogSiteUs5 CreateOutputDatadogSite = "us5"
	// CreateOutputDatadogSiteEu Europe
	CreateOutputDatadogSiteEu CreateOutputDatadogSite = "eu"
	// CreateOutputDatadogSiteFed1 US1-FED
	CreateOutputDatadogSiteFed1 CreateOutputDatadogSite = "fed1"
	// CreateOutputDatadogSiteAp1 AP1
	CreateOutputDatadogSiteAp1 CreateOutputDatadogSite = "ap1"
	// CreateOutputDatadogSiteCustom Custom
	CreateOutputDatadogSiteCustom CreateOutputDatadogSite = "custom"
)

func (e CreateOutputDatadogSite) ToPointer() *CreateOutputDatadogSite {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputDatadogSite) IsExact() bool {
	if e != nil {
		switch *e {
		case "us", "us3", "us5", "eu", "fed1", "ap1", "custom":
			return true
		}
	}
	return false
}

type CreateOutputPqControlsDatadog struct {
}

func (c CreateOutputPqControlsDatadog) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsDatadog) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputDatadog struct {
	// Unique ID for this output
	ID   string                  `json:"id"`
	Type CreateOutputTypeDatadog `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The content type to use when sending logs
	ContentType *CreateOutputSendLogsAs `json:"contentType,omitempty"`
	// Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
	Message *string `json:"message,omitempty"`
	// Name of the source to send with logs. When you send logs as JSON objects, the event's 'source' field (if set) will override this value.
	Source *string `json:"source,omitempty"`
	// Name of the host to send with logs. When you send logs as JSON objects, the event's 'host' field (if set) will override this value.
	Host *string `json:"host,omitempty"`
	// Name of the service to send with logs. When you send logs as JSON objects, the event's '__service' field (if set) will override this value.
	Service *string `json:"service,omitempty"`
	// List of tags to send with logs, such as 'env:prod' and 'env_staging:east'
	Tags []string `json:"tags,omitempty"`
	// Batch events by API key and the ddtags field on the event. When disabled, batches events only by API key. If incoming events have high cardinality in the ddtags field, disabling this setting may improve Destination performance.
	BatchByTags *bool `json:"batchByTags,omitempty"`
	// Allow API key to be set from the event's '__agent_api_key' field
	AllowAPIKeyFromEvents *bool `json:"allowApiKeyFromEvents,omitempty"`
	// Default value for message severity. When you send logs as JSON objects, the event's '__severity' field (if set) will override this value.
	Severity *CreateOutputSeverityDatadog `json:"severity,omitempty"`
	// Datadog site to which events should be sent
	Site *CreateOutputDatadogSite `json:"site,omitempty"`
	// If not enabled, Datadog will transform 'counter' metrics to 'gauge'. [Learn more about Datadog metrics types.](https://docs.datadoghq.com/metrics/types/?tab=count)
	SendCountersAsCount *bool `json:"sendCountersAsCount,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Enter API key directly, or select a stored secret
	AuthType *components.AuthenticationMethodOptions2 `json:"authType,omitempty"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	CustomURL          *string  `json:"customUrl,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsDatadog       `json:"pqControls,omitempty"`
	// Organization's API key in Datadog
	APIKey *string `json:"apiKey,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
}

func (c CreateOutputOutputDatadog) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputDatadog) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputDatadog) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputDatadog) GetType() CreateOutputTypeDatadog {
	if c == nil {
		return CreateOutputTypeDatadog("")
	}
	return c.Type
}

func (c *CreateOutputOutputDatadog) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputDatadog) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputDatadog) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputDatadog) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputDatadog) GetContentType() *CreateOutputSendLogsAs {
	if c == nil {
		return nil
	}
	return c.ContentType
}

func (c *CreateOutputOutputDatadog) GetMessage() *string {
	if c == nil {
		return nil
	}
	return c.Message
}

func (c *CreateOutputOutputDatadog) GetSource() *string {
	if c == nil {
		return nil
	}
	return c.Source
}

func (c *CreateOutputOutputDatadog) GetHost() *string {
	if c == nil {
		return nil
	}
	return c.Host
}

func (c *CreateOutputOutputDatadog) GetService() *string {
	if c == nil {
		return nil
	}
	return c.Service
}

func (c *CreateOutputOutputDatadog) GetTags() []string {
	if c == nil {
		return nil
	}
	return c.Tags
}

func (c *CreateOutputOutputDatadog) GetBatchByTags() *bool {
	if c == nil {
		return nil
	}
	return c.BatchByTags
}

func (c *CreateOutputOutputDatadog) GetAllowAPIKeyFromEvents() *bool {
	if c == nil {
		return nil
	}
	return c.AllowAPIKeyFromEvents
}

func (c *CreateOutputOutputDatadog) GetSeverity() *CreateOutputSeverityDatadog {
	if c == nil {
		return nil
	}
	return c.Severity
}

func (c *CreateOutputOutputDatadog) GetSite() *CreateOutputDatadogSite {
	if c == nil {
		return nil
	}
	return c.Site
}

func (c *CreateOutputOutputDatadog) GetSendCountersAsCount() *bool {
	if c == nil {
		return nil
	}
	return c.SendCountersAsCount
}

func (c *CreateOutputOutputDatadog) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputDatadog) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputDatadog) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputDatadog) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputDatadog) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputDatadog) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputDatadog) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputDatadog) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputDatadog) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputDatadog) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputDatadog) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputDatadog) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputDatadog) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputDatadog) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputDatadog) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputDatadog) GetAuthType() *components.AuthenticationMethodOptions2 {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputDatadog) GetTotalMemoryLimitKB() *float64 {
	if c == nil {
		return nil
	}
	return c.TotalMemoryLimitKB
}

func (c *CreateOutputOutputDatadog) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputDatadog) GetCustomURL() *string {
	if c == nil {
		return nil
	}
	return c.CustomURL
}

func (c *CreateOutputOutputDatadog) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputDatadog) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputDatadog) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputDatadog) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputDatadog) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputDatadog) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputDatadog) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputDatadog) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputDatadog) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputDatadog) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputDatadog) GetPqControls() *CreateOutputPqControlsDatadog {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputDatadog) GetAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.APIKey
}

func (c *CreateOutputOutputDatadog) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

type CreateOutputTypeSumoLogic string

const (
	CreateOutputTypeSumoLogicSumoLogic CreateOutputTypeSumoLogic = "sumo_logic"
)

func (e CreateOutputTypeSumoLogic) ToPointer() *CreateOutputTypeSumoLogic {
	return &e
}
func (e *CreateOutputTypeSumoLogic) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sumo_logic":
		*e = CreateOutputTypeSumoLogic(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeSumoLogic: %v", v)
	}
}

// CreateOutputDataFormatSumoLogic - Preserve the raw event format instead of JSONifying it
type CreateOutputDataFormatSumoLogic string

const (
	// CreateOutputDataFormatSumoLogicJSON JSON
	CreateOutputDataFormatSumoLogicJSON CreateOutputDataFormatSumoLogic = "json"
	// CreateOutputDataFormatSumoLogicRaw Raw
	CreateOutputDataFormatSumoLogicRaw CreateOutputDataFormatSumoLogic = "raw"
)

func (e CreateOutputDataFormatSumoLogic) ToPointer() *CreateOutputDataFormatSumoLogic {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputDataFormatSumoLogic) IsExact() bool {
	if e != nil {
		switch *e {
		case "json", "raw":
			return true
		}
	}
	return false
}

type CreateOutputPqControlsSumoLogic struct {
}

func (c CreateOutputPqControlsSumoLogic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsSumoLogic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputSumoLogic struct {
	// Unique ID for this output
	ID   string                    `json:"id"`
	Type CreateOutputTypeSumoLogic `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Sumo Logic HTTP collector URL to which events should be sent
	URL string `json:"url"`
	// Override the source name configured on the Sumo Logic HTTP collector. This can also be overridden at the event level with the __sourceName field.
	CustomSource *string `json:"customSource,omitempty"`
	// Override the source category configured on the Sumo Logic HTTP collector. This can also be overridden at the event level with the __sourceCategory field.
	CustomCategory *string `json:"customCategory,omitempty"`
	// Preserve the raw event format instead of JSONifying it
	Format *CreateOutputDataFormatSumoLogic `json:"format,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsSumoLogic     `json:"pqControls,omitempty"`
	// Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
	TemplateURL *string `json:"__template_url,omitempty"`
}

func (c CreateOutputOutputSumoLogic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputSumoLogic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "url"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputSumoLogic) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputSumoLogic) GetType() CreateOutputTypeSumoLogic {
	if c == nil {
		return CreateOutputTypeSumoLogic("")
	}
	return c.Type
}

func (c *CreateOutputOutputSumoLogic) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputSumoLogic) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputSumoLogic) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputSumoLogic) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputSumoLogic) GetURL() string {
	if c == nil {
		return ""
	}
	return c.URL
}

func (c *CreateOutputOutputSumoLogic) GetCustomSource() *string {
	if c == nil {
		return nil
	}
	return c.CustomSource
}

func (c *CreateOutputOutputSumoLogic) GetCustomCategory() *string {
	if c == nil {
		return nil
	}
	return c.CustomCategory
}

func (c *CreateOutputOutputSumoLogic) GetFormat() *CreateOutputDataFormatSumoLogic {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputSumoLogic) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputSumoLogic) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputSumoLogic) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputSumoLogic) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputSumoLogic) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputSumoLogic) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputSumoLogic) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputSumoLogic) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputSumoLogic) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputSumoLogic) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputSumoLogic) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputSumoLogic) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputSumoLogic) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputSumoLogic) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputSumoLogic) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputSumoLogic) GetTotalMemoryLimitKB() *float64 {
	if c == nil {
		return nil
	}
	return c.TotalMemoryLimitKB
}

func (c *CreateOutputOutputSumoLogic) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputSumoLogic) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputSumoLogic) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputSumoLogic) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputSumoLogic) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputSumoLogic) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputSumoLogic) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputSumoLogic) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputSumoLogic) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputSumoLogic) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputSumoLogic) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputSumoLogic) GetPqControls() *CreateOutputPqControlsSumoLogic {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputSumoLogic) GetTemplateURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateURL
}

type CreateOutputTypeSnmp string

const (
	CreateOutputTypeSnmpSnmp CreateOutputTypeSnmp = "snmp"
)

func (e CreateOutputTypeSnmp) ToPointer() *CreateOutputTypeSnmp {
	return &e
}
func (e *CreateOutputTypeSnmp) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "snmp":
		*e = CreateOutputTypeSnmp(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeSnmp: %v", v)
	}
}

type CreateOutputHostSnmp struct {
	// Destination host
	Host string `json:"host"`
	// Destination port, default is 162
	Port float64 `json:"port"`
	// Binds 'host' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'host' at runtime.
	TemplateHost *string `json:"__template_host,omitempty"`
	// Binds 'port' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'port' at runtime.
	TemplatePort *string `json:"__template_port,omitempty"`
}

func (c CreateOutputHostSnmp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputHostSnmp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"host", "port"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputHostSnmp) GetHost() string {
	if c == nil {
		return ""
	}
	return c.Host
}

func (c *CreateOutputHostSnmp) GetPort() float64 {
	if c == nil {
		return 0.0
	}
	return c.Port
}

func (c *CreateOutputHostSnmp) GetTemplateHost() *string {
	if c == nil {
		return nil
	}
	return c.TemplateHost
}

func (c *CreateOutputHostSnmp) GetTemplatePort() *string {
	if c == nil {
		return nil
	}
	return c.TemplatePort
}

type CreateOutputOutputSnmp struct {
	// Unique ID for this output
	ID   string               `json:"id"`
	Type CreateOutputTypeSnmp `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// One or more SNMP destinations to forward traps to
	Hosts []CreateOutputHostSnmp `json:"hosts"`
	// How often to resolve the destination hostname to an IP address. Ignored if all destinations are IP addresses. A value of 0 means every trap sent will incur a DNS lookup.
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	Description         *string  `json:"description,omitempty"`
}

func (c CreateOutputOutputSnmp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputSnmp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "hosts"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputSnmp) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputSnmp) GetType() CreateOutputTypeSnmp {
	if c == nil {
		return CreateOutputTypeSnmp("")
	}
	return c.Type
}

func (c *CreateOutputOutputSnmp) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputSnmp) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputSnmp) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputSnmp) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputSnmp) GetHosts() []CreateOutputHostSnmp {
	if c == nil {
		return []CreateOutputHostSnmp{}
	}
	return c.Hosts
}

func (c *CreateOutputOutputSnmp) GetDNSResolvePeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.DNSResolvePeriodSec
}

func (c *CreateOutputOutputSnmp) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

type CreateOutputTypeSqs string

const (
	CreateOutputTypeSqsSqs CreateOutputTypeSqs = "sqs"
)

func (e CreateOutputTypeSqs) ToPointer() *CreateOutputTypeSqs {
	return &e
}
func (e *CreateOutputTypeSqs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sqs":
		*e = CreateOutputTypeSqs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeSqs: %v", v)
	}
}

// CreateOutputQueueType - The queue type used (or created). Defaults to Standard.
type CreateOutputQueueType string

const (
	// CreateOutputQueueTypeStandard Standard
	CreateOutputQueueTypeStandard CreateOutputQueueType = "standard"
	// CreateOutputQueueTypeFifo FIFO
	CreateOutputQueueTypeFifo CreateOutputQueueType = "fifo"
)

func (e CreateOutputQueueType) ToPointer() *CreateOutputQueueType {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputQueueType) IsExact() bool {
	if e != nil {
		switch *e {
		case "standard", "fifo":
			return true
		}
	}
	return false
}

type CreateOutputPqControlsSqs struct {
}

func (c CreateOutputPqControlsSqs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsSqs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputSqs struct {
	// Unique ID for this output
	ID   string              `json:"id"`
	Type CreateOutputTypeSqs `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The name, URL, or ARN of the SQS queue to send events to. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// The queue type used (or created). Defaults to Standard.
	QueueType CreateOutputQueueType `json:"queueType"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// This parameter applies only to FIFO queues. The tag that specifies that a message belongs to a specific message group. Messages that belong to the same message group are processed in a FIFO manner. Use event field __messageGroupId to override this value.
	MessageGroupID *string `json:"messageGroupId,omitempty"`
	// Create queue if it does not exist.
	CreateQueue *bool `json:"createQueue,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitempty"`
	AwsSecretKey            *string                                                `json:"awsSecretKey,omitempty"`
	// AWS Region where the SQS queue is located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// SQS service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to SQS-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing SQS requests
	SignatureVersion *components.SignatureVersionOptions3 `json:"signatureVersion,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Use Assume Role credentials to access SQS
	EnableAssumeRole *bool `json:"enableAssumeRole,omitempty"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitempty"`
	// Maximum number of queued batches before blocking.
	MaxQueueSize *float64 `json:"maxQueueSize,omitempty"`
	// Maximum size (KB) of batches to send. Per the SQS spec, the max allowed value is 256 KB.
	MaxRecordSizeKB *float64 `json:"maxRecordSizeKB,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// The maximum number of in-progress API requests before backpressure is applied.
	MaxInProgress *float64 `json:"maxInProgress,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	AwsAPIKey      *string                                 `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsSqs           `json:"pqControls,omitempty"`
	// Binds 'queueName' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'queueName' at runtime.
	TemplateQueueName *string `json:"__template_queueName,omitempty"`
	// Binds 'awsAccountId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsAccountId' at runtime.
	TemplateAwsAccountID *string `json:"__template_awsAccountId,omitempty"`
	// Binds 'awsSecretKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsSecretKey' at runtime.
	TemplateAwsSecretKey *string `json:"__template_awsSecretKey,omitempty"`
	// Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime.
	TemplateRegion *string `json:"__template_region,omitempty"`
	// Binds 'assumeRoleArn' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleArn' at runtime.
	TemplateAssumeRoleArn *string `json:"__template_assumeRoleArn,omitempty"`
	// Binds 'assumeRoleExternalId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleExternalId' at runtime.
	TemplateAssumeRoleExternalID *string `json:"__template_assumeRoleExternalId,omitempty"`
	// Binds 'awsApiKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsApiKey' at runtime.
	TemplateAwsAPIKey *string `json:"__template_awsApiKey,omitempty"`
}

func (c CreateOutputOutputSqs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputSqs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "queueName", "queueType"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputSqs) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputSqs) GetType() CreateOutputTypeSqs {
	if c == nil {
		return CreateOutputTypeSqs("")
	}
	return c.Type
}

func (c *CreateOutputOutputSqs) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputSqs) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputSqs) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputSqs) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputSqs) GetQueueName() string {
	if c == nil {
		return ""
	}
	return c.QueueName
}

func (c *CreateOutputOutputSqs) GetQueueType() CreateOutputQueueType {
	if c == nil {
		return CreateOutputQueueType("")
	}
	return c.QueueType
}

func (c *CreateOutputOutputSqs) GetAwsAccountID() *string {
	if c == nil {
		return nil
	}
	return c.AwsAccountID
}

func (c *CreateOutputOutputSqs) GetMessageGroupID() *string {
	if c == nil {
		return nil
	}
	return c.MessageGroupID
}

func (c *CreateOutputOutputSqs) GetCreateQueue() *bool {
	if c == nil {
		return nil
	}
	return c.CreateQueue
}

func (c *CreateOutputOutputSqs) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if c == nil {
		return nil
	}
	return c.AwsAuthenticationMethod
}

func (c *CreateOutputOutputSqs) GetAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecretKey
}

func (c *CreateOutputOutputSqs) GetRegion() *string {
	if c == nil {
		return nil
	}
	return c.Region
}

func (c *CreateOutputOutputSqs) GetEndpoint() *string {
	if c == nil {
		return nil
	}
	return c.Endpoint
}

func (c *CreateOutputOutputSqs) GetSignatureVersion() *components.SignatureVersionOptions3 {
	if c == nil {
		return nil
	}
	return c.SignatureVersion
}

func (c *CreateOutputOutputSqs) GetReuseConnections() *bool {
	if c == nil {
		return nil
	}
	return c.ReuseConnections
}

func (c *CreateOutputOutputSqs) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputSqs) GetEnableAssumeRole() *bool {
	if c == nil {
		return nil
	}
	return c.EnableAssumeRole
}

func (c *CreateOutputOutputSqs) GetAssumeRoleArn() *string {
	if c == nil {
		return nil
	}
	return c.AssumeRoleArn
}

func (c *CreateOutputOutputSqs) GetAssumeRoleExternalID() *string {
	if c == nil {
		return nil
	}
	return c.AssumeRoleExternalID
}

func (c *CreateOutputOutputSqs) GetDurationSeconds() *float64 {
	if c == nil {
		return nil
	}
	return c.DurationSeconds
}

func (c *CreateOutputOutputSqs) GetMaxQueueSize() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxQueueSize
}

func (c *CreateOutputOutputSqs) GetMaxRecordSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRecordSizeKB
}

func (c *CreateOutputOutputSqs) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputSqs) GetMaxInProgress() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxInProgress
}

func (c *CreateOutputOutputSqs) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputSqs) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputSqs) GetAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsAPIKey
}

func (c *CreateOutputOutputSqs) GetAwsSecret() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecret
}

func (c *CreateOutputOutputSqs) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputSqs) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputSqs) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputSqs) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputSqs) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputSqs) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputSqs) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputSqs) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputSqs) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputSqs) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputSqs) GetPqControls() *CreateOutputPqControlsSqs {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputSqs) GetTemplateQueueName() *string {
	if c == nil {
		return nil
	}
	return c.TemplateQueueName
}

func (c *CreateOutputOutputSqs) GetTemplateAwsAccountID() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAwsAccountID
}

func (c *CreateOutputOutputSqs) GetTemplateAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAwsSecretKey
}

func (c *CreateOutputOutputSqs) GetTemplateRegion() *string {
	if c == nil {
		return nil
	}
	return c.TemplateRegion
}

func (c *CreateOutputOutputSqs) GetTemplateAssumeRoleArn() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAssumeRoleArn
}

func (c *CreateOutputOutputSqs) GetTemplateAssumeRoleExternalID() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAssumeRoleExternalID
}

func (c *CreateOutputOutputSqs) GetTemplateAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAwsAPIKey
}

type CreateOutputTypeSns string

const (
	CreateOutputTypeSnsSns CreateOutputTypeSns = "sns"
)

func (e CreateOutputTypeSns) ToPointer() *CreateOutputTypeSns {
	return &e
}
func (e *CreateOutputTypeSns) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sns":
		*e = CreateOutputTypeSns(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeSns: %v", v)
	}
}

// CreateOutputSignatureVersionSns - Signature version to use for signing SNS requests
type CreateOutputSignatureVersionSns string

const (
	CreateOutputSignatureVersionSnsV2 CreateOutputSignatureVersionSns = "v2"
	CreateOutputSignatureVersionSnsV4 CreateOutputSignatureVersionSns = "v4"
)

func (e CreateOutputSignatureVersionSns) ToPointer() *CreateOutputSignatureVersionSns {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputSignatureVersionSns) IsExact() bool {
	if e != nil {
		switch *e {
		case "v2", "v4":
			return true
		}
	}
	return false
}

type CreateOutputPqControlsSns struct {
}

func (c CreateOutputPqControlsSns) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsSns) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputSns struct {
	// Unique ID for this output
	ID   string              `json:"id"`
	Type CreateOutputTypeSns `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The ARN of the SNS topic to send events to. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. E.g., 'https://host:port/myQueueName'. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`
	TopicArn string `json:"topicArn"`
	// Messages in the same group are processed in a FIFO manner. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	MessageGroupID string `json:"messageGroupId"`
	// Maximum number of retries before the output returns an error. Note that not all errors are retryable. The retries use an exponential backoff policy.
	MaxRetries *float64 `json:"maxRetries,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitempty"`
	AwsSecretKey            *string                                                `json:"awsSecretKey,omitempty"`
	// Region where the SNS is located
	Region *string `json:"region,omitempty"`
	// SNS service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to SNS-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing SNS requests
	SignatureVersion *CreateOutputSignatureVersionSns `json:"signatureVersion,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Use Assume Role credentials to access SNS
	EnableAssumeRole *bool `json:"enableAssumeRole,omitempty"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	AwsAPIKey      *string                                 `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsSns           `json:"pqControls,omitempty"`
	// Binds 'awsSecretKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsSecretKey' at runtime.
	TemplateAwsSecretKey *string `json:"__template_awsSecretKey,omitempty"`
	// Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime.
	TemplateRegion *string `json:"__template_region,omitempty"`
	// Binds 'assumeRoleArn' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleArn' at runtime.
	TemplateAssumeRoleArn *string `json:"__template_assumeRoleArn,omitempty"`
	// Binds 'assumeRoleExternalId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleExternalId' at runtime.
	TemplateAssumeRoleExternalID *string `json:"__template_assumeRoleExternalId,omitempty"`
	// Binds 'awsApiKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsApiKey' at runtime.
	TemplateAwsAPIKey *string `json:"__template_awsApiKey,omitempty"`
}

func (c CreateOutputOutputSns) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputSns) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "topicArn", "messageGroupId"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputSns) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputSns) GetType() CreateOutputTypeSns {
	if c == nil {
		return CreateOutputTypeSns("")
	}
	return c.Type
}

func (c *CreateOutputOutputSns) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputSns) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputSns) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputSns) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputSns) GetTopicArn() string {
	if c == nil {
		return ""
	}
	return c.TopicArn
}

func (c *CreateOutputOutputSns) GetMessageGroupID() string {
	if c == nil {
		return ""
	}
	return c.MessageGroupID
}

func (c *CreateOutputOutputSns) GetMaxRetries() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRetries
}

func (c *CreateOutputOutputSns) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if c == nil {
		return nil
	}
	return c.AwsAuthenticationMethod
}

func (c *CreateOutputOutputSns) GetAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecretKey
}

func (c *CreateOutputOutputSns) GetRegion() *string {
	if c == nil {
		return nil
	}
	return c.Region
}

func (c *CreateOutputOutputSns) GetEndpoint() *string {
	if c == nil {
		return nil
	}
	return c.Endpoint
}

func (c *CreateOutputOutputSns) GetSignatureVersion() *CreateOutputSignatureVersionSns {
	if c == nil {
		return nil
	}
	return c.SignatureVersion
}

func (c *CreateOutputOutputSns) GetReuseConnections() *bool {
	if c == nil {
		return nil
	}
	return c.ReuseConnections
}

func (c *CreateOutputOutputSns) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputSns) GetEnableAssumeRole() *bool {
	if c == nil {
		return nil
	}
	return c.EnableAssumeRole
}

func (c *CreateOutputOutputSns) GetAssumeRoleArn() *string {
	if c == nil {
		return nil
	}
	return c.AssumeRoleArn
}

func (c *CreateOutputOutputSns) GetAssumeRoleExternalID() *string {
	if c == nil {
		return nil
	}
	return c.AssumeRoleExternalID
}

func (c *CreateOutputOutputSns) GetDurationSeconds() *float64 {
	if c == nil {
		return nil
	}
	return c.DurationSeconds
}

func (c *CreateOutputOutputSns) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputSns) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputSns) GetAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsAPIKey
}

func (c *CreateOutputOutputSns) GetAwsSecret() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecret
}

func (c *CreateOutputOutputSns) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputSns) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputSns) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputSns) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputSns) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputSns) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputSns) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputSns) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputSns) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputSns) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputSns) GetPqControls() *CreateOutputPqControlsSns {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputSns) GetTemplateAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAwsSecretKey
}

func (c *CreateOutputOutputSns) GetTemplateRegion() *string {
	if c == nil {
		return nil
	}
	return c.TemplateRegion
}

func (c *CreateOutputOutputSns) GetTemplateAssumeRoleArn() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAssumeRoleArn
}

func (c *CreateOutputOutputSns) GetTemplateAssumeRoleExternalID() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAssumeRoleExternalID
}

func (c *CreateOutputOutputSns) GetTemplateAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAwsAPIKey
}

type CreateOutputTypeRouter string

const (
	CreateOutputTypeRouterRouter CreateOutputTypeRouter = "router"
)

func (e CreateOutputTypeRouter) ToPointer() *CreateOutputTypeRouter {
	return &e
}
func (e *CreateOutputTypeRouter) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "router":
		*e = CreateOutputTypeRouter(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeRouter: %v", v)
	}
}

type CreateOutputRule struct {
	// JavaScript expression to select events to send to output
	Filter string `json:"filter"`
	// Output to send matching events to
	Output string `json:"output"`
	// Description of this rule's purpose
	Description *string `json:"description,omitempty"`
	// Flag to control whether to stop the event from being checked against other rules
	Final *bool `json:"final,omitempty"`
}

func (c CreateOutputRule) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputRule) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"filter", "output"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputRule) GetFilter() string {
	if c == nil {
		return ""
	}
	return c.Filter
}

func (c *CreateOutputRule) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

func (c *CreateOutputRule) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputRule) GetFinal() *bool {
	if c == nil {
		return nil
	}
	return c.Final
}

type CreateOutputOutputRouter struct {
	// Unique ID for this output
	ID   string                 `json:"id"`
	Type CreateOutputTypeRouter `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Event routing rules
	Rules       []CreateOutputRule `json:"rules"`
	Description *string            `json:"description,omitempty"`
}

func (c CreateOutputOutputRouter) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputRouter) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "rules"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputRouter) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputRouter) GetType() CreateOutputTypeRouter {
	if c == nil {
		return CreateOutputTypeRouter("")
	}
	return c.Type
}

func (c *CreateOutputOutputRouter) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputRouter) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputRouter) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputRouter) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputRouter) GetRules() []CreateOutputRule {
	if c == nil {
		return []CreateOutputRule{}
	}
	return c.Rules
}

func (c *CreateOutputOutputRouter) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

type CreateOutputTypeGraphite string

const (
	CreateOutputTypeGraphiteGraphite CreateOutputTypeGraphite = "graphite"
)

func (e CreateOutputTypeGraphite) ToPointer() *CreateOutputTypeGraphite {
	return &e
}
func (e *CreateOutputTypeGraphite) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "graphite":
		*e = CreateOutputTypeGraphite(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeGraphite: %v", v)
	}
}

type CreateOutputPqControlsGraphite struct {
}

func (c CreateOutputPqControlsGraphite) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsGraphite) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputGraphite struct {
	// Unique ID for this output
	ID   string                   `json:"id"`
	Type CreateOutputTypeGraphite `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Protocol to use when communicating with the destination.
	Protocol components.DestinationProtocolOptions `json:"protocol"`
	// The hostname of the destination.
	Host string `json:"host"`
	// Destination port.
	Port float64 `json:"port"`
	// When protocol is UDP, specifies the maximum size of packets sent to the destination. Also known as the MTU for the network path to the destination system.
	Mtu *float64 `json:"mtu,omitempty"`
	// When protocol is TCP, specifies how often buffers should be flushed, resulting in records sent to the destination.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every batch sent will incur a DNS lookup.
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	Description         *string  `json:"description,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `json:"throttleRatePerSec,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64 `json:"writeTimeout,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsGraphite      `json:"pqControls,omitempty"`
}

func (c CreateOutputOutputGraphite) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputGraphite) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "protocol", "host", "port"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputGraphite) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputGraphite) GetType() CreateOutputTypeGraphite {
	if c == nil {
		return CreateOutputTypeGraphite("")
	}
	return c.Type
}

func (c *CreateOutputOutputGraphite) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputGraphite) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputGraphite) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputGraphite) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputGraphite) GetProtocol() components.DestinationProtocolOptions {
	if c == nil {
		return components.DestinationProtocolOptions("")
	}
	return c.Protocol
}

func (c *CreateOutputOutputGraphite) GetHost() string {
	if c == nil {
		return ""
	}
	return c.Host
}

func (c *CreateOutputOutputGraphite) GetPort() float64 {
	if c == nil {
		return 0.0
	}
	return c.Port
}

func (c *CreateOutputOutputGraphite) GetMtu() *float64 {
	if c == nil {
		return nil
	}
	return c.Mtu
}

func (c *CreateOutputOutputGraphite) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputGraphite) GetDNSResolvePeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.DNSResolvePeriodSec
}

func (c *CreateOutputOutputGraphite) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputGraphite) GetThrottleRatePerSec() *string {
	if c == nil {
		return nil
	}
	return c.ThrottleRatePerSec
}

func (c *CreateOutputOutputGraphite) GetConnectionTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.ConnectionTimeout
}

func (c *CreateOutputOutputGraphite) GetWriteTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.WriteTimeout
}

func (c *CreateOutputOutputGraphite) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputGraphite) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputGraphite) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputGraphite) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputGraphite) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputGraphite) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputGraphite) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputGraphite) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputGraphite) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputGraphite) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputGraphite) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputGraphite) GetPqControls() *CreateOutputPqControlsGraphite {
	if c == nil {
		return nil
	}
	return c.PqControls
}

type CreateOutputTypeStatsdExt string

const (
	CreateOutputTypeStatsdExtStatsdExt CreateOutputTypeStatsdExt = "statsd_ext"
)

func (e CreateOutputTypeStatsdExt) ToPointer() *CreateOutputTypeStatsdExt {
	return &e
}
func (e *CreateOutputTypeStatsdExt) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "statsd_ext":
		*e = CreateOutputTypeStatsdExt(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeStatsdExt: %v", v)
	}
}

type CreateOutputPqControlsStatsdExt struct {
}

func (c CreateOutputPqControlsStatsdExt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsStatsdExt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputStatsdExt struct {
	// Unique ID for this output
	ID   string                    `json:"id"`
	Type CreateOutputTypeStatsdExt `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Protocol to use when communicating with the destination.
	Protocol components.DestinationProtocolOptions `json:"protocol"`
	// The hostname of the destination.
	Host string `json:"host"`
	// Destination port.
	Port float64 `json:"port"`
	// When protocol is UDP, specifies the maximum size of packets sent to the destination. Also known as the MTU for the network path to the destination system.
	Mtu *float64 `json:"mtu,omitempty"`
	// When protocol is TCP, specifies how often buffers should be flushed, resulting in records sent to the destination.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every batch sent will incur a DNS lookup.
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	Description         *string  `json:"description,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `json:"throttleRatePerSec,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64 `json:"writeTimeout,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsStatsdExt     `json:"pqControls,omitempty"`
}

func (c CreateOutputOutputStatsdExt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputStatsdExt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "protocol", "host", "port"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputStatsdExt) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputStatsdExt) GetType() CreateOutputTypeStatsdExt {
	if c == nil {
		return CreateOutputTypeStatsdExt("")
	}
	return c.Type
}

func (c *CreateOutputOutputStatsdExt) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputStatsdExt) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputStatsdExt) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputStatsdExt) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputStatsdExt) GetProtocol() components.DestinationProtocolOptions {
	if c == nil {
		return components.DestinationProtocolOptions("")
	}
	return c.Protocol
}

func (c *CreateOutputOutputStatsdExt) GetHost() string {
	if c == nil {
		return ""
	}
	return c.Host
}

func (c *CreateOutputOutputStatsdExt) GetPort() float64 {
	if c == nil {
		return 0.0
	}
	return c.Port
}

func (c *CreateOutputOutputStatsdExt) GetMtu() *float64 {
	if c == nil {
		return nil
	}
	return c.Mtu
}

func (c *CreateOutputOutputStatsdExt) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputStatsdExt) GetDNSResolvePeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.DNSResolvePeriodSec
}

func (c *CreateOutputOutputStatsdExt) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputStatsdExt) GetThrottleRatePerSec() *string {
	if c == nil {
		return nil
	}
	return c.ThrottleRatePerSec
}

func (c *CreateOutputOutputStatsdExt) GetConnectionTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.ConnectionTimeout
}

func (c *CreateOutputOutputStatsdExt) GetWriteTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.WriteTimeout
}

func (c *CreateOutputOutputStatsdExt) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputStatsdExt) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputStatsdExt) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputStatsdExt) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputStatsdExt) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputStatsdExt) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputStatsdExt) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputStatsdExt) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputStatsdExt) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputStatsdExt) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputStatsdExt) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputStatsdExt) GetPqControls() *CreateOutputPqControlsStatsdExt {
	if c == nil {
		return nil
	}
	return c.PqControls
}

type CreateOutputTypeStatsd string

const (
	CreateOutputTypeStatsdStatsd CreateOutputTypeStatsd = "statsd"
)

func (e CreateOutputTypeStatsd) ToPointer() *CreateOutputTypeStatsd {
	return &e
}
func (e *CreateOutputTypeStatsd) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "statsd":
		*e = CreateOutputTypeStatsd(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeStatsd: %v", v)
	}
}

type CreateOutputPqControlsStatsd struct {
}

func (c CreateOutputPqControlsStatsd) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsStatsd) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputStatsd struct {
	// Unique ID for this output
	ID   string                 `json:"id"`
	Type CreateOutputTypeStatsd `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Protocol to use when communicating with the destination.
	Protocol components.DestinationProtocolOptions `json:"protocol"`
	// The hostname of the destination.
	Host string `json:"host"`
	// Destination port.
	Port float64 `json:"port"`
	// When protocol is UDP, specifies the maximum size of packets sent to the destination. Also known as the MTU for the network path to the destination system.
	Mtu *float64 `json:"mtu,omitempty"`
	// When protocol is TCP, specifies how often buffers should be flushed, resulting in records sent to the destination.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every batch sent will incur a DNS lookup.
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	Description         *string  `json:"description,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `json:"throttleRatePerSec,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64 `json:"writeTimeout,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsStatsd        `json:"pqControls,omitempty"`
}

func (c CreateOutputOutputStatsd) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputStatsd) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "protocol", "host", "port"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputStatsd) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputStatsd) GetType() CreateOutputTypeStatsd {
	if c == nil {
		return CreateOutputTypeStatsd("")
	}
	return c.Type
}

func (c *CreateOutputOutputStatsd) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputStatsd) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputStatsd) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputStatsd) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputStatsd) GetProtocol() components.DestinationProtocolOptions {
	if c == nil {
		return components.DestinationProtocolOptions("")
	}
	return c.Protocol
}

func (c *CreateOutputOutputStatsd) GetHost() string {
	if c == nil {
		return ""
	}
	return c.Host
}

func (c *CreateOutputOutputStatsd) GetPort() float64 {
	if c == nil {
		return 0.0
	}
	return c.Port
}

func (c *CreateOutputOutputStatsd) GetMtu() *float64 {
	if c == nil {
		return nil
	}
	return c.Mtu
}

func (c *CreateOutputOutputStatsd) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputStatsd) GetDNSResolvePeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.DNSResolvePeriodSec
}

func (c *CreateOutputOutputStatsd) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputStatsd) GetThrottleRatePerSec() *string {
	if c == nil {
		return nil
	}
	return c.ThrottleRatePerSec
}

func (c *CreateOutputOutputStatsd) GetConnectionTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.ConnectionTimeout
}

func (c *CreateOutputOutputStatsd) GetWriteTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.WriteTimeout
}

func (c *CreateOutputOutputStatsd) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputStatsd) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputStatsd) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputStatsd) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputStatsd) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputStatsd) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputStatsd) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputStatsd) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputStatsd) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputStatsd) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputStatsd) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputStatsd) GetPqControls() *CreateOutputPqControlsStatsd {
	if c == nil {
		return nil
	}
	return c.PqControls
}

type CreateOutputTypeMinio string

const (
	CreateOutputTypeMinioMinio CreateOutputTypeMinio = "minio"
)

func (e CreateOutputTypeMinio) ToPointer() *CreateOutputTypeMinio {
	return &e
}
func (e *CreateOutputTypeMinio) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "minio":
		*e = CreateOutputTypeMinio(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeMinio: %v", v)
	}
}

type CreateOutputOutputMinio struct {
	// Unique ID for this output
	ID   string                `json:"id"`
	Type CreateOutputTypeMinio `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// MinIO service url (e.g. http://minioHost:9000)
	Endpoint string `json:"endpoint"`
	// Name of the destination MinIO bucket. This value can be a constant or a JavaScript expression that can only be evaluated at init time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
	Bucket string `json:"bucket"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitempty"`
	// Secret key. This value can be a constant or a JavaScript expression, such as `${C.env.SOME_SECRET}`).
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	// Region where the MinIO service/cluster is located
	Region *string `json:"region,omitempty"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
	StagePath string `json:"stagePath"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Root directory to prepend to path before uploading. Enter a constant, or a JavaScript expression enclosed in quotes or backticks.
	DestPath *string `json:"destPath,omitempty"`
	// Signature version to use for signing MinIO requests
	SignatureVersion *components.SignatureVersionOptions5 `json:"signatureVersion,omitempty"`
	// Object ACL to assign to uploaded objects
	ObjectACL *components.ObjectACLOptions `json:"objectACL,omitempty"`
	// Storage class to select for uploaded objects
	StorageClass *components.StorageClassOptions2 `json:"storageClass,omitempty"`
	// Server-side encryption for uploaded objects
	ServerSideEncryption *components.ServerSideEncryptionOptions `json:"serverSideEncryption,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates)
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Disable if you can access files within the bucket but not the bucket itself
	VerifyPermissions *bool `json:"verifyPermissions,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
	PartitionExpr *string `json:"partitionExpr,omitempty"`
	// Format of the output data
	Format *components.DataFormatOptions `json:"format,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `json:"baseFileName,omitempty"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `json:"fileNameSuffix,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `json:"maxFileSizeMB,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `json:"maxOpenFiles,omitempty"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `json:"headerLine,omitempty"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `json:"writeHighWaterMark,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `json:"deadletterEnabled,omitempty"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *components.DiskSpaceProtectionOptions `json:"onDiskFullBackpressure,omitempty"`
	// Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
	ForceCloseOnShutdown *bool                         `json:"forceCloseOnShutdown,omitempty"`
	RetrySettings        *components.RetrySettingsType `json:"retrySettings,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *float64 `json:"maxConcurrentFileParts,omitempty"`
	Description            *string  `json:"description,omitempty"`
	// This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Data compression format to apply to HTTP content before it is delivered
	Compress *components.CompressionOptions2 `json:"compress,omitempty"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *components.CompressionLevelOptions `json:"compressionLevel,omitempty"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `json:"automaticSchema,omitempty"`
	// To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
	ParquetSchema *string `json:"parquetSchema,omitempty"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *components.ParquetVersionOptions `json:"parquetVersion,omitempty"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *components.DataPageVersionOptions `json:"parquetDataPageVersion,omitempty"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `json:"parquetRowGroupLength,omitempty"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
	KeyValueMetadata []components.ItemsTypeKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `json:"enableStatistics,omitempty"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `json:"enableWritePageIndex,omitempty"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `json:"enablePageChecksum,omitempty"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `json:"emptyDirCleanupSec,omitempty"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `json:"directoryBatchSize,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `json:"deadletterPath,omitempty"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `json:"maxRetryNum,omitempty"`
	// Binds 'bucket' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'bucket' at runtime.
	TemplateBucket *string `json:"__template_bucket,omitempty"`
	// Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime.
	TemplateRegion *string `json:"__template_region,omitempty"`
	// Binds 'format' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'format' at runtime.
	TemplateFormat *string `json:"__template_format,omitempty"`
	// Binds 'awsApiKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsApiKey' at runtime.
	TemplateAwsAPIKey *string `json:"__template_awsApiKey,omitempty"`
}

func (c CreateOutputOutputMinio) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputMinio) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "endpoint", "bucket", "stagePath"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputMinio) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputMinio) GetType() CreateOutputTypeMinio {
	if c == nil {
		return CreateOutputTypeMinio("")
	}
	return c.Type
}

func (c *CreateOutputOutputMinio) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputMinio) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputMinio) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputMinio) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputMinio) GetEndpoint() string {
	if c == nil {
		return ""
	}
	return c.Endpoint
}

func (c *CreateOutputOutputMinio) GetBucket() string {
	if c == nil {
		return ""
	}
	return c.Bucket
}

func (c *CreateOutputOutputMinio) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if c == nil {
		return nil
	}
	return c.AwsAuthenticationMethod
}

func (c *CreateOutputOutputMinio) GetAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecretKey
}

func (c *CreateOutputOutputMinio) GetRegion() *string {
	if c == nil {
		return nil
	}
	return c.Region
}

func (c *CreateOutputOutputMinio) GetStagePath() string {
	if c == nil {
		return ""
	}
	return c.StagePath
}

func (c *CreateOutputOutputMinio) GetAddIDToStagePath() *bool {
	if c == nil {
		return nil
	}
	return c.AddIDToStagePath
}

func (c *CreateOutputOutputMinio) GetDestPath() *string {
	if c == nil {
		return nil
	}
	return c.DestPath
}

func (c *CreateOutputOutputMinio) GetSignatureVersion() *components.SignatureVersionOptions5 {
	if c == nil {
		return nil
	}
	return c.SignatureVersion
}

func (c *CreateOutputOutputMinio) GetObjectACL() *components.ObjectACLOptions {
	if c == nil {
		return nil
	}
	return c.ObjectACL
}

func (c *CreateOutputOutputMinio) GetStorageClass() *components.StorageClassOptions2 {
	if c == nil {
		return nil
	}
	return c.StorageClass
}

func (c *CreateOutputOutputMinio) GetServerSideEncryption() *components.ServerSideEncryptionOptions {
	if c == nil {
		return nil
	}
	return c.ServerSideEncryption
}

func (c *CreateOutputOutputMinio) GetReuseConnections() *bool {
	if c == nil {
		return nil
	}
	return c.ReuseConnections
}

func (c *CreateOutputOutputMinio) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputMinio) GetVerifyPermissions() *bool {
	if c == nil {
		return nil
	}
	return c.VerifyPermissions
}

func (c *CreateOutputOutputMinio) GetRemoveEmptyDirs() *bool {
	if c == nil {
		return nil
	}
	return c.RemoveEmptyDirs
}

func (c *CreateOutputOutputMinio) GetPartitionExpr() *string {
	if c == nil {
		return nil
	}
	return c.PartitionExpr
}

func (c *CreateOutputOutputMinio) GetFormat() *components.DataFormatOptions {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputMinio) GetBaseFileName() *string {
	if c == nil {
		return nil
	}
	return c.BaseFileName
}

func (c *CreateOutputOutputMinio) GetFileNameSuffix() *string {
	if c == nil {
		return nil
	}
	return c.FileNameSuffix
}

func (c *CreateOutputOutputMinio) GetMaxFileSizeMB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileSizeMB
}

func (c *CreateOutputOutputMinio) GetMaxOpenFiles() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxOpenFiles
}

func (c *CreateOutputOutputMinio) GetHeaderLine() *string {
	if c == nil {
		return nil
	}
	return c.HeaderLine
}

func (c *CreateOutputOutputMinio) GetWriteHighWaterMark() *float64 {
	if c == nil {
		return nil
	}
	return c.WriteHighWaterMark
}

func (c *CreateOutputOutputMinio) GetOnBackpressure() *components.BackpressureBehaviorOptions1 {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputMinio) GetDeadletterEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.DeadletterEnabled
}

func (c *CreateOutputOutputMinio) GetOnDiskFullBackpressure() *components.DiskSpaceProtectionOptions {
	if c == nil {
		return nil
	}
	return c.OnDiskFullBackpressure
}

func (c *CreateOutputOutputMinio) GetForceCloseOnShutdown() *bool {
	if c == nil {
		return nil
	}
	return c.ForceCloseOnShutdown
}

func (c *CreateOutputOutputMinio) GetRetrySettings() *components.RetrySettingsType {
	if c == nil {
		return nil
	}
	return c.RetrySettings
}

func (c *CreateOutputOutputMinio) GetMaxFileOpenTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileOpenTimeSec
}

func (c *CreateOutputOutputMinio) GetMaxFileIdleTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileIdleTimeSec
}

func (c *CreateOutputOutputMinio) GetMaxConcurrentFileParts() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxConcurrentFileParts
}

func (c *CreateOutputOutputMinio) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputMinio) GetAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsAPIKey
}

func (c *CreateOutputOutputMinio) GetAwsSecret() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecret
}

func (c *CreateOutputOutputMinio) GetCompress() *components.CompressionOptions2 {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputMinio) GetCompressionLevel() *components.CompressionLevelOptions {
	if c == nil {
		return nil
	}
	return c.CompressionLevel
}

func (c *CreateOutputOutputMinio) GetAutomaticSchema() *bool {
	if c == nil {
		return nil
	}
	return c.AutomaticSchema
}

func (c *CreateOutputOutputMinio) GetParquetSchema() *string {
	if c == nil {
		return nil
	}
	return c.ParquetSchema
}

func (c *CreateOutputOutputMinio) GetParquetVersion() *components.ParquetVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetVersion
}

func (c *CreateOutputOutputMinio) GetParquetDataPageVersion() *components.DataPageVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetDataPageVersion
}

func (c *CreateOutputOutputMinio) GetParquetRowGroupLength() *float64 {
	if c == nil {
		return nil
	}
	return c.ParquetRowGroupLength
}

func (c *CreateOutputOutputMinio) GetParquetPageSize() *string {
	if c == nil {
		return nil
	}
	return c.ParquetPageSize
}

func (c *CreateOutputOutputMinio) GetShouldLogInvalidRows() *bool {
	if c == nil {
		return nil
	}
	return c.ShouldLogInvalidRows
}

func (c *CreateOutputOutputMinio) GetKeyValueMetadata() []components.ItemsTypeKeyValueMetadata {
	if c == nil {
		return nil
	}
	return c.KeyValueMetadata
}

func (c *CreateOutputOutputMinio) GetEnableStatistics() *bool {
	if c == nil {
		return nil
	}
	return c.EnableStatistics
}

func (c *CreateOutputOutputMinio) GetEnableWritePageIndex() *bool {
	if c == nil {
		return nil
	}
	return c.EnableWritePageIndex
}

func (c *CreateOutputOutputMinio) GetEnablePageChecksum() *bool {
	if c == nil {
		return nil
	}
	return c.EnablePageChecksum
}

func (c *CreateOutputOutputMinio) GetEmptyDirCleanupSec() *float64 {
	if c == nil {
		return nil
	}
	return c.EmptyDirCleanupSec
}

func (c *CreateOutputOutputMinio) GetDirectoryBatchSize() *float64 {
	if c == nil {
		return nil
	}
	return c.DirectoryBatchSize
}

func (c *CreateOutputOutputMinio) GetDeadletterPath() *string {
	if c == nil {
		return nil
	}
	return c.DeadletterPath
}

func (c *CreateOutputOutputMinio) GetMaxRetryNum() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRetryNum
}

func (c *CreateOutputOutputMinio) GetTemplateBucket() *string {
	if c == nil {
		return nil
	}
	return c.TemplateBucket
}

func (c *CreateOutputOutputMinio) GetTemplateRegion() *string {
	if c == nil {
		return nil
	}
	return c.TemplateRegion
}

func (c *CreateOutputOutputMinio) GetTemplateFormat() *string {
	if c == nil {
		return nil
	}
	return c.TemplateFormat
}

func (c *CreateOutputOutputMinio) GetTemplateAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAwsAPIKey
}

type CreateOutputTypeCloudwatch string

const (
	CreateOutputTypeCloudwatchCloudwatch CreateOutputTypeCloudwatch = "cloudwatch"
)

func (e CreateOutputTypeCloudwatch) ToPointer() *CreateOutputTypeCloudwatch {
	return &e
}
func (e *CreateOutputTypeCloudwatch) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cloudwatch":
		*e = CreateOutputTypeCloudwatch(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeCloudwatch: %v", v)
	}
}

type CreateOutputPqControlsCloudwatch struct {
}

func (c CreateOutputPqControlsCloudwatch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsCloudwatch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputCloudwatch struct {
	// Unique ID for this output
	ID   string                     `json:"id"`
	Type CreateOutputTypeCloudwatch `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// CloudWatch log group to associate events with
	LogGroupName string `json:"logGroupName"`
	// Prefix for CloudWatch log stream name. This prefix will be used to generate a unique log stream name per cribl instance, for example: myStream_myHost_myOutputId
	LogStreamName string `json:"logStreamName"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitempty"`
	AwsSecretKey            *string                                                `json:"awsSecretKey,omitempty"`
	// Region where the CloudWatchLogs is located
	Region string `json:"region"`
	// CloudWatchLogs service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to CloudWatchLogs-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Use Assume Role credentials to access CloudWatchLogs
	EnableAssumeRole *bool `json:"enableAssumeRole,omitempty"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitempty"`
	// Maximum number of queued batches before blocking
	MaxQueueSize *float64 `json:"maxQueueSize,omitempty"`
	// Maximum size (KB) of each individual record before compression. For non compressible data 1MB is the max recommended size
	MaxRecordSizeKB *float64 `json:"maxRecordSizeKB,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	AwsAPIKey      *string                                 `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsCloudwatch    `json:"pqControls,omitempty"`
	// Binds 'awsSecretKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsSecretKey' at runtime.
	TemplateAwsSecretKey *string `json:"__template_awsSecretKey,omitempty"`
	// Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime.
	TemplateRegion *string `json:"__template_region,omitempty"`
	// Binds 'assumeRoleArn' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleArn' at runtime.
	TemplateAssumeRoleArn *string `json:"__template_assumeRoleArn,omitempty"`
	// Binds 'assumeRoleExternalId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleExternalId' at runtime.
	TemplateAssumeRoleExternalID *string `json:"__template_assumeRoleExternalId,omitempty"`
	// Binds 'awsApiKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsApiKey' at runtime.
	TemplateAwsAPIKey *string `json:"__template_awsApiKey,omitempty"`
}

func (c CreateOutputOutputCloudwatch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputCloudwatch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "logGroupName", "logStreamName", "region"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputCloudwatch) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputCloudwatch) GetType() CreateOutputTypeCloudwatch {
	if c == nil {
		return CreateOutputTypeCloudwatch("")
	}
	return c.Type
}

func (c *CreateOutputOutputCloudwatch) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputCloudwatch) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputCloudwatch) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputCloudwatch) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputCloudwatch) GetLogGroupName() string {
	if c == nil {
		return ""
	}
	return c.LogGroupName
}

func (c *CreateOutputOutputCloudwatch) GetLogStreamName() string {
	if c == nil {
		return ""
	}
	return c.LogStreamName
}

func (c *CreateOutputOutputCloudwatch) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if c == nil {
		return nil
	}
	return c.AwsAuthenticationMethod
}

func (c *CreateOutputOutputCloudwatch) GetAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecretKey
}

func (c *CreateOutputOutputCloudwatch) GetRegion() string {
	if c == nil {
		return ""
	}
	return c.Region
}

func (c *CreateOutputOutputCloudwatch) GetEndpoint() *string {
	if c == nil {
		return nil
	}
	return c.Endpoint
}

func (c *CreateOutputOutputCloudwatch) GetReuseConnections() *bool {
	if c == nil {
		return nil
	}
	return c.ReuseConnections
}

func (c *CreateOutputOutputCloudwatch) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputCloudwatch) GetEnableAssumeRole() *bool {
	if c == nil {
		return nil
	}
	return c.EnableAssumeRole
}

func (c *CreateOutputOutputCloudwatch) GetAssumeRoleArn() *string {
	if c == nil {
		return nil
	}
	return c.AssumeRoleArn
}

func (c *CreateOutputOutputCloudwatch) GetAssumeRoleExternalID() *string {
	if c == nil {
		return nil
	}
	return c.AssumeRoleExternalID
}

func (c *CreateOutputOutputCloudwatch) GetDurationSeconds() *float64 {
	if c == nil {
		return nil
	}
	return c.DurationSeconds
}

func (c *CreateOutputOutputCloudwatch) GetMaxQueueSize() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxQueueSize
}

func (c *CreateOutputOutputCloudwatch) GetMaxRecordSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRecordSizeKB
}

func (c *CreateOutputOutputCloudwatch) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputCloudwatch) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputCloudwatch) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputCloudwatch) GetAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsAPIKey
}

func (c *CreateOutputOutputCloudwatch) GetAwsSecret() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecret
}

func (c *CreateOutputOutputCloudwatch) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputCloudwatch) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputCloudwatch) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputCloudwatch) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputCloudwatch) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputCloudwatch) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputCloudwatch) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputCloudwatch) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputCloudwatch) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputCloudwatch) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputCloudwatch) GetPqControls() *CreateOutputPqControlsCloudwatch {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputCloudwatch) GetTemplateAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAwsSecretKey
}

func (c *CreateOutputOutputCloudwatch) GetTemplateRegion() *string {
	if c == nil {
		return nil
	}
	return c.TemplateRegion
}

func (c *CreateOutputOutputCloudwatch) GetTemplateAssumeRoleArn() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAssumeRoleArn
}

func (c *CreateOutputOutputCloudwatch) GetTemplateAssumeRoleExternalID() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAssumeRoleExternalID
}

func (c *CreateOutputOutputCloudwatch) GetTemplateAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAwsAPIKey
}

type CreateOutputTypeInfluxdb string

const (
	CreateOutputTypeInfluxdbInfluxdb CreateOutputTypeInfluxdb = "influxdb"
)

func (e CreateOutputTypeInfluxdb) ToPointer() *CreateOutputTypeInfluxdb {
	return &e
}
func (e *CreateOutputTypeInfluxdb) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "influxdb":
		*e = CreateOutputTypeInfluxdb(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeInfluxdb: %v", v)
	}
}

// CreateOutputTimestampPrecision - Sets the precision for the supplied Unix time values. Defaults to milliseconds.
type CreateOutputTimestampPrecision string

const (
	// CreateOutputTimestampPrecisionNs Nanoseconds
	CreateOutputTimestampPrecisionNs CreateOutputTimestampPrecision = "ns"
	// CreateOutputTimestampPrecisionU Microseconds
	CreateOutputTimestampPrecisionU CreateOutputTimestampPrecision = "u"
	// CreateOutputTimestampPrecisionMs Milliseconds
	CreateOutputTimestampPrecisionMs CreateOutputTimestampPrecision = "ms"
	// CreateOutputTimestampPrecisionS Seconds
	CreateOutputTimestampPrecisionS CreateOutputTimestampPrecision = "s"
	// CreateOutputTimestampPrecisionM Minutes
	CreateOutputTimestampPrecisionM CreateOutputTimestampPrecision = "m"
	// CreateOutputTimestampPrecisionH Hours
	CreateOutputTimestampPrecisionH CreateOutputTimestampPrecision = "h"
)

func (e CreateOutputTimestampPrecision) ToPointer() *CreateOutputTimestampPrecision {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputTimestampPrecision) IsExact() bool {
	if e != nil {
		switch *e {
		case "ns", "u", "ms", "s", "m", "h":
			return true
		}
	}
	return false
}

// CreateOutputAuthenticationTypeInfluxdb - InfluxDB authentication type
type CreateOutputAuthenticationTypeInfluxdb string

const (
	// CreateOutputAuthenticationTypeInfluxdbNone None
	CreateOutputAuthenticationTypeInfluxdbNone CreateOutputAuthenticationTypeInfluxdb = "none"
	// CreateOutputAuthenticationTypeInfluxdbBasic Basic
	CreateOutputAuthenticationTypeInfluxdbBasic CreateOutputAuthenticationTypeInfluxdb = "basic"
	// CreateOutputAuthenticationTypeInfluxdbCredentialsSecret Basic (credentials secret)
	CreateOutputAuthenticationTypeInfluxdbCredentialsSecret CreateOutputAuthenticationTypeInfluxdb = "credentialsSecret"
	// CreateOutputAuthenticationTypeInfluxdbToken Token
	CreateOutputAuthenticationTypeInfluxdbToken CreateOutputAuthenticationTypeInfluxdb = "token"
	// CreateOutputAuthenticationTypeInfluxdbTextSecret Token (text secret)
	CreateOutputAuthenticationTypeInfluxdbTextSecret CreateOutputAuthenticationTypeInfluxdb = "textSecret"
)

func (e CreateOutputAuthenticationTypeInfluxdb) ToPointer() *CreateOutputAuthenticationTypeInfluxdb {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputAuthenticationTypeInfluxdb) IsExact() bool {
	if e != nil {
		switch *e {
		case "none", "basic", "credentialsSecret", "token", "textSecret":
			return true
		}
	}
	return false
}

type CreateOutputPqControlsInfluxdb struct {
}

func (c CreateOutputPqControlsInfluxdb) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsInfluxdb) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputInfluxdb struct {
	// Unique ID for this output
	ID   string                   `json:"id"`
	Type CreateOutputTypeInfluxdb `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// URL of an InfluxDB cluster to send events to, e.g., http://localhost:8086/write
	URL string `json:"url"`
	// The v2 API can be enabled with InfluxDB versions 1.8 and later.
	UseV2API *bool `json:"useV2API,omitempty"`
	// Sets the precision for the supplied Unix time values. Defaults to milliseconds.
	TimestampPrecision *CreateOutputTimestampPrecision `json:"timestampPrecision,omitempty"`
	// Enabling this will pull the value field from the metric name. E,g, 'db.query.user' will use 'db.query' as the measurement and 'user' as the value field.
	DynamicValueFieldName *bool `json:"dynamicValueFieldName,omitempty"`
	// Name of the field in which to store the metric when sending to InfluxDB. If dynamic generation is enabled and fails, this will be used as a fallback.
	ValueFieldName *string `json:"valueFieldName,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// InfluxDB authentication type
	AuthType    *CreateOutputAuthenticationTypeInfluxdb `json:"authType,omitempty"`
	Description *string                                 `json:"description,omitempty"`
	// Database to write to.
	Database *string `json:"database,omitempty"`
	// Bucket to write to.
	Bucket *string `json:"bucket,omitempty"`
	// Organization ID for this bucket.
	Org *string `json:"org,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsInfluxdb      `json:"pqControls,omitempty"`
	Username         *string                              `json:"username,omitempty"`
	Password         *string                              `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
	TemplateURL *string `json:"__template_url,omitempty"`
	// Binds 'database' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'database' at runtime.
	TemplateDatabase *string `json:"__template_database,omitempty"`
	// Binds 'bucket' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'bucket' at runtime.
	TemplateBucket *string `json:"__template_bucket,omitempty"`
}

func (c CreateOutputOutputInfluxdb) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputInfluxdb) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "url"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputInfluxdb) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputInfluxdb) GetType() CreateOutputTypeInfluxdb {
	if c == nil {
		return CreateOutputTypeInfluxdb("")
	}
	return c.Type
}

func (c *CreateOutputOutputInfluxdb) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputInfluxdb) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputInfluxdb) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputInfluxdb) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputInfluxdb) GetURL() string {
	if c == nil {
		return ""
	}
	return c.URL
}

func (c *CreateOutputOutputInfluxdb) GetUseV2API() *bool {
	if c == nil {
		return nil
	}
	return c.UseV2API
}

func (c *CreateOutputOutputInfluxdb) GetTimestampPrecision() *CreateOutputTimestampPrecision {
	if c == nil {
		return nil
	}
	return c.TimestampPrecision
}

func (c *CreateOutputOutputInfluxdb) GetDynamicValueFieldName() *bool {
	if c == nil {
		return nil
	}
	return c.DynamicValueFieldName
}

func (c *CreateOutputOutputInfluxdb) GetValueFieldName() *string {
	if c == nil {
		return nil
	}
	return c.ValueFieldName
}

func (c *CreateOutputOutputInfluxdb) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputInfluxdb) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputInfluxdb) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputInfluxdb) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputInfluxdb) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputInfluxdb) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputInfluxdb) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputInfluxdb) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputInfluxdb) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputInfluxdb) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputInfluxdb) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputInfluxdb) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputInfluxdb) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputInfluxdb) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputInfluxdb) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputInfluxdb) GetAuthType() *CreateOutputAuthenticationTypeInfluxdb {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputInfluxdb) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputInfluxdb) GetDatabase() *string {
	if c == nil {
		return nil
	}
	return c.Database
}

func (c *CreateOutputOutputInfluxdb) GetBucket() *string {
	if c == nil {
		return nil
	}
	return c.Bucket
}

func (c *CreateOutputOutputInfluxdb) GetOrg() *string {
	if c == nil {
		return nil
	}
	return c.Org
}

func (c *CreateOutputOutputInfluxdb) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputInfluxdb) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputInfluxdb) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputInfluxdb) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputInfluxdb) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputInfluxdb) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputInfluxdb) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputInfluxdb) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputInfluxdb) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputInfluxdb) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputInfluxdb) GetPqControls() *CreateOutputPqControlsInfluxdb {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputInfluxdb) GetUsername() *string {
	if c == nil {
		return nil
	}
	return c.Username
}

func (c *CreateOutputOutputInfluxdb) GetPassword() *string {
	if c == nil {
		return nil
	}
	return c.Password
}

func (c *CreateOutputOutputInfluxdb) GetToken() *string {
	if c == nil {
		return nil
	}
	return c.Token
}

func (c *CreateOutputOutputInfluxdb) GetCredentialsSecret() *string {
	if c == nil {
		return nil
	}
	return c.CredentialsSecret
}

func (c *CreateOutputOutputInfluxdb) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputInfluxdb) GetTemplateURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateURL
}

func (c *CreateOutputOutputInfluxdb) GetTemplateDatabase() *string {
	if c == nil {
		return nil
	}
	return c.TemplateDatabase
}

func (c *CreateOutputOutputInfluxdb) GetTemplateBucket() *string {
	if c == nil {
		return nil
	}
	return c.TemplateBucket
}

type CreateOutputTypeNewrelicEvents string

const (
	CreateOutputTypeNewrelicEventsNewrelicEvents CreateOutputTypeNewrelicEvents = "newrelic_events"
)

func (e CreateOutputTypeNewrelicEvents) ToPointer() *CreateOutputTypeNewrelicEvents {
	return &e
}
func (e *CreateOutputTypeNewrelicEvents) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "newrelic_events":
		*e = CreateOutputTypeNewrelicEvents(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeNewrelicEvents: %v", v)
	}
}

type CreateOutputPqControlsNewrelicEvents struct {
}

func (c CreateOutputPqControlsNewrelicEvents) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsNewrelicEvents) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputNewrelicEvents struct {
	// Unique ID for this output
	ID   string                         `json:"id"`
	Type CreateOutputTypeNewrelicEvents `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Which New Relic region endpoint to use.
	Region *components.RegionOptions `json:"region,omitempty"`
	// New Relic account ID
	AccountID string `json:"accountId"`
	// Default eventType to use when not present in an event. For more information, see [here](https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/#reserved-words).
	EventType string `json:"eventType"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Enter API key directly, or select a stored secret
	AuthType    *components.AuthenticationMethodOptions2 `json:"authType,omitempty"`
	Description *string                                  `json:"description,omitempty"`
	CustomURL   *string                                  `json:"customUrl,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions  `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsNewrelicEvents `json:"pqControls,omitempty"`
	// New Relic API key. Can be overridden using __newRelic_apiKey field.
	APIKey *string `json:"apiKey,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime.
	TemplateRegion *string `json:"__template_region,omitempty"`
	// Binds 'accountId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'accountId' at runtime.
	TemplateAccountID *string `json:"__template_accountId,omitempty"`
	// Binds 'eventType' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'eventType' at runtime.
	TemplateEventType *string `json:"__template_eventType,omitempty"`
	// Binds 'customUrl' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'customUrl' at runtime.
	TemplateCustomURL *string `json:"__template_customUrl,omitempty"`
}

func (c CreateOutputOutputNewrelicEvents) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputNewrelicEvents) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "accountId", "eventType"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputNewrelicEvents) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputNewrelicEvents) GetType() CreateOutputTypeNewrelicEvents {
	if c == nil {
		return CreateOutputTypeNewrelicEvents("")
	}
	return c.Type
}

func (c *CreateOutputOutputNewrelicEvents) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputNewrelicEvents) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputNewrelicEvents) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputNewrelicEvents) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputNewrelicEvents) GetRegion() *components.RegionOptions {
	if c == nil {
		return nil
	}
	return c.Region
}

func (c *CreateOutputOutputNewrelicEvents) GetAccountID() string {
	if c == nil {
		return ""
	}
	return c.AccountID
}

func (c *CreateOutputOutputNewrelicEvents) GetEventType() string {
	if c == nil {
		return ""
	}
	return c.EventType
}

func (c *CreateOutputOutputNewrelicEvents) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputNewrelicEvents) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputNewrelicEvents) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputNewrelicEvents) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputNewrelicEvents) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputNewrelicEvents) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputNewrelicEvents) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputNewrelicEvents) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputNewrelicEvents) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputNewrelicEvents) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputNewrelicEvents) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputNewrelicEvents) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputNewrelicEvents) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputNewrelicEvents) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputNewrelicEvents) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputNewrelicEvents) GetAuthType() *components.AuthenticationMethodOptions2 {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputNewrelicEvents) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputNewrelicEvents) GetCustomURL() *string {
	if c == nil {
		return nil
	}
	return c.CustomURL
}

func (c *CreateOutputOutputNewrelicEvents) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputNewrelicEvents) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputNewrelicEvents) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputNewrelicEvents) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputNewrelicEvents) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputNewrelicEvents) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputNewrelicEvents) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputNewrelicEvents) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputNewrelicEvents) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputNewrelicEvents) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputNewrelicEvents) GetPqControls() *CreateOutputPqControlsNewrelicEvents {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputNewrelicEvents) GetAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.APIKey
}

func (c *CreateOutputOutputNewrelicEvents) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputNewrelicEvents) GetTemplateRegion() *string {
	if c == nil {
		return nil
	}
	return c.TemplateRegion
}

func (c *CreateOutputOutputNewrelicEvents) GetTemplateAccountID() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAccountID
}

func (c *CreateOutputOutputNewrelicEvents) GetTemplateEventType() *string {
	if c == nil {
		return nil
	}
	return c.TemplateEventType
}

func (c *CreateOutputOutputNewrelicEvents) GetTemplateCustomURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateCustomURL
}

type CreateOutputTypeNewrelic string

const (
	CreateOutputTypeNewrelicNewrelic CreateOutputTypeNewrelic = "newrelic"
)

func (e CreateOutputTypeNewrelic) ToPointer() *CreateOutputTypeNewrelic {
	return &e
}
func (e *CreateOutputTypeNewrelic) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "newrelic":
		*e = CreateOutputTypeNewrelic(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeNewrelic: %v", v)
	}
}

type CreateOutputFieldName string

const (
	CreateOutputFieldNameService   CreateOutputFieldName = "service"
	CreateOutputFieldNameHostname  CreateOutputFieldName = "hostname"
	CreateOutputFieldNameTimestamp CreateOutputFieldName = "timestamp"
	CreateOutputFieldNameAuditID   CreateOutputFieldName = "auditId"
)

func (e CreateOutputFieldName) ToPointer() *CreateOutputFieldName {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputFieldName) IsExact() bool {
	if e != nil {
		switch *e {
		case "service", "hostname", "timestamp", "auditId":
			return true
		}
	}
	return false
}

type CreateOutputMetadatum struct {
	Name CreateOutputFieldName `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (c CreateOutputMetadatum) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputMetadatum) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputMetadatum) GetName() CreateOutputFieldName {
	if c == nil {
		return CreateOutputFieldName("")
	}
	return c.Name
}

func (c *CreateOutputMetadatum) GetValue() string {
	if c == nil {
		return ""
	}
	return c.Value
}

type CreateOutputPqControlsNewrelic struct {
}

func (c CreateOutputPqControlsNewrelic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsNewrelic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputNewrelic struct {
	// Unique ID for this output
	ID   string                   `json:"id"`
	Type CreateOutputTypeNewrelic `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Which New Relic region endpoint to use.
	Region *components.RegionOptions `json:"region,omitempty"`
	// Name of the logtype to send with events, e.g.: observability, access_log. The event's 'sourcetype' field (if set) will override this value.
	LogType *string `json:"logType,omitempty"`
	// Name of field to send as log message value. If not present, event will be serialized and sent as JSON.
	MessageField *string `json:"messageField,omitempty"`
	// Fields to add to events from this input
	Metadata []CreateOutputMetadatum `json:"metadata,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Enter API key directly, or select a stored secret
	AuthType *components.AuthenticationMethodOptions2 `json:"authType,omitempty"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	CustomURL          *string  `json:"customUrl,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsNewrelic      `json:"pqControls,omitempty"`
	// New Relic API key. Can be overridden using __newRelic_apiKey field.
	APIKey *string `json:"apiKey,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime.
	TemplateRegion *string `json:"__template_region,omitempty"`
	// Binds 'logType' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'logType' at runtime.
	TemplateLogType *string `json:"__template_logType,omitempty"`
	// Binds 'messageField' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'messageField' at runtime.
	TemplateMessageField *string `json:"__template_messageField,omitempty"`
}

func (c CreateOutputOutputNewrelic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputNewrelic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputNewrelic) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputNewrelic) GetType() CreateOutputTypeNewrelic {
	if c == nil {
		return CreateOutputTypeNewrelic("")
	}
	return c.Type
}

func (c *CreateOutputOutputNewrelic) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputNewrelic) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputNewrelic) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputNewrelic) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputNewrelic) GetRegion() *components.RegionOptions {
	if c == nil {
		return nil
	}
	return c.Region
}

func (c *CreateOutputOutputNewrelic) GetLogType() *string {
	if c == nil {
		return nil
	}
	return c.LogType
}

func (c *CreateOutputOutputNewrelic) GetMessageField() *string {
	if c == nil {
		return nil
	}
	return c.MessageField
}

func (c *CreateOutputOutputNewrelic) GetMetadata() []CreateOutputMetadatum {
	if c == nil {
		return nil
	}
	return c.Metadata
}

func (c *CreateOutputOutputNewrelic) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputNewrelic) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputNewrelic) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputNewrelic) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputNewrelic) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputNewrelic) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputNewrelic) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputNewrelic) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputNewrelic) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputNewrelic) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputNewrelic) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputNewrelic) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputNewrelic) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputNewrelic) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputNewrelic) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputNewrelic) GetAuthType() *components.AuthenticationMethodOptions2 {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputNewrelic) GetTotalMemoryLimitKB() *float64 {
	if c == nil {
		return nil
	}
	return c.TotalMemoryLimitKB
}

func (c *CreateOutputOutputNewrelic) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputNewrelic) GetCustomURL() *string {
	if c == nil {
		return nil
	}
	return c.CustomURL
}

func (c *CreateOutputOutputNewrelic) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputNewrelic) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputNewrelic) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputNewrelic) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputNewrelic) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputNewrelic) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputNewrelic) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputNewrelic) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputNewrelic) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputNewrelic) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputNewrelic) GetPqControls() *CreateOutputPqControlsNewrelic {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputNewrelic) GetAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.APIKey
}

func (c *CreateOutputOutputNewrelic) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputNewrelic) GetTemplateRegion() *string {
	if c == nil {
		return nil
	}
	return c.TemplateRegion
}

func (c *CreateOutputOutputNewrelic) GetTemplateLogType() *string {
	if c == nil {
		return nil
	}
	return c.TemplateLogType
}

func (c *CreateOutputOutputNewrelic) GetTemplateMessageField() *string {
	if c == nil {
		return nil
	}
	return c.TemplateMessageField
}

type CreateOutputTypeElasticCloud string

const (
	CreateOutputTypeElasticCloudElasticCloud CreateOutputTypeElasticCloud = "elastic_cloud"
)

func (e CreateOutputTypeElasticCloud) ToPointer() *CreateOutputTypeElasticCloud {
	return &e
}
func (e *CreateOutputTypeElasticCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "elastic_cloud":
		*e = CreateOutputTypeElasticCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeElasticCloud: %v", v)
	}
}

type CreateOutputPqControlsElasticCloud struct {
}

func (c CreateOutputPqControlsElasticCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsElasticCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputElasticCloud struct {
	// Unique ID for this output
	ID   string                       `json:"id"`
	Type CreateOutputTypeElasticCloud `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Enter Cloud ID of the Elastic Cloud environment to send events to
	URL string `json:"url"`
	// Data stream or index to send events to. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be overwritten by an event's __index field.
	Index string `json:"index"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Extra parameters to use in HTTP requests
	ExtraParams []components.ItemsTypeSaslSaslExtensions `json:"extraParams,omitempty"`
	Auth        *components.AuthType                     `json:"auth,omitempty"`
	// Optional Elastic Cloud Destination pipeline
	ElasticPipeline *string `json:"elasticPipeline,omitempty"`
	// Include the `document_id` field when sending events to an Elastic TSDS (time series data stream)
	IncludeDocID *bool `json:"includeDocId,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsElasticCloud  `json:"pqControls,omitempty"`
}

func (c CreateOutputOutputElasticCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputElasticCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "url", "index"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputElasticCloud) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputElasticCloud) GetType() CreateOutputTypeElasticCloud {
	if c == nil {
		return CreateOutputTypeElasticCloud("")
	}
	return c.Type
}

func (c *CreateOutputOutputElasticCloud) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputElasticCloud) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputElasticCloud) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputElasticCloud) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputElasticCloud) GetURL() string {
	if c == nil {
		return ""
	}
	return c.URL
}

func (c *CreateOutputOutputElasticCloud) GetIndex() string {
	if c == nil {
		return ""
	}
	return c.Index
}

func (c *CreateOutputOutputElasticCloud) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputElasticCloud) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputElasticCloud) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputElasticCloud) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputElasticCloud) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputElasticCloud) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputElasticCloud) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputElasticCloud) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputElasticCloud) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputElasticCloud) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputElasticCloud) GetExtraParams() []components.ItemsTypeSaslSaslExtensions {
	if c == nil {
		return nil
	}
	return c.ExtraParams
}

func (c *CreateOutputOutputElasticCloud) GetAuth() *components.AuthType {
	if c == nil {
		return nil
	}
	return c.Auth
}

func (c *CreateOutputOutputElasticCloud) GetElasticPipeline() *string {
	if c == nil {
		return nil
	}
	return c.ElasticPipeline
}

func (c *CreateOutputOutputElasticCloud) GetIncludeDocID() *bool {
	if c == nil {
		return nil
	}
	return c.IncludeDocID
}

func (c *CreateOutputOutputElasticCloud) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputElasticCloud) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputElasticCloud) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputElasticCloud) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputElasticCloud) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputElasticCloud) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputElasticCloud) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputElasticCloud) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputElasticCloud) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputElasticCloud) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputElasticCloud) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputElasticCloud) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputElasticCloud) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputElasticCloud) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputElasticCloud) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputElasticCloud) GetPqControls() *CreateOutputPqControlsElasticCloud {
	if c == nil {
		return nil
	}
	return c.PqControls
}

type CreateOutputTypeElastic string

const (
	CreateOutputTypeElasticElastic CreateOutputTypeElastic = "elastic"
)

func (e CreateOutputTypeElastic) ToPointer() *CreateOutputTypeElastic {
	return &e
}
func (e *CreateOutputTypeElastic) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "elastic":
		*e = CreateOutputTypeElastic(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeElastic: %v", v)
	}
}

// CreateOutputElasticVersion - Optional Elasticsearch version, used to format events. If not specified, will auto-discover version.
type CreateOutputElasticVersion string

const (
	// CreateOutputElasticVersionAuto Auto
	CreateOutputElasticVersionAuto CreateOutputElasticVersion = "auto"
	// CreateOutputElasticVersionSix 6.x
	CreateOutputElasticVersionSix CreateOutputElasticVersion = "6"
	// CreateOutputElasticVersionSeven 7.x
	CreateOutputElasticVersionSeven CreateOutputElasticVersion = "7"
)

func (e CreateOutputElasticVersion) ToPointer() *CreateOutputElasticVersion {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputElasticVersion) IsExact() bool {
	if e != nil {
		switch *e {
		case "auto", "6", "7":
			return true
		}
	}
	return false
}

// CreateOutputWriteAction - Action to use when writing events. Must be set to `Create` when writing to a data stream.
type CreateOutputWriteAction string

const (
	// CreateOutputWriteActionIndex Index
	CreateOutputWriteActionIndex CreateOutputWriteAction = "index"
	// CreateOutputWriteActionCreate Create
	CreateOutputWriteActionCreate CreateOutputWriteAction = "create"
)

func (e CreateOutputWriteAction) ToPointer() *CreateOutputWriteAction {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputWriteAction) IsExact() bool {
	if e != nil {
		switch *e {
		case "index", "create":
			return true
		}
	}
	return false
}

type CreateOutputURLElastic struct {
	// The URL to an Elastic node to send events to. Example: http://elastic:9200/_bulk
	URL string `json:"url"`
	// Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
	Weight *float64 `json:"weight,omitempty"`
	// Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
	TemplateURL *string `json:"__template_url,omitempty"`
}

func (c CreateOutputURLElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputURLElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"url"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputURLElastic) GetURL() string {
	if c == nil {
		return ""
	}
	return c.URL
}

func (c *CreateOutputURLElastic) GetWeight() *float64 {
	if c == nil {
		return nil
	}
	return c.Weight
}

func (c *CreateOutputURLElastic) GetTemplateURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateURL
}

type CreateOutputPqControlsElastic struct {
}

func (c CreateOutputPqControlsElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputElastic struct {
	// Unique ID for this output
	ID   string                  `json:"id"`
	Type CreateOutputTypeElastic `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Enable for optimal performance. Even if you have one hostname, it can expand to multiple IPs. If disabled, consider enabling round-robin DNS.
	LoadBalanced *bool `json:"loadBalanced,omitempty"`
	// Index or data stream to send events to. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be overwritten by an event's __index field.
	Index string `json:"index"`
	// Document type to use for events. Can be overwritten by an event's __type field.
	DocType *string `json:"docType,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool                                    `json:"responseHonorRetryAfterHeader,omitempty"`
	ExtraParams                   []components.ItemsTypeSaslSaslExtensions `json:"extraParams,omitempty"`
	Auth                          *components.AuthType                     `json:"auth,omitempty"`
	// Optional Elasticsearch version, used to format events. If not specified, will auto-discover version.
	ElasticVersion *CreateOutputElasticVersion `json:"elasticVersion,omitempty"`
	// Optional Elasticsearch destination pipeline
	ElasticPipeline *string `json:"elasticPipeline,omitempty"`
	// Include the `document_id` field when sending events to an Elastic TSDS (time series data stream)
	IncludeDocID *bool `json:"includeDocId,omitempty"`
	// Action to use when writing events. Must be set to `Create` when writing to a data stream.
	WriteAction *CreateOutputWriteAction `json:"writeAction,omitempty"`
	// Retry failed events when a bulk request to Elastic is successful, but the response body returns an error for one or more events in the batch
	RetryPartialErrors *bool `json:"retryPartialErrors,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// The Cloud ID or URL to an Elastic cluster to send events to. Example: http://elastic:9200/_bulk
	URL *string `json:"url,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Exclude all IPs of the current host from the list of any resolved hostnames
	ExcludeSelf *bool                    `json:"excludeSelf,omitempty"`
	Urls        []CreateOutputURLElastic `json:"urls,omitempty"`
	// The interval in which to re-resolve any hostnames and pick up destinations from A records
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	// How far back in time to keep traffic stats for load balancing purposes
	LoadBalanceStatsPeriodSec *float64 `json:"loadBalanceStatsPeriodSec,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsElastic       `json:"pqControls,omitempty"`
	// Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
	TemplateURL *string `json:"__template_url,omitempty"`
}

func (c CreateOutputOutputElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "index"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputElastic) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputElastic) GetType() CreateOutputTypeElastic {
	if c == nil {
		return CreateOutputTypeElastic("")
	}
	return c.Type
}

func (c *CreateOutputOutputElastic) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputElastic) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputElastic) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputElastic) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputElastic) GetLoadBalanced() *bool {
	if c == nil {
		return nil
	}
	return c.LoadBalanced
}

func (c *CreateOutputOutputElastic) GetIndex() string {
	if c == nil {
		return ""
	}
	return c.Index
}

func (c *CreateOutputOutputElastic) GetDocType() *string {
	if c == nil {
		return nil
	}
	return c.DocType
}

func (c *CreateOutputOutputElastic) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputElastic) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputElastic) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputElastic) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputElastic) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputElastic) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputElastic) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputElastic) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputElastic) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputElastic) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputElastic) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputElastic) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputElastic) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputElastic) GetExtraParams() []components.ItemsTypeSaslSaslExtensions {
	if c == nil {
		return nil
	}
	return c.ExtraParams
}

func (c *CreateOutputOutputElastic) GetAuth() *components.AuthType {
	if c == nil {
		return nil
	}
	return c.Auth
}

func (c *CreateOutputOutputElastic) GetElasticVersion() *CreateOutputElasticVersion {
	if c == nil {
		return nil
	}
	return c.ElasticVersion
}

func (c *CreateOutputOutputElastic) GetElasticPipeline() *string {
	if c == nil {
		return nil
	}
	return c.ElasticPipeline
}

func (c *CreateOutputOutputElastic) GetIncludeDocID() *bool {
	if c == nil {
		return nil
	}
	return c.IncludeDocID
}

func (c *CreateOutputOutputElastic) GetWriteAction() *CreateOutputWriteAction {
	if c == nil {
		return nil
	}
	return c.WriteAction
}

func (c *CreateOutputOutputElastic) GetRetryPartialErrors() *bool {
	if c == nil {
		return nil
	}
	return c.RetryPartialErrors
}

func (c *CreateOutputOutputElastic) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputElastic) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputElastic) GetURL() *string {
	if c == nil {
		return nil
	}
	return c.URL
}

func (c *CreateOutputOutputElastic) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputElastic) GetExcludeSelf() *bool {
	if c == nil {
		return nil
	}
	return c.ExcludeSelf
}

func (c *CreateOutputOutputElastic) GetUrls() []CreateOutputURLElastic {
	if c == nil {
		return nil
	}
	return c.Urls
}

func (c *CreateOutputOutputElastic) GetDNSResolvePeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.DNSResolvePeriodSec
}

func (c *CreateOutputOutputElastic) GetLoadBalanceStatsPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.LoadBalanceStatsPeriodSec
}

func (c *CreateOutputOutputElastic) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputElastic) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputElastic) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputElastic) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputElastic) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputElastic) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputElastic) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputElastic) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputElastic) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputElastic) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputElastic) GetPqControls() *CreateOutputPqControlsElastic {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputElastic) GetTemplateURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateURL
}

type CreateOutputTypeMsk string

const (
	CreateOutputTypeMskMsk CreateOutputTypeMsk = "msk"
)

func (e CreateOutputTypeMsk) ToPointer() *CreateOutputTypeMsk {
	return &e
}
func (e *CreateOutputTypeMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "msk":
		*e = CreateOutputTypeMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeMsk: %v", v)
	}
}

type CreateOutputPqControlsMsk struct {
}

func (c CreateOutputPqControlsMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputMsk struct {
	// Unique ID for this output
	ID   string              `json:"id"`
	Type CreateOutputTypeMsk `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Enter each Kafka bootstrap server you want to use. Specify hostname and port, e.g., mykafkabroker:9092, or just hostname, in which case @{product} will assign port 9092.
	Brokers []string `json:"brokers"`
	// The topic to publish events to. Can be overridden using the __topicOut field.
	Topic string `json:"topic"`
	// Control the number of required acknowledgments.
	Ack *components.AcknowledgmentsOptions1 `json:"ack,omitempty"`
	// Format to use to serialize events before writing to Kafka.
	Format *components.RecordDataFormatOptions1 `json:"format,omitempty"`
	// Codec to use to compress the data before sending to Kafka
	Compression *components.CompressionOptions3 `json:"compression,omitempty"`
	// Maximum size of each record batch before compression. The value must not exceed the Kafka brokers' message.max.bytes setting.
	MaxRecordSizeKB *float64 `json:"maxRecordSizeKB,omitempty"`
	// The maximum number of events you want the Destination to allow in a batch before forcing a flush
	FlushEventCount *float64 `json:"flushEventCount,omitempty"`
	// The maximum amount of time you want the Destination to wait before forcing a flush. Shorter intervals tend to result in smaller batches being sent.
	FlushPeriodSec      *float64                                           `json:"flushPeriodSec,omitempty"`
	KafkaSchemaRegistry *components.KafkaSchemaRegistryAuthenticationType1 `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `json:"requestTimeout,omitempty"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `json:"maxRetries,omitempty"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `json:"maxBackOff,omitempty"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `json:"initialBackoff,omitempty"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `json:"backoffRate,omitempty"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `json:"authenticationTimeout,omitempty"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `json:"reauthenticationThreshold,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                                               `json:"awsSecretKey,omitempty"`
	// Region where the MSK cluster is located
	Region string `json:"region"`
	// MSK cluster service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to MSK cluster-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing MSK cluster requests
	SignatureVersion *components.SignatureVersionOptions `json:"signatureVersion,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Use Assume Role credentials to access MSK
	EnableAssumeRole *bool `json:"enableAssumeRole,omitempty"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64                                                 `json:"durationSeconds,omitempty"`
	TLS             *components.TLSSettingsClientSideTypeKafkaSchemaRegistry `json:"tls,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	AwsAPIKey      *string                                 `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Select a set of Protobuf definitions for the events you want to send
	ProtobufLibraryID *string `json:"protobufLibraryId,omitempty"`
	// Select the type of object you want the Protobuf definitions to use for event encoding
	ProtobufEncodingID *string `json:"protobufEncodingId,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsMsk           `json:"pqControls,omitempty"`
	// Binds 'topic' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'topic' at runtime.
	TemplateTopic *string `json:"__template_topic,omitempty"`
	// Binds 'awsSecretKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsSecretKey' at runtime.
	TemplateAwsSecretKey *string `json:"__template_awsSecretKey,omitempty"`
	// Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime.
	TemplateRegion *string `json:"__template_region,omitempty"`
	// Binds 'assumeRoleArn' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleArn' at runtime.
	TemplateAssumeRoleArn *string `json:"__template_assumeRoleArn,omitempty"`
	// Binds 'assumeRoleExternalId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleExternalId' at runtime.
	TemplateAssumeRoleExternalID *string `json:"__template_assumeRoleExternalId,omitempty"`
	// Binds 'awsApiKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsApiKey' at runtime.
	TemplateAwsAPIKey *string `json:"__template_awsApiKey,omitempty"`
}

func (c CreateOutputOutputMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "brokers", "topic", "awsAuthenticationMethod", "region"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputMsk) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputMsk) GetType() CreateOutputTypeMsk {
	if c == nil {
		return CreateOutputTypeMsk("")
	}
	return c.Type
}

func (c *CreateOutputOutputMsk) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputMsk) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputMsk) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputMsk) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputMsk) GetBrokers() []string {
	if c == nil {
		return []string{}
	}
	return c.Brokers
}

func (c *CreateOutputOutputMsk) GetTopic() string {
	if c == nil {
		return ""
	}
	return c.Topic
}

func (c *CreateOutputOutputMsk) GetAck() *components.AcknowledgmentsOptions1 {
	if c == nil {
		return nil
	}
	return c.Ack
}

func (c *CreateOutputOutputMsk) GetFormat() *components.RecordDataFormatOptions1 {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputMsk) GetCompression() *components.CompressionOptions3 {
	if c == nil {
		return nil
	}
	return c.Compression
}

func (c *CreateOutputOutputMsk) GetMaxRecordSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRecordSizeKB
}

func (c *CreateOutputOutputMsk) GetFlushEventCount() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushEventCount
}

func (c *CreateOutputOutputMsk) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputMsk) GetKafkaSchemaRegistry() *components.KafkaSchemaRegistryAuthenticationType1 {
	if c == nil {
		return nil
	}
	return c.KafkaSchemaRegistry
}

func (c *CreateOutputOutputMsk) GetConnectionTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.ConnectionTimeout
}

func (c *CreateOutputOutputMsk) GetRequestTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.RequestTimeout
}

func (c *CreateOutputOutputMsk) GetMaxRetries() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRetries
}

func (c *CreateOutputOutputMsk) GetMaxBackOff() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxBackOff
}

func (c *CreateOutputOutputMsk) GetInitialBackoff() *float64 {
	if c == nil {
		return nil
	}
	return c.InitialBackoff
}

func (c *CreateOutputOutputMsk) GetBackoffRate() *float64 {
	if c == nil {
		return nil
	}
	return c.BackoffRate
}

func (c *CreateOutputOutputMsk) GetAuthenticationTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.AuthenticationTimeout
}

func (c *CreateOutputOutputMsk) GetReauthenticationThreshold() *float64 {
	if c == nil {
		return nil
	}
	return c.ReauthenticationThreshold
}

func (c *CreateOutputOutputMsk) GetAwsAuthenticationMethod() components.AuthenticationMethodOptionsS3CollectorConf {
	if c == nil {
		return components.AuthenticationMethodOptionsS3CollectorConf("")
	}
	return c.AwsAuthenticationMethod
}

func (c *CreateOutputOutputMsk) GetAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecretKey
}

func (c *CreateOutputOutputMsk) GetRegion() string {
	if c == nil {
		return ""
	}
	return c.Region
}

func (c *CreateOutputOutputMsk) GetEndpoint() *string {
	if c == nil {
		return nil
	}
	return c.Endpoint
}

func (c *CreateOutputOutputMsk) GetSignatureVersion() *components.SignatureVersionOptions {
	if c == nil {
		return nil
	}
	return c.SignatureVersion
}

func (c *CreateOutputOutputMsk) GetReuseConnections() *bool {
	if c == nil {
		return nil
	}
	return c.ReuseConnections
}

func (c *CreateOutputOutputMsk) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputMsk) GetEnableAssumeRole() *bool {
	if c == nil {
		return nil
	}
	return c.EnableAssumeRole
}

func (c *CreateOutputOutputMsk) GetAssumeRoleArn() *string {
	if c == nil {
		return nil
	}
	return c.AssumeRoleArn
}

func (c *CreateOutputOutputMsk) GetAssumeRoleExternalID() *string {
	if c == nil {
		return nil
	}
	return c.AssumeRoleExternalID
}

func (c *CreateOutputOutputMsk) GetDurationSeconds() *float64 {
	if c == nil {
		return nil
	}
	return c.DurationSeconds
}

func (c *CreateOutputOutputMsk) GetTLS() *components.TLSSettingsClientSideTypeKafkaSchemaRegistry {
	if c == nil {
		return nil
	}
	return c.TLS
}

func (c *CreateOutputOutputMsk) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputMsk) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputMsk) GetAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsAPIKey
}

func (c *CreateOutputOutputMsk) GetAwsSecret() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecret
}

func (c *CreateOutputOutputMsk) GetProtobufLibraryID() *string {
	if c == nil {
		return nil
	}
	return c.ProtobufLibraryID
}

func (c *CreateOutputOutputMsk) GetProtobufEncodingID() *string {
	if c == nil {
		return nil
	}
	return c.ProtobufEncodingID
}

func (c *CreateOutputOutputMsk) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputMsk) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputMsk) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputMsk) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputMsk) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputMsk) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputMsk) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputMsk) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputMsk) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputMsk) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputMsk) GetPqControls() *CreateOutputPqControlsMsk {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputMsk) GetTemplateTopic() *string {
	if c == nil {
		return nil
	}
	return c.TemplateTopic
}

func (c *CreateOutputOutputMsk) GetTemplateAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAwsSecretKey
}

func (c *CreateOutputOutputMsk) GetTemplateRegion() *string {
	if c == nil {
		return nil
	}
	return c.TemplateRegion
}

func (c *CreateOutputOutputMsk) GetTemplateAssumeRoleArn() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAssumeRoleArn
}

func (c *CreateOutputOutputMsk) GetTemplateAssumeRoleExternalID() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAssumeRoleExternalID
}

func (c *CreateOutputOutputMsk) GetTemplateAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAwsAPIKey
}

type CreateOutputTypeConfluentCloud string

const (
	CreateOutputTypeConfluentCloudConfluentCloud CreateOutputTypeConfluentCloud = "confluent_cloud"
)

func (e CreateOutputTypeConfluentCloud) ToPointer() *CreateOutputTypeConfluentCloud {
	return &e
}
func (e *CreateOutputTypeConfluentCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "confluent_cloud":
		*e = CreateOutputTypeConfluentCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeConfluentCloud: %v", v)
	}
}

type CreateOutputPqControlsConfluentCloud struct {
}

func (c CreateOutputPqControlsConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputConfluentCloud struct {
	// Unique ID for this output
	ID   string                         `json:"id"`
	Type CreateOutputTypeConfluentCloud `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// List of Confluent Cloud bootstrap servers to use, such as yourAccount.confluent.cloud:9092.
	Brokers []string                                                 `json:"brokers"`
	TLS     *components.TLSSettingsClientSideTypeKafkaSchemaRegistry `json:"tls,omitempty"`
	// The topic to publish events to. Can be overridden using the __topicOut field.
	Topic string `json:"topic"`
	// Control the number of required acknowledgments.
	Ack *components.AcknowledgmentsOptions1 `json:"ack,omitempty"`
	// Format to use to serialize events before writing to Kafka.
	Format *components.RecordDataFormatOptions1 `json:"format,omitempty"`
	// Codec to use to compress the data before sending to Kafka
	Compression *components.CompressionOptions3 `json:"compression,omitempty"`
	// Maximum size of each record batch before compression. The value must not exceed the Kafka brokers' message.max.bytes setting.
	MaxRecordSizeKB *float64 `json:"maxRecordSizeKB,omitempty"`
	// The maximum number of events you want the Destination to allow in a batch before forcing a flush
	FlushEventCount *float64 `json:"flushEventCount,omitempty"`
	// The maximum amount of time you want the Destination to wait before forcing a flush. Shorter intervals tend to result in smaller batches being sent.
	FlushPeriodSec      *float64                                           `json:"flushPeriodSec,omitempty"`
	KafkaSchemaRegistry *components.KafkaSchemaRegistryAuthenticationType1 `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `json:"requestTimeout,omitempty"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `json:"maxRetries,omitempty"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `json:"maxBackOff,omitempty"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `json:"initialBackoff,omitempty"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `json:"backoffRate,omitempty"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `json:"authenticationTimeout,omitempty"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `json:"reauthenticationThreshold,omitempty"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *components.AuthenticationType `json:"sasl,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// Select a set of Protobuf definitions for the events you want to send
	ProtobufLibraryID *string `json:"protobufLibraryId,omitempty"`
	// Select the type of object you want the Protobuf definitions to use for event encoding
	ProtobufEncodingID *string `json:"protobufEncodingId,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions  `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsConfluentCloud `json:"pqControls,omitempty"`
	// Binds 'topic' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'topic' at runtime.
	TemplateTopic *string `json:"__template_topic,omitempty"`
}

func (c CreateOutputOutputConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "brokers", "topic"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputConfluentCloud) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputConfluentCloud) GetType() CreateOutputTypeConfluentCloud {
	if c == nil {
		return CreateOutputTypeConfluentCloud("")
	}
	return c.Type
}

func (c *CreateOutputOutputConfluentCloud) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputConfluentCloud) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputConfluentCloud) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputConfluentCloud) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputConfluentCloud) GetBrokers() []string {
	if c == nil {
		return []string{}
	}
	return c.Brokers
}

func (c *CreateOutputOutputConfluentCloud) GetTLS() *components.TLSSettingsClientSideTypeKafkaSchemaRegistry {
	if c == nil {
		return nil
	}
	return c.TLS
}

func (c *CreateOutputOutputConfluentCloud) GetTopic() string {
	if c == nil {
		return ""
	}
	return c.Topic
}

func (c *CreateOutputOutputConfluentCloud) GetAck() *components.AcknowledgmentsOptions1 {
	if c == nil {
		return nil
	}
	return c.Ack
}

func (c *CreateOutputOutputConfluentCloud) GetFormat() *components.RecordDataFormatOptions1 {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputConfluentCloud) GetCompression() *components.CompressionOptions3 {
	if c == nil {
		return nil
	}
	return c.Compression
}

func (c *CreateOutputOutputConfluentCloud) GetMaxRecordSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRecordSizeKB
}

func (c *CreateOutputOutputConfluentCloud) GetFlushEventCount() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushEventCount
}

func (c *CreateOutputOutputConfluentCloud) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputConfluentCloud) GetKafkaSchemaRegistry() *components.KafkaSchemaRegistryAuthenticationType1 {
	if c == nil {
		return nil
	}
	return c.KafkaSchemaRegistry
}

func (c *CreateOutputOutputConfluentCloud) GetConnectionTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.ConnectionTimeout
}

func (c *CreateOutputOutputConfluentCloud) GetRequestTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.RequestTimeout
}

func (c *CreateOutputOutputConfluentCloud) GetMaxRetries() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRetries
}

func (c *CreateOutputOutputConfluentCloud) GetMaxBackOff() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxBackOff
}

func (c *CreateOutputOutputConfluentCloud) GetInitialBackoff() *float64 {
	if c == nil {
		return nil
	}
	return c.InitialBackoff
}

func (c *CreateOutputOutputConfluentCloud) GetBackoffRate() *float64 {
	if c == nil {
		return nil
	}
	return c.BackoffRate
}

func (c *CreateOutputOutputConfluentCloud) GetAuthenticationTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.AuthenticationTimeout
}

func (c *CreateOutputOutputConfluentCloud) GetReauthenticationThreshold() *float64 {
	if c == nil {
		return nil
	}
	return c.ReauthenticationThreshold
}

func (c *CreateOutputOutputConfluentCloud) GetSasl() *components.AuthenticationType {
	if c == nil {
		return nil
	}
	return c.Sasl
}

func (c *CreateOutputOutputConfluentCloud) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputConfluentCloud) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputConfluentCloud) GetProtobufLibraryID() *string {
	if c == nil {
		return nil
	}
	return c.ProtobufLibraryID
}

func (c *CreateOutputOutputConfluentCloud) GetProtobufEncodingID() *string {
	if c == nil {
		return nil
	}
	return c.ProtobufEncodingID
}

func (c *CreateOutputOutputConfluentCloud) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputConfluentCloud) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputConfluentCloud) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputConfluentCloud) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputConfluentCloud) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputConfluentCloud) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputConfluentCloud) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputConfluentCloud) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputConfluentCloud) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputConfluentCloud) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputConfluentCloud) GetPqControls() *CreateOutputPqControlsConfluentCloud {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputConfluentCloud) GetTemplateTopic() *string {
	if c == nil {
		return nil
	}
	return c.TemplateTopic
}

type CreateOutputTypeKafka string

const (
	CreateOutputTypeKafkaKafka CreateOutputTypeKafka = "kafka"
)

func (e CreateOutputTypeKafka) ToPointer() *CreateOutputTypeKafka {
	return &e
}
func (e *CreateOutputTypeKafka) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kafka":
		*e = CreateOutputTypeKafka(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeKafka: %v", v)
	}
}

type CreateOutputPqControlsKafka struct {
}

func (c CreateOutputPqControlsKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputKafka struct {
	// Unique ID for this output
	ID   string                `json:"id"`
	Type CreateOutputTypeKafka `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Enter each Kafka bootstrap server you want to use. Specify hostname and port, e.g., mykafkabroker:9092, or just hostname, in which case @{product} will assign port 9092.
	Brokers []string `json:"brokers"`
	// The topic to publish events to. Can be overridden using the __topicOut field.
	Topic string `json:"topic"`
	// Control the number of required acknowledgments.
	Ack *components.AcknowledgmentsOptions1 `json:"ack,omitempty"`
	// Format to use to serialize events before writing to Kafka.
	Format *components.RecordDataFormatOptions1 `json:"format,omitempty"`
	// Codec to use to compress the data before sending to Kafka
	Compression *components.CompressionOptions3 `json:"compression,omitempty"`
	// Maximum size of each record batch before compression. The value must not exceed the Kafka brokers' message.max.bytes setting.
	MaxRecordSizeKB *float64 `json:"maxRecordSizeKB,omitempty"`
	// The maximum number of events you want the Destination to allow in a batch before forcing a flush
	FlushEventCount *float64 `json:"flushEventCount,omitempty"`
	// The maximum amount of time you want the Destination to wait before forcing a flush. Shorter intervals tend to result in smaller batches being sent.
	FlushPeriodSec      *float64                                           `json:"flushPeriodSec,omitempty"`
	KafkaSchemaRegistry *components.KafkaSchemaRegistryAuthenticationType1 `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `json:"requestTimeout,omitempty"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `json:"maxRetries,omitempty"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `json:"maxBackOff,omitempty"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `json:"initialBackoff,omitempty"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `json:"backoffRate,omitempty"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `json:"authenticationTimeout,omitempty"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `json:"reauthenticationThreshold,omitempty"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *components.AuthenticationType                           `json:"sasl,omitempty"`
	TLS  *components.TLSSettingsClientSideTypeKafkaSchemaRegistry `json:"tls,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// Select a set of Protobuf definitions for the events you want to send
	ProtobufLibraryID *string `json:"protobufLibraryId,omitempty"`
	// Select the type of object you want the Protobuf definitions to use for event encoding
	ProtobufEncodingID *string `json:"protobufEncodingId,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsKafka         `json:"pqControls,omitempty"`
	// Binds 'topic' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'topic' at runtime.
	TemplateTopic *string `json:"__template_topic,omitempty"`
}

func (c CreateOutputOutputKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "brokers", "topic"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputKafka) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputKafka) GetType() CreateOutputTypeKafka {
	if c == nil {
		return CreateOutputTypeKafka("")
	}
	return c.Type
}

func (c *CreateOutputOutputKafka) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputKafka) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputKafka) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputKafka) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputKafka) GetBrokers() []string {
	if c == nil {
		return []string{}
	}
	return c.Brokers
}

func (c *CreateOutputOutputKafka) GetTopic() string {
	if c == nil {
		return ""
	}
	return c.Topic
}

func (c *CreateOutputOutputKafka) GetAck() *components.AcknowledgmentsOptions1 {
	if c == nil {
		return nil
	}
	return c.Ack
}

func (c *CreateOutputOutputKafka) GetFormat() *components.RecordDataFormatOptions1 {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputKafka) GetCompression() *components.CompressionOptions3 {
	if c == nil {
		return nil
	}
	return c.Compression
}

func (c *CreateOutputOutputKafka) GetMaxRecordSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRecordSizeKB
}

func (c *CreateOutputOutputKafka) GetFlushEventCount() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushEventCount
}

func (c *CreateOutputOutputKafka) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputKafka) GetKafkaSchemaRegistry() *components.KafkaSchemaRegistryAuthenticationType1 {
	if c == nil {
		return nil
	}
	return c.KafkaSchemaRegistry
}

func (c *CreateOutputOutputKafka) GetConnectionTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.ConnectionTimeout
}

func (c *CreateOutputOutputKafka) GetRequestTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.RequestTimeout
}

func (c *CreateOutputOutputKafka) GetMaxRetries() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRetries
}

func (c *CreateOutputOutputKafka) GetMaxBackOff() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxBackOff
}

func (c *CreateOutputOutputKafka) GetInitialBackoff() *float64 {
	if c == nil {
		return nil
	}
	return c.InitialBackoff
}

func (c *CreateOutputOutputKafka) GetBackoffRate() *float64 {
	if c == nil {
		return nil
	}
	return c.BackoffRate
}

func (c *CreateOutputOutputKafka) GetAuthenticationTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.AuthenticationTimeout
}

func (c *CreateOutputOutputKafka) GetReauthenticationThreshold() *float64 {
	if c == nil {
		return nil
	}
	return c.ReauthenticationThreshold
}

func (c *CreateOutputOutputKafka) GetSasl() *components.AuthenticationType {
	if c == nil {
		return nil
	}
	return c.Sasl
}

func (c *CreateOutputOutputKafka) GetTLS() *components.TLSSettingsClientSideTypeKafkaSchemaRegistry {
	if c == nil {
		return nil
	}
	return c.TLS
}

func (c *CreateOutputOutputKafka) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputKafka) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputKafka) GetProtobufLibraryID() *string {
	if c == nil {
		return nil
	}
	return c.ProtobufLibraryID
}

func (c *CreateOutputOutputKafka) GetProtobufEncodingID() *string {
	if c == nil {
		return nil
	}
	return c.ProtobufEncodingID
}

func (c *CreateOutputOutputKafka) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputKafka) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputKafka) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputKafka) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputKafka) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputKafka) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputKafka) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputKafka) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputKafka) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputKafka) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputKafka) GetPqControls() *CreateOutputPqControlsKafka {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputKafka) GetTemplateTopic() *string {
	if c == nil {
		return nil
	}
	return c.TemplateTopic
}

type CreateOutputTypeExabeam string

const (
	CreateOutputTypeExabeamExabeam CreateOutputTypeExabeam = "exabeam"
)

func (e CreateOutputTypeExabeam) ToPointer() *CreateOutputTypeExabeam {
	return &e
}
func (e *CreateOutputTypeExabeam) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "exabeam":
		*e = CreateOutputTypeExabeam(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeExabeam: %v", v)
	}
}

type CreateOutputOutputExabeam struct {
	// Unique ID for this output
	ID   string                  `json:"id"`
	Type CreateOutputTypeExabeam `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the destination bucket. A constant or a JavaScript expression that can only be evaluated at init time. Example of referencing a JavaScript Global Variable: `myBucket-${C.vars.myVar}`.
	Bucket string `json:"bucket"`
	// Region where the bucket is located
	Region string `json:"region"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
	StagePath string `json:"stagePath"`
	// Google Cloud Storage service endpoint
	Endpoint string `json:"endpoint"`
	// Signature version to use for signing Google Cloud Storage requests
	SignatureVersion *components.SignatureVersionOptions4 `json:"signatureVersion,omitempty"`
	// Object ACL to assign to uploaded objects
	ObjectACL *components.ObjectACLOptions1 `json:"objectACL,omitempty"`
	// Storage class to select for uploaded objects
	StorageClass *components.StorageClassOptions1 `json:"storageClass,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `json:"maxOpenFiles,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `json:"deadletterEnabled,omitempty"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *components.DiskSpaceProtectionOptions `json:"onDiskFullBackpressure,omitempty"`
	RetrySettings          *components.RetrySettingsType          `json:"retrySettings,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `json:"maxFileSizeMB,omitempty"`
	// Enter an encoded string containing Exabeam configurations
	EncodedConfiguration *string `json:"encodedConfiguration,omitempty"`
	// ID of the Exabeam Collector where data should be sent. Example: 11112222-3333-4444-5555-666677778888
	//
	CollectorInstanceID string `json:"collectorInstanceId"`
	// Constant or JavaScript expression to create an Exabeam site name. Values that aren't successfully evaluated will be treated as string constants.
	SiteName *string `json:"siteName,omitempty"`
	// Exabeam site ID. If left blank, @{product} will use the value of the Exabeam site name.
	SiteID         *string `json:"siteId,omitempty"`
	TimezoneOffset *string `json:"timezoneOffset,omitempty"`
	// HMAC access key. Can be a constant or a JavaScript expression, such as `${C.env.GCS_ACCESS_KEY}`.
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// HMAC secret. Can be a constant or a JavaScript expression, such as `${C.env.GCS_SECRET}`.
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	Description  *string `json:"description,omitempty"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `json:"emptyDirCleanupSec,omitempty"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `json:"directoryBatchSize,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `json:"deadletterPath,omitempty"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `json:"maxRetryNum,omitempty"`
	// Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime.
	TemplateRegion *string `json:"__template_region,omitempty"`
}

func (c CreateOutputOutputExabeam) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputExabeam) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "bucket", "region", "stagePath", "endpoint", "collectorInstanceId"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputExabeam) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputExabeam) GetType() CreateOutputTypeExabeam {
	if c == nil {
		return CreateOutputTypeExabeam("")
	}
	return c.Type
}

func (c *CreateOutputOutputExabeam) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputExabeam) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputExabeam) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputExabeam) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputExabeam) GetBucket() string {
	if c == nil {
		return ""
	}
	return c.Bucket
}

func (c *CreateOutputOutputExabeam) GetRegion() string {
	if c == nil {
		return ""
	}
	return c.Region
}

func (c *CreateOutputOutputExabeam) GetStagePath() string {
	if c == nil {
		return ""
	}
	return c.StagePath
}

func (c *CreateOutputOutputExabeam) GetEndpoint() string {
	if c == nil {
		return ""
	}
	return c.Endpoint
}

func (c *CreateOutputOutputExabeam) GetSignatureVersion() *components.SignatureVersionOptions4 {
	if c == nil {
		return nil
	}
	return c.SignatureVersion
}

func (c *CreateOutputOutputExabeam) GetObjectACL() *components.ObjectACLOptions1 {
	if c == nil {
		return nil
	}
	return c.ObjectACL
}

func (c *CreateOutputOutputExabeam) GetStorageClass() *components.StorageClassOptions1 {
	if c == nil {
		return nil
	}
	return c.StorageClass
}

func (c *CreateOutputOutputExabeam) GetReuseConnections() *bool {
	if c == nil {
		return nil
	}
	return c.ReuseConnections
}

func (c *CreateOutputOutputExabeam) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputExabeam) GetAddIDToStagePath() *bool {
	if c == nil {
		return nil
	}
	return c.AddIDToStagePath
}

func (c *CreateOutputOutputExabeam) GetRemoveEmptyDirs() *bool {
	if c == nil {
		return nil
	}
	return c.RemoveEmptyDirs
}

func (c *CreateOutputOutputExabeam) GetMaxFileOpenTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileOpenTimeSec
}

func (c *CreateOutputOutputExabeam) GetMaxFileIdleTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileIdleTimeSec
}

func (c *CreateOutputOutputExabeam) GetMaxOpenFiles() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxOpenFiles
}

func (c *CreateOutputOutputExabeam) GetOnBackpressure() *components.BackpressureBehaviorOptions1 {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputExabeam) GetDeadletterEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.DeadletterEnabled
}

func (c *CreateOutputOutputExabeam) GetOnDiskFullBackpressure() *components.DiskSpaceProtectionOptions {
	if c == nil {
		return nil
	}
	return c.OnDiskFullBackpressure
}

func (c *CreateOutputOutputExabeam) GetRetrySettings() *components.RetrySettingsType {
	if c == nil {
		return nil
	}
	return c.RetrySettings
}

func (c *CreateOutputOutputExabeam) GetMaxFileSizeMB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileSizeMB
}

func (c *CreateOutputOutputExabeam) GetEncodedConfiguration() *string {
	if c == nil {
		return nil
	}
	return c.EncodedConfiguration
}

func (c *CreateOutputOutputExabeam) GetCollectorInstanceID() string {
	if c == nil {
		return ""
	}
	return c.CollectorInstanceID
}

func (c *CreateOutputOutputExabeam) GetSiteName() *string {
	if c == nil {
		return nil
	}
	return c.SiteName
}

func (c *CreateOutputOutputExabeam) GetSiteID() *string {
	if c == nil {
		return nil
	}
	return c.SiteID
}

func (c *CreateOutputOutputExabeam) GetTimezoneOffset() *string {
	if c == nil {
		return nil
	}
	return c.TimezoneOffset
}

func (c *CreateOutputOutputExabeam) GetAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsAPIKey
}

func (c *CreateOutputOutputExabeam) GetAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecretKey
}

func (c *CreateOutputOutputExabeam) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputExabeam) GetEmptyDirCleanupSec() *float64 {
	if c == nil {
		return nil
	}
	return c.EmptyDirCleanupSec
}

func (c *CreateOutputOutputExabeam) GetDirectoryBatchSize() *float64 {
	if c == nil {
		return nil
	}
	return c.DirectoryBatchSize
}

func (c *CreateOutputOutputExabeam) GetDeadletterPath() *string {
	if c == nil {
		return nil
	}
	return c.DeadletterPath
}

func (c *CreateOutputOutputExabeam) GetMaxRetryNum() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRetryNum
}

func (c *CreateOutputOutputExabeam) GetTemplateRegion() *string {
	if c == nil {
		return nil
	}
	return c.TemplateRegion
}

type CreateOutputTypeGooglePubsub string

const (
	CreateOutputTypeGooglePubsubGooglePubsub CreateOutputTypeGooglePubsub = "google_pubsub"
)

func (e CreateOutputTypeGooglePubsub) ToPointer() *CreateOutputTypeGooglePubsub {
	return &e
}
func (e *CreateOutputTypeGooglePubsub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "google_pubsub":
		*e = CreateOutputTypeGooglePubsub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeGooglePubsub: %v", v)
	}
}

type CreateOutputPqControlsGooglePubsub struct {
}

func (c CreateOutputPqControlsGooglePubsub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsGooglePubsub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputGooglePubsub struct {
	// Unique ID for this output
	ID   string                       `json:"id"`
	Type CreateOutputTypeGooglePubsub `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// ID of the topic to send events to.
	TopicName string `json:"topicName"`
	// If enabled, create topic if it does not exist.
	CreateTopic *bool `json:"createTopic,omitempty"`
	// If enabled, send events in the order they were added to the queue. For this to work correctly, the process receiving events must have ordering enabled.
	OrderedDelivery *bool `json:"orderedDelivery,omitempty"`
	// Region to publish messages to. Select 'default' to allow Google to auto-select the nearest region. When using ordered delivery, the selected region must be allowed by message storage policy.
	Region *string `json:"region,omitempty"`
	// Choose Auto to use Google Application Default Credentials (ADC), Manual to enter Google service account credentials directly, or Secret to select or create a stored secret that references Google service account credentials.
	GoogleAuthMethod *components.GoogleAuthenticationMethodOptions `json:"googleAuthMethod,omitempty"`
	// Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
	ServiceAccountCredentials *string `json:"serviceAccountCredentials,omitempty"`
	// Select or create a stored text secret
	Secret *string `json:"secret,omitempty"`
	// The maximum number of items the Google API should batch before it sends them to the topic.
	BatchSize *float64 `json:"batchSize,omitempty"`
	// The maximum amount of time, in milliseconds, that the Google API should wait to send a batch (if the Batch size is not reached).
	BatchTimeout *float64 `json:"batchTimeout,omitempty"`
	// Maximum number of queued batches before blocking.
	MaxQueueSize *float64 `json:"maxQueueSize,omitempty"`
	// Maximum size (KB) of batches to send.
	MaxRecordSizeKB *float64 `json:"maxRecordSizeKB,omitempty"`
	// Maximum time to wait before sending a batch (when batch size limit is not reached)
	FlushPeriod *float64 `json:"flushPeriod,omitempty"`
	// The maximum number of in-progress API requests before backpressure is applied.
	MaxInProgress *float64 `json:"maxInProgress,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsGooglePubsub  `json:"pqControls,omitempty"`
	// Binds 'topicName' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'topicName' at runtime.
	TemplateTopicName *string `json:"__template_topicName,omitempty"`
	// Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime.
	TemplateRegion *string `json:"__template_region,omitempty"`
}

func (c CreateOutputOutputGooglePubsub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputGooglePubsub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "topicName"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputGooglePubsub) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputGooglePubsub) GetType() CreateOutputTypeGooglePubsub {
	if c == nil {
		return CreateOutputTypeGooglePubsub("")
	}
	return c.Type
}

func (c *CreateOutputOutputGooglePubsub) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputGooglePubsub) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputGooglePubsub) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputGooglePubsub) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputGooglePubsub) GetTopicName() string {
	if c == nil {
		return ""
	}
	return c.TopicName
}

func (c *CreateOutputOutputGooglePubsub) GetCreateTopic() *bool {
	if c == nil {
		return nil
	}
	return c.CreateTopic
}

func (c *CreateOutputOutputGooglePubsub) GetOrderedDelivery() *bool {
	if c == nil {
		return nil
	}
	return c.OrderedDelivery
}

func (c *CreateOutputOutputGooglePubsub) GetRegion() *string {
	if c == nil {
		return nil
	}
	return c.Region
}

func (c *CreateOutputOutputGooglePubsub) GetGoogleAuthMethod() *components.GoogleAuthenticationMethodOptions {
	if c == nil {
		return nil
	}
	return c.GoogleAuthMethod
}

func (c *CreateOutputOutputGooglePubsub) GetServiceAccountCredentials() *string {
	if c == nil {
		return nil
	}
	return c.ServiceAccountCredentials
}

func (c *CreateOutputOutputGooglePubsub) GetSecret() *string {
	if c == nil {
		return nil
	}
	return c.Secret
}

func (c *CreateOutputOutputGooglePubsub) GetBatchSize() *float64 {
	if c == nil {
		return nil
	}
	return c.BatchSize
}

func (c *CreateOutputOutputGooglePubsub) GetBatchTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.BatchTimeout
}

func (c *CreateOutputOutputGooglePubsub) GetMaxQueueSize() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxQueueSize
}

func (c *CreateOutputOutputGooglePubsub) GetMaxRecordSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRecordSizeKB
}

func (c *CreateOutputOutputGooglePubsub) GetFlushPeriod() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriod
}

func (c *CreateOutputOutputGooglePubsub) GetMaxInProgress() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxInProgress
}

func (c *CreateOutputOutputGooglePubsub) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputGooglePubsub) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputGooglePubsub) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputGooglePubsub) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputGooglePubsub) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputGooglePubsub) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputGooglePubsub) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputGooglePubsub) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputGooglePubsub) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputGooglePubsub) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputGooglePubsub) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputGooglePubsub) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputGooglePubsub) GetPqControls() *CreateOutputPqControlsGooglePubsub {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputGooglePubsub) GetTemplateTopicName() *string {
	if c == nil {
		return nil
	}
	return c.TemplateTopicName
}

func (c *CreateOutputOutputGooglePubsub) GetTemplateRegion() *string {
	if c == nil {
		return nil
	}
	return c.TemplateRegion
}

type CreateOutputTypeGoogleCloudLogging string

const (
	CreateOutputTypeGoogleCloudLoggingGoogleCloudLogging CreateOutputTypeGoogleCloudLogging = "google_cloud_logging"
)

func (e CreateOutputTypeGoogleCloudLogging) ToPointer() *CreateOutputTypeGoogleCloudLogging {
	return &e
}
func (e *CreateOutputTypeGoogleCloudLogging) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "google_cloud_logging":
		*e = CreateOutputTypeGoogleCloudLogging(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeGoogleCloudLogging: %v", v)
	}
}

type CreateOutputLogLocationType string

const (
	// CreateOutputLogLocationTypeProject Project
	CreateOutputLogLocationTypeProject CreateOutputLogLocationType = "project"
	// CreateOutputLogLocationTypeOrganization Organization
	CreateOutputLogLocationTypeOrganization CreateOutputLogLocationType = "organization"
	// CreateOutputLogLocationTypeBillingAccount Billing Account
	CreateOutputLogLocationTypeBillingAccount CreateOutputLogLocationType = "billingAccount"
	// CreateOutputLogLocationTypeFolder Folder
	CreateOutputLogLocationTypeFolder CreateOutputLogLocationType = "folder"
)

func (e CreateOutputLogLocationType) ToPointer() *CreateOutputLogLocationType {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputLogLocationType) IsExact() bool {
	if e != nil {
		switch *e {
		case "project", "organization", "billingAccount", "folder":
			return true
		}
	}
	return false
}

// CreateOutputPayloadFormat - Format to use when sending payload. Defaults to Text.
type CreateOutputPayloadFormat string

const (
	// CreateOutputPayloadFormatText Text
	CreateOutputPayloadFormatText CreateOutputPayloadFormat = "text"
	// CreateOutputPayloadFormatJSON JSON
	CreateOutputPayloadFormatJSON CreateOutputPayloadFormat = "json"
)

func (e CreateOutputPayloadFormat) ToPointer() *CreateOutputPayloadFormat {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputPayloadFormat) IsExact() bool {
	if e != nil {
		switch *e {
		case "text", "json":
			return true
		}
	}
	return false
}

type CreateOutputPqControlsGoogleCloudLogging struct {
}

func (c CreateOutputPqControlsGoogleCloudLogging) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsGoogleCloudLogging) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputGoogleCloudLogging struct {
	// Unique ID for this output
	ID   string                             `json:"id"`
	Type CreateOutputTypeGoogleCloudLogging `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags      []string                    `json:"streamtags,omitempty"`
	LogLocationType CreateOutputLogLocationType `json:"logLocationType"`
	// JavaScript expression to compute the value of the log name. If Validate and correct log name is enabled, invalid characters (characters other than alphanumerics, forward-slashes, underscores, hyphens, and periods) will be replaced with an underscore.
	LogNameExpression string `json:"logNameExpression"`
	SanitizeLogNames  *bool  `json:"sanitizeLogNames,omitempty"`
	// Format to use when sending payload. Defaults to Text.
	PayloadFormat *CreateOutputPayloadFormat `json:"payloadFormat,omitempty"`
	// Labels to apply to the log entry
	LogLabels []components.ItemsTypeLogLabels `json:"logLabels,omitempty"`
	// JavaScript expression to compute the value of the managed resource type field. Must evaluate to one of the valid values [here](https://cloud.google.com/logging/docs/api/v2/resource-list#resource-types). Defaults to "global".
	ResourceTypeExpression *string `json:"resourceTypeExpression,omitempty"`
	// Labels to apply to the managed resource. These must correspond to the valid labels for the specified resource type (see [here](https://cloud.google.com/logging/docs/api/v2/resource-list#resource-types)). Otherwise, they will be dropped by Google Cloud Logging.
	ResourceTypeLabels []components.ItemsTypeLogLabels `json:"resourceTypeLabels,omitempty"`
	// JavaScript expression to compute the value of the severity field. Must evaluate to one of the severity values supported by Google Cloud Logging [here](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logseverity) (case insensitive). Defaults to "DEFAULT".
	SeverityExpression *string `json:"severityExpression,omitempty"`
	// JavaScript expression to compute the value of the insert ID field.
	InsertIDExpression *string `json:"insertIdExpression,omitempty"`
	// Choose Auto to use Google Application Default Credentials (ADC), Manual to enter Google service account credentials directly, or Secret to select or create a stored secret that references Google service account credentials.
	GoogleAuthMethod *components.GoogleAuthenticationMethodOptions `json:"googleAuthMethod,omitempty"`
	// Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
	ServiceAccountCredentials *string `json:"serviceAccountCredentials,omitempty"`
	// Select or create a stored text secret
	Secret *string `json:"secret,omitempty"`
	// Maximum size, in KB, of the request body.
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Max number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Maximum number of ongoing requests before blocking.
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it.
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum number of requests to limit to per second.
	ThrottleRateReqPerSec *int64 `json:"throttleRateReqPerSec,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request method as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	RequestMethodExpression *string `json:"requestMethodExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request URL as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	RequestURLExpression *string `json:"requestUrlExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request size as a string, in int64 format. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	RequestSizeExpression *string `json:"requestSizeExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request method as a number. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	StatusExpression *string `json:"statusExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP response size as a string, in int64 format. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	ResponseSizeExpression *string `json:"responseSizeExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request user agent as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	UserAgentExpression *string `json:"userAgentExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request remote IP as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	RemoteIPExpression *string `json:"remoteIpExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request server IP as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	ServerIPExpression *string `json:"serverIpExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request referer as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	RefererExpression *string `json:"refererExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request latency, formatted as <seconds>.<nanoseconds>s (for example, 1.23s). See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	LatencyExpression *string `json:"latencyExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request cache lookup as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	CacheLookupExpression *string `json:"cacheLookupExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request cache hit as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	CacheHitExpression *string `json:"cacheHitExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request cache validated with origin server as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	CacheValidatedExpression *string `json:"cacheValidatedExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request cache fill bytes as a string, in int64 format. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	CacheFillBytesExpression *string `json:"cacheFillBytesExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request protocol as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	ProtocolExpression *string `json:"protocolExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry operation ID as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentryoperation) for details.
	IDExpression *string `json:"idExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry operation producer as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentryoperation) for details.
	ProducerExpression *string `json:"producerExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry operation first flag as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentryoperation) for details.
	FirstExpression *string `json:"firstExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry operation last flag as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentryoperation) for details.
	LastExpression *string `json:"lastExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry source location file as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentrysourcelocation) for details.
	FileExpression *string `json:"fileExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry source location line as a string, in int64 format. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentrysourcelocation) for details.
	LineExpression *string `json:"lineExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry source location function as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentrysourcelocation) for details.
	FunctionExpression *string `json:"functionExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry log split UID as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logsplit) for details.
	UIDExpression *string `json:"uidExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry log split index as a number. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logsplit) for details.
	IndexExpression *string `json:"indexExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry log split total splits as a number. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logsplit) for details.
	TotalSplitsExpression *string `json:"totalSplitsExpression,omitempty"`
	// A JavaScript expression that evaluates to the REST resource name of the trace being written as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry) for details.
	TraceExpression *string `json:"traceExpression,omitempty"`
	// A JavaScript expression that evaluates to the ID of the cloud trace span associated with the current operation in which the log is being written as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry) for details.
	SpanIDExpression *string `json:"spanIdExpression,omitempty"`
	// A JavaScript expression that evaluates to the the sampling decision of the span associated with the log entry. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry) for details.
	TraceSampledExpression *string `json:"traceSampledExpression,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	// JavaScript expression to compute the value of the folder ID with which log entries should be associated. If Validate and correct log name is enabled, invalid characters (characters other than alphanumerics, forward-slashes, underscores, hyphens, and periods) will be replaced with an underscore.
	LogLocationExpression string `json:"logLocationExpression"`
	// JavaScript expression to compute the value of the payload. Must evaluate to a JavaScript object value. If an invalid value is encountered it will result in the default value instead. Defaults to the entire event.
	PayloadExpression *string `json:"payloadExpression,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions      `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsGoogleCloudLogging `json:"pqControls,omitempty"`
}

func (c CreateOutputOutputGoogleCloudLogging) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputGoogleCloudLogging) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "logLocationType", "logNameExpression", "logLocationExpression"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputGoogleCloudLogging) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputGoogleCloudLogging) GetType() CreateOutputTypeGoogleCloudLogging {
	if c == nil {
		return CreateOutputTypeGoogleCloudLogging("")
	}
	return c.Type
}

func (c *CreateOutputOutputGoogleCloudLogging) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputGoogleCloudLogging) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputGoogleCloudLogging) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputGoogleCloudLogging) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputGoogleCloudLogging) GetLogLocationType() CreateOutputLogLocationType {
	if c == nil {
		return CreateOutputLogLocationType("")
	}
	return c.LogLocationType
}

func (c *CreateOutputOutputGoogleCloudLogging) GetLogNameExpression() string {
	if c == nil {
		return ""
	}
	return c.LogNameExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetSanitizeLogNames() *bool {
	if c == nil {
		return nil
	}
	return c.SanitizeLogNames
}

func (c *CreateOutputOutputGoogleCloudLogging) GetPayloadFormat() *CreateOutputPayloadFormat {
	if c == nil {
		return nil
	}
	return c.PayloadFormat
}

func (c *CreateOutputOutputGoogleCloudLogging) GetLogLabels() []components.ItemsTypeLogLabels {
	if c == nil {
		return nil
	}
	return c.LogLabels
}

func (c *CreateOutputOutputGoogleCloudLogging) GetResourceTypeExpression() *string {
	if c == nil {
		return nil
	}
	return c.ResourceTypeExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetResourceTypeLabels() []components.ItemsTypeLogLabels {
	if c == nil {
		return nil
	}
	return c.ResourceTypeLabels
}

func (c *CreateOutputOutputGoogleCloudLogging) GetSeverityExpression() *string {
	if c == nil {
		return nil
	}
	return c.SeverityExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetInsertIDExpression() *string {
	if c == nil {
		return nil
	}
	return c.InsertIDExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetGoogleAuthMethod() *components.GoogleAuthenticationMethodOptions {
	if c == nil {
		return nil
	}
	return c.GoogleAuthMethod
}

func (c *CreateOutputOutputGoogleCloudLogging) GetServiceAccountCredentials() *string {
	if c == nil {
		return nil
	}
	return c.ServiceAccountCredentials
}

func (c *CreateOutputOutputGoogleCloudLogging) GetSecret() *string {
	if c == nil {
		return nil
	}
	return c.Secret
}

func (c *CreateOutputOutputGoogleCloudLogging) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputGoogleCloudLogging) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputGoogleCloudLogging) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputGoogleCloudLogging) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputGoogleCloudLogging) GetConnectionTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.ConnectionTimeout
}

func (c *CreateOutputOutputGoogleCloudLogging) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputGoogleCloudLogging) GetThrottleRateReqPerSec() *int64 {
	if c == nil {
		return nil
	}
	return c.ThrottleRateReqPerSec
}

func (c *CreateOutputOutputGoogleCloudLogging) GetRequestMethodExpression() *string {
	if c == nil {
		return nil
	}
	return c.RequestMethodExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetRequestURLExpression() *string {
	if c == nil {
		return nil
	}
	return c.RequestURLExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetRequestSizeExpression() *string {
	if c == nil {
		return nil
	}
	return c.RequestSizeExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetStatusExpression() *string {
	if c == nil {
		return nil
	}
	return c.StatusExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetResponseSizeExpression() *string {
	if c == nil {
		return nil
	}
	return c.ResponseSizeExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetUserAgentExpression() *string {
	if c == nil {
		return nil
	}
	return c.UserAgentExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetRemoteIPExpression() *string {
	if c == nil {
		return nil
	}
	return c.RemoteIPExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetServerIPExpression() *string {
	if c == nil {
		return nil
	}
	return c.ServerIPExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetRefererExpression() *string {
	if c == nil {
		return nil
	}
	return c.RefererExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetLatencyExpression() *string {
	if c == nil {
		return nil
	}
	return c.LatencyExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetCacheLookupExpression() *string {
	if c == nil {
		return nil
	}
	return c.CacheLookupExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetCacheHitExpression() *string {
	if c == nil {
		return nil
	}
	return c.CacheHitExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetCacheValidatedExpression() *string {
	if c == nil {
		return nil
	}
	return c.CacheValidatedExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetCacheFillBytesExpression() *string {
	if c == nil {
		return nil
	}
	return c.CacheFillBytesExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetProtocolExpression() *string {
	if c == nil {
		return nil
	}
	return c.ProtocolExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetIDExpression() *string {
	if c == nil {
		return nil
	}
	return c.IDExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetProducerExpression() *string {
	if c == nil {
		return nil
	}
	return c.ProducerExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetFirstExpression() *string {
	if c == nil {
		return nil
	}
	return c.FirstExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetLastExpression() *string {
	if c == nil {
		return nil
	}
	return c.LastExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetFileExpression() *string {
	if c == nil {
		return nil
	}
	return c.FileExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetLineExpression() *string {
	if c == nil {
		return nil
	}
	return c.LineExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetFunctionExpression() *string {
	if c == nil {
		return nil
	}
	return c.FunctionExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetUIDExpression() *string {
	if c == nil {
		return nil
	}
	return c.UIDExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetIndexExpression() *string {
	if c == nil {
		return nil
	}
	return c.IndexExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetTotalSplitsExpression() *string {
	if c == nil {
		return nil
	}
	return c.TotalSplitsExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetTraceExpression() *string {
	if c == nil {
		return nil
	}
	return c.TraceExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetSpanIDExpression() *string {
	if c == nil {
		return nil
	}
	return c.SpanIDExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetTraceSampledExpression() *string {
	if c == nil {
		return nil
	}
	return c.TraceSampledExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputGoogleCloudLogging) GetTotalMemoryLimitKB() *float64 {
	if c == nil {
		return nil
	}
	return c.TotalMemoryLimitKB
}

func (c *CreateOutputOutputGoogleCloudLogging) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputGoogleCloudLogging) GetLogLocationExpression() string {
	if c == nil {
		return ""
	}
	return c.LogLocationExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetPayloadExpression() *string {
	if c == nil {
		return nil
	}
	return c.PayloadExpression
}

func (c *CreateOutputOutputGoogleCloudLogging) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputGoogleCloudLogging) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputGoogleCloudLogging) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputGoogleCloudLogging) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputGoogleCloudLogging) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputGoogleCloudLogging) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputGoogleCloudLogging) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputGoogleCloudLogging) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputGoogleCloudLogging) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputGoogleCloudLogging) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputGoogleCloudLogging) GetPqControls() *CreateOutputPqControlsGoogleCloudLogging {
	if c == nil {
		return nil
	}
	return c.PqControls
}

type CreateOutputTypeGoogleCloudStorage string

const (
	CreateOutputTypeGoogleCloudStorageGoogleCloudStorage CreateOutputTypeGoogleCloudStorage = "google_cloud_storage"
)

func (e CreateOutputTypeGoogleCloudStorage) ToPointer() *CreateOutputTypeGoogleCloudStorage {
	return &e
}
func (e *CreateOutputTypeGoogleCloudStorage) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "google_cloud_storage":
		*e = CreateOutputTypeGoogleCloudStorage(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeGoogleCloudStorage: %v", v)
	}
}

type CreateOutputAuthenticationMethodGoogleCloudStorage string

const (
	// CreateOutputAuthenticationMethodGoogleCloudStorageAuto auto
	CreateOutputAuthenticationMethodGoogleCloudStorageAuto CreateOutputAuthenticationMethodGoogleCloudStorage = "auto"
	// CreateOutputAuthenticationMethodGoogleCloudStorageManual manual
	CreateOutputAuthenticationMethodGoogleCloudStorageManual CreateOutputAuthenticationMethodGoogleCloudStorage = "manual"
	// CreateOutputAuthenticationMethodGoogleCloudStorageSecret Secret Key pair
	CreateOutputAuthenticationMethodGoogleCloudStorageSecret CreateOutputAuthenticationMethodGoogleCloudStorage = "secret"
)

func (e CreateOutputAuthenticationMethodGoogleCloudStorage) ToPointer() *CreateOutputAuthenticationMethodGoogleCloudStorage {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputAuthenticationMethodGoogleCloudStorage) IsExact() bool {
	if e != nil {
		switch *e {
		case "auto", "manual", "secret":
			return true
		}
	}
	return false
}

type CreateOutputOutputGoogleCloudStorage struct {
	// Unique ID for this output
	ID   string                             `json:"id"`
	Type CreateOutputTypeGoogleCloudStorage `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the destination bucket. This value can be a constant or a JavaScript expression that can only be evaluated at init time. Example of referencing a Global Variable: `myBucket-${C.vars.myVar}`.
	Bucket string `json:"bucket"`
	// Region where the bucket is located
	Region string `json:"region"`
	// Google Cloud Storage service endpoint
	Endpoint string `json:"endpoint"`
	// Signature version to use for signing Google Cloud Storage requests
	SignatureVersion        *components.SignatureVersionOptions4                `json:"signatureVersion,omitempty"`
	AwsAuthenticationMethod *CreateOutputAuthenticationMethodGoogleCloudStorage `json:"awsAuthenticationMethod,omitempty"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
	StagePath string `json:"stagePath"`
	// Prefix to prepend to files before uploading. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `myKeyPrefix-${C.vars.myVar}`
	DestPath *string `json:"destPath,omitempty"`
	// Disable if you can access files within the bucket but not the bucket itself
	VerifyPermissions *bool `json:"verifyPermissions,omitempty"`
	// Object ACL to assign to uploaded objects
	ObjectACL *components.ObjectACLOptions1 `json:"objectACL,omitempty"`
	// Storage class to select for uploaded objects
	StorageClass *components.StorageClassOptions1 `json:"storageClass,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
	PartitionExpr *string `json:"partitionExpr,omitempty"`
	// Format of the output data
	Format *components.DataFormatOptions `json:"format,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `json:"baseFileName,omitempty"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `json:"fileNameSuffix,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `json:"maxFileSizeMB,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `json:"maxOpenFiles,omitempty"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `json:"headerLine,omitempty"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `json:"writeHighWaterMark,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `json:"deadletterEnabled,omitempty"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *components.DiskSpaceProtectionOptions `json:"onDiskFullBackpressure,omitempty"`
	// Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
	ForceCloseOnShutdown *bool                         `json:"forceCloseOnShutdown,omitempty"`
	RetrySettings        *components.RetrySettingsType `json:"retrySettings,omitempty"`
	Description          *string                       `json:"description,omitempty"`
	// Data compression format to apply to HTTP content before it is delivered
	Compress *components.CompressionOptions2 `json:"compress,omitempty"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *components.CompressionLevelOptions `json:"compressionLevel,omitempty"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `json:"automaticSchema,omitempty"`
	// To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
	ParquetSchema *string `json:"parquetSchema,omitempty"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *components.ParquetVersionOptions `json:"parquetVersion,omitempty"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *components.DataPageVersionOptions `json:"parquetDataPageVersion,omitempty"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `json:"parquetRowGroupLength,omitempty"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
	KeyValueMetadata []components.ItemsTypeKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `json:"enableStatistics,omitempty"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `json:"enableWritePageIndex,omitempty"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `json:"enablePageChecksum,omitempty"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `json:"emptyDirCleanupSec,omitempty"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `json:"directoryBatchSize,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `json:"deadletterPath,omitempty"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `json:"maxRetryNum,omitempty"`
	// HMAC access key. This value can be a constant or a JavaScript expression, such as `${C.env.GCS_ACCESS_KEY}`.
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// HMAC secret. This value can be a constant or a JavaScript expression, such as `${C.env.GCS_SECRET}`.
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Binds 'bucket' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'bucket' at runtime.
	TemplateBucket *string `json:"__template_bucket,omitempty"`
	// Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime.
	TemplateRegion *string `json:"__template_region,omitempty"`
	// Binds 'format' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'format' at runtime.
	TemplateFormat *string `json:"__template_format,omitempty"`
}

func (c CreateOutputOutputGoogleCloudStorage) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputGoogleCloudStorage) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "bucket", "region", "endpoint", "stagePath"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputGoogleCloudStorage) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputGoogleCloudStorage) GetType() CreateOutputTypeGoogleCloudStorage {
	if c == nil {
		return CreateOutputTypeGoogleCloudStorage("")
	}
	return c.Type
}

func (c *CreateOutputOutputGoogleCloudStorage) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputGoogleCloudStorage) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputGoogleCloudStorage) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputGoogleCloudStorage) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputGoogleCloudStorage) GetBucket() string {
	if c == nil {
		return ""
	}
	return c.Bucket
}

func (c *CreateOutputOutputGoogleCloudStorage) GetRegion() string {
	if c == nil {
		return ""
	}
	return c.Region
}

func (c *CreateOutputOutputGoogleCloudStorage) GetEndpoint() string {
	if c == nil {
		return ""
	}
	return c.Endpoint
}

func (c *CreateOutputOutputGoogleCloudStorage) GetSignatureVersion() *components.SignatureVersionOptions4 {
	if c == nil {
		return nil
	}
	return c.SignatureVersion
}

func (c *CreateOutputOutputGoogleCloudStorage) GetAwsAuthenticationMethod() *CreateOutputAuthenticationMethodGoogleCloudStorage {
	if c == nil {
		return nil
	}
	return c.AwsAuthenticationMethod
}

func (c *CreateOutputOutputGoogleCloudStorage) GetStagePath() string {
	if c == nil {
		return ""
	}
	return c.StagePath
}

func (c *CreateOutputOutputGoogleCloudStorage) GetDestPath() *string {
	if c == nil {
		return nil
	}
	return c.DestPath
}

func (c *CreateOutputOutputGoogleCloudStorage) GetVerifyPermissions() *bool {
	if c == nil {
		return nil
	}
	return c.VerifyPermissions
}

func (c *CreateOutputOutputGoogleCloudStorage) GetObjectACL() *components.ObjectACLOptions1 {
	if c == nil {
		return nil
	}
	return c.ObjectACL
}

func (c *CreateOutputOutputGoogleCloudStorage) GetStorageClass() *components.StorageClassOptions1 {
	if c == nil {
		return nil
	}
	return c.StorageClass
}

func (c *CreateOutputOutputGoogleCloudStorage) GetReuseConnections() *bool {
	if c == nil {
		return nil
	}
	return c.ReuseConnections
}

func (c *CreateOutputOutputGoogleCloudStorage) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputGoogleCloudStorage) GetAddIDToStagePath() *bool {
	if c == nil {
		return nil
	}
	return c.AddIDToStagePath
}

func (c *CreateOutputOutputGoogleCloudStorage) GetRemoveEmptyDirs() *bool {
	if c == nil {
		return nil
	}
	return c.RemoveEmptyDirs
}

func (c *CreateOutputOutputGoogleCloudStorage) GetPartitionExpr() *string {
	if c == nil {
		return nil
	}
	return c.PartitionExpr
}

func (c *CreateOutputOutputGoogleCloudStorage) GetFormat() *components.DataFormatOptions {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputGoogleCloudStorage) GetBaseFileName() *string {
	if c == nil {
		return nil
	}
	return c.BaseFileName
}

func (c *CreateOutputOutputGoogleCloudStorage) GetFileNameSuffix() *string {
	if c == nil {
		return nil
	}
	return c.FileNameSuffix
}

func (c *CreateOutputOutputGoogleCloudStorage) GetMaxFileSizeMB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileSizeMB
}

func (c *CreateOutputOutputGoogleCloudStorage) GetMaxFileOpenTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileOpenTimeSec
}

func (c *CreateOutputOutputGoogleCloudStorage) GetMaxFileIdleTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileIdleTimeSec
}

func (c *CreateOutputOutputGoogleCloudStorage) GetMaxOpenFiles() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxOpenFiles
}

func (c *CreateOutputOutputGoogleCloudStorage) GetHeaderLine() *string {
	if c == nil {
		return nil
	}
	return c.HeaderLine
}

func (c *CreateOutputOutputGoogleCloudStorage) GetWriteHighWaterMark() *float64 {
	if c == nil {
		return nil
	}
	return c.WriteHighWaterMark
}

func (c *CreateOutputOutputGoogleCloudStorage) GetOnBackpressure() *components.BackpressureBehaviorOptions1 {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputGoogleCloudStorage) GetDeadletterEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.DeadletterEnabled
}

func (c *CreateOutputOutputGoogleCloudStorage) GetOnDiskFullBackpressure() *components.DiskSpaceProtectionOptions {
	if c == nil {
		return nil
	}
	return c.OnDiskFullBackpressure
}

func (c *CreateOutputOutputGoogleCloudStorage) GetForceCloseOnShutdown() *bool {
	if c == nil {
		return nil
	}
	return c.ForceCloseOnShutdown
}

func (c *CreateOutputOutputGoogleCloudStorage) GetRetrySettings() *components.RetrySettingsType {
	if c == nil {
		return nil
	}
	return c.RetrySettings
}

func (c *CreateOutputOutputGoogleCloudStorage) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputGoogleCloudStorage) GetCompress() *components.CompressionOptions2 {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputGoogleCloudStorage) GetCompressionLevel() *components.CompressionLevelOptions {
	if c == nil {
		return nil
	}
	return c.CompressionLevel
}

func (c *CreateOutputOutputGoogleCloudStorage) GetAutomaticSchema() *bool {
	if c == nil {
		return nil
	}
	return c.AutomaticSchema
}

func (c *CreateOutputOutputGoogleCloudStorage) GetParquetSchema() *string {
	if c == nil {
		return nil
	}
	return c.ParquetSchema
}

func (c *CreateOutputOutputGoogleCloudStorage) GetParquetVersion() *components.ParquetVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetVersion
}

func (c *CreateOutputOutputGoogleCloudStorage) GetParquetDataPageVersion() *components.DataPageVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetDataPageVersion
}

func (c *CreateOutputOutputGoogleCloudStorage) GetParquetRowGroupLength() *float64 {
	if c == nil {
		return nil
	}
	return c.ParquetRowGroupLength
}

func (c *CreateOutputOutputGoogleCloudStorage) GetParquetPageSize() *string {
	if c == nil {
		return nil
	}
	return c.ParquetPageSize
}

func (c *CreateOutputOutputGoogleCloudStorage) GetShouldLogInvalidRows() *bool {
	if c == nil {
		return nil
	}
	return c.ShouldLogInvalidRows
}

func (c *CreateOutputOutputGoogleCloudStorage) GetKeyValueMetadata() []components.ItemsTypeKeyValueMetadata {
	if c == nil {
		return nil
	}
	return c.KeyValueMetadata
}

func (c *CreateOutputOutputGoogleCloudStorage) GetEnableStatistics() *bool {
	if c == nil {
		return nil
	}
	return c.EnableStatistics
}

func (c *CreateOutputOutputGoogleCloudStorage) GetEnableWritePageIndex() *bool {
	if c == nil {
		return nil
	}
	return c.EnableWritePageIndex
}

func (c *CreateOutputOutputGoogleCloudStorage) GetEnablePageChecksum() *bool {
	if c == nil {
		return nil
	}
	return c.EnablePageChecksum
}

func (c *CreateOutputOutputGoogleCloudStorage) GetEmptyDirCleanupSec() *float64 {
	if c == nil {
		return nil
	}
	return c.EmptyDirCleanupSec
}

func (c *CreateOutputOutputGoogleCloudStorage) GetDirectoryBatchSize() *float64 {
	if c == nil {
		return nil
	}
	return c.DirectoryBatchSize
}

func (c *CreateOutputOutputGoogleCloudStorage) GetDeadletterPath() *string {
	if c == nil {
		return nil
	}
	return c.DeadletterPath
}

func (c *CreateOutputOutputGoogleCloudStorage) GetMaxRetryNum() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRetryNum
}

func (c *CreateOutputOutputGoogleCloudStorage) GetAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsAPIKey
}

func (c *CreateOutputOutputGoogleCloudStorage) GetAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecretKey
}

func (c *CreateOutputOutputGoogleCloudStorage) GetAwsSecret() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecret
}

func (c *CreateOutputOutputGoogleCloudStorage) GetTemplateBucket() *string {
	if c == nil {
		return nil
	}
	return c.TemplateBucket
}

func (c *CreateOutputOutputGoogleCloudStorage) GetTemplateRegion() *string {
	if c == nil {
		return nil
	}
	return c.TemplateRegion
}

func (c *CreateOutputOutputGoogleCloudStorage) GetTemplateFormat() *string {
	if c == nil {
		return nil
	}
	return c.TemplateFormat
}

type CreateOutputTypeGoogleChronicle string

const (
	CreateOutputTypeGoogleChronicleGoogleChronicle CreateOutputTypeGoogleChronicle = "google_chronicle"
)

func (e CreateOutputTypeGoogleChronicle) ToPointer() *CreateOutputTypeGoogleChronicle {
	return &e
}
func (e *CreateOutputTypeGoogleChronicle) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "google_chronicle":
		*e = CreateOutputTypeGoogleChronicle(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeGoogleChronicle: %v", v)
	}
}

type CreateOutputAPIVersion string

const (
	// CreateOutputAPIVersionV1 V1
	CreateOutputAPIVersionV1 CreateOutputAPIVersion = "v1"
	// CreateOutputAPIVersionV2 V2
	CreateOutputAPIVersionV2 CreateOutputAPIVersion = "v2"
)

func (e CreateOutputAPIVersion) ToPointer() *CreateOutputAPIVersion {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputAPIVersion) IsExact() bool {
	if e != nil {
		switch *e {
		case "v1", "v2":
			return true
		}
	}
	return false
}

type CreateOutputAuthenticationMethodGoogleChronicle string

const (
	// CreateOutputAuthenticationMethodGoogleChronicleManual API key
	CreateOutputAuthenticationMethodGoogleChronicleManual CreateOutputAuthenticationMethodGoogleChronicle = "manual"
	// CreateOutputAuthenticationMethodGoogleChronicleSecret API key secret
	CreateOutputAuthenticationMethodGoogleChronicleSecret CreateOutputAuthenticationMethodGoogleChronicle = "secret"
	// CreateOutputAuthenticationMethodGoogleChronicleServiceAccount Service account credentials
	CreateOutputAuthenticationMethodGoogleChronicleServiceAccount CreateOutputAuthenticationMethodGoogleChronicle = "serviceAccount"
	// CreateOutputAuthenticationMethodGoogleChronicleServiceAccountSecret Service account credentials secret
	CreateOutputAuthenticationMethodGoogleChronicleServiceAccountSecret CreateOutputAuthenticationMethodGoogleChronicle = "serviceAccountSecret"
)

func (e CreateOutputAuthenticationMethodGoogleChronicle) ToPointer() *CreateOutputAuthenticationMethodGoogleChronicle {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputAuthenticationMethodGoogleChronicle) IsExact() bool {
	if e != nil {
		switch *e {
		case "manual", "secret", "serviceAccount", "serviceAccountSecret":
			return true
		}
	}
	return false
}

type CreateOutputSendEventsAs string

const (
	// CreateOutputSendEventsAsUnstructured Unstructured
	CreateOutputSendEventsAsUnstructured CreateOutputSendEventsAs = "unstructured"
	// CreateOutputSendEventsAsUdm UDM
	CreateOutputSendEventsAsUdm CreateOutputSendEventsAs = "udm"
)

func (e CreateOutputSendEventsAs) ToPointer() *CreateOutputSendEventsAs {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputSendEventsAs) IsExact() bool {
	if e != nil {
		switch *e {
		case "unstructured", "udm":
			return true
		}
	}
	return false
}

type CreateOutputExtraLogType struct {
	LogType     string  `json:"logType"`
	Description *string `json:"description,omitempty"`
}

func (c CreateOutputExtraLogType) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputExtraLogType) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"logType"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputExtraLogType) GetLogType() string {
	if c == nil {
		return ""
	}
	return c.LogType
}

func (c *CreateOutputExtraLogType) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

// CreateOutputUDMType - Defines the specific format for UDM events sent to Google SecOps. This must match the type of UDM data being sent.
type CreateOutputUDMType string

const (
	CreateOutputUDMTypeEntities CreateOutputUDMType = "entities"
	CreateOutputUDMTypeLogs     CreateOutputUDMType = "logs"
)

func (e CreateOutputUDMType) ToPointer() *CreateOutputUDMType {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputUDMType) IsExact() bool {
	if e != nil {
		switch *e {
		case "entities", "logs":
			return true
		}
	}
	return false
}

type CreateOutputPqControlsGoogleChronicle struct {
}

func (c CreateOutputPqControlsGoogleChronicle) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsGoogleChronicle) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputGoogleChronicle struct {
	// Unique ID for this output
	ID   string                          `json:"id"`
	Type CreateOutputTypeGoogleChronicle `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags           []string                                         `json:"streamtags,omitempty"`
	APIVersion           *CreateOutputAPIVersion                          `json:"apiVersion,omitempty"`
	AuthenticationMethod *CreateOutputAuthenticationMethodGoogleChronicle `json:"authenticationMethod,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool                    `json:"responseHonorRetryAfterHeader,omitempty"`
	LogFormatType                 CreateOutputSendEventsAs `json:"logFormatType"`
	// Regional endpoint to send events to
	Region *string `json:"region,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	// Custom log types. If the value "Custom" is selected in the setting "Default log type" above, the first custom log type in this table will be automatically selected as default log type.
	ExtraLogTypes []CreateOutputExtraLogType `json:"extraLogTypes,omitempty"`
	// Default log type value to send to SecOps. Can be overwritten by event field __logType.
	LogType *string `json:"logType,omitempty"`
	// Name of the event field that contains the log text to send. If not specified, Stream sends a JSON representation of the whole event.
	LogTextField *string `json:"logTextField,omitempty"`
	// A unique identifier (UUID) for your Google SecOps instance. This is provided by your Google representative and is required for API V2 authentication.
	CustomerID *string `json:"customerId,omitempty"`
	// User-configured environment namespace to identify the data domain the logs originated from. Use namespace as a tag to identify the appropriate data domain for indexing and enrichment functionality. Can be overwritten by event field __namespace.
	Namespace *string `json:"namespace,omitempty"`
	// Custom labels to be added to every batch
	CustomLabels []components.ItemsTypeKeyValueMetadata `json:"customLabels,omitempty"`
	// Defines the specific format for UDM events sent to Google SecOps. This must match the type of UDM data being sent.
	UdmType *CreateOutputUDMType `json:"udmType,omitempty"`
	// Organization's API key in Google SecOps
	APIKey *string `json:"apiKey,omitempty"`
	// Select or create a stored text secret
	APIKeySecret *string `json:"apiKeySecret,omitempty"`
	// Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
	ServiceAccountCredentials *string `json:"serviceAccountCredentials,omitempty"`
	// Select or create a stored text secret
	ServiceAccountCredentialsSecret *string `json:"serviceAccountCredentialsSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions   `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsGoogleChronicle `json:"pqControls,omitempty"`
	// Binds 'apiVersion' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'apiVersion' at runtime.
	TemplateAPIVersion *string `json:"__template_apiVersion,omitempty"`
	// Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime.
	TemplateRegion *string `json:"__template_region,omitempty"`
	// Binds 'customerId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'customerId' at runtime.
	TemplateCustomerID *string `json:"__template_customerId,omitempty"`
}

func (c CreateOutputOutputGoogleChronicle) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputGoogleChronicle) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "logFormatType"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputGoogleChronicle) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputGoogleChronicle) GetType() CreateOutputTypeGoogleChronicle {
	if c == nil {
		return CreateOutputTypeGoogleChronicle("")
	}
	return c.Type
}

func (c *CreateOutputOutputGoogleChronicle) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputGoogleChronicle) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputGoogleChronicle) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputGoogleChronicle) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputGoogleChronicle) GetAPIVersion() *CreateOutputAPIVersion {
	if c == nil {
		return nil
	}
	return c.APIVersion
}

func (c *CreateOutputOutputGoogleChronicle) GetAuthenticationMethod() *CreateOutputAuthenticationMethodGoogleChronicle {
	if c == nil {
		return nil
	}
	return c.AuthenticationMethod
}

func (c *CreateOutputOutputGoogleChronicle) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputGoogleChronicle) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputGoogleChronicle) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputGoogleChronicle) GetLogFormatType() CreateOutputSendEventsAs {
	if c == nil {
		return CreateOutputSendEventsAs("")
	}
	return c.LogFormatType
}

func (c *CreateOutputOutputGoogleChronicle) GetRegion() *string {
	if c == nil {
		return nil
	}
	return c.Region
}

func (c *CreateOutputOutputGoogleChronicle) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputGoogleChronicle) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputGoogleChronicle) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputGoogleChronicle) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputGoogleChronicle) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputGoogleChronicle) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputGoogleChronicle) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputGoogleChronicle) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputGoogleChronicle) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputGoogleChronicle) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputGoogleChronicle) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputGoogleChronicle) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputGoogleChronicle) GetTotalMemoryLimitKB() *float64 {
	if c == nil {
		return nil
	}
	return c.TotalMemoryLimitKB
}

func (c *CreateOutputOutputGoogleChronicle) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputGoogleChronicle) GetExtraLogTypes() []CreateOutputExtraLogType {
	if c == nil {
		return nil
	}
	return c.ExtraLogTypes
}

func (c *CreateOutputOutputGoogleChronicle) GetLogType() *string {
	if c == nil {
		return nil
	}
	return c.LogType
}

func (c *CreateOutputOutputGoogleChronicle) GetLogTextField() *string {
	if c == nil {
		return nil
	}
	return c.LogTextField
}

func (c *CreateOutputOutputGoogleChronicle) GetCustomerID() *string {
	if c == nil {
		return nil
	}
	return c.CustomerID
}

func (c *CreateOutputOutputGoogleChronicle) GetNamespace() *string {
	if c == nil {
		return nil
	}
	return c.Namespace
}

func (c *CreateOutputOutputGoogleChronicle) GetCustomLabels() []components.ItemsTypeKeyValueMetadata {
	if c == nil {
		return nil
	}
	return c.CustomLabels
}

func (c *CreateOutputOutputGoogleChronicle) GetUdmType() *CreateOutputUDMType {
	if c == nil {
		return nil
	}
	return c.UdmType
}

func (c *CreateOutputOutputGoogleChronicle) GetAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.APIKey
}

func (c *CreateOutputOutputGoogleChronicle) GetAPIKeySecret() *string {
	if c == nil {
		return nil
	}
	return c.APIKeySecret
}

func (c *CreateOutputOutputGoogleChronicle) GetServiceAccountCredentials() *string {
	if c == nil {
		return nil
	}
	return c.ServiceAccountCredentials
}

func (c *CreateOutputOutputGoogleChronicle) GetServiceAccountCredentialsSecret() *string {
	if c == nil {
		return nil
	}
	return c.ServiceAccountCredentialsSecret
}

func (c *CreateOutputOutputGoogleChronicle) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputGoogleChronicle) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputGoogleChronicle) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputGoogleChronicle) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputGoogleChronicle) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputGoogleChronicle) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputGoogleChronicle) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputGoogleChronicle) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputGoogleChronicle) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputGoogleChronicle) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputGoogleChronicle) GetPqControls() *CreateOutputPqControlsGoogleChronicle {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputGoogleChronicle) GetTemplateAPIVersion() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAPIVersion
}

func (c *CreateOutputOutputGoogleChronicle) GetTemplateRegion() *string {
	if c == nil {
		return nil
	}
	return c.TemplateRegion
}

func (c *CreateOutputOutputGoogleChronicle) GetTemplateCustomerID() *string {
	if c == nil {
		return nil
	}
	return c.TemplateCustomerID
}

type CreateOutputTypeAzureEventhub string

const (
	CreateOutputTypeAzureEventhubAzureEventhub CreateOutputTypeAzureEventhub = "azure_eventhub"
)

func (e CreateOutputTypeAzureEventhub) ToPointer() *CreateOutputTypeAzureEventhub {
	return &e
}
func (e *CreateOutputTypeAzureEventhub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_eventhub":
		*e = CreateOutputTypeAzureEventhub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeAzureEventhub: %v", v)
	}
}

type CreateOutputPqControlsAzureEventhub struct {
}

func (c CreateOutputPqControlsAzureEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsAzureEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputAzureEventhub struct {
	// Unique ID for this output
	ID   string                        `json:"id"`
	Type CreateOutputTypeAzureEventhub `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// List of Event Hubs Kafka brokers to connect to, eg. yourdomain.servicebus.windows.net:9093. The hostname can be found in the host portion of the primary or secondary connection string in Shared Access Policies.
	Brokers []string `json:"brokers"`
	// The name of the Event Hub (Kafka Topic) to publish events. Can be overwritten using field __topicOut.
	Topic string `json:"topic"`
	// Control the number of required acknowledgments
	Ack *components.AcknowledgmentsOptions `json:"ack,omitempty"`
	// Format to use to serialize events before writing to the Event Hubs Kafka brokers
	Format *components.RecordDataFormatOptions `json:"format,omitempty"`
	// Maximum size of each record batch before compression. Setting should be < message.max.bytes settings in Event Hubs brokers.
	MaxRecordSizeKB *float64 `json:"maxRecordSizeKB,omitempty"`
	// Maximum number of events in a batch before forcing a flush
	FlushEventCount *float64 `json:"flushEventCount,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `json:"requestTimeout,omitempty"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `json:"maxRetries,omitempty"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `json:"maxBackOff,omitempty"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `json:"initialBackoff,omitempty"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `json:"backoffRate,omitempty"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `json:"authenticationTimeout,omitempty"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `json:"reauthenticationThreshold,omitempty"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *components.AuthenticationType1       `json:"sasl,omitempty"`
	TLS  *components.TLSSettingsClientSideType `json:"tls,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsAzureEventhub `json:"pqControls,omitempty"`
	// Binds 'topic' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'topic' at runtime.
	TemplateTopic *string `json:"__template_topic,omitempty"`
}

func (c CreateOutputOutputAzureEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputAzureEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "brokers", "topic"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputAzureEventhub) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputAzureEventhub) GetType() CreateOutputTypeAzureEventhub {
	if c == nil {
		return CreateOutputTypeAzureEventhub("")
	}
	return c.Type
}

func (c *CreateOutputOutputAzureEventhub) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputAzureEventhub) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputAzureEventhub) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputAzureEventhub) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputAzureEventhub) GetBrokers() []string {
	if c == nil {
		return []string{}
	}
	return c.Brokers
}

func (c *CreateOutputOutputAzureEventhub) GetTopic() string {
	if c == nil {
		return ""
	}
	return c.Topic
}

func (c *CreateOutputOutputAzureEventhub) GetAck() *components.AcknowledgmentsOptions {
	if c == nil {
		return nil
	}
	return c.Ack
}

func (c *CreateOutputOutputAzureEventhub) GetFormat() *components.RecordDataFormatOptions {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputAzureEventhub) GetMaxRecordSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRecordSizeKB
}

func (c *CreateOutputOutputAzureEventhub) GetFlushEventCount() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushEventCount
}

func (c *CreateOutputOutputAzureEventhub) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputAzureEventhub) GetConnectionTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.ConnectionTimeout
}

func (c *CreateOutputOutputAzureEventhub) GetRequestTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.RequestTimeout
}

func (c *CreateOutputOutputAzureEventhub) GetMaxRetries() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRetries
}

func (c *CreateOutputOutputAzureEventhub) GetMaxBackOff() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxBackOff
}

func (c *CreateOutputOutputAzureEventhub) GetInitialBackoff() *float64 {
	if c == nil {
		return nil
	}
	return c.InitialBackoff
}

func (c *CreateOutputOutputAzureEventhub) GetBackoffRate() *float64 {
	if c == nil {
		return nil
	}
	return c.BackoffRate
}

func (c *CreateOutputOutputAzureEventhub) GetAuthenticationTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.AuthenticationTimeout
}

func (c *CreateOutputOutputAzureEventhub) GetReauthenticationThreshold() *float64 {
	if c == nil {
		return nil
	}
	return c.ReauthenticationThreshold
}

func (c *CreateOutputOutputAzureEventhub) GetSasl() *components.AuthenticationType1 {
	if c == nil {
		return nil
	}
	return c.Sasl
}

func (c *CreateOutputOutputAzureEventhub) GetTLS() *components.TLSSettingsClientSideType {
	if c == nil {
		return nil
	}
	return c.TLS
}

func (c *CreateOutputOutputAzureEventhub) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputAzureEventhub) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputAzureEventhub) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputAzureEventhub) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputAzureEventhub) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputAzureEventhub) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputAzureEventhub) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputAzureEventhub) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputAzureEventhub) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputAzureEventhub) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputAzureEventhub) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputAzureEventhub) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputAzureEventhub) GetPqControls() *CreateOutputPqControlsAzureEventhub {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputAzureEventhub) GetTemplateTopic() *string {
	if c == nil {
		return nil
	}
	return c.TemplateTopic
}

type CreateOutputTypeHoneycomb string

const (
	CreateOutputTypeHoneycombHoneycomb CreateOutputTypeHoneycomb = "honeycomb"
)

func (e CreateOutputTypeHoneycomb) ToPointer() *CreateOutputTypeHoneycomb {
	return &e
}
func (e *CreateOutputTypeHoneycomb) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "honeycomb":
		*e = CreateOutputTypeHoneycomb(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeHoneycomb: %v", v)
	}
}

type CreateOutputPqControlsHoneycomb struct {
}

func (c CreateOutputPqControlsHoneycomb) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsHoneycomb) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputHoneycomb struct {
	// Unique ID for this output
	ID   string                    `json:"id"`
	Type CreateOutputTypeHoneycomb `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the dataset to send events to – e.g., observability
	Dataset string `json:"dataset"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Enter API key directly, or select a stored secret
	AuthType    *components.AuthenticationMethodOptions2 `json:"authType,omitempty"`
	Description *string                                  `json:"description,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsHoneycomb     `json:"pqControls,omitempty"`
	// Team API key where the dataset belongs
	Team *string `json:"team,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
}

func (c CreateOutputOutputHoneycomb) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputHoneycomb) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "dataset"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputHoneycomb) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputHoneycomb) GetType() CreateOutputTypeHoneycomb {
	if c == nil {
		return CreateOutputTypeHoneycomb("")
	}
	return c.Type
}

func (c *CreateOutputOutputHoneycomb) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputHoneycomb) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputHoneycomb) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputHoneycomb) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputHoneycomb) GetDataset() string {
	if c == nil {
		return ""
	}
	return c.Dataset
}

func (c *CreateOutputOutputHoneycomb) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputHoneycomb) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputHoneycomb) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputHoneycomb) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputHoneycomb) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputHoneycomb) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputHoneycomb) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputHoneycomb) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputHoneycomb) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputHoneycomb) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputHoneycomb) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputHoneycomb) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputHoneycomb) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputHoneycomb) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputHoneycomb) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputHoneycomb) GetAuthType() *components.AuthenticationMethodOptions2 {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputHoneycomb) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputHoneycomb) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputHoneycomb) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputHoneycomb) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputHoneycomb) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputHoneycomb) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputHoneycomb) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputHoneycomb) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputHoneycomb) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputHoneycomb) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputHoneycomb) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputHoneycomb) GetPqControls() *CreateOutputPqControlsHoneycomb {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputHoneycomb) GetTeam() *string {
	if c == nil {
		return nil
	}
	return c.Team
}

func (c *CreateOutputOutputHoneycomb) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

type CreateOutputTypeKinesis string

const (
	CreateOutputTypeKinesisKinesis CreateOutputTypeKinesis = "kinesis"
)

func (e CreateOutputTypeKinesis) ToPointer() *CreateOutputTypeKinesis {
	return &e
}
func (e *CreateOutputTypeKinesis) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kinesis":
		*e = CreateOutputTypeKinesis(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeKinesis: %v", v)
	}
}

// CreateOutputCompression - Compression type to use for records
type CreateOutputCompression string

const (
	// CreateOutputCompressionNone None
	CreateOutputCompressionNone CreateOutputCompression = "none"
	// CreateOutputCompressionGzip Gzip
	CreateOutputCompressionGzip CreateOutputCompression = "gzip"
)

func (e CreateOutputCompression) ToPointer() *CreateOutputCompression {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputCompression) IsExact() bool {
	if e != nil {
		switch *e {
		case "none", "gzip":
			return true
		}
	}
	return false
}

type CreateOutputPqControlsKinesis struct {
}

func (c CreateOutputPqControlsKinesis) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsKinesis) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputKinesis struct {
	// Unique ID for this output
	ID   string                  `json:"id"`
	Type CreateOutputTypeKinesis `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Kinesis stream name to send events to.
	StreamName string `json:"streamName"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitempty"`
	AwsSecretKey            *string                                                `json:"awsSecretKey,omitempty"`
	// Region where the Kinesis stream is located
	Region string `json:"region"`
	// Kinesis stream service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to Kinesis stream-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing Kinesis stream requests
	SignatureVersion *components.SignatureVersionOptions2 `json:"signatureVersion,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Use Assume Role credentials to access Kinesis stream
	EnableAssumeRole *bool `json:"enableAssumeRole,omitempty"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitempty"`
	// Maximum number of ongoing put requests before blocking.
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size (KB) of each individual record before compression. For uncompressed or non-compressible data 1MB is the max recommended size
	MaxRecordSizeKB *float64 `json:"maxRecordSizeKB,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Compression type to use for records
	Compression *CreateOutputCompression `json:"compression,omitempty"`
	// Provides higher stream rate limits, improving delivery speed and reliability by minimizing throttling. See the [ListShards API](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_ListShards.html) documentation for details.
	UseListShards *bool `json:"useListShards,omitempty"`
	// Batch events into a single record as NDJSON
	AsNdjson *bool `json:"asNdjson,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	AwsAPIKey      *string                                 `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Maximum number of records to send in a single request
	MaxEventsPerFlush *float64 `json:"maxEventsPerFlush,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsKinesis       `json:"pqControls,omitempty"`
	// Binds 'streamName' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'streamName' at runtime.
	TemplateStreamName *string `json:"__template_streamName,omitempty"`
	// Binds 'awsSecretKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsSecretKey' at runtime.
	TemplateAwsSecretKey *string `json:"__template_awsSecretKey,omitempty"`
	// Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime.
	TemplateRegion *string `json:"__template_region,omitempty"`
	// Binds 'assumeRoleArn' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleArn' at runtime.
	TemplateAssumeRoleArn *string `json:"__template_assumeRoleArn,omitempty"`
	// Binds 'assumeRoleExternalId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleExternalId' at runtime.
	TemplateAssumeRoleExternalID *string `json:"__template_assumeRoleExternalId,omitempty"`
	// Binds 'awsApiKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsApiKey' at runtime.
	TemplateAwsAPIKey *string `json:"__template_awsApiKey,omitempty"`
}

func (c CreateOutputOutputKinesis) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputKinesis) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "streamName", "region"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputKinesis) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputKinesis) GetType() CreateOutputTypeKinesis {
	if c == nil {
		return CreateOutputTypeKinesis("")
	}
	return c.Type
}

func (c *CreateOutputOutputKinesis) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputKinesis) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputKinesis) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputKinesis) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputKinesis) GetStreamName() string {
	if c == nil {
		return ""
	}
	return c.StreamName
}

func (c *CreateOutputOutputKinesis) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if c == nil {
		return nil
	}
	return c.AwsAuthenticationMethod
}

func (c *CreateOutputOutputKinesis) GetAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecretKey
}

func (c *CreateOutputOutputKinesis) GetRegion() string {
	if c == nil {
		return ""
	}
	return c.Region
}

func (c *CreateOutputOutputKinesis) GetEndpoint() *string {
	if c == nil {
		return nil
	}
	return c.Endpoint
}

func (c *CreateOutputOutputKinesis) GetSignatureVersion() *components.SignatureVersionOptions2 {
	if c == nil {
		return nil
	}
	return c.SignatureVersion
}

func (c *CreateOutputOutputKinesis) GetReuseConnections() *bool {
	if c == nil {
		return nil
	}
	return c.ReuseConnections
}

func (c *CreateOutputOutputKinesis) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputKinesis) GetEnableAssumeRole() *bool {
	if c == nil {
		return nil
	}
	return c.EnableAssumeRole
}

func (c *CreateOutputOutputKinesis) GetAssumeRoleArn() *string {
	if c == nil {
		return nil
	}
	return c.AssumeRoleArn
}

func (c *CreateOutputOutputKinesis) GetAssumeRoleExternalID() *string {
	if c == nil {
		return nil
	}
	return c.AssumeRoleExternalID
}

func (c *CreateOutputOutputKinesis) GetDurationSeconds() *float64 {
	if c == nil {
		return nil
	}
	return c.DurationSeconds
}

func (c *CreateOutputOutputKinesis) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputKinesis) GetMaxRecordSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRecordSizeKB
}

func (c *CreateOutputOutputKinesis) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputKinesis) GetCompression() *CreateOutputCompression {
	if c == nil {
		return nil
	}
	return c.Compression
}

func (c *CreateOutputOutputKinesis) GetUseListShards() *bool {
	if c == nil {
		return nil
	}
	return c.UseListShards
}

func (c *CreateOutputOutputKinesis) GetAsNdjson() *bool {
	if c == nil {
		return nil
	}
	return c.AsNdjson
}

func (c *CreateOutputOutputKinesis) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputKinesis) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputKinesis) GetAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsAPIKey
}

func (c *CreateOutputOutputKinesis) GetAwsSecret() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecret
}

func (c *CreateOutputOutputKinesis) GetMaxEventsPerFlush() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxEventsPerFlush
}

func (c *CreateOutputOutputKinesis) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputKinesis) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputKinesis) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputKinesis) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputKinesis) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputKinesis) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputKinesis) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputKinesis) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputKinesis) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputKinesis) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputKinesis) GetPqControls() *CreateOutputPqControlsKinesis {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputKinesis) GetTemplateStreamName() *string {
	if c == nil {
		return nil
	}
	return c.TemplateStreamName
}

func (c *CreateOutputOutputKinesis) GetTemplateAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAwsSecretKey
}

func (c *CreateOutputOutputKinesis) GetTemplateRegion() *string {
	if c == nil {
		return nil
	}
	return c.TemplateRegion
}

func (c *CreateOutputOutputKinesis) GetTemplateAssumeRoleArn() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAssumeRoleArn
}

func (c *CreateOutputOutputKinesis) GetTemplateAssumeRoleExternalID() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAssumeRoleExternalID
}

func (c *CreateOutputOutputKinesis) GetTemplateAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAwsAPIKey
}

type CreateOutputTypeAzureLogs string

const (
	CreateOutputTypeAzureLogsAzureLogs CreateOutputTypeAzureLogs = "azure_logs"
)

func (e CreateOutputTypeAzureLogs) ToPointer() *CreateOutputTypeAzureLogs {
	return &e
}
func (e *CreateOutputTypeAzureLogs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_logs":
		*e = CreateOutputTypeAzureLogs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeAzureLogs: %v", v)
	}
}

// CreateOutputAuthenticationMethodAzureLogs - Enter workspace ID and workspace key directly, or select a stored secret
type CreateOutputAuthenticationMethodAzureLogs string

const (
	CreateOutputAuthenticationMethodAzureLogsManual CreateOutputAuthenticationMethodAzureLogs = "manual"
	CreateOutputAuthenticationMethodAzureLogsSecret CreateOutputAuthenticationMethodAzureLogs = "secret"
)

func (e CreateOutputAuthenticationMethodAzureLogs) ToPointer() *CreateOutputAuthenticationMethodAzureLogs {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputAuthenticationMethodAzureLogs) IsExact() bool {
	if e != nil {
		switch *e {
		case "manual", "secret":
			return true
		}
	}
	return false
}

type CreateOutputPqControlsAzureLogs struct {
}

func (c CreateOutputPqControlsAzureLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsAzureLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputAzureLogs struct {
	// Unique ID for this output
	ID   string                    `json:"id"`
	Type CreateOutputTypeAzureLogs `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The Log Type of events sent to this LogAnalytics workspace. Defaults to `Cribl`. Use only letters, numbers, and `_` characters, and can't exceed 100 characters. Can be overwritten by event field __logType.
	LogType string `json:"logType"`
	// Optional Resource ID of the Azure resource to associate the data with. Can be overridden by the __resourceId event field. This ID populates the _ResourceId property, allowing the data to be included in resource-centric queries. If the ID is neither specified nor overridden, resource-centric queries will omit the data.
	ResourceID *string `json:"resourceId,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	Compress         *bool    `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// The DNS name of the Log API endpoint that sends log data to a Log Analytics workspace in Azure Monitor. Defaults to .ods.opinsights.azure.com. @{product} will add a prefix and suffix to construct a URI in this format: <https://<Workspace_ID><your_DNS_name>/api/logs?api-version=<API version>.
	APIURL *string `json:"apiUrl,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Enter workspace ID and workspace key directly, or select a stored secret
	AuthType    *CreateOutputAuthenticationMethodAzureLogs `json:"authType,omitempty"`
	Description *string                                    `json:"description,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsAzureLogs     `json:"pqControls,omitempty"`
	// Azure Log Analytics Workspace ID. See Azure Dashboard Workspace > Advanced settings.
	WorkspaceID *string `json:"workspaceId,omitempty"`
	// Azure Log Analytics Workspace Primary or Secondary Shared Key. See Azure Dashboard Workspace > Advanced settings.
	WorkspaceKey *string `json:"workspaceKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	KeypairSecret *string `json:"keypairSecret,omitempty"`
	// Binds 'workspaceId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'workspaceId' at runtime.
	TemplateWorkspaceID *string `json:"__template_workspaceId,omitempty"`
	// Binds 'workspaceKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'workspaceKey' at runtime.
	TemplateWorkspaceKey *string `json:"__template_workspaceKey,omitempty"`
}

func (c CreateOutputOutputAzureLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputAzureLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "logType"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputAzureLogs) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputAzureLogs) GetType() CreateOutputTypeAzureLogs {
	if c == nil {
		return CreateOutputTypeAzureLogs("")
	}
	return c.Type
}

func (c *CreateOutputOutputAzureLogs) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputAzureLogs) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputAzureLogs) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputAzureLogs) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputAzureLogs) GetLogType() string {
	if c == nil {
		return ""
	}
	return c.LogType
}

func (c *CreateOutputOutputAzureLogs) GetResourceID() *string {
	if c == nil {
		return nil
	}
	return c.ResourceID
}

func (c *CreateOutputOutputAzureLogs) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputAzureLogs) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputAzureLogs) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputAzureLogs) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputAzureLogs) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputAzureLogs) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputAzureLogs) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputAzureLogs) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputAzureLogs) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputAzureLogs) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputAzureLogs) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputAzureLogs) GetAPIURL() *string {
	if c == nil {
		return nil
	}
	return c.APIURL
}

func (c *CreateOutputOutputAzureLogs) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputAzureLogs) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputAzureLogs) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputAzureLogs) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputAzureLogs) GetAuthType() *CreateOutputAuthenticationMethodAzureLogs {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputAzureLogs) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputAzureLogs) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputAzureLogs) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputAzureLogs) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputAzureLogs) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputAzureLogs) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputAzureLogs) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputAzureLogs) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputAzureLogs) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputAzureLogs) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputAzureLogs) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputAzureLogs) GetPqControls() *CreateOutputPqControlsAzureLogs {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputAzureLogs) GetWorkspaceID() *string {
	if c == nil {
		return nil
	}
	return c.WorkspaceID
}

func (c *CreateOutputOutputAzureLogs) GetWorkspaceKey() *string {
	if c == nil {
		return nil
	}
	return c.WorkspaceKey
}

func (c *CreateOutputOutputAzureLogs) GetKeypairSecret() *string {
	if c == nil {
		return nil
	}
	return c.KeypairSecret
}

func (c *CreateOutputOutputAzureLogs) GetTemplateWorkspaceID() *string {
	if c == nil {
		return nil
	}
	return c.TemplateWorkspaceID
}

func (c *CreateOutputOutputAzureLogs) GetTemplateWorkspaceKey() *string {
	if c == nil {
		return nil
	}
	return c.TemplateWorkspaceKey
}

type CreateOutputTypeAzureDataExplorer string

const (
	CreateOutputTypeAzureDataExplorerAzureDataExplorer CreateOutputTypeAzureDataExplorer = "azure_data_explorer"
)

func (e CreateOutputTypeAzureDataExplorer) ToPointer() *CreateOutputTypeAzureDataExplorer {
	return &e
}
func (e *CreateOutputTypeAzureDataExplorer) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_data_explorer":
		*e = CreateOutputTypeAzureDataExplorer(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeAzureDataExplorer: %v", v)
	}
}

type CreateOutputIngestionMode string

const (
	// CreateOutputIngestionModeBatching Batching
	CreateOutputIngestionModeBatching CreateOutputIngestionMode = "batching"
	// CreateOutputIngestionModeStreaming Streaming
	CreateOutputIngestionModeStreaming CreateOutputIngestionMode = "streaming"
)

func (e CreateOutputIngestionMode) ToPointer() *CreateOutputIngestionMode {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputIngestionMode) IsExact() bool {
	if e != nil {
		switch *e {
		case "batching", "streaming":
			return true
		}
	}
	return false
}

// CreateOutputOauthTypeAuthenticationMethod - The type of OAuth 2.0 client credentials grant flow to use
type CreateOutputOauthTypeAuthenticationMethod string

const (
	// CreateOutputOauthTypeAuthenticationMethodClientSecret Client secret
	CreateOutputOauthTypeAuthenticationMethodClientSecret CreateOutputOauthTypeAuthenticationMethod = "clientSecret"
	// CreateOutputOauthTypeAuthenticationMethodClientTextSecret Client secret (text secret)
	CreateOutputOauthTypeAuthenticationMethodClientTextSecret CreateOutputOauthTypeAuthenticationMethod = "clientTextSecret"
	// CreateOutputOauthTypeAuthenticationMethodCertificate Certificate
	CreateOutputOauthTypeAuthenticationMethodCertificate CreateOutputOauthTypeAuthenticationMethod = "certificate"
)

func (e CreateOutputOauthTypeAuthenticationMethod) ToPointer() *CreateOutputOauthTypeAuthenticationMethod {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputOauthTypeAuthenticationMethod) IsExact() bool {
	if e != nil {
		switch *e {
		case "clientSecret", "clientTextSecret", "certificate":
			return true
		}
	}
	return false
}

type CreateOutputCertificate struct {
	// The certificate you registered as credentials for your app in the Azure portal
	CertificateName *string `json:"certificateName,omitempty"`
}

func (c CreateOutputCertificate) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputCertificate) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputCertificate) GetCertificateName() *string {
	if c == nil {
		return nil
	}
	return c.CertificateName
}

type CreateOutputPrefixOptional string

const (
	// CreateOutputPrefixOptionalDropBy drop-by
	CreateOutputPrefixOptionalDropBy CreateOutputPrefixOptional = "dropBy"
	// CreateOutputPrefixOptionalIngestBy ingest-by
	CreateOutputPrefixOptionalIngestBy CreateOutputPrefixOptional = "ingestBy"
)

func (e CreateOutputPrefixOptional) ToPointer() *CreateOutputPrefixOptional {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputPrefixOptional) IsExact() bool {
	if e != nil {
		switch *e {
		case "dropBy", "ingestBy":
			return true
		}
	}
	return false
}

type CreateOutputExtentTag struct {
	Prefix *CreateOutputPrefixOptional `json:"prefix,omitempty"`
	Value  string                      `json:"value"`
}

func (c CreateOutputExtentTag) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputExtentTag) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"value"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputExtentTag) GetPrefix() *CreateOutputPrefixOptional {
	if c == nil {
		return nil
	}
	return c.Prefix
}

func (c *CreateOutputExtentTag) GetValue() string {
	if c == nil {
		return ""
	}
	return c.Value
}

type CreateOutputIngestIfNotExist struct {
	Value string `json:"value"`
}

func (c CreateOutputIngestIfNotExist) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputIngestIfNotExist) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"value"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputIngestIfNotExist) GetValue() string {
	if c == nil {
		return ""
	}
	return c.Value
}

// CreateOutputReportLevel - Level of ingestion status reporting. Defaults to FailuresOnly.
type CreateOutputReportLevel string

const (
	// CreateOutputReportLevelFailuresOnly FailuresOnly
	CreateOutputReportLevelFailuresOnly CreateOutputReportLevel = "failuresOnly"
	// CreateOutputReportLevelDoNotReport DoNotReport
	CreateOutputReportLevelDoNotReport CreateOutputReportLevel = "doNotReport"
	// CreateOutputReportLevelFailuresAndSuccesses FailuresAndSuccesses
	CreateOutputReportLevelFailuresAndSuccesses CreateOutputReportLevel = "failuresAndSuccesses"
)

func (e CreateOutputReportLevel) ToPointer() *CreateOutputReportLevel {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputReportLevel) IsExact() bool {
	if e != nil {
		switch *e {
		case "failuresOnly", "doNotReport", "failuresAndSuccesses":
			return true
		}
	}
	return false
}

// CreateOutputReportMethod - Target of the ingestion status reporting. Defaults to Queue.
type CreateOutputReportMethod string

const (
	// CreateOutputReportMethodQueue Queue
	CreateOutputReportMethodQueue CreateOutputReportMethod = "queue"
	// CreateOutputReportMethodTable Table
	CreateOutputReportMethodTable CreateOutputReportMethod = "table"
	// CreateOutputReportMethodQueueAndTable QueueAndTable
	CreateOutputReportMethodQueueAndTable CreateOutputReportMethod = "queueAndTable"
)

func (e CreateOutputReportMethod) ToPointer() *CreateOutputReportMethod {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputReportMethod) IsExact() bool {
	if e != nil {
		switch *e {
		case "queue", "table", "queueAndTable":
			return true
		}
	}
	return false
}

type CreateOutputAdditionalProperty struct {
	Key   string `json:"key"`
	Value string `json:"value"`
}

func (c CreateOutputAdditionalProperty) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputAdditionalProperty) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"key", "value"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputAdditionalProperty) GetKey() string {
	if c == nil {
		return ""
	}
	return c.Key
}

func (c *CreateOutputAdditionalProperty) GetValue() string {
	if c == nil {
		return ""
	}
	return c.Value
}

type CreateOutputPqControlsAzureDataExplorer struct {
}

func (c CreateOutputPqControlsAzureDataExplorer) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsAzureDataExplorer) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputAzureDataExplorer struct {
	// Unique ID for this output
	ID   string                            `json:"id"`
	Type CreateOutputTypeAzureDataExplorer `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The base URI for your cluster. Typically, `https://<cluster>.<region>.kusto.windows.net`.
	ClusterURL string `json:"clusterUrl"`
	// Name of the database containing the table where data will be ingested
	Database string `json:"database"`
	// Name of the table to ingest data into
	Table string `json:"table"`
	// When saving or starting the Destination, validate the database name and credentials; also validate table name, except when creating a new table. Disable if your Azure app does not have both the Database Viewer and the Table Viewer role.
	ValidateDatabaseSettings *bool                      `json:"validateDatabaseSettings,omitempty"`
	IngestMode               *CreateOutputIngestionMode `json:"ingestMode,omitempty"`
	// Endpoint used to acquire authentication tokens from Azure
	OauthEndpoint components.MicrosoftEntraIDAuthenticationEndpointOptionsSasl `json:"oauthEndpoint"`
	// Directory ID (tenant identifier) in Azure Active Directory
	TenantID string `json:"tenantId"`
	// client_id to pass in the OAuth request parameter
	ClientID string `json:"clientId"`
	// Scope to pass in the OAuth request parameter
	Scope string `json:"scope"`
	// The type of OAuth 2.0 client credentials grant flow to use
	OauthType   CreateOutputOauthTypeAuthenticationMethod `json:"oauthType"`
	Description *string                                   `json:"description,omitempty"`
	// The client secret that you generated for your app in the Azure portal
	ClientSecret *string `json:"clientSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret  *string                  `json:"textSecret,omitempty"`
	Certificate *CreateOutputCertificate `json:"certificate,omitempty"`
	// Format of the output data
	Format *components.DataFormatOptions `json:"format,omitempty"`
	// Data compression format to apply to HTTP content before it is delivered
	Compress components.CompressionOptions2 `json:"compress"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *components.CompressionLevelOptions `json:"compressionLevel,omitempty"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `json:"automaticSchema,omitempty"`
	// To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
	ParquetSchema *string `json:"parquetSchema,omitempty"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *components.ParquetVersionOptions `json:"parquetVersion,omitempty"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *components.DataPageVersionOptions `json:"parquetDataPageVersion,omitempty"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `json:"parquetRowGroupLength,omitempty"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
	KeyValueMetadata []components.ItemsTypeKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `json:"enableStatistics,omitempty"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `json:"enableWritePageIndex,omitempty"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `json:"enablePageChecksum,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `json:"emptyDirCleanupSec,omitempty"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `json:"directoryBatchSize,omitempty"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `json:"deadletterEnabled,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `json:"deadletterPath,omitempty"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `json:"maxRetryNum,omitempty"`
	// Send a JSON mapping object instead of specifying an existing named data mapping
	IsMappingObj *bool `json:"isMappingObj,omitempty"`
	// Enter a JSON object that defines your desired data mapping
	MappingObj *string `json:"mappingObj,omitempty"`
	// Enter the name of a data mapping associated with your target table. Or, if incoming event and target table fields match exactly, you can leave the field empty.
	MappingRef *string `json:"mappingRef,omitempty"`
	// The ingestion service URI for your cluster. Typically, `https://ingest-<cluster>.<region>.kusto.windows.net`.
	IngestURL *string `json:"ingestUrl,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Filesystem location in which to buffer files before compressing and moving to final destination. Use performant and stable storage.
	StagePath *string `json:"stagePath,omitempty"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `json:"fileNameSuffix,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `json:"maxFileSizeMB,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `json:"maxOpenFiles,omitempty"`
	// Maximum number of parts to upload in parallel per file
	MaxConcurrentFileParts *float64 `json:"maxConcurrentFileParts,omitempty"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *components.DiskSpaceProtectionOptions `json:"onDiskFullBackpressure,omitempty"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool                         `json:"addIdToStagePath,omitempty"`
	RetrySettings    *components.RetrySettingsType `json:"retrySettings,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Bypass the data management service's aggregation mechanism
	FlushImmediately *bool `json:"flushImmediately,omitempty"`
	// Prevent blob deletion after ingestion is complete
	RetainBlobOnSuccess *bool `json:"retainBlobOnSuccess,omitempty"`
	// Strings or tags associated with the extent (ingested data shard)
	ExtentTags []CreateOutputExtentTag `json:"extentTags,omitempty"`
	// Prevents duplicate ingestion by verifying whether an extent with the specified ingest-by tag already exists
	IngestIfNotExists []CreateOutputIngestIfNotExist `json:"ingestIfNotExists,omitempty"`
	// Level of ingestion status reporting. Defaults to FailuresOnly.
	ReportLevel *CreateOutputReportLevel `json:"reportLevel,omitempty"`
	// Target of the ingestion status reporting. Defaults to Queue.
	ReportMethod *CreateOutputReportMethod `json:"reportMethod,omitempty"`
	// Optionally, enter additional configuration properties to send to the ingestion service
	AdditionalProperties []CreateOutputAdditionalProperty `json:"additionalProperties,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Disable to close the connection immediately after sending the outgoing request
	KeepAlive *bool `json:"keepAlive,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions     `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsAzureDataExplorer `json:"pqControls,omitempty"`
	// Binds 'clusterUrl' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'clusterUrl' at runtime.
	TemplateClusterURL *string `json:"__template_clusterUrl,omitempty"`
	// Binds 'database' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'database' at runtime.
	TemplateDatabase *string `json:"__template_database,omitempty"`
	// Binds 'table' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'table' at runtime.
	TemplateTable *string `json:"__template_table,omitempty"`
	// Binds 'tenantId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'tenantId' at runtime.
	TemplateTenantID *string `json:"__template_tenantId,omitempty"`
	// Binds 'clientId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'clientId' at runtime.
	TemplateClientID *string `json:"__template_clientId,omitempty"`
	// Binds 'scope' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'scope' at runtime.
	TemplateScope *string `json:"__template_scope,omitempty"`
	// Binds 'clientSecret' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'clientSecret' at runtime.
	TemplateClientSecret *string `json:"__template_clientSecret,omitempty"`
	// Binds 'format' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'format' at runtime.
	TemplateFormat *string `json:"__template_format,omitempty"`
	// Binds 'ingestUrl' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'ingestUrl' at runtime.
	TemplateIngestURL *string `json:"__template_ingestUrl,omitempty"`
}

func (c CreateOutputOutputAzureDataExplorer) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputAzureDataExplorer) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "clusterUrl", "database", "table", "oauthEndpoint", "tenantId", "clientId", "scope", "oauthType", "compress"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputAzureDataExplorer) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputAzureDataExplorer) GetType() CreateOutputTypeAzureDataExplorer {
	if c == nil {
		return CreateOutputTypeAzureDataExplorer("")
	}
	return c.Type
}

func (c *CreateOutputOutputAzureDataExplorer) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputAzureDataExplorer) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputAzureDataExplorer) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputAzureDataExplorer) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputAzureDataExplorer) GetClusterURL() string {
	if c == nil {
		return ""
	}
	return c.ClusterURL
}

func (c *CreateOutputOutputAzureDataExplorer) GetDatabase() string {
	if c == nil {
		return ""
	}
	return c.Database
}

func (c *CreateOutputOutputAzureDataExplorer) GetTable() string {
	if c == nil {
		return ""
	}
	return c.Table
}

func (c *CreateOutputOutputAzureDataExplorer) GetValidateDatabaseSettings() *bool {
	if c == nil {
		return nil
	}
	return c.ValidateDatabaseSettings
}

func (c *CreateOutputOutputAzureDataExplorer) GetIngestMode() *CreateOutputIngestionMode {
	if c == nil {
		return nil
	}
	return c.IngestMode
}

func (c *CreateOutputOutputAzureDataExplorer) GetOauthEndpoint() components.MicrosoftEntraIDAuthenticationEndpointOptionsSasl {
	if c == nil {
		return components.MicrosoftEntraIDAuthenticationEndpointOptionsSasl("")
	}
	return c.OauthEndpoint
}

func (c *CreateOutputOutputAzureDataExplorer) GetTenantID() string {
	if c == nil {
		return ""
	}
	return c.TenantID
}

func (c *CreateOutputOutputAzureDataExplorer) GetClientID() string {
	if c == nil {
		return ""
	}
	return c.ClientID
}

func (c *CreateOutputOutputAzureDataExplorer) GetScope() string {
	if c == nil {
		return ""
	}
	return c.Scope
}

func (c *CreateOutputOutputAzureDataExplorer) GetOauthType() CreateOutputOauthTypeAuthenticationMethod {
	if c == nil {
		return CreateOutputOauthTypeAuthenticationMethod("")
	}
	return c.OauthType
}

func (c *CreateOutputOutputAzureDataExplorer) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputAzureDataExplorer) GetClientSecret() *string {
	if c == nil {
		return nil
	}
	return c.ClientSecret
}

func (c *CreateOutputOutputAzureDataExplorer) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputAzureDataExplorer) GetCertificate() *CreateOutputCertificate {
	if c == nil {
		return nil
	}
	return c.Certificate
}

func (c *CreateOutputOutputAzureDataExplorer) GetFormat() *components.DataFormatOptions {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputAzureDataExplorer) GetCompress() components.CompressionOptions2 {
	if c == nil {
		return components.CompressionOptions2("")
	}
	return c.Compress
}

func (c *CreateOutputOutputAzureDataExplorer) GetCompressionLevel() *components.CompressionLevelOptions {
	if c == nil {
		return nil
	}
	return c.CompressionLevel
}

func (c *CreateOutputOutputAzureDataExplorer) GetAutomaticSchema() *bool {
	if c == nil {
		return nil
	}
	return c.AutomaticSchema
}

func (c *CreateOutputOutputAzureDataExplorer) GetParquetSchema() *string {
	if c == nil {
		return nil
	}
	return c.ParquetSchema
}

func (c *CreateOutputOutputAzureDataExplorer) GetParquetVersion() *components.ParquetVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetVersion
}

func (c *CreateOutputOutputAzureDataExplorer) GetParquetDataPageVersion() *components.DataPageVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetDataPageVersion
}

func (c *CreateOutputOutputAzureDataExplorer) GetParquetRowGroupLength() *float64 {
	if c == nil {
		return nil
	}
	return c.ParquetRowGroupLength
}

func (c *CreateOutputOutputAzureDataExplorer) GetParquetPageSize() *string {
	if c == nil {
		return nil
	}
	return c.ParquetPageSize
}

func (c *CreateOutputOutputAzureDataExplorer) GetShouldLogInvalidRows() *bool {
	if c == nil {
		return nil
	}
	return c.ShouldLogInvalidRows
}

func (c *CreateOutputOutputAzureDataExplorer) GetKeyValueMetadata() []components.ItemsTypeKeyValueMetadata {
	if c == nil {
		return nil
	}
	return c.KeyValueMetadata
}

func (c *CreateOutputOutputAzureDataExplorer) GetEnableStatistics() *bool {
	if c == nil {
		return nil
	}
	return c.EnableStatistics
}

func (c *CreateOutputOutputAzureDataExplorer) GetEnableWritePageIndex() *bool {
	if c == nil {
		return nil
	}
	return c.EnableWritePageIndex
}

func (c *CreateOutputOutputAzureDataExplorer) GetEnablePageChecksum() *bool {
	if c == nil {
		return nil
	}
	return c.EnablePageChecksum
}

func (c *CreateOutputOutputAzureDataExplorer) GetRemoveEmptyDirs() *bool {
	if c == nil {
		return nil
	}
	return c.RemoveEmptyDirs
}

func (c *CreateOutputOutputAzureDataExplorer) GetEmptyDirCleanupSec() *float64 {
	if c == nil {
		return nil
	}
	return c.EmptyDirCleanupSec
}

func (c *CreateOutputOutputAzureDataExplorer) GetDirectoryBatchSize() *float64 {
	if c == nil {
		return nil
	}
	return c.DirectoryBatchSize
}

func (c *CreateOutputOutputAzureDataExplorer) GetDeadletterEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.DeadletterEnabled
}

func (c *CreateOutputOutputAzureDataExplorer) GetDeadletterPath() *string {
	if c == nil {
		return nil
	}
	return c.DeadletterPath
}

func (c *CreateOutputOutputAzureDataExplorer) GetMaxRetryNum() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRetryNum
}

func (c *CreateOutputOutputAzureDataExplorer) GetIsMappingObj() *bool {
	if c == nil {
		return nil
	}
	return c.IsMappingObj
}

func (c *CreateOutputOutputAzureDataExplorer) GetMappingObj() *string {
	if c == nil {
		return nil
	}
	return c.MappingObj
}

func (c *CreateOutputOutputAzureDataExplorer) GetMappingRef() *string {
	if c == nil {
		return nil
	}
	return c.MappingRef
}

func (c *CreateOutputOutputAzureDataExplorer) GetIngestURL() *string {
	if c == nil {
		return nil
	}
	return c.IngestURL
}

func (c *CreateOutputOutputAzureDataExplorer) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputAzureDataExplorer) GetStagePath() *string {
	if c == nil {
		return nil
	}
	return c.StagePath
}

func (c *CreateOutputOutputAzureDataExplorer) GetFileNameSuffix() *string {
	if c == nil {
		return nil
	}
	return c.FileNameSuffix
}

func (c *CreateOutputOutputAzureDataExplorer) GetMaxFileSizeMB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileSizeMB
}

func (c *CreateOutputOutputAzureDataExplorer) GetMaxFileOpenTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileOpenTimeSec
}

func (c *CreateOutputOutputAzureDataExplorer) GetMaxFileIdleTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileIdleTimeSec
}

func (c *CreateOutputOutputAzureDataExplorer) GetMaxOpenFiles() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxOpenFiles
}

func (c *CreateOutputOutputAzureDataExplorer) GetMaxConcurrentFileParts() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxConcurrentFileParts
}

func (c *CreateOutputOutputAzureDataExplorer) GetOnDiskFullBackpressure() *components.DiskSpaceProtectionOptions {
	if c == nil {
		return nil
	}
	return c.OnDiskFullBackpressure
}

func (c *CreateOutputOutputAzureDataExplorer) GetAddIDToStagePath() *bool {
	if c == nil {
		return nil
	}
	return c.AddIDToStagePath
}

func (c *CreateOutputOutputAzureDataExplorer) GetRetrySettings() *components.RetrySettingsType {
	if c == nil {
		return nil
	}
	return c.RetrySettings
}

func (c *CreateOutputOutputAzureDataExplorer) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputAzureDataExplorer) GetFlushImmediately() *bool {
	if c == nil {
		return nil
	}
	return c.FlushImmediately
}

func (c *CreateOutputOutputAzureDataExplorer) GetRetainBlobOnSuccess() *bool {
	if c == nil {
		return nil
	}
	return c.RetainBlobOnSuccess
}

func (c *CreateOutputOutputAzureDataExplorer) GetExtentTags() []CreateOutputExtentTag {
	if c == nil {
		return nil
	}
	return c.ExtentTags
}

func (c *CreateOutputOutputAzureDataExplorer) GetIngestIfNotExists() []CreateOutputIngestIfNotExist {
	if c == nil {
		return nil
	}
	return c.IngestIfNotExists
}

func (c *CreateOutputOutputAzureDataExplorer) GetReportLevel() *CreateOutputReportLevel {
	if c == nil {
		return nil
	}
	return c.ReportLevel
}

func (c *CreateOutputOutputAzureDataExplorer) GetReportMethod() *CreateOutputReportMethod {
	if c == nil {
		return nil
	}
	return c.ReportMethod
}

func (c *CreateOutputOutputAzureDataExplorer) GetAdditionalProperties() []CreateOutputAdditionalProperty {
	if c == nil {
		return nil
	}
	return c.AdditionalProperties
}

func (c *CreateOutputOutputAzureDataExplorer) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputAzureDataExplorer) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputAzureDataExplorer) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputAzureDataExplorer) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputAzureDataExplorer) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputAzureDataExplorer) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputAzureDataExplorer) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputAzureDataExplorer) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputAzureDataExplorer) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputAzureDataExplorer) GetKeepAlive() *bool {
	if c == nil {
		return nil
	}
	return c.KeepAlive
}

func (c *CreateOutputOutputAzureDataExplorer) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputAzureDataExplorer) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputAzureDataExplorer) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputAzureDataExplorer) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputAzureDataExplorer) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputAzureDataExplorer) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputAzureDataExplorer) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputAzureDataExplorer) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputAzureDataExplorer) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputAzureDataExplorer) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputAzureDataExplorer) GetPqControls() *CreateOutputPqControlsAzureDataExplorer {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputAzureDataExplorer) GetTemplateClusterURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateClusterURL
}

func (c *CreateOutputOutputAzureDataExplorer) GetTemplateDatabase() *string {
	if c == nil {
		return nil
	}
	return c.TemplateDatabase
}

func (c *CreateOutputOutputAzureDataExplorer) GetTemplateTable() *string {
	if c == nil {
		return nil
	}
	return c.TemplateTable
}

func (c *CreateOutputOutputAzureDataExplorer) GetTemplateTenantID() *string {
	if c == nil {
		return nil
	}
	return c.TemplateTenantID
}

func (c *CreateOutputOutputAzureDataExplorer) GetTemplateClientID() *string {
	if c == nil {
		return nil
	}
	return c.TemplateClientID
}

func (c *CreateOutputOutputAzureDataExplorer) GetTemplateScope() *string {
	if c == nil {
		return nil
	}
	return c.TemplateScope
}

func (c *CreateOutputOutputAzureDataExplorer) GetTemplateClientSecret() *string {
	if c == nil {
		return nil
	}
	return c.TemplateClientSecret
}

func (c *CreateOutputOutputAzureDataExplorer) GetTemplateFormat() *string {
	if c == nil {
		return nil
	}
	return c.TemplateFormat
}

func (c *CreateOutputOutputAzureDataExplorer) GetTemplateIngestURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateIngestURL
}

type CreateOutputTypeAzureBlob string

const (
	CreateOutputTypeAzureBlobAzureBlob CreateOutputTypeAzureBlob = "azure_blob"
)

func (e CreateOutputTypeAzureBlob) ToPointer() *CreateOutputTypeAzureBlob {
	return &e
}
func (e *CreateOutputTypeAzureBlob) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_blob":
		*e = CreateOutputTypeAzureBlob(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeAzureBlob: %v", v)
	}
}

type CreateOutputBlobAccessTier string

const (
	// CreateOutputBlobAccessTierInferred Default account access tier
	CreateOutputBlobAccessTierInferred CreateOutputBlobAccessTier = "Inferred"
	// CreateOutputBlobAccessTierHot Hot tier
	CreateOutputBlobAccessTierHot CreateOutputBlobAccessTier = "Hot"
	// CreateOutputBlobAccessTierCool Cool tier
	CreateOutputBlobAccessTierCool CreateOutputBlobAccessTier = "Cool"
	// CreateOutputBlobAccessTierCold Cold tier
	CreateOutputBlobAccessTierCold CreateOutputBlobAccessTier = "Cold"
	// CreateOutputBlobAccessTierArchive Archive tier
	CreateOutputBlobAccessTierArchive CreateOutputBlobAccessTier = "Archive"
)

func (e CreateOutputBlobAccessTier) ToPointer() *CreateOutputBlobAccessTier {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputBlobAccessTier) IsExact() bool {
	if e != nil {
		switch *e {
		case "Inferred", "Hot", "Cool", "Cold", "Archive":
			return true
		}
	}
	return false
}

type CreateOutputOutputAzureBlob struct {
	// Unique ID for this output
	ID   string                    `json:"id"`
	Type CreateOutputTypeAzureBlob `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The Azure Blob Storage container name. Name can include only lowercase letters, numbers, and hyphens. For dynamic container names, enter a JavaScript expression within quotes or backticks, to be evaluated at initialization. The expression can evaluate to a constant value and can reference Global Variables, such as `myContainer-${C.env["CRIBL_WORKER_ID"]}`.
	ContainerName string `json:"containerName"`
	// Create the configured container in Azure Blob Storage if it does not already exist
	CreateContainer *bool `json:"createContainer,omitempty"`
	// Root directory prepended to path before uploading. Value can be a JavaScript expression enclosed in quotes or backticks, to be evaluated at initialization. The expression can evaluate to a constant value and can reference Global Variables, such as `myBlobPrefix-${C.env["CRIBL_WORKER_ID"]}`.
	DestPath *string `json:"destPath,omitempty"`
	// Filesystem location in which to buffer files before compressing and moving to final destination. Use performant and stable storage.
	StagePath string `json:"stagePath"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Maximum number of parts to upload in parallel per file
	MaxConcurrentFileParts *float64 `json:"maxConcurrentFileParts,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
	PartitionExpr *string `json:"partitionExpr,omitempty"`
	// Format of the output data
	Format *components.DataFormatOptions `json:"format,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `json:"baseFileName,omitempty"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `json:"fileNameSuffix,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `json:"maxFileSizeMB,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `json:"maxOpenFiles,omitempty"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `json:"headerLine,omitempty"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `json:"writeHighWaterMark,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `json:"deadletterEnabled,omitempty"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *components.DiskSpaceProtectionOptions `json:"onDiskFullBackpressure,omitempty"`
	// Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
	ForceCloseOnShutdown *bool                                   `json:"forceCloseOnShutdown,omitempty"`
	RetrySettings        *components.RetrySettingsType           `json:"retrySettings,omitempty"`
	AuthType             *components.AuthenticationMethodOptions `json:"authType,omitempty"`
	StorageClass         *CreateOutputBlobAccessTier             `json:"storageClass,omitempty"`
	Description          *string                                 `json:"description,omitempty"`
	// Data compression format to apply to HTTP content before it is delivered
	Compress *components.CompressionOptions2 `json:"compress,omitempty"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *components.CompressionLevelOptions `json:"compressionLevel,omitempty"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `json:"automaticSchema,omitempty"`
	// To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
	ParquetSchema *string `json:"parquetSchema,omitempty"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *components.ParquetVersionOptions `json:"parquetVersion,omitempty"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *components.DataPageVersionOptions `json:"parquetDataPageVersion,omitempty"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `json:"parquetRowGroupLength,omitempty"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
	KeyValueMetadata []components.ItemsTypeKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `json:"enableStatistics,omitempty"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `json:"enableWritePageIndex,omitempty"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `json:"enablePageChecksum,omitempty"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `json:"emptyDirCleanupSec,omitempty"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `json:"directoryBatchSize,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `json:"deadletterPath,omitempty"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `json:"maxRetryNum,omitempty"`
	// Enter your Azure Storage account connection string. If left blank, Stream will fall back to env.AZURE_STORAGE_CONNECTION_STRING.
	ConnectionString *string `json:"connectionString,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// The name of your Azure storage account
	StorageAccountName *string `json:"storageAccountName,omitempty"`
	// The service principal's tenant ID
	TenantID *string `json:"tenantId,omitempty"`
	// The service principal's client ID
	ClientID *string `json:"clientId,omitempty"`
	// The Azure cloud to use. Defaults to Azure Public Cloud.
	AzureCloud *string `json:"azureCloud,omitempty"`
	// Endpoint suffix for the service URL. Takes precedence over the Azure Cloud setting. Defaults to core.windows.net.
	EndpointSuffix *string `json:"endpointSuffix,omitempty"`
	// Select or create a stored text secret
	ClientTextSecret *string                                                `json:"clientTextSecret,omitempty"`
	Certificate      *components.CertificateTypeAzureBlobAuthTypeClientCert `json:"certificate,omitempty"`
	// Binds 'containerName' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'containerName' at runtime.
	TemplateContainerName *string `json:"__template_containerName,omitempty"`
	// Binds 'format' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'format' at runtime.
	TemplateFormat *string `json:"__template_format,omitempty"`
	// Binds 'connectionString' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'connectionString' at runtime.
	TemplateConnectionString *string `json:"__template_connectionString,omitempty"`
	// Binds 'tenantId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'tenantId' at runtime.
	TemplateTenantID *string `json:"__template_tenantId,omitempty"`
	// Binds 'clientId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'clientId' at runtime.
	TemplateClientID *string `json:"__template_clientId,omitempty"`
}

func (c CreateOutputOutputAzureBlob) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputAzureBlob) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "containerName", "stagePath"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputAzureBlob) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputAzureBlob) GetType() CreateOutputTypeAzureBlob {
	if c == nil {
		return CreateOutputTypeAzureBlob("")
	}
	return c.Type
}

func (c *CreateOutputOutputAzureBlob) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputAzureBlob) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputAzureBlob) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputAzureBlob) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputAzureBlob) GetContainerName() string {
	if c == nil {
		return ""
	}
	return c.ContainerName
}

func (c *CreateOutputOutputAzureBlob) GetCreateContainer() *bool {
	if c == nil {
		return nil
	}
	return c.CreateContainer
}

func (c *CreateOutputOutputAzureBlob) GetDestPath() *string {
	if c == nil {
		return nil
	}
	return c.DestPath
}

func (c *CreateOutputOutputAzureBlob) GetStagePath() string {
	if c == nil {
		return ""
	}
	return c.StagePath
}

func (c *CreateOutputOutputAzureBlob) GetAddIDToStagePath() *bool {
	if c == nil {
		return nil
	}
	return c.AddIDToStagePath
}

func (c *CreateOutputOutputAzureBlob) GetMaxConcurrentFileParts() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxConcurrentFileParts
}

func (c *CreateOutputOutputAzureBlob) GetRemoveEmptyDirs() *bool {
	if c == nil {
		return nil
	}
	return c.RemoveEmptyDirs
}

func (c *CreateOutputOutputAzureBlob) GetPartitionExpr() *string {
	if c == nil {
		return nil
	}
	return c.PartitionExpr
}

func (c *CreateOutputOutputAzureBlob) GetFormat() *components.DataFormatOptions {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputAzureBlob) GetBaseFileName() *string {
	if c == nil {
		return nil
	}
	return c.BaseFileName
}

func (c *CreateOutputOutputAzureBlob) GetFileNameSuffix() *string {
	if c == nil {
		return nil
	}
	return c.FileNameSuffix
}

func (c *CreateOutputOutputAzureBlob) GetMaxFileSizeMB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileSizeMB
}

func (c *CreateOutputOutputAzureBlob) GetMaxFileOpenTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileOpenTimeSec
}

func (c *CreateOutputOutputAzureBlob) GetMaxFileIdleTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileIdleTimeSec
}

func (c *CreateOutputOutputAzureBlob) GetMaxOpenFiles() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxOpenFiles
}

func (c *CreateOutputOutputAzureBlob) GetHeaderLine() *string {
	if c == nil {
		return nil
	}
	return c.HeaderLine
}

func (c *CreateOutputOutputAzureBlob) GetWriteHighWaterMark() *float64 {
	if c == nil {
		return nil
	}
	return c.WriteHighWaterMark
}

func (c *CreateOutputOutputAzureBlob) GetOnBackpressure() *components.BackpressureBehaviorOptions1 {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputAzureBlob) GetDeadletterEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.DeadletterEnabled
}

func (c *CreateOutputOutputAzureBlob) GetOnDiskFullBackpressure() *components.DiskSpaceProtectionOptions {
	if c == nil {
		return nil
	}
	return c.OnDiskFullBackpressure
}

func (c *CreateOutputOutputAzureBlob) GetForceCloseOnShutdown() *bool {
	if c == nil {
		return nil
	}
	return c.ForceCloseOnShutdown
}

func (c *CreateOutputOutputAzureBlob) GetRetrySettings() *components.RetrySettingsType {
	if c == nil {
		return nil
	}
	return c.RetrySettings
}

func (c *CreateOutputOutputAzureBlob) GetAuthType() *components.AuthenticationMethodOptions {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputAzureBlob) GetStorageClass() *CreateOutputBlobAccessTier {
	if c == nil {
		return nil
	}
	return c.StorageClass
}

func (c *CreateOutputOutputAzureBlob) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputAzureBlob) GetCompress() *components.CompressionOptions2 {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputAzureBlob) GetCompressionLevel() *components.CompressionLevelOptions {
	if c == nil {
		return nil
	}
	return c.CompressionLevel
}

func (c *CreateOutputOutputAzureBlob) GetAutomaticSchema() *bool {
	if c == nil {
		return nil
	}
	return c.AutomaticSchema
}

func (c *CreateOutputOutputAzureBlob) GetParquetSchema() *string {
	if c == nil {
		return nil
	}
	return c.ParquetSchema
}

func (c *CreateOutputOutputAzureBlob) GetParquetVersion() *components.ParquetVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetVersion
}

func (c *CreateOutputOutputAzureBlob) GetParquetDataPageVersion() *components.DataPageVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetDataPageVersion
}

func (c *CreateOutputOutputAzureBlob) GetParquetRowGroupLength() *float64 {
	if c == nil {
		return nil
	}
	return c.ParquetRowGroupLength
}

func (c *CreateOutputOutputAzureBlob) GetParquetPageSize() *string {
	if c == nil {
		return nil
	}
	return c.ParquetPageSize
}

func (c *CreateOutputOutputAzureBlob) GetShouldLogInvalidRows() *bool {
	if c == nil {
		return nil
	}
	return c.ShouldLogInvalidRows
}

func (c *CreateOutputOutputAzureBlob) GetKeyValueMetadata() []components.ItemsTypeKeyValueMetadata {
	if c == nil {
		return nil
	}
	return c.KeyValueMetadata
}

func (c *CreateOutputOutputAzureBlob) GetEnableStatistics() *bool {
	if c == nil {
		return nil
	}
	return c.EnableStatistics
}

func (c *CreateOutputOutputAzureBlob) GetEnableWritePageIndex() *bool {
	if c == nil {
		return nil
	}
	return c.EnableWritePageIndex
}

func (c *CreateOutputOutputAzureBlob) GetEnablePageChecksum() *bool {
	if c == nil {
		return nil
	}
	return c.EnablePageChecksum
}

func (c *CreateOutputOutputAzureBlob) GetEmptyDirCleanupSec() *float64 {
	if c == nil {
		return nil
	}
	return c.EmptyDirCleanupSec
}

func (c *CreateOutputOutputAzureBlob) GetDirectoryBatchSize() *float64 {
	if c == nil {
		return nil
	}
	return c.DirectoryBatchSize
}

func (c *CreateOutputOutputAzureBlob) GetDeadletterPath() *string {
	if c == nil {
		return nil
	}
	return c.DeadletterPath
}

func (c *CreateOutputOutputAzureBlob) GetMaxRetryNum() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRetryNum
}

func (c *CreateOutputOutputAzureBlob) GetConnectionString() *string {
	if c == nil {
		return nil
	}
	return c.ConnectionString
}

func (c *CreateOutputOutputAzureBlob) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputAzureBlob) GetStorageAccountName() *string {
	if c == nil {
		return nil
	}
	return c.StorageAccountName
}

func (c *CreateOutputOutputAzureBlob) GetTenantID() *string {
	if c == nil {
		return nil
	}
	return c.TenantID
}

func (c *CreateOutputOutputAzureBlob) GetClientID() *string {
	if c == nil {
		return nil
	}
	return c.ClientID
}

func (c *CreateOutputOutputAzureBlob) GetAzureCloud() *string {
	if c == nil {
		return nil
	}
	return c.AzureCloud
}

func (c *CreateOutputOutputAzureBlob) GetEndpointSuffix() *string {
	if c == nil {
		return nil
	}
	return c.EndpointSuffix
}

func (c *CreateOutputOutputAzureBlob) GetClientTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.ClientTextSecret
}

func (c *CreateOutputOutputAzureBlob) GetCertificate() *components.CertificateTypeAzureBlobAuthTypeClientCert {
	if c == nil {
		return nil
	}
	return c.Certificate
}

func (c *CreateOutputOutputAzureBlob) GetTemplateContainerName() *string {
	if c == nil {
		return nil
	}
	return c.TemplateContainerName
}

func (c *CreateOutputOutputAzureBlob) GetTemplateFormat() *string {
	if c == nil {
		return nil
	}
	return c.TemplateFormat
}

func (c *CreateOutputOutputAzureBlob) GetTemplateConnectionString() *string {
	if c == nil {
		return nil
	}
	return c.TemplateConnectionString
}

func (c *CreateOutputOutputAzureBlob) GetTemplateTenantID() *string {
	if c == nil {
		return nil
	}
	return c.TemplateTenantID
}

func (c *CreateOutputOutputAzureBlob) GetTemplateClientID() *string {
	if c == nil {
		return nil
	}
	return c.TemplateClientID
}

type CreateOutputTypeS3 string

const (
	CreateOutputTypeS3S3 CreateOutputTypeS3 = "s3"
)

func (e CreateOutputTypeS3) ToPointer() *CreateOutputTypeS3 {
	return &e
}
func (e *CreateOutputTypeS3) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "s3":
		*e = CreateOutputTypeS3(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeS3: %v", v)
	}
}

type CreateOutputOutputS3 struct {
	// Unique ID for this output
	ID   string             `json:"id"`
	Type CreateOutputTypeS3 `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
	Bucket string `json:"bucket"`
	// Region where the S3 bucket is located
	Region *string `json:"region,omitempty"`
	// Secret key. This value can be a constant or a JavaScript expression. Example: `${C.env.SOME_SECRET}`)
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *components.SignatureVersionOptionsS3CollectorConf `json:"signatureVersion,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `json:"enableAssumeRole,omitempty"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitempty"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
	StagePath string `json:"stagePath"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Prefix to prepend to files before uploading. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `myKeyPrefix-${C.vars.myVar}`
	DestPath *string `json:"destPath,omitempty"`
	// Object ACL to assign to uploaded objects
	ObjectACL *components.ObjectACLOptions `json:"objectACL,omitempty"`
	// Storage class to select for uploaded objects
	StorageClass         *components.StorageClassOptions                           `json:"storageClass,omitempty"`
	ServerSideEncryption *components.ServerSideEncryptionForUploadedObjectsOptions `json:"serverSideEncryption,omitempty"`
	// ID or ARN of the KMS customer-managed key to use for encryption
	KmsKeyID *string `json:"kmsKeyId,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
	PartitionExpr *string `json:"partitionExpr,omitempty"`
	// Format of the output data
	Format *components.DataFormatOptions `json:"format,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `json:"baseFileName,omitempty"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `json:"fileNameSuffix,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `json:"maxFileSizeMB,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `json:"maxOpenFiles,omitempty"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `json:"headerLine,omitempty"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `json:"writeHighWaterMark,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `json:"deadletterEnabled,omitempty"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *components.DiskSpaceProtectionOptions `json:"onDiskFullBackpressure,omitempty"`
	// Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
	ForceCloseOnShutdown *bool                         `json:"forceCloseOnShutdown,omitempty"`
	RetrySettings        *components.RetrySettingsType `json:"retrySettings,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *float64 `json:"maxConcurrentFileParts,omitempty"`
	// Disable if you can access files within the bucket but not the bucket itself
	VerifyPermissions *bool `json:"verifyPermissions,omitempty"`
	// Maximum number of files that can be waiting for upload before backpressure is applied
	MaxClosingFilesToBackpressure *float64 `json:"maxClosingFilesToBackpressure,omitempty"`
	Description                   *string  `json:"description,omitempty"`
	// This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Data compression format to apply to HTTP content before it is delivered
	Compress *components.CompressionOptions2 `json:"compress,omitempty"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *components.CompressionLevelOptions `json:"compressionLevel,omitempty"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `json:"automaticSchema,omitempty"`
	// To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
	ParquetSchema *string `json:"parquetSchema,omitempty"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *components.ParquetVersionOptions `json:"parquetVersion,omitempty"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *components.DataPageVersionOptions `json:"parquetDataPageVersion,omitempty"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `json:"parquetRowGroupLength,omitempty"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
	KeyValueMetadata []components.ItemsTypeKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `json:"enableStatistics,omitempty"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `json:"enableWritePageIndex,omitempty"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `json:"enablePageChecksum,omitempty"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `json:"emptyDirCleanupSec,omitempty"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `json:"directoryBatchSize,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `json:"deadletterPath,omitempty"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `json:"maxRetryNum,omitempty"`
	// Binds 'bucket' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'bucket' at runtime.
	TemplateBucket *string `json:"__template_bucket,omitempty"`
	// Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime.
	TemplateRegion *string `json:"__template_region,omitempty"`
	// Binds 'awsSecretKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsSecretKey' at runtime.
	TemplateAwsSecretKey *string `json:"__template_awsSecretKey,omitempty"`
	// Binds 'assumeRoleArn' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleArn' at runtime.
	TemplateAssumeRoleArn *string `json:"__template_assumeRoleArn,omitempty"`
	// Binds 'assumeRoleExternalId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleExternalId' at runtime.
	TemplateAssumeRoleExternalID *string `json:"__template_assumeRoleExternalId,omitempty"`
	// Binds 'format' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'format' at runtime.
	TemplateFormat *string `json:"__template_format,omitempty"`
	// Binds 'awsApiKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsApiKey' at runtime.
	TemplateAwsAPIKey *string `json:"__template_awsApiKey,omitempty"`
}

func (c CreateOutputOutputS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "bucket", "stagePath"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputS3) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputS3) GetType() CreateOutputTypeS3 {
	if c == nil {
		return CreateOutputTypeS3("")
	}
	return c.Type
}

func (c *CreateOutputOutputS3) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputS3) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputS3) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputS3) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputS3) GetBucket() string {
	if c == nil {
		return ""
	}
	return c.Bucket
}

func (c *CreateOutputOutputS3) GetRegion() *string {
	if c == nil {
		return nil
	}
	return c.Region
}

func (c *CreateOutputOutputS3) GetAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecretKey
}

func (c *CreateOutputOutputS3) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if c == nil {
		return nil
	}
	return c.AwsAuthenticationMethod
}

func (c *CreateOutputOutputS3) GetEndpoint() *string {
	if c == nil {
		return nil
	}
	return c.Endpoint
}

func (c *CreateOutputOutputS3) GetSignatureVersion() *components.SignatureVersionOptionsS3CollectorConf {
	if c == nil {
		return nil
	}
	return c.SignatureVersion
}

func (c *CreateOutputOutputS3) GetReuseConnections() *bool {
	if c == nil {
		return nil
	}
	return c.ReuseConnections
}

func (c *CreateOutputOutputS3) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputS3) GetEnableAssumeRole() *bool {
	if c == nil {
		return nil
	}
	return c.EnableAssumeRole
}

func (c *CreateOutputOutputS3) GetAssumeRoleArn() *string {
	if c == nil {
		return nil
	}
	return c.AssumeRoleArn
}

func (c *CreateOutputOutputS3) GetAssumeRoleExternalID() *string {
	if c == nil {
		return nil
	}
	return c.AssumeRoleExternalID
}

func (c *CreateOutputOutputS3) GetDurationSeconds() *float64 {
	if c == nil {
		return nil
	}
	return c.DurationSeconds
}

func (c *CreateOutputOutputS3) GetStagePath() string {
	if c == nil {
		return ""
	}
	return c.StagePath
}

func (c *CreateOutputOutputS3) GetAddIDToStagePath() *bool {
	if c == nil {
		return nil
	}
	return c.AddIDToStagePath
}

func (c *CreateOutputOutputS3) GetDestPath() *string {
	if c == nil {
		return nil
	}
	return c.DestPath
}

func (c *CreateOutputOutputS3) GetObjectACL() *components.ObjectACLOptions {
	if c == nil {
		return nil
	}
	return c.ObjectACL
}

func (c *CreateOutputOutputS3) GetStorageClass() *components.StorageClassOptions {
	if c == nil {
		return nil
	}
	return c.StorageClass
}

func (c *CreateOutputOutputS3) GetServerSideEncryption() *components.ServerSideEncryptionForUploadedObjectsOptions {
	if c == nil {
		return nil
	}
	return c.ServerSideEncryption
}

func (c *CreateOutputOutputS3) GetKmsKeyID() *string {
	if c == nil {
		return nil
	}
	return c.KmsKeyID
}

func (c *CreateOutputOutputS3) GetRemoveEmptyDirs() *bool {
	if c == nil {
		return nil
	}
	return c.RemoveEmptyDirs
}

func (c *CreateOutputOutputS3) GetPartitionExpr() *string {
	if c == nil {
		return nil
	}
	return c.PartitionExpr
}

func (c *CreateOutputOutputS3) GetFormat() *components.DataFormatOptions {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputS3) GetBaseFileName() *string {
	if c == nil {
		return nil
	}
	return c.BaseFileName
}

func (c *CreateOutputOutputS3) GetFileNameSuffix() *string {
	if c == nil {
		return nil
	}
	return c.FileNameSuffix
}

func (c *CreateOutputOutputS3) GetMaxFileSizeMB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileSizeMB
}

func (c *CreateOutputOutputS3) GetMaxOpenFiles() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxOpenFiles
}

func (c *CreateOutputOutputS3) GetHeaderLine() *string {
	if c == nil {
		return nil
	}
	return c.HeaderLine
}

func (c *CreateOutputOutputS3) GetWriteHighWaterMark() *float64 {
	if c == nil {
		return nil
	}
	return c.WriteHighWaterMark
}

func (c *CreateOutputOutputS3) GetOnBackpressure() *components.BackpressureBehaviorOptions1 {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputS3) GetDeadletterEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.DeadletterEnabled
}

func (c *CreateOutputOutputS3) GetOnDiskFullBackpressure() *components.DiskSpaceProtectionOptions {
	if c == nil {
		return nil
	}
	return c.OnDiskFullBackpressure
}

func (c *CreateOutputOutputS3) GetForceCloseOnShutdown() *bool {
	if c == nil {
		return nil
	}
	return c.ForceCloseOnShutdown
}

func (c *CreateOutputOutputS3) GetRetrySettings() *components.RetrySettingsType {
	if c == nil {
		return nil
	}
	return c.RetrySettings
}

func (c *CreateOutputOutputS3) GetMaxFileOpenTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileOpenTimeSec
}

func (c *CreateOutputOutputS3) GetMaxFileIdleTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileIdleTimeSec
}

func (c *CreateOutputOutputS3) GetMaxConcurrentFileParts() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxConcurrentFileParts
}

func (c *CreateOutputOutputS3) GetVerifyPermissions() *bool {
	if c == nil {
		return nil
	}
	return c.VerifyPermissions
}

func (c *CreateOutputOutputS3) GetMaxClosingFilesToBackpressure() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxClosingFilesToBackpressure
}

func (c *CreateOutputOutputS3) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputS3) GetAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.AwsAPIKey
}

func (c *CreateOutputOutputS3) GetAwsSecret() *string {
	if c == nil {
		return nil
	}
	return c.AwsSecret
}

func (c *CreateOutputOutputS3) GetCompress() *components.CompressionOptions2 {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputS3) GetCompressionLevel() *components.CompressionLevelOptions {
	if c == nil {
		return nil
	}
	return c.CompressionLevel
}

func (c *CreateOutputOutputS3) GetAutomaticSchema() *bool {
	if c == nil {
		return nil
	}
	return c.AutomaticSchema
}

func (c *CreateOutputOutputS3) GetParquetSchema() *string {
	if c == nil {
		return nil
	}
	return c.ParquetSchema
}

func (c *CreateOutputOutputS3) GetParquetVersion() *components.ParquetVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetVersion
}

func (c *CreateOutputOutputS3) GetParquetDataPageVersion() *components.DataPageVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetDataPageVersion
}

func (c *CreateOutputOutputS3) GetParquetRowGroupLength() *float64 {
	if c == nil {
		return nil
	}
	return c.ParquetRowGroupLength
}

func (c *CreateOutputOutputS3) GetParquetPageSize() *string {
	if c == nil {
		return nil
	}
	return c.ParquetPageSize
}

func (c *CreateOutputOutputS3) GetShouldLogInvalidRows() *bool {
	if c == nil {
		return nil
	}
	return c.ShouldLogInvalidRows
}

func (c *CreateOutputOutputS3) GetKeyValueMetadata() []components.ItemsTypeKeyValueMetadata {
	if c == nil {
		return nil
	}
	return c.KeyValueMetadata
}

func (c *CreateOutputOutputS3) GetEnableStatistics() *bool {
	if c == nil {
		return nil
	}
	return c.EnableStatistics
}

func (c *CreateOutputOutputS3) GetEnableWritePageIndex() *bool {
	if c == nil {
		return nil
	}
	return c.EnableWritePageIndex
}

func (c *CreateOutputOutputS3) GetEnablePageChecksum() *bool {
	if c == nil {
		return nil
	}
	return c.EnablePageChecksum
}

func (c *CreateOutputOutputS3) GetEmptyDirCleanupSec() *float64 {
	if c == nil {
		return nil
	}
	return c.EmptyDirCleanupSec
}

func (c *CreateOutputOutputS3) GetDirectoryBatchSize() *float64 {
	if c == nil {
		return nil
	}
	return c.DirectoryBatchSize
}

func (c *CreateOutputOutputS3) GetDeadletterPath() *string {
	if c == nil {
		return nil
	}
	return c.DeadletterPath
}

func (c *CreateOutputOutputS3) GetMaxRetryNum() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRetryNum
}

func (c *CreateOutputOutputS3) GetTemplateBucket() *string {
	if c == nil {
		return nil
	}
	return c.TemplateBucket
}

func (c *CreateOutputOutputS3) GetTemplateRegion() *string {
	if c == nil {
		return nil
	}
	return c.TemplateRegion
}

func (c *CreateOutputOutputS3) GetTemplateAwsSecretKey() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAwsSecretKey
}

func (c *CreateOutputOutputS3) GetTemplateAssumeRoleArn() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAssumeRoleArn
}

func (c *CreateOutputOutputS3) GetTemplateAssumeRoleExternalID() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAssumeRoleExternalID
}

func (c *CreateOutputOutputS3) GetTemplateFormat() *string {
	if c == nil {
		return nil
	}
	return c.TemplateFormat
}

func (c *CreateOutputOutputS3) GetTemplateAwsAPIKey() *string {
	if c == nil {
		return nil
	}
	return c.TemplateAwsAPIKey
}

type CreateOutputTypeFilesystem string

const (
	CreateOutputTypeFilesystemFilesystem CreateOutputTypeFilesystem = "filesystem"
)

func (e CreateOutputTypeFilesystem) ToPointer() *CreateOutputTypeFilesystem {
	return &e
}
func (e *CreateOutputTypeFilesystem) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "filesystem":
		*e = CreateOutputTypeFilesystem(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeFilesystem: %v", v)
	}
}

type CreateOutputOutputFilesystem struct {
	// Unique ID for this output
	ID   string                     `json:"id"`
	Type CreateOutputTypeFilesystem `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Final destination for the output files
	DestPath string `json:"destPath"`
	// Filesystem location in which to buffer files before compressing and moving to final destination. Use performant, stable storage.
	StagePath *string `json:"stagePath,omitempty"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
	PartitionExpr *string `json:"partitionExpr,omitempty"`
	// Format of the output data
	Format *components.DataFormatOptions `json:"format,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `json:"baseFileName,omitempty"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `json:"fileNameSuffix,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `json:"maxFileSizeMB,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `json:"maxOpenFiles,omitempty"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `json:"headerLine,omitempty"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `json:"writeHighWaterMark,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `json:"deadletterEnabled,omitempty"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *components.DiskSpaceProtectionOptions `json:"onDiskFullBackpressure,omitempty"`
	// Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
	ForceCloseOnShutdown *bool                         `json:"forceCloseOnShutdown,omitempty"`
	RetrySettings        *components.RetrySettingsType `json:"retrySettings,omitempty"`
	Description          *string                       `json:"description,omitempty"`
	// Data compression format to apply to HTTP content before it is delivered
	Compress *components.CompressionOptions2 `json:"compress,omitempty"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *components.CompressionLevelOptions `json:"compressionLevel,omitempty"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `json:"automaticSchema,omitempty"`
	// To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
	ParquetSchema *string `json:"parquetSchema,omitempty"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *components.ParquetVersionOptions `json:"parquetVersion,omitempty"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *components.DataPageVersionOptions `json:"parquetDataPageVersion,omitempty"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `json:"parquetRowGroupLength,omitempty"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
	KeyValueMetadata []components.ItemsTypeKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `json:"enableStatistics,omitempty"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `json:"enableWritePageIndex,omitempty"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `json:"enablePageChecksum,omitempty"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `json:"emptyDirCleanupSec,omitempty"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `json:"directoryBatchSize,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `json:"deadletterPath,omitempty"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `json:"maxRetryNum,omitempty"`
	// Binds 'format' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'format' at runtime.
	TemplateFormat *string `json:"__template_format,omitempty"`
}

func (c CreateOutputOutputFilesystem) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputFilesystem) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "destPath"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputFilesystem) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputFilesystem) GetType() CreateOutputTypeFilesystem {
	if c == nil {
		return CreateOutputTypeFilesystem("")
	}
	return c.Type
}

func (c *CreateOutputOutputFilesystem) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputFilesystem) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputFilesystem) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputFilesystem) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputFilesystem) GetDestPath() string {
	if c == nil {
		return ""
	}
	return c.DestPath
}

func (c *CreateOutputOutputFilesystem) GetStagePath() *string {
	if c == nil {
		return nil
	}
	return c.StagePath
}

func (c *CreateOutputOutputFilesystem) GetAddIDToStagePath() *bool {
	if c == nil {
		return nil
	}
	return c.AddIDToStagePath
}

func (c *CreateOutputOutputFilesystem) GetRemoveEmptyDirs() *bool {
	if c == nil {
		return nil
	}
	return c.RemoveEmptyDirs
}

func (c *CreateOutputOutputFilesystem) GetPartitionExpr() *string {
	if c == nil {
		return nil
	}
	return c.PartitionExpr
}

func (c *CreateOutputOutputFilesystem) GetFormat() *components.DataFormatOptions {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputFilesystem) GetBaseFileName() *string {
	if c == nil {
		return nil
	}
	return c.BaseFileName
}

func (c *CreateOutputOutputFilesystem) GetFileNameSuffix() *string {
	if c == nil {
		return nil
	}
	return c.FileNameSuffix
}

func (c *CreateOutputOutputFilesystem) GetMaxFileSizeMB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileSizeMB
}

func (c *CreateOutputOutputFilesystem) GetMaxFileOpenTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileOpenTimeSec
}

func (c *CreateOutputOutputFilesystem) GetMaxFileIdleTimeSec() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFileIdleTimeSec
}

func (c *CreateOutputOutputFilesystem) GetMaxOpenFiles() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxOpenFiles
}

func (c *CreateOutputOutputFilesystem) GetHeaderLine() *string {
	if c == nil {
		return nil
	}
	return c.HeaderLine
}

func (c *CreateOutputOutputFilesystem) GetWriteHighWaterMark() *float64 {
	if c == nil {
		return nil
	}
	return c.WriteHighWaterMark
}

func (c *CreateOutputOutputFilesystem) GetOnBackpressure() *components.BackpressureBehaviorOptions1 {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputFilesystem) GetDeadletterEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.DeadletterEnabled
}

func (c *CreateOutputOutputFilesystem) GetOnDiskFullBackpressure() *components.DiskSpaceProtectionOptions {
	if c == nil {
		return nil
	}
	return c.OnDiskFullBackpressure
}

func (c *CreateOutputOutputFilesystem) GetForceCloseOnShutdown() *bool {
	if c == nil {
		return nil
	}
	return c.ForceCloseOnShutdown
}

func (c *CreateOutputOutputFilesystem) GetRetrySettings() *components.RetrySettingsType {
	if c == nil {
		return nil
	}
	return c.RetrySettings
}

func (c *CreateOutputOutputFilesystem) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputFilesystem) GetCompress() *components.CompressionOptions2 {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputFilesystem) GetCompressionLevel() *components.CompressionLevelOptions {
	if c == nil {
		return nil
	}
	return c.CompressionLevel
}

func (c *CreateOutputOutputFilesystem) GetAutomaticSchema() *bool {
	if c == nil {
		return nil
	}
	return c.AutomaticSchema
}

func (c *CreateOutputOutputFilesystem) GetParquetSchema() *string {
	if c == nil {
		return nil
	}
	return c.ParquetSchema
}

func (c *CreateOutputOutputFilesystem) GetParquetVersion() *components.ParquetVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetVersion
}

func (c *CreateOutputOutputFilesystem) GetParquetDataPageVersion() *components.DataPageVersionOptions {
	if c == nil {
		return nil
	}
	return c.ParquetDataPageVersion
}

func (c *CreateOutputOutputFilesystem) GetParquetRowGroupLength() *float64 {
	if c == nil {
		return nil
	}
	return c.ParquetRowGroupLength
}

func (c *CreateOutputOutputFilesystem) GetParquetPageSize() *string {
	if c == nil {
		return nil
	}
	return c.ParquetPageSize
}

func (c *CreateOutputOutputFilesystem) GetShouldLogInvalidRows() *bool {
	if c == nil {
		return nil
	}
	return c.ShouldLogInvalidRows
}

func (c *CreateOutputOutputFilesystem) GetKeyValueMetadata() []components.ItemsTypeKeyValueMetadata {
	if c == nil {
		return nil
	}
	return c.KeyValueMetadata
}

func (c *CreateOutputOutputFilesystem) GetEnableStatistics() *bool {
	if c == nil {
		return nil
	}
	return c.EnableStatistics
}

func (c *CreateOutputOutputFilesystem) GetEnableWritePageIndex() *bool {
	if c == nil {
		return nil
	}
	return c.EnableWritePageIndex
}

func (c *CreateOutputOutputFilesystem) GetEnablePageChecksum() *bool {
	if c == nil {
		return nil
	}
	return c.EnablePageChecksum
}

func (c *CreateOutputOutputFilesystem) GetEmptyDirCleanupSec() *float64 {
	if c == nil {
		return nil
	}
	return c.EmptyDirCleanupSec
}

func (c *CreateOutputOutputFilesystem) GetDirectoryBatchSize() *float64 {
	if c == nil {
		return nil
	}
	return c.DirectoryBatchSize
}

func (c *CreateOutputOutputFilesystem) GetDeadletterPath() *string {
	if c == nil {
		return nil
	}
	return c.DeadletterPath
}

func (c *CreateOutputOutputFilesystem) GetMaxRetryNum() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRetryNum
}

func (c *CreateOutputOutputFilesystem) GetTemplateFormat() *string {
	if c == nil {
		return nil
	}
	return c.TemplateFormat
}

type CreateOutputTypeSignalfx string

const (
	CreateOutputTypeSignalfxSignalfx CreateOutputTypeSignalfx = "signalfx"
)

func (e CreateOutputTypeSignalfx) ToPointer() *CreateOutputTypeSignalfx {
	return &e
}
func (e *CreateOutputTypeSignalfx) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "signalfx":
		*e = CreateOutputTypeSignalfx(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeSignalfx: %v", v)
	}
}

type CreateOutputPqControlsSignalfx struct {
}

func (c CreateOutputPqControlsSignalfx) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsSignalfx) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputSignalfx struct {
	// Unique ID for this output
	ID   string                   `json:"id"`
	Type CreateOutputTypeSignalfx `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitempty"`
	// SignalFx realm name, e.g. "us0". For a complete list of available SignalFx realm names, please check [here](https://docs.splunk.com/observability/en/get-started/service-description.html#sd-regions).
	Realm string `json:"realm"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// SignalFx API access token (see [here](https://docs.signalfx.com/en/latest/admin-guide/tokens.html#working-with-access-tokens))
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsSignalfx      `json:"pqControls,omitempty"`
}

func (c CreateOutputOutputSignalfx) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputSignalfx) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "realm"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputSignalfx) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputSignalfx) GetType() CreateOutputTypeSignalfx {
	if c == nil {
		return CreateOutputTypeSignalfx("")
	}
	return c.Type
}

func (c *CreateOutputOutputSignalfx) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputSignalfx) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputSignalfx) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputSignalfx) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputSignalfx) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputSignalfx) GetRealm() string {
	if c == nil {
		return ""
	}
	return c.Realm
}

func (c *CreateOutputOutputSignalfx) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputSignalfx) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputSignalfx) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputSignalfx) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputSignalfx) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputSignalfx) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputSignalfx) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputSignalfx) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputSignalfx) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputSignalfx) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputSignalfx) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputSignalfx) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputSignalfx) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputSignalfx) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputSignalfx) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputSignalfx) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputSignalfx) GetToken() *string {
	if c == nil {
		return nil
	}
	return c.Token
}

func (c *CreateOutputOutputSignalfx) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputSignalfx) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputSignalfx) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputSignalfx) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputSignalfx) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputSignalfx) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputSignalfx) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputSignalfx) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputSignalfx) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputSignalfx) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputSignalfx) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputSignalfx) GetPqControls() *CreateOutputPqControlsSignalfx {
	if c == nil {
		return nil
	}
	return c.PqControls
}

type CreateOutputTypeWavefront string

const (
	CreateOutputTypeWavefrontWavefront CreateOutputTypeWavefront = "wavefront"
)

func (e CreateOutputTypeWavefront) ToPointer() *CreateOutputTypeWavefront {
	return &e
}
func (e *CreateOutputTypeWavefront) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "wavefront":
		*e = CreateOutputTypeWavefront(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeWavefront: %v", v)
	}
}

type CreateOutputPqControlsWavefront struct {
}

func (c CreateOutputPqControlsWavefront) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsWavefront) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputWavefront struct {
	// Unique ID for this output
	ID   string                    `json:"id"`
	Type CreateOutputTypeWavefront `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitempty"`
	// WaveFront domain name, e.g. "longboard"
	Domain string `json:"domain"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// WaveFront API authentication token (see [here](https://docs.wavefront.com/wavefront_api.html#generating-an-api-token))
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsWavefront     `json:"pqControls,omitempty"`
}

func (c CreateOutputOutputWavefront) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputWavefront) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "domain"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputWavefront) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputWavefront) GetType() CreateOutputTypeWavefront {
	if c == nil {
		return CreateOutputTypeWavefront("")
	}
	return c.Type
}

func (c *CreateOutputOutputWavefront) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputWavefront) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputWavefront) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputWavefront) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputWavefront) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputWavefront) GetDomain() string {
	if c == nil {
		return ""
	}
	return c.Domain
}

func (c *CreateOutputOutputWavefront) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputWavefront) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputWavefront) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputWavefront) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputWavefront) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputWavefront) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputWavefront) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputWavefront) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputWavefront) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputWavefront) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputWavefront) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputWavefront) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputWavefront) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputWavefront) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputWavefront) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputWavefront) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputWavefront) GetToken() *string {
	if c == nil {
		return nil
	}
	return c.Token
}

func (c *CreateOutputOutputWavefront) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputWavefront) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputWavefront) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputWavefront) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputWavefront) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputWavefront) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputWavefront) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputWavefront) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputWavefront) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputWavefront) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputWavefront) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputWavefront) GetPqControls() *CreateOutputPqControlsWavefront {
	if c == nil {
		return nil
	}
	return c.PqControls
}

type CreateOutputTypeTcpjson string

const (
	CreateOutputTypeTcpjsonTcpjson CreateOutputTypeTcpjson = "tcpjson"
)

func (e CreateOutputTypeTcpjson) ToPointer() *CreateOutputTypeTcpjson {
	return &e
}
func (e *CreateOutputTypeTcpjson) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "tcpjson":
		*e = CreateOutputTypeTcpjson(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeTcpjson: %v", v)
	}
}

type CreateOutputPqControlsTcpjson struct {
}

func (c CreateOutputPqControlsTcpjson) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsTcpjson) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputTcpjson struct {
	// Unique ID for this output
	ID   string                  `json:"id"`
	Type CreateOutputTypeTcpjson `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Use load-balanced destinations
	LoadBalanced *bool `json:"loadBalanced,omitempty"`
	// Codec to use to compress the data before sending
	Compression *components.CompressionOptions1 `json:"compression,omitempty"`
	// Use to troubleshoot issues with sending data
	LogFailedRequests *bool `json:"logFailedRequests,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string                                                  `json:"throttleRatePerSec,omitempty"`
	TLS                *components.TLSSettingsClientSideTypeKafkaSchemaRegistry `json:"tls,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64 `json:"writeTimeout,omitempty"`
	// The number of minutes before the internally generated authentication token expires, valid values between 1 and 60
	TokenTTLMinutes *float64 `json:"tokenTTLMinutes,omitempty"`
	// Upon connection, send a header-like record containing the auth token and other metadata.This record will not contain an actual event – only subsequent records will.
	SendHeader *bool `json:"sendHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitempty"`
	Description *string                                                `json:"description,omitempty"`
	// The hostname of the receiver
	Host *string `json:"host,omitempty"`
	// The port to connect to on the provided host
	Port *float64 `json:"port,omitempty"`
	// Exclude all IPs of the current host from the list of any resolved hostnames
	ExcludeSelf *bool `json:"excludeSelf,omitempty"`
	// Set of hosts to load-balance data to
	Hosts []components.ItemsTypeHosts `json:"hosts,omitempty"`
	// The interval in which to re-resolve any hostnames and pick up destinations from A records
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	// How far back in time to keep traffic stats for load balancing purposes
	LoadBalanceStatsPeriodSec *float64 `json:"loadBalanceStatsPeriodSec,omitempty"`
	// Maximum number of concurrent connections (per Worker Process). A random set of IPs will be picked on every DNS resolution period. Use 0 for unlimited.
	MaxConcurrentSenders *float64 `json:"maxConcurrentSenders,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsTcpjson       `json:"pqControls,omitempty"`
	// Optional authentication token to include as part of the connection header
	AuthToken *string `json:"authToken,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Binds 'host' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'host' at runtime.
	TemplateHost *string `json:"__template_host,omitempty"`
	// Binds 'port' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'port' at runtime.
	TemplatePort *string `json:"__template_port,omitempty"`
}

func (c CreateOutputOutputTcpjson) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputTcpjson) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputTcpjson) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputTcpjson) GetType() CreateOutputTypeTcpjson {
	if c == nil {
		return CreateOutputTypeTcpjson("")
	}
	return c.Type
}

func (c *CreateOutputOutputTcpjson) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputTcpjson) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputTcpjson) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputTcpjson) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputTcpjson) GetLoadBalanced() *bool {
	if c == nil {
		return nil
	}
	return c.LoadBalanced
}

func (c *CreateOutputOutputTcpjson) GetCompression() *components.CompressionOptions1 {
	if c == nil {
		return nil
	}
	return c.Compression
}

func (c *CreateOutputOutputTcpjson) GetLogFailedRequests() *bool {
	if c == nil {
		return nil
	}
	return c.LogFailedRequests
}

func (c *CreateOutputOutputTcpjson) GetThrottleRatePerSec() *string {
	if c == nil {
		return nil
	}
	return c.ThrottleRatePerSec
}

func (c *CreateOutputOutputTcpjson) GetTLS() *components.TLSSettingsClientSideTypeKafkaSchemaRegistry {
	if c == nil {
		return nil
	}
	return c.TLS
}

func (c *CreateOutputOutputTcpjson) GetConnectionTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.ConnectionTimeout
}

func (c *CreateOutputOutputTcpjson) GetWriteTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.WriteTimeout
}

func (c *CreateOutputOutputTcpjson) GetTokenTTLMinutes() *float64 {
	if c == nil {
		return nil
	}
	return c.TokenTTLMinutes
}

func (c *CreateOutputOutputTcpjson) GetSendHeader() *bool {
	if c == nil {
		return nil
	}
	return c.SendHeader
}

func (c *CreateOutputOutputTcpjson) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputTcpjson) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputTcpjson) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputTcpjson) GetHost() *string {
	if c == nil {
		return nil
	}
	return c.Host
}

func (c *CreateOutputOutputTcpjson) GetPort() *float64 {
	if c == nil {
		return nil
	}
	return c.Port
}

func (c *CreateOutputOutputTcpjson) GetExcludeSelf() *bool {
	if c == nil {
		return nil
	}
	return c.ExcludeSelf
}

func (c *CreateOutputOutputTcpjson) GetHosts() []components.ItemsTypeHosts {
	if c == nil {
		return nil
	}
	return c.Hosts
}

func (c *CreateOutputOutputTcpjson) GetDNSResolvePeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.DNSResolvePeriodSec
}

func (c *CreateOutputOutputTcpjson) GetLoadBalanceStatsPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.LoadBalanceStatsPeriodSec
}

func (c *CreateOutputOutputTcpjson) GetMaxConcurrentSenders() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxConcurrentSenders
}

func (c *CreateOutputOutputTcpjson) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputTcpjson) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputTcpjson) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputTcpjson) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputTcpjson) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputTcpjson) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputTcpjson) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputTcpjson) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputTcpjson) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputTcpjson) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputTcpjson) GetPqControls() *CreateOutputPqControlsTcpjson {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputTcpjson) GetAuthToken() *string {
	if c == nil {
		return nil
	}
	return c.AuthToken
}

func (c *CreateOutputOutputTcpjson) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputTcpjson) GetTemplateHost() *string {
	if c == nil {
		return nil
	}
	return c.TemplateHost
}

func (c *CreateOutputOutputTcpjson) GetTemplatePort() *string {
	if c == nil {
		return nil
	}
	return c.TemplatePort
}

type CreateOutputTypeWizHec string

const (
	CreateOutputTypeWizHecWizHec CreateOutputTypeWizHec = "wiz_hec"
)

func (e CreateOutputTypeWizHec) ToPointer() *CreateOutputTypeWizHec {
	return &e
}
func (e *CreateOutputTypeWizHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "wiz_hec":
		*e = CreateOutputTypeWizHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeWizHec: %v", v)
	}
}

type CreateOutputPqControlsWizHec struct {
}

func (c CreateOutputPqControlsWizHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsWizHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputWizHec struct {
	// Unique ID for this output
	ID   string                 `json:"id"`
	Type CreateOutputTypeWizHec `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags   []string `json:"streamtags,omitempty"`
	LoadBalanced any      `json:"loadBalanced,omitempty"`
	// In the Splunk app, define which Splunk processing queue to send the events after HEC processing.
	NextQueue *string `json:"nextQueue,omitempty"`
	// In the Splunk app, set the value of _TCP_ROUTING for events that do not have _ctrl._TCP_ROUTING set.
	TCPRouting *string                                `json:"tcpRouting,omitempty"`
	TLS        *components.TLSSettingsClientSideType1 `json:"tls,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders        []string `json:"safeHeaders,omitempty"`
	EnableMultiMetrics any      `json:"enableMultiMetrics,omitempty"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// The unique identifier for the specific Cribl connector defined in your Wiz Settings. This is used to cross-validate the bearer token and ensure traffic is originating from the authorized integration.
	WizConnectorID string `json:"wiz_connector_id"`
	// Your Wiz deployment environment.
	WizEnvironment string `json:"wiz_environment"`
	// Your Wiz deployment data center (e.g., us1, us8, eu1). From Tenant Info → Data Center and Regions → Tenant Data Center in your Wiz console.
	DataCenter    string  `json:"data_center"`
	WizSourcetype string  `json:"wiz_sourcetype"`
	Description   *string `json:"description,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsWizHec        `json:"pqControls,omitempty"`
	// Wiz Defend Auth token
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Binds 'wiz_environment' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'wiz_environment' at runtime.
	TemplateWizEnvironment *string `json:"__template_wiz_environment,omitempty"`
	// Binds 'data_center' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'data_center' at runtime.
	TemplateDataCenter *string `json:"__template_data_center,omitempty"`
	// Binds 'wiz_sourcetype' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'wiz_sourcetype' at runtime.
	TemplateWizSourcetype *string `json:"__template_wiz_sourcetype,omitempty"`
}

func (c CreateOutputOutputWizHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputWizHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "wiz_connector_id", "wiz_environment", "data_center", "wiz_sourcetype"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputWizHec) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputWizHec) GetType() CreateOutputTypeWizHec {
	if c == nil {
		return CreateOutputTypeWizHec("")
	}
	return c.Type
}

func (c *CreateOutputOutputWizHec) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputWizHec) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputWizHec) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputWizHec) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputWizHec) GetLoadBalanced() any {
	if c == nil {
		return nil
	}
	return c.LoadBalanced
}

func (c *CreateOutputOutputWizHec) GetNextQueue() *string {
	if c == nil {
		return nil
	}
	return c.NextQueue
}

func (c *CreateOutputOutputWizHec) GetTCPRouting() *string {
	if c == nil {
		return nil
	}
	return c.TCPRouting
}

func (c *CreateOutputOutputWizHec) GetTLS() *components.TLSSettingsClientSideType1 {
	if c == nil {
		return nil
	}
	return c.TLS
}

func (c *CreateOutputOutputWizHec) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputWizHec) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputWizHec) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputWizHec) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputWizHec) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputWizHec) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputWizHec) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputWizHec) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputWizHec) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputWizHec) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputWizHec) GetEnableMultiMetrics() any {
	if c == nil {
		return nil
	}
	return c.EnableMultiMetrics
}

func (c *CreateOutputOutputWizHec) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputWizHec) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputWizHec) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputWizHec) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputWizHec) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputWizHec) GetWizConnectorID() string {
	if c == nil {
		return ""
	}
	return c.WizConnectorID
}

func (c *CreateOutputOutputWizHec) GetWizEnvironment() string {
	if c == nil {
		return ""
	}
	return c.WizEnvironment
}

func (c *CreateOutputOutputWizHec) GetDataCenter() string {
	if c == nil {
		return ""
	}
	return c.DataCenter
}

func (c *CreateOutputOutputWizHec) GetWizSourcetype() string {
	if c == nil {
		return ""
	}
	return c.WizSourcetype
}

func (c *CreateOutputOutputWizHec) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputWizHec) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputWizHec) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputWizHec) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputWizHec) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputWizHec) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputWizHec) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputWizHec) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputWizHec) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputWizHec) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputWizHec) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputWizHec) GetPqControls() *CreateOutputPqControlsWizHec {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputWizHec) GetToken() *string {
	if c == nil {
		return nil
	}
	return c.Token
}

func (c *CreateOutputOutputWizHec) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputWizHec) GetTemplateWizEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.TemplateWizEnvironment
}

func (c *CreateOutputOutputWizHec) GetTemplateDataCenter() *string {
	if c == nil {
		return nil
	}
	return c.TemplateDataCenter
}

func (c *CreateOutputOutputWizHec) GetTemplateWizSourcetype() *string {
	if c == nil {
		return nil
	}
	return c.TemplateWizSourcetype
}

type CreateOutputTypeSplunkHec string

const (
	CreateOutputTypeSplunkHecSplunkHec CreateOutputTypeSplunkHec = "splunk_hec"
)

func (e CreateOutputTypeSplunkHec) ToPointer() *CreateOutputTypeSplunkHec {
	return &e
}
func (e *CreateOutputTypeSplunkHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk_hec":
		*e = CreateOutputTypeSplunkHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeSplunkHec: %v", v)
	}
}

type CreateOutputURLSplunkHec struct {
	// URL to a Splunk HEC endpoint to send events to, e.g., http://localhost:8088/services/collector/event
	URL string `json:"url"`
	// Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
	Weight *float64 `json:"weight,omitempty"`
	// Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
	TemplateURL *string `json:"__template_url,omitempty"`
}

func (c CreateOutputURLSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputURLSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"url"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputURLSplunkHec) GetURL() string {
	if c == nil {
		return ""
	}
	return c.URL
}

func (c *CreateOutputURLSplunkHec) GetWeight() *float64 {
	if c == nil {
		return nil
	}
	return c.Weight
}

func (c *CreateOutputURLSplunkHec) GetTemplateURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateURL
}

type CreateOutputPqControlsSplunkHec struct {
}

func (c CreateOutputPqControlsSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputSplunkHec struct {
	// Unique ID for this output
	ID   string                    `json:"id"`
	Type CreateOutputTypeSplunkHec `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Enable for optimal performance. Even if you have one hostname, it can expand to multiple IPs. If disabled, consider enabling round-robin DNS.
	LoadBalanced *bool `json:"loadBalanced,omitempty"`
	// In the Splunk app, define which Splunk processing queue to send the events after HEC processing.
	NextQueue *string `json:"nextQueue,omitempty"`
	// In the Splunk app, set the value of _TCP_ROUTING for events that do not have _ctrl._TCP_ROUTING set.
	TCPRouting *string                                `json:"tcpRouting,omitempty"`
	TLS        *components.TLSSettingsClientSideType1 `json:"tls,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Output metrics in multiple-metric format, supported in Splunk 8.0 and above to allow multiple metrics in a single event.
	EnableMultiMetrics *bool `json:"enableMultiMetrics,omitempty"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// URL to a Splunk HEC endpoint to send events to, e.g., http://localhost:8088/services/collector/event
	URL *string `json:"url,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Exclude all IPs of the current host from the list of any resolved hostnames
	ExcludeSelf *bool                      `json:"excludeSelf,omitempty"`
	Urls        []CreateOutputURLSplunkHec `json:"urls,omitempty"`
	// The interval in which to re-resolve any hostnames and pick up destinations from A records
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	// How far back in time to keep traffic stats for load balancing purposes
	LoadBalanceStatsPeriodSec *float64 `json:"loadBalanceStatsPeriodSec,omitempty"`
	// Splunk HEC authentication token
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsSplunkHec     `json:"pqControls,omitempty"`
	// Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
	TemplateURL *string `json:"__template_url,omitempty"`
}

func (c CreateOutputOutputSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputSplunkHec) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputSplunkHec) GetType() CreateOutputTypeSplunkHec {
	if c == nil {
		return CreateOutputTypeSplunkHec("")
	}
	return c.Type
}

func (c *CreateOutputOutputSplunkHec) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputSplunkHec) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputSplunkHec) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputSplunkHec) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputSplunkHec) GetLoadBalanced() *bool {
	if c == nil {
		return nil
	}
	return c.LoadBalanced
}

func (c *CreateOutputOutputSplunkHec) GetNextQueue() *string {
	if c == nil {
		return nil
	}
	return c.NextQueue
}

func (c *CreateOutputOutputSplunkHec) GetTCPRouting() *string {
	if c == nil {
		return nil
	}
	return c.TCPRouting
}

func (c *CreateOutputOutputSplunkHec) GetTLS() *components.TLSSettingsClientSideType1 {
	if c == nil {
		return nil
	}
	return c.TLS
}

func (c *CreateOutputOutputSplunkHec) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputSplunkHec) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputSplunkHec) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputSplunkHec) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputSplunkHec) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputSplunkHec) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputSplunkHec) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputSplunkHec) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputSplunkHec) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputSplunkHec) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputSplunkHec) GetEnableMultiMetrics() *bool {
	if c == nil {
		return nil
	}
	return c.EnableMultiMetrics
}

func (c *CreateOutputOutputSplunkHec) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputSplunkHec) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputSplunkHec) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputSplunkHec) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputSplunkHec) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputSplunkHec) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputSplunkHec) GetURL() *string {
	if c == nil {
		return nil
	}
	return c.URL
}

func (c *CreateOutputOutputSplunkHec) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputSplunkHec) GetExcludeSelf() *bool {
	if c == nil {
		return nil
	}
	return c.ExcludeSelf
}

func (c *CreateOutputOutputSplunkHec) GetUrls() []CreateOutputURLSplunkHec {
	if c == nil {
		return nil
	}
	return c.Urls
}

func (c *CreateOutputOutputSplunkHec) GetDNSResolvePeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.DNSResolvePeriodSec
}

func (c *CreateOutputOutputSplunkHec) GetLoadBalanceStatsPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.LoadBalanceStatsPeriodSec
}

func (c *CreateOutputOutputSplunkHec) GetToken() *string {
	if c == nil {
		return nil
	}
	return c.Token
}

func (c *CreateOutputOutputSplunkHec) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputSplunkHec) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputSplunkHec) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputSplunkHec) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputSplunkHec) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputSplunkHec) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputSplunkHec) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputSplunkHec) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputSplunkHec) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputSplunkHec) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputSplunkHec) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputSplunkHec) GetPqControls() *CreateOutputPqControlsSplunkHec {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputSplunkHec) GetTemplateURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateURL
}

type CreateOutputTypeSplunkLb string

const (
	CreateOutputTypeSplunkLbSplunkLb CreateOutputTypeSplunkLb = "splunk_lb"
)

func (e CreateOutputTypeSplunkLb) ToPointer() *CreateOutputTypeSplunkLb {
	return &e
}
func (e *CreateOutputTypeSplunkLb) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk_lb":
		*e = CreateOutputTypeSplunkLb(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeSplunkLb: %v", v)
	}
}

type CreateOutputAuthToken struct {
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitempty"`
	// Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
	AuthToken *string `json:"authToken,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
}

func (c CreateOutputAuthToken) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputAuthToken) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputAuthToken) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputAuthToken) GetAuthToken() *string {
	if c == nil {
		return nil
	}
	return c.AuthToken
}

func (c *CreateOutputAuthToken) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

// CreateOutputIndexerDiscoveryConfigs - List of configurations to set up indexer discovery in Splunk Indexer clustering environment.
type CreateOutputIndexerDiscoveryConfigs struct {
	// Clustering site of the indexers from where indexers need to be discovered. In case of single site cluster, it defaults to 'default' site.
	Site string `json:"site"`
	// Full URI of Splunk cluster manager (scheme://host:port). Example: https://managerAddress:8089
	MasterURI string `json:"masterUri"`
	// Time interval, in seconds, between two consecutive indexer list fetches from cluster manager
	RefreshIntervalSec float64 `json:"refreshIntervalSec"`
	// During indexer discovery, reject cluster manager certificates that are not authorized by the system's CA. Disable to allow untrusted (for example, self-signed) certificates.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Tokens required to authenticate to cluster manager for indexer discovery
	AuthTokens []CreateOutputAuthToken `json:"authTokens,omitempty"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitempty"`
	// Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
	AuthToken *string `json:"authToken,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
}

func (c CreateOutputIndexerDiscoveryConfigs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputIndexerDiscoveryConfigs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"site", "masterUri", "refreshIntervalSec"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputIndexerDiscoveryConfigs) GetSite() string {
	if c == nil {
		return ""
	}
	return c.Site
}

func (c *CreateOutputIndexerDiscoveryConfigs) GetMasterURI() string {
	if c == nil {
		return ""
	}
	return c.MasterURI
}

func (c *CreateOutputIndexerDiscoveryConfigs) GetRefreshIntervalSec() float64 {
	if c == nil {
		return 0.0
	}
	return c.RefreshIntervalSec
}

func (c *CreateOutputIndexerDiscoveryConfigs) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputIndexerDiscoveryConfigs) GetAuthTokens() []CreateOutputAuthToken {
	if c == nil {
		return nil
	}
	return c.AuthTokens
}

func (c *CreateOutputIndexerDiscoveryConfigs) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputIndexerDiscoveryConfigs) GetAuthToken() *string {
	if c == nil {
		return nil
	}
	return c.AuthToken
}

func (c *CreateOutputIndexerDiscoveryConfigs) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

type CreateOutputPqControlsSplunkLb struct {
}

func (c CreateOutputPqControlsSplunkLb) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsSplunkLb) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputSplunkLb struct {
	// Unique ID for this output
	ID   string                   `json:"id"`
	Type CreateOutputTypeSplunkLb `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The interval in which to re-resolve any hostnames and pick up destinations from A records
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	// How far back in time to keep traffic stats for load balancing purposes
	LoadBalanceStatsPeriodSec *float64 `json:"loadBalanceStatsPeriodSec,omitempty"`
	// Maximum number of concurrent connections (per Worker Process). A random set of IPs will be picked on every DNS resolution period. Use 0 for unlimited.
	MaxConcurrentSenders *float64 `json:"maxConcurrentSenders,omitempty"`
	// How to serialize nested fields into index-time fields
	NestedFields *components.NestedFieldSerializationOptions `json:"nestedFields,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `json:"throttleRatePerSec,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64                                                 `json:"writeTimeout,omitempty"`
	TLS          *components.TLSSettingsClientSideTypeKafkaSchemaRegistry `json:"tls,omitempty"`
	// Output metrics in multiple-metric format in a single event. Supported in Splunk 8.0 and above.
	EnableMultiMetrics *bool `json:"enableMultiMetrics,omitempty"`
	// Check if indexer is shutting down and stop sending data. This helps minimize data loss during shutdown.
	EnableACK *bool `json:"enableACK,omitempty"`
	// Use to troubleshoot issues with sending data
	LogFailedRequests *bool `json:"logFailedRequests,omitempty"`
	// The highest S2S protocol version to advertise during handshake
	MaxS2Sversion *components.MaxS2SVersionOptions `json:"maxS2Sversion,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Automatically discover indexers in indexer clustering environment.
	IndexerDiscovery *bool `json:"indexerDiscovery,omitempty"`
	// How long (in milliseconds) each LB endpoint can report blocked before the Destination reports unhealthy, blocking the sender. (Grace period for fluctuations.) Use 0 to disable; max 1 minute.
	SenderUnhealthyTimeAllowance *float64 `json:"senderUnhealthyTimeAllowance,omitempty"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitempty"`
	Description *string                                                `json:"description,omitempty"`
	// Maximum number of times healthcheck can fail before we close connection. If set to 0 (disabled), and the connection to Splunk is forcibly closed, some data loss might occur.
	MaxFailedHealthChecks *float64 `json:"maxFailedHealthChecks,omitempty"`
	// Controls whether the sender should send compressed data to the server. Select 'Disabled' to reject compressed connections or 'Always' to ignore server's configuration and send compressed data.
	Compress *components.CompressionOptions `json:"compress,omitempty"`
	// List of configurations to set up indexer discovery in Splunk Indexer clustering environment.
	IndexerDiscoveryConfigs *CreateOutputIndexerDiscoveryConfigs `json:"indexerDiscoveryConfigs,omitempty"`
	// Exclude all IPs of the current host from the list of any resolved hostnames
	ExcludeSelf *bool `json:"excludeSelf,omitempty"`
	// Set of Splunk indexers to load-balance data to.
	Hosts []components.ItemsTypeHosts `json:"hosts"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsSplunkLb      `json:"pqControls,omitempty"`
	// Shared secret token to use when establishing a connection to a Splunk indexer.
	AuthToken *string `json:"authToken,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
}

func (c CreateOutputOutputSplunkLb) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputSplunkLb) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "hosts"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputSplunkLb) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputSplunkLb) GetType() CreateOutputTypeSplunkLb {
	if c == nil {
		return CreateOutputTypeSplunkLb("")
	}
	return c.Type
}

func (c *CreateOutputOutputSplunkLb) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputSplunkLb) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputSplunkLb) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputSplunkLb) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputSplunkLb) GetDNSResolvePeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.DNSResolvePeriodSec
}

func (c *CreateOutputOutputSplunkLb) GetLoadBalanceStatsPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.LoadBalanceStatsPeriodSec
}

func (c *CreateOutputOutputSplunkLb) GetMaxConcurrentSenders() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxConcurrentSenders
}

func (c *CreateOutputOutputSplunkLb) GetNestedFields() *components.NestedFieldSerializationOptions {
	if c == nil {
		return nil
	}
	return c.NestedFields
}

func (c *CreateOutputOutputSplunkLb) GetThrottleRatePerSec() *string {
	if c == nil {
		return nil
	}
	return c.ThrottleRatePerSec
}

func (c *CreateOutputOutputSplunkLb) GetConnectionTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.ConnectionTimeout
}

func (c *CreateOutputOutputSplunkLb) GetWriteTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.WriteTimeout
}

func (c *CreateOutputOutputSplunkLb) GetTLS() *components.TLSSettingsClientSideTypeKafkaSchemaRegistry {
	if c == nil {
		return nil
	}
	return c.TLS
}

func (c *CreateOutputOutputSplunkLb) GetEnableMultiMetrics() *bool {
	if c == nil {
		return nil
	}
	return c.EnableMultiMetrics
}

func (c *CreateOutputOutputSplunkLb) GetEnableACK() *bool {
	if c == nil {
		return nil
	}
	return c.EnableACK
}

func (c *CreateOutputOutputSplunkLb) GetLogFailedRequests() *bool {
	if c == nil {
		return nil
	}
	return c.LogFailedRequests
}

func (c *CreateOutputOutputSplunkLb) GetMaxS2Sversion() *components.MaxS2SVersionOptions {
	if c == nil {
		return nil
	}
	return c.MaxS2Sversion
}

func (c *CreateOutputOutputSplunkLb) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputSplunkLb) GetIndexerDiscovery() *bool {
	if c == nil {
		return nil
	}
	return c.IndexerDiscovery
}

func (c *CreateOutputOutputSplunkLb) GetSenderUnhealthyTimeAllowance() *float64 {
	if c == nil {
		return nil
	}
	return c.SenderUnhealthyTimeAllowance
}

func (c *CreateOutputOutputSplunkLb) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputSplunkLb) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputSplunkLb) GetMaxFailedHealthChecks() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFailedHealthChecks
}

func (c *CreateOutputOutputSplunkLb) GetCompress() *components.CompressionOptions {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputSplunkLb) GetIndexerDiscoveryConfigs() *CreateOutputIndexerDiscoveryConfigs {
	if c == nil {
		return nil
	}
	return c.IndexerDiscoveryConfigs
}

func (c *CreateOutputOutputSplunkLb) GetExcludeSelf() *bool {
	if c == nil {
		return nil
	}
	return c.ExcludeSelf
}

func (c *CreateOutputOutputSplunkLb) GetHosts() []components.ItemsTypeHosts {
	if c == nil {
		return []components.ItemsTypeHosts{}
	}
	return c.Hosts
}

func (c *CreateOutputOutputSplunkLb) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputSplunkLb) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputSplunkLb) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputSplunkLb) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputSplunkLb) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputSplunkLb) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputSplunkLb) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputSplunkLb) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputSplunkLb) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputSplunkLb) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputSplunkLb) GetPqControls() *CreateOutputPqControlsSplunkLb {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputSplunkLb) GetAuthToken() *string {
	if c == nil {
		return nil
	}
	return c.AuthToken
}

func (c *CreateOutputOutputSplunkLb) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

type CreateOutputTypeSplunk string

const (
	CreateOutputTypeSplunkSplunk CreateOutputTypeSplunk = "splunk"
)

func (e CreateOutputTypeSplunk) ToPointer() *CreateOutputTypeSplunk {
	return &e
}
func (e *CreateOutputTypeSplunk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk":
		*e = CreateOutputTypeSplunk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeSplunk: %v", v)
	}
}

type CreateOutputPqControlsSplunk struct {
}

func (c CreateOutputPqControlsSplunk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsSplunk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputSplunk struct {
	// Unique ID for this output
	ID   string                 `json:"id"`
	Type CreateOutputTypeSplunk `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The hostname of the receiver
	Host string `json:"host"`
	// The port to connect to on the provided host
	Port float64 `json:"port"`
	// How to serialize nested fields into index-time fields
	NestedFields *components.NestedFieldSerializationOptions `json:"nestedFields,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `json:"throttleRatePerSec,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64                                                 `json:"writeTimeout,omitempty"`
	TLS          *components.TLSSettingsClientSideTypeKafkaSchemaRegistry `json:"tls,omitempty"`
	// Output metrics in multiple-metric format in a single event. Supported in Splunk 8.0 and above.
	EnableMultiMetrics *bool `json:"enableMultiMetrics,omitempty"`
	// Check if indexer is shutting down and stop sending data. This helps minimize data loss during shutdown.
	EnableACK *bool `json:"enableACK,omitempty"`
	// Use to troubleshoot issues with sending data
	LogFailedRequests *bool `json:"logFailedRequests,omitempty"`
	// The highest S2S protocol version to advertise during handshake
	MaxS2Sversion *components.MaxS2SVersionOptions `json:"maxS2Sversion,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitempty"`
	Description *string                                                `json:"description,omitempty"`
	// Maximum number of times healthcheck can fail before we close connection. If set to 0 (disabled), and the connection to Splunk is forcibly closed, some data loss might occur.
	MaxFailedHealthChecks *float64 `json:"maxFailedHealthChecks,omitempty"`
	// Controls whether the sender should send compressed data to the server. Select 'Disabled' to reject compressed connections or 'Always' to ignore server's configuration and send compressed data.
	Compress *components.CompressionOptions `json:"compress,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsSplunk        `json:"pqControls,omitempty"`
	// Shared secret token to use when establishing a connection to a Splunk indexer.
	AuthToken *string `json:"authToken,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Binds 'host' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'host' at runtime.
	TemplateHost *string `json:"__template_host,omitempty"`
	// Binds 'port' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'port' at runtime.
	TemplatePort *string `json:"__template_port,omitempty"`
}

func (c CreateOutputOutputSplunk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputSplunk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "host", "port"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputSplunk) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputSplunk) GetType() CreateOutputTypeSplunk {
	if c == nil {
		return CreateOutputTypeSplunk("")
	}
	return c.Type
}

func (c *CreateOutputOutputSplunk) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputSplunk) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputSplunk) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputSplunk) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputSplunk) GetHost() string {
	if c == nil {
		return ""
	}
	return c.Host
}

func (c *CreateOutputOutputSplunk) GetPort() float64 {
	if c == nil {
		return 0.0
	}
	return c.Port
}

func (c *CreateOutputOutputSplunk) GetNestedFields() *components.NestedFieldSerializationOptions {
	if c == nil {
		return nil
	}
	return c.NestedFields
}

func (c *CreateOutputOutputSplunk) GetThrottleRatePerSec() *string {
	if c == nil {
		return nil
	}
	return c.ThrottleRatePerSec
}

func (c *CreateOutputOutputSplunk) GetConnectionTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.ConnectionTimeout
}

func (c *CreateOutputOutputSplunk) GetWriteTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.WriteTimeout
}

func (c *CreateOutputOutputSplunk) GetTLS() *components.TLSSettingsClientSideTypeKafkaSchemaRegistry {
	if c == nil {
		return nil
	}
	return c.TLS
}

func (c *CreateOutputOutputSplunk) GetEnableMultiMetrics() *bool {
	if c == nil {
		return nil
	}
	return c.EnableMultiMetrics
}

func (c *CreateOutputOutputSplunk) GetEnableACK() *bool {
	if c == nil {
		return nil
	}
	return c.EnableACK
}

func (c *CreateOutputOutputSplunk) GetLogFailedRequests() *bool {
	if c == nil {
		return nil
	}
	return c.LogFailedRequests
}

func (c *CreateOutputOutputSplunk) GetMaxS2Sversion() *components.MaxS2SVersionOptions {
	if c == nil {
		return nil
	}
	return c.MaxS2Sversion
}

func (c *CreateOutputOutputSplunk) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputSplunk) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputSplunk) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputSplunk) GetMaxFailedHealthChecks() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxFailedHealthChecks
}

func (c *CreateOutputOutputSplunk) GetCompress() *components.CompressionOptions {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputSplunk) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputSplunk) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputSplunk) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputSplunk) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputSplunk) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputSplunk) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputSplunk) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputSplunk) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputSplunk) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputSplunk) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputSplunk) GetPqControls() *CreateOutputPqControlsSplunk {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputSplunk) GetAuthToken() *string {
	if c == nil {
		return nil
	}
	return c.AuthToken
}

func (c *CreateOutputOutputSplunk) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputSplunk) GetTemplateHost() *string {
	if c == nil {
		return nil
	}
	return c.TemplateHost
}

func (c *CreateOutputOutputSplunk) GetTemplatePort() *string {
	if c == nil {
		return nil
	}
	return c.TemplatePort
}

type CreateOutputTypeSyslog string

const (
	CreateOutputTypeSyslogSyslog CreateOutputTypeSyslog = "syslog"
)

func (e CreateOutputTypeSyslog) ToPointer() *CreateOutputTypeSyslog {
	return &e
}
func (e *CreateOutputTypeSyslog) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "syslog":
		*e = CreateOutputTypeSyslog(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeSyslog: %v", v)
	}
}

// CreateOutputProtocolSyslog - The network protocol to use for sending out syslog messages
type CreateOutputProtocolSyslog string

const (
	// CreateOutputProtocolSyslogTCP TCP
	CreateOutputProtocolSyslogTCP CreateOutputProtocolSyslog = "tcp"
	// CreateOutputProtocolSyslogUDP UDP
	CreateOutputProtocolSyslogUDP CreateOutputProtocolSyslog = "udp"
)

func (e CreateOutputProtocolSyslog) ToPointer() *CreateOutputProtocolSyslog {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputProtocolSyslog) IsExact() bool {
	if e != nil {
		switch *e {
		case "tcp", "udp":
			return true
		}
	}
	return false
}

// CreateOutputFacility - Default value for message facility. Will be overwritten by value of __facility if set. Defaults to user.
type CreateOutputFacility int64

const (
	CreateOutputFacilityZero      CreateOutputFacility = 0
	CreateOutputFacilityOne       CreateOutputFacility = 1
	CreateOutputFacilityTwo       CreateOutputFacility = 2
	CreateOutputFacilityThree     CreateOutputFacility = 3
	CreateOutputFacilityFour      CreateOutputFacility = 4
	CreateOutputFacilityFive      CreateOutputFacility = 5
	CreateOutputFacilitySix       CreateOutputFacility = 6
	CreateOutputFacilitySeven     CreateOutputFacility = 7
	CreateOutputFacilityEight     CreateOutputFacility = 8
	CreateOutputFacilityNine      CreateOutputFacility = 9
	CreateOutputFacilityTen       CreateOutputFacility = 10
	CreateOutputFacilityEleven    CreateOutputFacility = 11
	CreateOutputFacilityTwelve    CreateOutputFacility = 12
	CreateOutputFacilityThirteen  CreateOutputFacility = 13
	CreateOutputFacilityFourteen  CreateOutputFacility = 14
	CreateOutputFacilityFifteen   CreateOutputFacility = 15
	CreateOutputFacilitySixteen   CreateOutputFacility = 16
	CreateOutputFacilitySeventeen CreateOutputFacility = 17
	CreateOutputFacilityEighteen  CreateOutputFacility = 18
	CreateOutputFacilityNineteen  CreateOutputFacility = 19
	CreateOutputFacilityTwenty    CreateOutputFacility = 20
	CreateOutputFacilityTwentyOne CreateOutputFacility = 21
)

func (e CreateOutputFacility) ToPointer() *CreateOutputFacility {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputFacility) IsExact() bool {
	if e != nil {
		switch *e {
		case 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21:
			return true
		}
	}
	return false
}

// CreateOutputSeveritySyslog - Default value for message severity. Will be overwritten by value of __severity if set. Defaults to notice.
type CreateOutputSeveritySyslog int64

const (
	// CreateOutputSeveritySyslogZero emergency
	CreateOutputSeveritySyslogZero CreateOutputSeveritySyslog = 0
	// CreateOutputSeveritySyslogOne alert
	CreateOutputSeveritySyslogOne CreateOutputSeveritySyslog = 1
	// CreateOutputSeveritySyslogTwo critical
	CreateOutputSeveritySyslogTwo CreateOutputSeveritySyslog = 2
	// CreateOutputSeveritySyslogThree error
	CreateOutputSeveritySyslogThree CreateOutputSeveritySyslog = 3
	// CreateOutputSeveritySyslogFour warning
	CreateOutputSeveritySyslogFour CreateOutputSeveritySyslog = 4
	// CreateOutputSeveritySyslogFive notice
	CreateOutputSeveritySyslogFive CreateOutputSeveritySyslog = 5
	// CreateOutputSeveritySyslogSix info
	CreateOutputSeveritySyslogSix CreateOutputSeveritySyslog = 6
	// CreateOutputSeveritySyslogSeven debug
	CreateOutputSeveritySyslogSeven CreateOutputSeveritySyslog = 7
)

func (e CreateOutputSeveritySyslog) ToPointer() *CreateOutputSeveritySyslog {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputSeveritySyslog) IsExact() bool {
	if e != nil {
		switch *e {
		case 0, 1, 2, 3, 4, 5, 6, 7:
			return true
		}
	}
	return false
}

// CreateOutputMessageFormat - The syslog message format depending on the receiver's support
type CreateOutputMessageFormat string

const (
	// CreateOutputMessageFormatRfc3164 RFC3164
	CreateOutputMessageFormatRfc3164 CreateOutputMessageFormat = "rfc3164"
	// CreateOutputMessageFormatRfc5424 RFC5424
	CreateOutputMessageFormatRfc5424 CreateOutputMessageFormat = "rfc5424"
)

func (e CreateOutputMessageFormat) ToPointer() *CreateOutputMessageFormat {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputMessageFormat) IsExact() bool {
	if e != nil {
		switch *e {
		case "rfc3164", "rfc5424":
			return true
		}
	}
	return false
}

// CreateOutputTimestampFormat - Timestamp format to use when serializing event's time field
type CreateOutputTimestampFormat string

const (
	// CreateOutputTimestampFormatSyslog Syslog
	CreateOutputTimestampFormatSyslog CreateOutputTimestampFormat = "syslog"
	// CreateOutputTimestampFormatIso8601 ISO8601
	CreateOutputTimestampFormatIso8601 CreateOutputTimestampFormat = "iso8601"
)

func (e CreateOutputTimestampFormat) ToPointer() *CreateOutputTimestampFormat {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputTimestampFormat) IsExact() bool {
	if e != nil {
		switch *e {
		case "syslog", "iso8601":
			return true
		}
	}
	return false
}

type CreateOutputPqControlsSyslog struct {
}

func (c CreateOutputPqControlsSyslog) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsSyslog) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputSyslog struct {
	// Unique ID for this output
	ID   string                 `json:"id"`
	Type CreateOutputTypeSyslog `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The network protocol to use for sending out syslog messages
	Protocol *CreateOutputProtocolSyslog `json:"protocol,omitempty"`
	// Default value for message facility. Will be overwritten by value of __facility if set. Defaults to user.
	Facility *CreateOutputFacility `json:"facility,omitempty"`
	// Default value for message severity. Will be overwritten by value of __severity if set. Defaults to notice.
	Severity *CreateOutputSeveritySyslog `json:"severity,omitempty"`
	// Default name for device or application that originated the message. Defaults to Cribl, but will be overwritten by value of __appname if set.
	AppName *string `json:"appName,omitempty"`
	// The syslog message format depending on the receiver's support
	MessageFormat *CreateOutputMessageFormat `json:"messageFormat,omitempty"`
	// Timestamp format to use when serializing event's time field
	TimestampFormat *CreateOutputTimestampFormat `json:"timestampFormat,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `json:"throttleRatePerSec,omitempty"`
	// Prefix messages with the byte count of the message. If disabled, no prefix will be set, and the message will be appended with a \n.
	OctetCountFraming *bool `json:"octetCountFraming,omitempty"`
	// Use to troubleshoot issues with sending data
	LogFailedRequests *bool   `json:"logFailedRequests,omitempty"`
	Description       *string `json:"description,omitempty"`
	// For optimal performance, enable load balancing even if you have one hostname, as it can expand to multiple IPs.  If this setting is disabled, consider enabling round-robin DNS.
	LoadBalanced *bool `json:"loadBalanced,omitempty"`
	// The hostname of the receiver
	Host *string `json:"host,omitempty"`
	// The port to connect to on the provided host
	Port *float64 `json:"port,omitempty"`
	// Exclude all IPs of the current host from the list of any resolved hostnames
	ExcludeSelf *bool `json:"excludeSelf,omitempty"`
	// Set of hosts to load-balance data to
	Hosts []components.ItemsTypeHosts `json:"hosts,omitempty"`
	// The interval in which to re-resolve any hostnames and pick up destinations from A records
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	// How far back in time to keep traffic stats for load balancing purposes
	LoadBalanceStatsPeriodSec *float64 `json:"loadBalanceStatsPeriodSec,omitempty"`
	// Maximum number of concurrent connections (per Worker Process). A random set of IPs will be picked on every DNS resolution period. Use 0 for unlimited.
	MaxConcurrentSenders *float64 `json:"maxConcurrentSenders,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64                                                 `json:"writeTimeout,omitempty"`
	TLS          *components.TLSSettingsClientSideTypeKafkaSchemaRegistry `json:"tls,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Maximum size of syslog messages. Make sure this value is less than or equal to the MTU to avoid UDP packet fragmentation.
	MaxRecordSize *float64 `json:"maxRecordSize,omitempty"`
	// How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every message sent will incur a DNS lookup.
	UDPDNSResolvePeriodSec *float64 `json:"udpDnsResolvePeriodSec,omitempty"`
	// Send Syslog traffic using the original event's Source IP and port. To enable this, you must install the external `udp-sender` helper binary at `/usr/bin/udp-sender` on all Worker Nodes and grant it the `CAP_NET_RAW` capability.
	EnableIPSpoofing *bool `json:"enableIpSpoofing,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsSyslog        `json:"pqControls,omitempty"`
	// Binds 'host' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'host' at runtime.
	TemplateHost *string `json:"__template_host,omitempty"`
	// Binds 'port' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'port' at runtime.
	TemplatePort *string `json:"__template_port,omitempty"`
}

func (c CreateOutputOutputSyslog) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputSyslog) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputSyslog) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputSyslog) GetType() CreateOutputTypeSyslog {
	if c == nil {
		return CreateOutputTypeSyslog("")
	}
	return c.Type
}

func (c *CreateOutputOutputSyslog) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputSyslog) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputSyslog) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputSyslog) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputSyslog) GetProtocol() *CreateOutputProtocolSyslog {
	if c == nil {
		return nil
	}
	return c.Protocol
}

func (c *CreateOutputOutputSyslog) GetFacility() *CreateOutputFacility {
	if c == nil {
		return nil
	}
	return c.Facility
}

func (c *CreateOutputOutputSyslog) GetSeverity() *CreateOutputSeveritySyslog {
	if c == nil {
		return nil
	}
	return c.Severity
}

func (c *CreateOutputOutputSyslog) GetAppName() *string {
	if c == nil {
		return nil
	}
	return c.AppName
}

func (c *CreateOutputOutputSyslog) GetMessageFormat() *CreateOutputMessageFormat {
	if c == nil {
		return nil
	}
	return c.MessageFormat
}

func (c *CreateOutputOutputSyslog) GetTimestampFormat() *CreateOutputTimestampFormat {
	if c == nil {
		return nil
	}
	return c.TimestampFormat
}

func (c *CreateOutputOutputSyslog) GetThrottleRatePerSec() *string {
	if c == nil {
		return nil
	}
	return c.ThrottleRatePerSec
}

func (c *CreateOutputOutputSyslog) GetOctetCountFraming() *bool {
	if c == nil {
		return nil
	}
	return c.OctetCountFraming
}

func (c *CreateOutputOutputSyslog) GetLogFailedRequests() *bool {
	if c == nil {
		return nil
	}
	return c.LogFailedRequests
}

func (c *CreateOutputOutputSyslog) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputSyslog) GetLoadBalanced() *bool {
	if c == nil {
		return nil
	}
	return c.LoadBalanced
}

func (c *CreateOutputOutputSyslog) GetHost() *string {
	if c == nil {
		return nil
	}
	return c.Host
}

func (c *CreateOutputOutputSyslog) GetPort() *float64 {
	if c == nil {
		return nil
	}
	return c.Port
}

func (c *CreateOutputOutputSyslog) GetExcludeSelf() *bool {
	if c == nil {
		return nil
	}
	return c.ExcludeSelf
}

func (c *CreateOutputOutputSyslog) GetHosts() []components.ItemsTypeHosts {
	if c == nil {
		return nil
	}
	return c.Hosts
}

func (c *CreateOutputOutputSyslog) GetDNSResolvePeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.DNSResolvePeriodSec
}

func (c *CreateOutputOutputSyslog) GetLoadBalanceStatsPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.LoadBalanceStatsPeriodSec
}

func (c *CreateOutputOutputSyslog) GetMaxConcurrentSenders() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxConcurrentSenders
}

func (c *CreateOutputOutputSyslog) GetConnectionTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.ConnectionTimeout
}

func (c *CreateOutputOutputSyslog) GetWriteTimeout() *float64 {
	if c == nil {
		return nil
	}
	return c.WriteTimeout
}

func (c *CreateOutputOutputSyslog) GetTLS() *components.TLSSettingsClientSideTypeKafkaSchemaRegistry {
	if c == nil {
		return nil
	}
	return c.TLS
}

func (c *CreateOutputOutputSyslog) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputSyslog) GetMaxRecordSize() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxRecordSize
}

func (c *CreateOutputOutputSyslog) GetUDPDNSResolvePeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.UDPDNSResolvePeriodSec
}

func (c *CreateOutputOutputSyslog) GetEnableIPSpoofing() *bool {
	if c == nil {
		return nil
	}
	return c.EnableIPSpoofing
}

func (c *CreateOutputOutputSyslog) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputSyslog) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputSyslog) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputSyslog) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputSyslog) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputSyslog) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputSyslog) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputSyslog) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputSyslog) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputSyslog) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputSyslog) GetPqControls() *CreateOutputPqControlsSyslog {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputSyslog) GetTemplateHost() *string {
	if c == nil {
		return nil
	}
	return c.TemplateHost
}

func (c *CreateOutputOutputSyslog) GetTemplatePort() *string {
	if c == nil {
		return nil
	}
	return c.TemplatePort
}

type CreateOutputTypeDevnull string

const (
	CreateOutputTypeDevnullDevnull CreateOutputTypeDevnull = "devnull"
)

func (e CreateOutputTypeDevnull) ToPointer() *CreateOutputTypeDevnull {
	return &e
}
func (e *CreateOutputTypeDevnull) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "devnull":
		*e = CreateOutputTypeDevnull(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeDevnull: %v", v)
	}
}

type CreateOutputOutputDevnull struct {
	// Unique ID for this output
	ID   string                  `json:"id"`
	Type CreateOutputTypeDevnull `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
}

func (c CreateOutputOutputDevnull) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputDevnull) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputDevnull) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputDevnull) GetType() CreateOutputTypeDevnull {
	if c == nil {
		return CreateOutputTypeDevnull("")
	}
	return c.Type
}

func (c *CreateOutputOutputDevnull) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputDevnull) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputDevnull) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputDevnull) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

type CreateOutputTypeSentinel string

const (
	CreateOutputTypeSentinelSentinel CreateOutputTypeSentinel = "sentinel"
)

func (e CreateOutputTypeSentinel) ToPointer() *CreateOutputTypeSentinel {
	return &e
}
func (e *CreateOutputTypeSentinel) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sentinel":
		*e = CreateOutputTypeSentinel(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeSentinel: %v", v)
	}
}

type CreateOutputAuthType string

const (
	CreateOutputAuthTypeOauth CreateOutputAuthType = "oauth"
)

func (e CreateOutputAuthType) ToPointer() *CreateOutputAuthType {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputAuthType) IsExact() bool {
	if e != nil {
		switch *e {
		case "oauth":
			return true
		}
	}
	return false
}

// CreateOutputEndpointConfiguration - Enter the data collection endpoint URL or the individual ID
type CreateOutputEndpointConfiguration string

const (
	// CreateOutputEndpointConfigurationURL URL
	CreateOutputEndpointConfigurationURL CreateOutputEndpointConfiguration = "url"
	// CreateOutputEndpointConfigurationID ID
	CreateOutputEndpointConfigurationID CreateOutputEndpointConfiguration = "ID"
)

func (e CreateOutputEndpointConfiguration) ToPointer() *CreateOutputEndpointConfiguration {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputEndpointConfiguration) IsExact() bool {
	if e != nil {
		switch *e {
		case "url", "ID":
			return true
		}
	}
	return false
}

type CreateOutputFormatSentinel string

const (
	CreateOutputFormatSentinelNdjson    CreateOutputFormatSentinel = "ndjson"
	CreateOutputFormatSentinelJSONArray CreateOutputFormatSentinel = "json_array"
	CreateOutputFormatSentinelCustom    CreateOutputFormatSentinel = "custom"
	CreateOutputFormatSentinelAdvanced  CreateOutputFormatSentinel = "advanced"
)

func (e CreateOutputFormatSentinel) ToPointer() *CreateOutputFormatSentinel {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputFormatSentinel) IsExact() bool {
	if e != nil {
		switch *e {
		case "ndjson", "json_array", "custom", "advanced":
			return true
		}
	}
	return false
}

type CreateOutputPqControlsSentinel struct {
}

func (c CreateOutputPqControlsSentinel) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsSentinel) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOutputSentinel struct {
	// Unique ID for this output
	ID   string                   `json:"id"`
	Type CreateOutputTypeSentinel `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Disable to close the connection immediately after sending the outgoing request
	KeepAlive *bool `json:"keepAlive,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size (KB) of the request body (defaults to the API's maximum limit of 1000 KB)
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events. You can also add headers dynamically on a per-event basis in the __headers field, as explained in [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook/#internal-fields).
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	AuthType       *CreateOutputAuthType                   `json:"authType,omitempty"`
	// URL for OAuth
	LoginURL string `json:"loginUrl"`
	// Secret parameter value to pass in request body
	Secret string `json:"secret"`
	// JavaScript expression to compute the Client ID for the Azure application. Can be a constant.
	ClientID string `json:"client_id"`
	// Scope to pass in the OAuth request
	Scope *string `json:"scope,omitempty"`
	// Enter the data collection endpoint URL or the individual ID
	EndpointURLConfiguration CreateOutputEndpointConfiguration `json:"endpointURLConfiguration"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64                    `json:"totalMemoryLimitKB,omitempty"`
	Description        *string                     `json:"description,omitempty"`
	Format             *CreateOutputFormatSentinel `json:"format,omitempty"`
	// Expression to evaluate on events to generate output. Example: `raw=${_raw}`. See [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook#custom-format) for other examples. If empty, the full event is sent as stringified JSON.
	CustomSourceExpression *string `json:"customSourceExpression,omitempty"`
	// Whether to drop events when the source expression evaluates to null
	CustomDropWhenNull *bool `json:"customDropWhenNull,omitempty"`
	// Delimiter string to insert between individual events. Defaults to newline character.
	CustomEventDelimiter *string `json:"customEventDelimiter,omitempty"`
	// Content type to use for request. Defaults to application/x-ndjson. Any content types set in Advanced Settings > Extra HTTP headers will override this entry.
	CustomContentType *string `json:"customContentType,omitempty"`
	// Expression specifying how to format the payload for each batch. To reference the events to send, use the `${events}` variable. Example expression: `{ "items" : [${events}] }` would send the batch inside a JSON object.
	CustomPayloadExpression *string `json:"customPayloadExpression,omitempty"`
	// HTTP content-type header value
	AdvancedContentType *string `json:"advancedContentType,omitempty"`
	// Custom JavaScript code to format incoming event data accessible through the __e variable. The formatted content is added to (__e['__eventOut']) if available. Otherwise, the original event is serialized as JSON. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
	FormatEventCode *string `json:"formatEventCode,omitempty"`
	// Optional JavaScript code to format the payload sent to the Destination. The payload, containing a batch of formatted events, is accessible through the __e['payload'] variable. The formatted payload is returned in the __e['__payloadOut'] variable. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
	FormatPayloadCode *string `json:"formatPayloadCode,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsSentinel      `json:"pqControls,omitempty"`
	// URL to send events to. Can be overwritten by an event's __url field.
	URL *string `json:"url,omitempty"`
	// Immutable ID for the Data Collection Rule (DCR)
	DcrID *string `json:"dcrID,omitempty"`
	// Data collection endpoint (DCE) URL. In the format: `https://<Endpoint-Name>-<Identifier>.<Region>.ingest.monitor.azure.com`
	DceEndpoint *string `json:"dceEndpoint,omitempty"`
	// The name of the stream (Sentinel table) in which to store the events
	StreamName *string `json:"streamName,omitempty"`
	// Binds 'loginUrl' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'loginUrl' at runtime.
	TemplateLoginURL *string `json:"__template_loginUrl,omitempty"`
	// Binds 'secret' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'secret' at runtime.
	TemplateSecret *string `json:"__template_secret,omitempty"`
	// Binds 'client_id' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'client_id' at runtime.
	TemplateClientID *string `json:"__template_client_id,omitempty"`
	// Binds 'scope' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'scope' at runtime.
	TemplateScope *string `json:"__template_scope,omitempty"`
	// Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
	TemplateURL *string `json:"__template_url,omitempty"`
	// Binds 'dcrID' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'dcrID' at runtime.
	TemplateDcrID *string `json:"__template_dcrID,omitempty"`
	// Binds 'dceEndpoint' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'dceEndpoint' at runtime.
	TemplateDceEndpoint *string `json:"__template_dceEndpoint,omitempty"`
	// Binds 'streamName' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'streamName' at runtime.
	TemplateStreamName *string `json:"__template_streamName,omitempty"`
}

func (c CreateOutputOutputSentinel) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputSentinel) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "loginUrl", "secret", "client_id", "endpointURLConfiguration"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputSentinel) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputSentinel) GetType() CreateOutputTypeSentinel {
	if c == nil {
		return CreateOutputTypeSentinel("")
	}
	return c.Type
}

func (c *CreateOutputOutputSentinel) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputSentinel) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputSentinel) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputSentinel) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputSentinel) GetKeepAlive() *bool {
	if c == nil {
		return nil
	}
	return c.KeepAlive
}

func (c *CreateOutputOutputSentinel) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputSentinel) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputSentinel) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputSentinel) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputSentinel) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputSentinel) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputSentinel) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputSentinel) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputSentinel) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputSentinel) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputSentinel) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputSentinel) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputSentinel) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputSentinel) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputSentinel) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputSentinel) GetAuthType() *CreateOutputAuthType {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputSentinel) GetLoginURL() string {
	if c == nil {
		return ""
	}
	return c.LoginURL
}

func (c *CreateOutputOutputSentinel) GetSecret() string {
	if c == nil {
		return ""
	}
	return c.Secret
}

func (c *CreateOutputOutputSentinel) GetClientID() string {
	if c == nil {
		return ""
	}
	return c.ClientID
}

func (c *CreateOutputOutputSentinel) GetScope() *string {
	if c == nil {
		return nil
	}
	return c.Scope
}

func (c *CreateOutputOutputSentinel) GetEndpointURLConfiguration() CreateOutputEndpointConfiguration {
	if c == nil {
		return CreateOutputEndpointConfiguration("")
	}
	return c.EndpointURLConfiguration
}

func (c *CreateOutputOutputSentinel) GetTotalMemoryLimitKB() *float64 {
	if c == nil {
		return nil
	}
	return c.TotalMemoryLimitKB
}

func (c *CreateOutputOutputSentinel) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputSentinel) GetFormat() *CreateOutputFormatSentinel {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputSentinel) GetCustomSourceExpression() *string {
	if c == nil {
		return nil
	}
	return c.CustomSourceExpression
}

func (c *CreateOutputOutputSentinel) GetCustomDropWhenNull() *bool {
	if c == nil {
		return nil
	}
	return c.CustomDropWhenNull
}

func (c *CreateOutputOutputSentinel) GetCustomEventDelimiter() *string {
	if c == nil {
		return nil
	}
	return c.CustomEventDelimiter
}

func (c *CreateOutputOutputSentinel) GetCustomContentType() *string {
	if c == nil {
		return nil
	}
	return c.CustomContentType
}

func (c *CreateOutputOutputSentinel) GetCustomPayloadExpression() *string {
	if c == nil {
		return nil
	}
	return c.CustomPayloadExpression
}

func (c *CreateOutputOutputSentinel) GetAdvancedContentType() *string {
	if c == nil {
		return nil
	}
	return c.AdvancedContentType
}

func (c *CreateOutputOutputSentinel) GetFormatEventCode() *string {
	if c == nil {
		return nil
	}
	return c.FormatEventCode
}

func (c *CreateOutputOutputSentinel) GetFormatPayloadCode() *string {
	if c == nil {
		return nil
	}
	return c.FormatPayloadCode
}

func (c *CreateOutputOutputSentinel) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputSentinel) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputSentinel) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputSentinel) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputSentinel) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputSentinel) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputSentinel) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputSentinel) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputSentinel) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputSentinel) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputSentinel) GetPqControls() *CreateOutputPqControlsSentinel {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputSentinel) GetURL() *string {
	if c == nil {
		return nil
	}
	return c.URL
}

func (c *CreateOutputOutputSentinel) GetDcrID() *string {
	if c == nil {
		return nil
	}
	return c.DcrID
}

func (c *CreateOutputOutputSentinel) GetDceEndpoint() *string {
	if c == nil {
		return nil
	}
	return c.DceEndpoint
}

func (c *CreateOutputOutputSentinel) GetStreamName() *string {
	if c == nil {
		return nil
	}
	return c.StreamName
}

func (c *CreateOutputOutputSentinel) GetTemplateLoginURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateLoginURL
}

func (c *CreateOutputOutputSentinel) GetTemplateSecret() *string {
	if c == nil {
		return nil
	}
	return c.TemplateSecret
}

func (c *CreateOutputOutputSentinel) GetTemplateClientID() *string {
	if c == nil {
		return nil
	}
	return c.TemplateClientID
}

func (c *CreateOutputOutputSentinel) GetTemplateScope() *string {
	if c == nil {
		return nil
	}
	return c.TemplateScope
}

func (c *CreateOutputOutputSentinel) GetTemplateURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateURL
}

func (c *CreateOutputOutputSentinel) GetTemplateDcrID() *string {
	if c == nil {
		return nil
	}
	return c.TemplateDcrID
}

func (c *CreateOutputOutputSentinel) GetTemplateDceEndpoint() *string {
	if c == nil {
		return nil
	}
	return c.TemplateDceEndpoint
}

func (c *CreateOutputOutputSentinel) GetTemplateStreamName() *string {
	if c == nil {
		return nil
	}
	return c.TemplateStreamName
}

type CreateOutputTypeWebhook string

const (
	CreateOutputTypeWebhookWebhook CreateOutputTypeWebhook = "webhook"
)

func (e CreateOutputTypeWebhook) ToPointer() *CreateOutputTypeWebhook {
	return &e
}
func (e *CreateOutputTypeWebhook) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "webhook":
		*e = CreateOutputTypeWebhook(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeWebhook: %v", v)
	}
}

// CreateOutputFormatWebhook - How to format events before sending out
type CreateOutputFormatWebhook string

const (
	// CreateOutputFormatWebhookNdjson NDJSON (Newline Delimited JSON)
	CreateOutputFormatWebhookNdjson CreateOutputFormatWebhook = "ndjson"
	// CreateOutputFormatWebhookJSONArray JSON Array
	CreateOutputFormatWebhookJSONArray CreateOutputFormatWebhook = "json_array"
	// CreateOutputFormatWebhookCustom Custom
	CreateOutputFormatWebhookCustom CreateOutputFormatWebhook = "custom"
	// CreateOutputFormatWebhookAdvanced Advanced
	CreateOutputFormatWebhookAdvanced CreateOutputFormatWebhook = "advanced"
)

func (e CreateOutputFormatWebhook) ToPointer() *CreateOutputFormatWebhook {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputFormatWebhook) IsExact() bool {
	if e != nil {
		switch *e {
		case "ndjson", "json_array", "custom", "advanced":
			return true
		}
	}
	return false
}

// CreateOutputAuthenticationTypeWebhook - Authentication method to use for the HTTP request
type CreateOutputAuthenticationTypeWebhook string

const (
	// CreateOutputAuthenticationTypeWebhookNone None
	CreateOutputAuthenticationTypeWebhookNone CreateOutputAuthenticationTypeWebhook = "none"
	// CreateOutputAuthenticationTypeWebhookBasic Basic
	CreateOutputAuthenticationTypeWebhookBasic CreateOutputAuthenticationTypeWebhook = "basic"
	// CreateOutputAuthenticationTypeWebhookCredentialsSecret Basic (credentials secret)
	CreateOutputAuthenticationTypeWebhookCredentialsSecret CreateOutputAuthenticationTypeWebhook = "credentialsSecret"
	// CreateOutputAuthenticationTypeWebhookToken Token
	CreateOutputAuthenticationTypeWebhookToken CreateOutputAuthenticationTypeWebhook = "token"
	// CreateOutputAuthenticationTypeWebhookTextSecret Token (text secret)
	CreateOutputAuthenticationTypeWebhookTextSecret CreateOutputAuthenticationTypeWebhook = "textSecret"
	// CreateOutputAuthenticationTypeWebhookOauth OAuth
	CreateOutputAuthenticationTypeWebhookOauth CreateOutputAuthenticationTypeWebhook = "oauth"
)

func (e CreateOutputAuthenticationTypeWebhook) ToPointer() *CreateOutputAuthenticationTypeWebhook {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputAuthenticationTypeWebhook) IsExact() bool {
	if e != nil {
		switch *e {
		case "none", "basic", "credentialsSecret", "token", "textSecret", "oauth":
			return true
		}
	}
	return false
}

type CreateOutputPqControlsWebhook struct {
}

func (c CreateOutputPqControlsWebhook) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputPqControlsWebhook) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

type CreateOutputOauthParam struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (c CreateOutputOauthParam) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOauthParam) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOauthParam) GetName() string {
	if c == nil {
		return ""
	}
	return c.Name
}

func (c *CreateOutputOauthParam) GetValue() string {
	if c == nil {
		return ""
	}
	return c.Value
}

type CreateOutputOauthHeader struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (c CreateOutputOauthHeader) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOauthHeader) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOauthHeader) GetName() string {
	if c == nil {
		return ""
	}
	return c.Name
}

func (c *CreateOutputOauthHeader) GetValue() string {
	if c == nil {
		return ""
	}
	return c.Value
}

type CreateOutputURLWebhook struct {
	// URL of a webhook endpoint to send events to, such as http://localhost:10200
	URL string `json:"url"`
	// Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
	Weight *float64 `json:"weight,omitempty"`
	// Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
	TemplateURL *string `json:"__template_url,omitempty"`
}

func (c CreateOutputURLWebhook) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputURLWebhook) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"url"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputURLWebhook) GetURL() string {
	if c == nil {
		return ""
	}
	return c.URL
}

func (c *CreateOutputURLWebhook) GetWeight() *float64 {
	if c == nil {
		return nil
	}
	return c.Weight
}

func (c *CreateOutputURLWebhook) GetTemplateURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateURL
}

type CreateOutputOutputWebhook struct {
	// Unique ID for this output
	ID   string                  `json:"id"`
	Type CreateOutputTypeWebhook `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The method to use when sending events
	Method *components.MethodOptions `json:"method,omitempty"`
	// How to format events before sending out
	Format *CreateOutputFormatWebhook `json:"format,omitempty"`
	// Disable to close the connection immediately after sending the outgoing request
	KeepAlive *bool `json:"keepAlive,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events. You can also add headers dynamically on a per-event basis in the __headers field, as explained in [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook/#internal-fields).
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Authentication method to use for the HTTP request
	AuthType *CreateOutputAuthenticationTypeWebhook `json:"authType,omitempty"`
	TLS      *components.TLSSettingsClientSideType1 `json:"tls,omitempty"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	// Enable for optimal performance. Even if you have one hostname, it can expand to multiple IPs. If disabled, consider enabling round-robin DNS.
	LoadBalanced *bool   `json:"loadBalanced,omitempty"`
	Description  *string `json:"description,omitempty"`
	// Expression to evaluate on events to generate output. Example: `raw=${_raw}`. See [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook#custom-format) for other examples. If empty, the full event is sent as stringified JSON.
	CustomSourceExpression *string `json:"customSourceExpression,omitempty"`
	// Whether to drop events when the source expression evaluates to null
	CustomDropWhenNull *bool `json:"customDropWhenNull,omitempty"`
	// Delimiter string to insert between individual events. Defaults to newline character.
	CustomEventDelimiter *string `json:"customEventDelimiter,omitempty"`
	// Content type to use for request. Defaults to application/x-ndjson. Any content types set in Advanced Settings > Extra HTTP headers will override this entry.
	CustomContentType *string `json:"customContentType,omitempty"`
	// Expression specifying how to format the payload for each batch. To reference the events to send, use the `${events}` variable. Example expression: `{ "items" : [${events}] }` would send the batch inside a JSON object.
	CustomPayloadExpression *string `json:"customPayloadExpression,omitempty"`
	// HTTP content-type header value
	AdvancedContentType *string `json:"advancedContentType,omitempty"`
	// Custom JavaScript code to format incoming event data accessible through the __e variable. The formatted content is added to (__e['__eventOut']) if available. Otherwise, the original event is serialized as JSON. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
	FormatEventCode *string `json:"formatEventCode,omitempty"`
	// Optional JavaScript code to format the payload sent to the Destination. The payload, containing a batch of formatted events, is accessible through the __e['payload'] variable. The formatted payload is returned in the __e['__payloadOut'] variable. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
	FormatPayloadCode *string `json:"formatPayloadCode,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *CreateOutputPqControlsWebhook       `json:"pqControls,omitempty"`
	Username         *string                              `json:"username,omitempty"`
	Password         *string                              `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `json:"authHeaderExpr,omitempty"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `json:"tokenTimeoutSecs,omitempty"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []CreateOutputOauthParam `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []CreateOutputOauthHeader `json:"oauthHeaders,omitempty"`
	// URL of a webhook endpoint to send events to, such as http://localhost:10200
	URL *string `json:"url,omitempty"`
	// Exclude all IPs of the current host from the list of any resolved hostnames
	ExcludeSelf *bool                    `json:"excludeSelf,omitempty"`
	Urls        []CreateOutputURLWebhook `json:"urls,omitempty"`
	// The interval in which to re-resolve any hostnames and pick up destinations from A records
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	// How far back in time to keep traffic stats for load balancing purposes
	LoadBalanceStatsPeriodSec *float64 `json:"loadBalanceStatsPeriodSec,omitempty"`
	// Binds 'loginUrl' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'loginUrl' at runtime.
	TemplateLoginURL *string `json:"__template_loginUrl,omitempty"`
	// Binds 'secret' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'secret' at runtime.
	TemplateSecret *string `json:"__template_secret,omitempty"`
	// Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
	TemplateURL *string `json:"__template_url,omitempty"`
}

func (c CreateOutputOutputWebhook) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputWebhook) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputWebhook) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputWebhook) GetType() CreateOutputTypeWebhook {
	if c == nil {
		return CreateOutputTypeWebhook("")
	}
	return c.Type
}

func (c *CreateOutputOutputWebhook) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputWebhook) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputWebhook) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputWebhook) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputWebhook) GetMethod() *components.MethodOptions {
	if c == nil {
		return nil
	}
	return c.Method
}

func (c *CreateOutputOutputWebhook) GetFormat() *CreateOutputFormatWebhook {
	if c == nil {
		return nil
	}
	return c.Format
}

func (c *CreateOutputOutputWebhook) GetKeepAlive() *bool {
	if c == nil {
		return nil
	}
	return c.KeepAlive
}

func (c *CreateOutputOutputWebhook) GetConcurrency() *float64 {
	if c == nil {
		return nil
	}
	return c.Concurrency
}

func (c *CreateOutputOutputWebhook) GetMaxPayloadSizeKB() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadSizeKB
}

func (c *CreateOutputOutputWebhook) GetMaxPayloadEvents() *float64 {
	if c == nil {
		return nil
	}
	return c.MaxPayloadEvents
}

func (c *CreateOutputOutputWebhook) GetCompress() *bool {
	if c == nil {
		return nil
	}
	return c.Compress
}

func (c *CreateOutputOutputWebhook) GetRejectUnauthorized() *bool {
	if c == nil {
		return nil
	}
	return c.RejectUnauthorized
}

func (c *CreateOutputOutputWebhook) GetTimeoutSec() *float64 {
	if c == nil {
		return nil
	}
	return c.TimeoutSec
}

func (c *CreateOutputOutputWebhook) GetFlushPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.FlushPeriodSec
}

func (c *CreateOutputOutputWebhook) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if c == nil {
		return nil
	}
	return c.ExtraHTTPHeaders
}

func (c *CreateOutputOutputWebhook) GetUseRoundRobinDNS() *bool {
	if c == nil {
		return nil
	}
	return c.UseRoundRobinDNS
}

func (c *CreateOutputOutputWebhook) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if c == nil {
		return nil
	}
	return c.FailedRequestLoggingMode
}

func (c *CreateOutputOutputWebhook) GetSafeHeaders() []string {
	if c == nil {
		return nil
	}
	return c.SafeHeaders
}

func (c *CreateOutputOutputWebhook) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if c == nil {
		return nil
	}
	return c.ResponseRetrySettings
}

func (c *CreateOutputOutputWebhook) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if c == nil {
		return nil
	}
	return c.TimeoutRetrySettings
}

func (c *CreateOutputOutputWebhook) GetResponseHonorRetryAfterHeader() *bool {
	if c == nil {
		return nil
	}
	return c.ResponseHonorRetryAfterHeader
}

func (c *CreateOutputOutputWebhook) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.OnBackpressure
}

func (c *CreateOutputOutputWebhook) GetAuthType() *CreateOutputAuthenticationTypeWebhook {
	if c == nil {
		return nil
	}
	return c.AuthType
}

func (c *CreateOutputOutputWebhook) GetTLS() *components.TLSSettingsClientSideType1 {
	if c == nil {
		return nil
	}
	return c.TLS
}

func (c *CreateOutputOutputWebhook) GetTotalMemoryLimitKB() *float64 {
	if c == nil {
		return nil
	}
	return c.TotalMemoryLimitKB
}

func (c *CreateOutputOutputWebhook) GetLoadBalanced() *bool {
	if c == nil {
		return nil
	}
	return c.LoadBalanced
}

func (c *CreateOutputOutputWebhook) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputOutputWebhook) GetCustomSourceExpression() *string {
	if c == nil {
		return nil
	}
	return c.CustomSourceExpression
}

func (c *CreateOutputOutputWebhook) GetCustomDropWhenNull() *bool {
	if c == nil {
		return nil
	}
	return c.CustomDropWhenNull
}

func (c *CreateOutputOutputWebhook) GetCustomEventDelimiter() *string {
	if c == nil {
		return nil
	}
	return c.CustomEventDelimiter
}

func (c *CreateOutputOutputWebhook) GetCustomContentType() *string {
	if c == nil {
		return nil
	}
	return c.CustomContentType
}

func (c *CreateOutputOutputWebhook) GetCustomPayloadExpression() *string {
	if c == nil {
		return nil
	}
	return c.CustomPayloadExpression
}

func (c *CreateOutputOutputWebhook) GetAdvancedContentType() *string {
	if c == nil {
		return nil
	}
	return c.AdvancedContentType
}

func (c *CreateOutputOutputWebhook) GetFormatEventCode() *string {
	if c == nil {
		return nil
	}
	return c.FormatEventCode
}

func (c *CreateOutputOutputWebhook) GetFormatPayloadCode() *string {
	if c == nil {
		return nil
	}
	return c.FormatPayloadCode
}

func (c *CreateOutputOutputWebhook) GetPqStrictOrdering() *bool {
	if c == nil {
		return nil
	}
	return c.PqStrictOrdering
}

func (c *CreateOutputOutputWebhook) GetPqRatePerSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqRatePerSec
}

func (c *CreateOutputOutputWebhook) GetPqMode() *components.ModeOptions {
	if c == nil {
		return nil
	}
	return c.PqMode
}

func (c *CreateOutputOutputWebhook) GetPqMaxBufferSize() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBufferSize
}

func (c *CreateOutputOutputWebhook) GetPqMaxBackpressureSec() *float64 {
	if c == nil {
		return nil
	}
	return c.PqMaxBackpressureSec
}

func (c *CreateOutputOutputWebhook) GetPqMaxFileSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxFileSize
}

func (c *CreateOutputOutputWebhook) GetPqMaxSize() *string {
	if c == nil {
		return nil
	}
	return c.PqMaxSize
}

func (c *CreateOutputOutputWebhook) GetPqPath() *string {
	if c == nil {
		return nil
	}
	return c.PqPath
}

func (c *CreateOutputOutputWebhook) GetPqCompress() *components.CompressionOptionsPq {
	if c == nil {
		return nil
	}
	return c.PqCompress
}

func (c *CreateOutputOutputWebhook) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if c == nil {
		return nil
	}
	return c.PqOnBackpressure
}

func (c *CreateOutputOutputWebhook) GetPqControls() *CreateOutputPqControlsWebhook {
	if c == nil {
		return nil
	}
	return c.PqControls
}

func (c *CreateOutputOutputWebhook) GetUsername() *string {
	if c == nil {
		return nil
	}
	return c.Username
}

func (c *CreateOutputOutputWebhook) GetPassword() *string {
	if c == nil {
		return nil
	}
	return c.Password
}

func (c *CreateOutputOutputWebhook) GetToken() *string {
	if c == nil {
		return nil
	}
	return c.Token
}

func (c *CreateOutputOutputWebhook) GetCredentialsSecret() *string {
	if c == nil {
		return nil
	}
	return c.CredentialsSecret
}

func (c *CreateOutputOutputWebhook) GetTextSecret() *string {
	if c == nil {
		return nil
	}
	return c.TextSecret
}

func (c *CreateOutputOutputWebhook) GetLoginURL() *string {
	if c == nil {
		return nil
	}
	return c.LoginURL
}

func (c *CreateOutputOutputWebhook) GetSecretParamName() *string {
	if c == nil {
		return nil
	}
	return c.SecretParamName
}

func (c *CreateOutputOutputWebhook) GetSecret() *string {
	if c == nil {
		return nil
	}
	return c.Secret
}

func (c *CreateOutputOutputWebhook) GetTokenAttributeName() *string {
	if c == nil {
		return nil
	}
	return c.TokenAttributeName
}

func (c *CreateOutputOutputWebhook) GetAuthHeaderExpr() *string {
	if c == nil {
		return nil
	}
	return c.AuthHeaderExpr
}

func (c *CreateOutputOutputWebhook) GetTokenTimeoutSecs() *float64 {
	if c == nil {
		return nil
	}
	return c.TokenTimeoutSecs
}

func (c *CreateOutputOutputWebhook) GetOauthParams() []CreateOutputOauthParam {
	if c == nil {
		return nil
	}
	return c.OauthParams
}

func (c *CreateOutputOutputWebhook) GetOauthHeaders() []CreateOutputOauthHeader {
	if c == nil {
		return nil
	}
	return c.OauthHeaders
}

func (c *CreateOutputOutputWebhook) GetURL() *string {
	if c == nil {
		return nil
	}
	return c.URL
}

func (c *CreateOutputOutputWebhook) GetExcludeSelf() *bool {
	if c == nil {
		return nil
	}
	return c.ExcludeSelf
}

func (c *CreateOutputOutputWebhook) GetUrls() []CreateOutputURLWebhook {
	if c == nil {
		return nil
	}
	return c.Urls
}

func (c *CreateOutputOutputWebhook) GetDNSResolvePeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.DNSResolvePeriodSec
}

func (c *CreateOutputOutputWebhook) GetLoadBalanceStatsPeriodSec() *float64 {
	if c == nil {
		return nil
	}
	return c.LoadBalanceStatsPeriodSec
}

func (c *CreateOutputOutputWebhook) GetTemplateLoginURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateLoginURL
}

func (c *CreateOutputOutputWebhook) GetTemplateSecret() *string {
	if c == nil {
		return nil
	}
	return c.TemplateSecret
}

func (c *CreateOutputOutputWebhook) GetTemplateURL() *string {
	if c == nil {
		return nil
	}
	return c.TemplateURL
}

type CreateOutputTypeDefault string

const (
	CreateOutputTypeDefaultDefault CreateOutputTypeDefault = "default"
)

func (e CreateOutputTypeDefault) ToPointer() *CreateOutputTypeDefault {
	return &e
}
func (e *CreateOutputTypeDefault) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "default":
		*e = CreateOutputTypeDefault(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeDefault: %v", v)
	}
}

type CreateOutputOutputDefault struct {
	// Unique ID for this output
	ID   string                  `json:"id"`
	Type CreateOutputTypeDefault `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// ID of the default output. This will be used whenever a nonexistent/deleted output is referenced.
	DefaultID string `json:"defaultId"`
}

func (c CreateOutputOutputDefault) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputOutputDefault) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, []string{"id", "type", "defaultId"}); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputOutputDefault) GetID() string {
	if c == nil {
		return ""
	}
	return c.ID
}

func (c *CreateOutputOutputDefault) GetType() CreateOutputTypeDefault {
	if c == nil {
		return CreateOutputTypeDefault("")
	}
	return c.Type
}

func (c *CreateOutputOutputDefault) GetPipeline() *string {
	if c == nil {
		return nil
	}
	return c.Pipeline
}

func (c *CreateOutputOutputDefault) GetSystemFields() []string {
	if c == nil {
		return nil
	}
	return c.SystemFields
}

func (c *CreateOutputOutputDefault) GetEnvironment() *string {
	if c == nil {
		return nil
	}
	return c.Environment
}

func (c *CreateOutputOutputDefault) GetStreamtags() []string {
	if c == nil {
		return nil
	}
	return c.Streamtags
}

func (c *CreateOutputOutputDefault) GetDefaultID() string {
	if c == nil {
		return ""
	}
	return c.DefaultID
}

type CreateOutputRequestType string

const (
	CreateOutputRequestTypeDefault                CreateOutputRequestType = "default"
	CreateOutputRequestTypeWebhook                CreateOutputRequestType = "webhook"
	CreateOutputRequestTypeSentinel               CreateOutputRequestType = "sentinel"
	CreateOutputRequestTypeDevnull                CreateOutputRequestType = "devnull"
	CreateOutputRequestTypeSyslog                 CreateOutputRequestType = "syslog"
	CreateOutputRequestTypeSplunk                 CreateOutputRequestType = "splunk"
	CreateOutputRequestTypeSplunkLb               CreateOutputRequestType = "splunk_lb"
	CreateOutputRequestTypeSplunkHec              CreateOutputRequestType = "splunk_hec"
	CreateOutputRequestTypeWizHec                 CreateOutputRequestType = "wiz_hec"
	CreateOutputRequestTypeTcpjson                CreateOutputRequestType = "tcpjson"
	CreateOutputRequestTypeWavefront              CreateOutputRequestType = "wavefront"
	CreateOutputRequestTypeSignalfx               CreateOutputRequestType = "signalfx"
	CreateOutputRequestTypeFilesystem             CreateOutputRequestType = "filesystem"
	CreateOutputRequestTypeS3                     CreateOutputRequestType = "s3"
	CreateOutputRequestTypeAzureBlob              CreateOutputRequestType = "azure_blob"
	CreateOutputRequestTypeAzureDataExplorer      CreateOutputRequestType = "azure_data_explorer"
	CreateOutputRequestTypeAzureLogs              CreateOutputRequestType = "azure_logs"
	CreateOutputRequestTypeKinesis                CreateOutputRequestType = "kinesis"
	CreateOutputRequestTypeHoneycomb              CreateOutputRequestType = "honeycomb"
	CreateOutputRequestTypeAzureEventhub          CreateOutputRequestType = "azure_eventhub"
	CreateOutputRequestTypeGoogleChronicle        CreateOutputRequestType = "google_chronicle"
	CreateOutputRequestTypeGoogleCloudStorage     CreateOutputRequestType = "google_cloud_storage"
	CreateOutputRequestTypeGoogleCloudLogging     CreateOutputRequestType = "google_cloud_logging"
	CreateOutputRequestTypeGooglePubsub           CreateOutputRequestType = "google_pubsub"
	CreateOutputRequestTypeExabeam                CreateOutputRequestType = "exabeam"
	CreateOutputRequestTypeKafka                  CreateOutputRequestType = "kafka"
	CreateOutputRequestTypeConfluentCloud         CreateOutputRequestType = "confluent_cloud"
	CreateOutputRequestTypeMsk                    CreateOutputRequestType = "msk"
	CreateOutputRequestTypeElastic                CreateOutputRequestType = "elastic"
	CreateOutputRequestTypeElasticCloud           CreateOutputRequestType = "elastic_cloud"
	CreateOutputRequestTypeNewrelic               CreateOutputRequestType = "newrelic"
	CreateOutputRequestTypeNewrelicEvents         CreateOutputRequestType = "newrelic_events"
	CreateOutputRequestTypeInfluxdb               CreateOutputRequestType = "influxdb"
	CreateOutputRequestTypeCloudwatch             CreateOutputRequestType = "cloudwatch"
	CreateOutputRequestTypeMinio                  CreateOutputRequestType = "minio"
	CreateOutputRequestTypeStatsd                 CreateOutputRequestType = "statsd"
	CreateOutputRequestTypeStatsdExt              CreateOutputRequestType = "statsd_ext"
	CreateOutputRequestTypeGraphite               CreateOutputRequestType = "graphite"
	CreateOutputRequestTypeRouter                 CreateOutputRequestType = "router"
	CreateOutputRequestTypeSns                    CreateOutputRequestType = "sns"
	CreateOutputRequestTypeSqs                    CreateOutputRequestType = "sqs"
	CreateOutputRequestTypeSnmp                   CreateOutputRequestType = "snmp"
	CreateOutputRequestTypeSumoLogic              CreateOutputRequestType = "sumo_logic"
	CreateOutputRequestTypeDatadog                CreateOutputRequestType = "datadog"
	CreateOutputRequestTypeGrafanaCloud           CreateOutputRequestType = "grafana_cloud"
	CreateOutputRequestTypeLoki                   CreateOutputRequestType = "loki"
	CreateOutputRequestTypePrometheus             CreateOutputRequestType = "prometheus"
	CreateOutputRequestTypeRing                   CreateOutputRequestType = "ring"
	CreateOutputRequestTypeOpenTelemetry          CreateOutputRequestType = "open_telemetry"
	CreateOutputRequestTypeServiceNow             CreateOutputRequestType = "service_now"
	CreateOutputRequestTypeDataset                CreateOutputRequestType = "dataset"
	CreateOutputRequestTypeCriblTCP               CreateOutputRequestType = "cribl_tcp"
	CreateOutputRequestTypeCriblHTTP              CreateOutputRequestType = "cribl_http"
	CreateOutputRequestTypeCriblSearchEngine      CreateOutputRequestType = "cribl_search_engine"
	CreateOutputRequestTypeHumioHec               CreateOutputRequestType = "humio_hec"
	CreateOutputRequestTypeCrowdstrikeNextGenSiem CreateOutputRequestType = "crowdstrike_next_gen_siem"
	CreateOutputRequestTypeDlS3                   CreateOutputRequestType = "dl_s3"
	CreateOutputRequestTypeSecurityLake           CreateOutputRequestType = "security_lake"
	CreateOutputRequestTypeCriblLake              CreateOutputRequestType = "cribl_lake"
	CreateOutputRequestTypeDiskSpool              CreateOutputRequestType = "disk_spool"
	CreateOutputRequestTypeClickHouse             CreateOutputRequestType = "click_house"
	CreateOutputRequestTypeXsiam                  CreateOutputRequestType = "xsiam"
	CreateOutputRequestTypeNetflow                CreateOutputRequestType = "netflow"
	CreateOutputRequestTypeDynatraceHTTP          CreateOutputRequestType = "dynatrace_http"
	CreateOutputRequestTypeDynatraceOtlp          CreateOutputRequestType = "dynatrace_otlp"
	CreateOutputRequestTypeSentinelOneAiSiem      CreateOutputRequestType = "sentinel_one_ai_siem"
	CreateOutputRequestTypeChronicle              CreateOutputRequestType = "chronicle"
	CreateOutputRequestTypeDatabricks             CreateOutputRequestType = "databricks"
	CreateOutputRequestTypeMicrosoftFabric        CreateOutputRequestType = "microsoft_fabric"
	CreateOutputRequestTypeCloudflareR2           CreateOutputRequestType = "cloudflare_r2"
)

// CreateOutputRequest - Output object
type CreateOutputRequest struct {
	CreateOutputOutputDefault                *CreateOutputOutputDefault                `queryParam:"inline" union:"member"`
	CreateOutputOutputWebhook                *CreateOutputOutputWebhook                `queryParam:"inline" union:"member"`
	CreateOutputOutputSentinel               *CreateOutputOutputSentinel               `queryParam:"inline" union:"member"`
	CreateOutputOutputDevnull                *CreateOutputOutputDevnull                `queryParam:"inline" union:"member"`
	CreateOutputOutputSyslog                 *CreateOutputOutputSyslog                 `queryParam:"inline" union:"member"`
	CreateOutputOutputSplunk                 *CreateOutputOutputSplunk                 `queryParam:"inline" union:"member"`
	CreateOutputOutputSplunkLb               *CreateOutputOutputSplunkLb               `queryParam:"inline" union:"member"`
	CreateOutputOutputSplunkHec              *CreateOutputOutputSplunkHec              `queryParam:"inline" union:"member"`
	CreateOutputOutputWizHec                 *CreateOutputOutputWizHec                 `queryParam:"inline" union:"member"`
	CreateOutputOutputTcpjson                *CreateOutputOutputTcpjson                `queryParam:"inline" union:"member"`
	CreateOutputOutputWavefront              *CreateOutputOutputWavefront              `queryParam:"inline" union:"member"`
	CreateOutputOutputSignalfx               *CreateOutputOutputSignalfx               `queryParam:"inline" union:"member"`
	CreateOutputOutputFilesystem             *CreateOutputOutputFilesystem             `queryParam:"inline" union:"member"`
	CreateOutputOutputS3                     *CreateOutputOutputS3                     `queryParam:"inline" union:"member"`
	CreateOutputOutputAzureBlob              *CreateOutputOutputAzureBlob              `queryParam:"inline" union:"member"`
	CreateOutputOutputAzureDataExplorer      *CreateOutputOutputAzureDataExplorer      `queryParam:"inline" union:"member"`
	CreateOutputOutputAzureLogs              *CreateOutputOutputAzureLogs              `queryParam:"inline" union:"member"`
	CreateOutputOutputKinesis                *CreateOutputOutputKinesis                `queryParam:"inline" union:"member"`
	CreateOutputOutputHoneycomb              *CreateOutputOutputHoneycomb              `queryParam:"inline" union:"member"`
	CreateOutputOutputAzureEventhub          *CreateOutputOutputAzureEventhub          `queryParam:"inline" union:"member"`
	CreateOutputOutputGoogleChronicle        *CreateOutputOutputGoogleChronicle        `queryParam:"inline" union:"member"`
	CreateOutputOutputGoogleCloudStorage     *CreateOutputOutputGoogleCloudStorage     `queryParam:"inline" union:"member"`
	CreateOutputOutputGoogleCloudLogging     *CreateOutputOutputGoogleCloudLogging     `queryParam:"inline" union:"member"`
	CreateOutputOutputGooglePubsub           *CreateOutputOutputGooglePubsub           `queryParam:"inline" union:"member"`
	CreateOutputOutputExabeam                *CreateOutputOutputExabeam                `queryParam:"inline" union:"member"`
	CreateOutputOutputKafka                  *CreateOutputOutputKafka                  `queryParam:"inline" union:"member"`
	CreateOutputOutputConfluentCloud         *CreateOutputOutputConfluentCloud         `queryParam:"inline" union:"member"`
	CreateOutputOutputMsk                    *CreateOutputOutputMsk                    `queryParam:"inline" union:"member"`
	CreateOutputOutputElastic                *CreateOutputOutputElastic                `queryParam:"inline" union:"member"`
	CreateOutputOutputElasticCloud           *CreateOutputOutputElasticCloud           `queryParam:"inline" union:"member"`
	CreateOutputOutputNewrelic               *CreateOutputOutputNewrelic               `queryParam:"inline" union:"member"`
	CreateOutputOutputNewrelicEvents         *CreateOutputOutputNewrelicEvents         `queryParam:"inline" union:"member"`
	CreateOutputOutputInfluxdb               *CreateOutputOutputInfluxdb               `queryParam:"inline" union:"member"`
	CreateOutputOutputCloudwatch             *CreateOutputOutputCloudwatch             `queryParam:"inline" union:"member"`
	CreateOutputOutputMinio                  *CreateOutputOutputMinio                  `queryParam:"inline" union:"member"`
	CreateOutputOutputStatsd                 *CreateOutputOutputStatsd                 `queryParam:"inline" union:"member"`
	CreateOutputOutputStatsdExt              *CreateOutputOutputStatsdExt              `queryParam:"inline" union:"member"`
	CreateOutputOutputGraphite               *CreateOutputOutputGraphite               `queryParam:"inline" union:"member"`
	CreateOutputOutputRouter                 *CreateOutputOutputRouter                 `queryParam:"inline" union:"member"`
	CreateOutputOutputSns                    *CreateOutputOutputSns                    `queryParam:"inline" union:"member"`
	CreateOutputOutputSqs                    *CreateOutputOutputSqs                    `queryParam:"inline" union:"member"`
	CreateOutputOutputSnmp                   *CreateOutputOutputSnmp                   `queryParam:"inline" union:"member"`
	CreateOutputOutputSumoLogic              *CreateOutputOutputSumoLogic              `queryParam:"inline" union:"member"`
	CreateOutputOutputDatadog                *CreateOutputOutputDatadog                `queryParam:"inline" union:"member"`
	CreateOutputOutputGrafanaCloudUnion      *CreateOutputOutputGrafanaCloudUnion      `queryParam:"inline" union:"member"`
	CreateOutputOutputLoki                   *CreateOutputOutputLoki                   `queryParam:"inline" union:"member"`
	CreateOutputOutputPrometheus             *CreateOutputOutputPrometheus             `queryParam:"inline" union:"member"`
	CreateOutputOutputRing                   *CreateOutputOutputRing                   `queryParam:"inline" union:"member"`
	CreateOutputOutputOpenTelemetry          *CreateOutputOutputOpenTelemetry          `queryParam:"inline" union:"member"`
	CreateOutputOutputServiceNow             *CreateOutputOutputServiceNow             `queryParam:"inline" union:"member"`
	CreateOutputOutputDataset                *CreateOutputOutputDataset                `queryParam:"inline" union:"member"`
	CreateOutputOutputCriblTCP               *CreateOutputOutputCriblTCP               `queryParam:"inline" union:"member"`
	CreateOutputOutputCriblHTTP              *CreateOutputOutputCriblHTTP              `queryParam:"inline" union:"member"`
	CreateOutputOutputCriblSearchEngine      *CreateOutputOutputCriblSearchEngine      `queryParam:"inline" union:"member"`
	CreateOutputOutputHumioHec               *CreateOutputOutputHumioHec               `queryParam:"inline" union:"member"`
	CreateOutputOutputCrowdstrikeNextGenSiem *CreateOutputOutputCrowdstrikeNextGenSiem `queryParam:"inline" union:"member"`
	CreateOutputOutputDlS3                   *CreateOutputOutputDlS3                   `queryParam:"inline" union:"member"`
	CreateOutputOutputSecurityLake           *CreateOutputOutputSecurityLake           `queryParam:"inline" union:"member"`
	CreateOutputOutputCriblLake              *CreateOutputOutputCriblLake              `queryParam:"inline" union:"member"`
	CreateOutputOutputDiskSpool              *CreateOutputOutputDiskSpool              `queryParam:"inline" union:"member"`
	CreateOutputOutputClickHouse             *CreateOutputOutputClickHouse             `queryParam:"inline" union:"member"`
	CreateOutputOutputXsiam                  *CreateOutputOutputXsiam                  `queryParam:"inline" union:"member"`
	CreateOutputOutputNetflow                *CreateOutputOutputNetflow                `queryParam:"inline" union:"member"`
	CreateOutputOutputDynatraceHTTP          *CreateOutputOutputDynatraceHTTP          `queryParam:"inline" union:"member"`
	CreateOutputOutputDynatraceOtlp          *CreateOutputOutputDynatraceOtlp          `queryParam:"inline" union:"member"`
	CreateOutputOutputSentinelOneAiSiem      *CreateOutputOutputSentinelOneAiSiem      `queryParam:"inline" union:"member"`
	CreateOutputOutputChronicle              *CreateOutputOutputChronicle              `queryParam:"inline" union:"member"`
	CreateOutputOutputDatabricks             *CreateOutputOutputDatabricks             `queryParam:"inline" union:"member"`
	CreateOutputOutputMicrosoftFabric        *CreateOutputOutputMicrosoftFabric        `queryParam:"inline" union:"member"`
	CreateOutputOutputCloudflareR2           *CreateOutputOutputCloudflareR2           `queryParam:"inline" union:"member"`

	Type CreateOutputRequestType
}

func CreateCreateOutputRequestDefault(defaultT CreateOutputOutputDefault) CreateOutputRequest {
	typ := CreateOutputRequestTypeDefault

	typStr := CreateOutputTypeDefault(typ)
	defaultT.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputDefault: &defaultT,
		Type:                      typ,
	}
}

func CreateCreateOutputRequestWebhook(webhook CreateOutputOutputWebhook) CreateOutputRequest {
	typ := CreateOutputRequestTypeWebhook

	typStr := CreateOutputTypeWebhook(typ)
	webhook.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputWebhook: &webhook,
		Type:                      typ,
	}
}

func CreateCreateOutputRequestSentinel(sentinel CreateOutputOutputSentinel) CreateOutputRequest {
	typ := CreateOutputRequestTypeSentinel

	typStr := CreateOutputTypeSentinel(typ)
	sentinel.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputSentinel: &sentinel,
		Type:                       typ,
	}
}

func CreateCreateOutputRequestDevnull(devnull CreateOutputOutputDevnull) CreateOutputRequest {
	typ := CreateOutputRequestTypeDevnull

	typStr := CreateOutputTypeDevnull(typ)
	devnull.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputDevnull: &devnull,
		Type:                      typ,
	}
}

func CreateCreateOutputRequestSyslog(syslog CreateOutputOutputSyslog) CreateOutputRequest {
	typ := CreateOutputRequestTypeSyslog

	typStr := CreateOutputTypeSyslog(typ)
	syslog.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputSyslog: &syslog,
		Type:                     typ,
	}
}

func CreateCreateOutputRequestSplunk(splunk CreateOutputOutputSplunk) CreateOutputRequest {
	typ := CreateOutputRequestTypeSplunk

	typStr := CreateOutputTypeSplunk(typ)
	splunk.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputSplunk: &splunk,
		Type:                     typ,
	}
}

func CreateCreateOutputRequestSplunkLb(splunkLb CreateOutputOutputSplunkLb) CreateOutputRequest {
	typ := CreateOutputRequestTypeSplunkLb

	typStr := CreateOutputTypeSplunkLb(typ)
	splunkLb.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputSplunkLb: &splunkLb,
		Type:                       typ,
	}
}

func CreateCreateOutputRequestSplunkHec(splunkHec CreateOutputOutputSplunkHec) CreateOutputRequest {
	typ := CreateOutputRequestTypeSplunkHec

	typStr := CreateOutputTypeSplunkHec(typ)
	splunkHec.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputSplunkHec: &splunkHec,
		Type:                        typ,
	}
}

func CreateCreateOutputRequestWizHec(wizHec CreateOutputOutputWizHec) CreateOutputRequest {
	typ := CreateOutputRequestTypeWizHec

	typStr := CreateOutputTypeWizHec(typ)
	wizHec.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputWizHec: &wizHec,
		Type:                     typ,
	}
}

func CreateCreateOutputRequestTcpjson(tcpjson CreateOutputOutputTcpjson) CreateOutputRequest {
	typ := CreateOutputRequestTypeTcpjson

	typStr := CreateOutputTypeTcpjson(typ)
	tcpjson.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputTcpjson: &tcpjson,
		Type:                      typ,
	}
}

func CreateCreateOutputRequestWavefront(wavefront CreateOutputOutputWavefront) CreateOutputRequest {
	typ := CreateOutputRequestTypeWavefront

	typStr := CreateOutputTypeWavefront(typ)
	wavefront.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputWavefront: &wavefront,
		Type:                        typ,
	}
}

func CreateCreateOutputRequestSignalfx(signalfx CreateOutputOutputSignalfx) CreateOutputRequest {
	typ := CreateOutputRequestTypeSignalfx

	typStr := CreateOutputTypeSignalfx(typ)
	signalfx.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputSignalfx: &signalfx,
		Type:                       typ,
	}
}

func CreateCreateOutputRequestFilesystem(filesystem CreateOutputOutputFilesystem) CreateOutputRequest {
	typ := CreateOutputRequestTypeFilesystem

	typStr := CreateOutputTypeFilesystem(typ)
	filesystem.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputFilesystem: &filesystem,
		Type:                         typ,
	}
}

func CreateCreateOutputRequestS3(s3 CreateOutputOutputS3) CreateOutputRequest {
	typ := CreateOutputRequestTypeS3

	typStr := CreateOutputTypeS3(typ)
	s3.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputS3: &s3,
		Type:                 typ,
	}
}

func CreateCreateOutputRequestAzureBlob(azureBlob CreateOutputOutputAzureBlob) CreateOutputRequest {
	typ := CreateOutputRequestTypeAzureBlob

	typStr := CreateOutputTypeAzureBlob(typ)
	azureBlob.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputAzureBlob: &azureBlob,
		Type:                        typ,
	}
}

func CreateCreateOutputRequestAzureDataExplorer(azureDataExplorer CreateOutputOutputAzureDataExplorer) CreateOutputRequest {
	typ := CreateOutputRequestTypeAzureDataExplorer

	typStr := CreateOutputTypeAzureDataExplorer(typ)
	azureDataExplorer.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputAzureDataExplorer: &azureDataExplorer,
		Type:                                typ,
	}
}

func CreateCreateOutputRequestAzureLogs(azureLogs CreateOutputOutputAzureLogs) CreateOutputRequest {
	typ := CreateOutputRequestTypeAzureLogs

	typStr := CreateOutputTypeAzureLogs(typ)
	azureLogs.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputAzureLogs: &azureLogs,
		Type:                        typ,
	}
}

func CreateCreateOutputRequestKinesis(kinesis CreateOutputOutputKinesis) CreateOutputRequest {
	typ := CreateOutputRequestTypeKinesis

	typStr := CreateOutputTypeKinesis(typ)
	kinesis.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputKinesis: &kinesis,
		Type:                      typ,
	}
}

func CreateCreateOutputRequestHoneycomb(honeycomb CreateOutputOutputHoneycomb) CreateOutputRequest {
	typ := CreateOutputRequestTypeHoneycomb

	typStr := CreateOutputTypeHoneycomb(typ)
	honeycomb.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputHoneycomb: &honeycomb,
		Type:                        typ,
	}
}

func CreateCreateOutputRequestAzureEventhub(azureEventhub CreateOutputOutputAzureEventhub) CreateOutputRequest {
	typ := CreateOutputRequestTypeAzureEventhub

	typStr := CreateOutputTypeAzureEventhub(typ)
	azureEventhub.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputAzureEventhub: &azureEventhub,
		Type:                            typ,
	}
}

func CreateCreateOutputRequestGoogleChronicle(googleChronicle CreateOutputOutputGoogleChronicle) CreateOutputRequest {
	typ := CreateOutputRequestTypeGoogleChronicle

	typStr := CreateOutputTypeGoogleChronicle(typ)
	googleChronicle.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputGoogleChronicle: &googleChronicle,
		Type:                              typ,
	}
}

func CreateCreateOutputRequestGoogleCloudStorage(googleCloudStorage CreateOutputOutputGoogleCloudStorage) CreateOutputRequest {
	typ := CreateOutputRequestTypeGoogleCloudStorage

	typStr := CreateOutputTypeGoogleCloudStorage(typ)
	googleCloudStorage.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputGoogleCloudStorage: &googleCloudStorage,
		Type:                                 typ,
	}
}

func CreateCreateOutputRequestGoogleCloudLogging(googleCloudLogging CreateOutputOutputGoogleCloudLogging) CreateOutputRequest {
	typ := CreateOutputRequestTypeGoogleCloudLogging

	typStr := CreateOutputTypeGoogleCloudLogging(typ)
	googleCloudLogging.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputGoogleCloudLogging: &googleCloudLogging,
		Type:                                 typ,
	}
}

func CreateCreateOutputRequestGooglePubsub(googlePubsub CreateOutputOutputGooglePubsub) CreateOutputRequest {
	typ := CreateOutputRequestTypeGooglePubsub

	typStr := CreateOutputTypeGooglePubsub(typ)
	googlePubsub.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputGooglePubsub: &googlePubsub,
		Type:                           typ,
	}
}

func CreateCreateOutputRequestExabeam(exabeam CreateOutputOutputExabeam) CreateOutputRequest {
	typ := CreateOutputRequestTypeExabeam

	typStr := CreateOutputTypeExabeam(typ)
	exabeam.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputExabeam: &exabeam,
		Type:                      typ,
	}
}

func CreateCreateOutputRequestKafka(kafka CreateOutputOutputKafka) CreateOutputRequest {
	typ := CreateOutputRequestTypeKafka

	typStr := CreateOutputTypeKafka(typ)
	kafka.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputKafka: &kafka,
		Type:                    typ,
	}
}

func CreateCreateOutputRequestConfluentCloud(confluentCloud CreateOutputOutputConfluentCloud) CreateOutputRequest {
	typ := CreateOutputRequestTypeConfluentCloud

	typStr := CreateOutputTypeConfluentCloud(typ)
	confluentCloud.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputConfluentCloud: &confluentCloud,
		Type:                             typ,
	}
}

func CreateCreateOutputRequestMsk(msk CreateOutputOutputMsk) CreateOutputRequest {
	typ := CreateOutputRequestTypeMsk

	typStr := CreateOutputTypeMsk(typ)
	msk.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputMsk: &msk,
		Type:                  typ,
	}
}

func CreateCreateOutputRequestElastic(elastic CreateOutputOutputElastic) CreateOutputRequest {
	typ := CreateOutputRequestTypeElastic

	typStr := CreateOutputTypeElastic(typ)
	elastic.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputElastic: &elastic,
		Type:                      typ,
	}
}

func CreateCreateOutputRequestElasticCloud(elasticCloud CreateOutputOutputElasticCloud) CreateOutputRequest {
	typ := CreateOutputRequestTypeElasticCloud

	typStr := CreateOutputTypeElasticCloud(typ)
	elasticCloud.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputElasticCloud: &elasticCloud,
		Type:                           typ,
	}
}

func CreateCreateOutputRequestNewrelic(newrelic CreateOutputOutputNewrelic) CreateOutputRequest {
	typ := CreateOutputRequestTypeNewrelic

	typStr := CreateOutputTypeNewrelic(typ)
	newrelic.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputNewrelic: &newrelic,
		Type:                       typ,
	}
}

func CreateCreateOutputRequestNewrelicEvents(newrelicEvents CreateOutputOutputNewrelicEvents) CreateOutputRequest {
	typ := CreateOutputRequestTypeNewrelicEvents

	typStr := CreateOutputTypeNewrelicEvents(typ)
	newrelicEvents.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputNewrelicEvents: &newrelicEvents,
		Type:                             typ,
	}
}

func CreateCreateOutputRequestInfluxdb(influxdb CreateOutputOutputInfluxdb) CreateOutputRequest {
	typ := CreateOutputRequestTypeInfluxdb

	typStr := CreateOutputTypeInfluxdb(typ)
	influxdb.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputInfluxdb: &influxdb,
		Type:                       typ,
	}
}

func CreateCreateOutputRequestCloudwatch(cloudwatch CreateOutputOutputCloudwatch) CreateOutputRequest {
	typ := CreateOutputRequestTypeCloudwatch

	typStr := CreateOutputTypeCloudwatch(typ)
	cloudwatch.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputCloudwatch: &cloudwatch,
		Type:                         typ,
	}
}

func CreateCreateOutputRequestMinio(minio CreateOutputOutputMinio) CreateOutputRequest {
	typ := CreateOutputRequestTypeMinio

	typStr := CreateOutputTypeMinio(typ)
	minio.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputMinio: &minio,
		Type:                    typ,
	}
}

func CreateCreateOutputRequestStatsd(statsd CreateOutputOutputStatsd) CreateOutputRequest {
	typ := CreateOutputRequestTypeStatsd

	typStr := CreateOutputTypeStatsd(typ)
	statsd.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputStatsd: &statsd,
		Type:                     typ,
	}
}

func CreateCreateOutputRequestStatsdExt(statsdExt CreateOutputOutputStatsdExt) CreateOutputRequest {
	typ := CreateOutputRequestTypeStatsdExt

	typStr := CreateOutputTypeStatsdExt(typ)
	statsdExt.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputStatsdExt: &statsdExt,
		Type:                        typ,
	}
}

func CreateCreateOutputRequestGraphite(graphite CreateOutputOutputGraphite) CreateOutputRequest {
	typ := CreateOutputRequestTypeGraphite

	typStr := CreateOutputTypeGraphite(typ)
	graphite.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputGraphite: &graphite,
		Type:                       typ,
	}
}

func CreateCreateOutputRequestRouter(router CreateOutputOutputRouter) CreateOutputRequest {
	typ := CreateOutputRequestTypeRouter

	typStr := CreateOutputTypeRouter(typ)
	router.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputRouter: &router,
		Type:                     typ,
	}
}

func CreateCreateOutputRequestSns(sns CreateOutputOutputSns) CreateOutputRequest {
	typ := CreateOutputRequestTypeSns

	typStr := CreateOutputTypeSns(typ)
	sns.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputSns: &sns,
		Type:                  typ,
	}
}

func CreateCreateOutputRequestSqs(sqs CreateOutputOutputSqs) CreateOutputRequest {
	typ := CreateOutputRequestTypeSqs

	typStr := CreateOutputTypeSqs(typ)
	sqs.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputSqs: &sqs,
		Type:                  typ,
	}
}

func CreateCreateOutputRequestSnmp(snmp CreateOutputOutputSnmp) CreateOutputRequest {
	typ := CreateOutputRequestTypeSnmp

	typStr := CreateOutputTypeSnmp(typ)
	snmp.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputSnmp: &snmp,
		Type:                   typ,
	}
}

func CreateCreateOutputRequestSumoLogic(sumoLogic CreateOutputOutputSumoLogic) CreateOutputRequest {
	typ := CreateOutputRequestTypeSumoLogic

	typStr := CreateOutputTypeSumoLogic(typ)
	sumoLogic.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputSumoLogic: &sumoLogic,
		Type:                        typ,
	}
}

func CreateCreateOutputRequestDatadog(datadog CreateOutputOutputDatadog) CreateOutputRequest {
	typ := CreateOutputRequestTypeDatadog

	typStr := CreateOutputTypeDatadog(typ)
	datadog.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputDatadog: &datadog,
		Type:                      typ,
	}
}

func CreateCreateOutputRequestGrafanaCloud(grafanaCloud CreateOutputOutputGrafanaCloudUnion) CreateOutputRequest {
	typ := CreateOutputRequestTypeGrafanaCloud

	return CreateOutputRequest{
		CreateOutputOutputGrafanaCloudUnion: &grafanaCloud,
		Type:                                typ,
	}
}

func CreateCreateOutputRequestLoki(loki CreateOutputOutputLoki) CreateOutputRequest {
	typ := CreateOutputRequestTypeLoki

	typStr := CreateOutputTypeLoki(typ)
	loki.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputLoki: &loki,
		Type:                   typ,
	}
}

func CreateCreateOutputRequestPrometheus(prometheus CreateOutputOutputPrometheus) CreateOutputRequest {
	typ := CreateOutputRequestTypePrometheus

	typStr := CreateOutputTypePrometheus(typ)
	prometheus.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputPrometheus: &prometheus,
		Type:                         typ,
	}
}

func CreateCreateOutputRequestRing(ring CreateOutputOutputRing) CreateOutputRequest {
	typ := CreateOutputRequestTypeRing

	typStr := CreateOutputTypeRing(typ)
	ring.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputRing: &ring,
		Type:                   typ,
	}
}

func CreateCreateOutputRequestOpenTelemetry(openTelemetry CreateOutputOutputOpenTelemetry) CreateOutputRequest {
	typ := CreateOutputRequestTypeOpenTelemetry

	typStr := CreateOutputTypeOpenTelemetry(typ)
	openTelemetry.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputOpenTelemetry: &openTelemetry,
		Type:                            typ,
	}
}

func CreateCreateOutputRequestServiceNow(serviceNow CreateOutputOutputServiceNow) CreateOutputRequest {
	typ := CreateOutputRequestTypeServiceNow

	typStr := CreateOutputTypeServiceNow(typ)
	serviceNow.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputServiceNow: &serviceNow,
		Type:                         typ,
	}
}

func CreateCreateOutputRequestDataset(dataset CreateOutputOutputDataset) CreateOutputRequest {
	typ := CreateOutputRequestTypeDataset

	typStr := CreateOutputTypeDataset(typ)
	dataset.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputDataset: &dataset,
		Type:                      typ,
	}
}

func CreateCreateOutputRequestCriblTCP(criblTCP CreateOutputOutputCriblTCP) CreateOutputRequest {
	typ := CreateOutputRequestTypeCriblTCP

	typStr := CreateOutputTypeCriblTCP(typ)
	criblTCP.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputCriblTCP: &criblTCP,
		Type:                       typ,
	}
}

func CreateCreateOutputRequestCriblHTTP(criblHTTP CreateOutputOutputCriblHTTP) CreateOutputRequest {
	typ := CreateOutputRequestTypeCriblHTTP

	typStr := CreateOutputTypeCriblHTTP(typ)
	criblHTTP.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputCriblHTTP: &criblHTTP,
		Type:                        typ,
	}
}

func CreateCreateOutputRequestCriblSearchEngine(criblSearchEngine CreateOutputOutputCriblSearchEngine) CreateOutputRequest {
	typ := CreateOutputRequestTypeCriblSearchEngine

	typStr := CreateOutputTypeCriblSearchEngine(typ)
	criblSearchEngine.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputCriblSearchEngine: &criblSearchEngine,
		Type:                                typ,
	}
}

func CreateCreateOutputRequestHumioHec(humioHec CreateOutputOutputHumioHec) CreateOutputRequest {
	typ := CreateOutputRequestTypeHumioHec

	typStr := CreateOutputTypeHumioHec(typ)
	humioHec.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputHumioHec: &humioHec,
		Type:                       typ,
	}
}

func CreateCreateOutputRequestCrowdstrikeNextGenSiem(crowdstrikeNextGenSiem CreateOutputOutputCrowdstrikeNextGenSiem) CreateOutputRequest {
	typ := CreateOutputRequestTypeCrowdstrikeNextGenSiem

	typStr := CreateOutputTypeCrowdstrikeNextGenSiem(typ)
	crowdstrikeNextGenSiem.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputCrowdstrikeNextGenSiem: &crowdstrikeNextGenSiem,
		Type:                                     typ,
	}
}

func CreateCreateOutputRequestDlS3(dlS3 CreateOutputOutputDlS3) CreateOutputRequest {
	typ := CreateOutputRequestTypeDlS3

	typStr := CreateOutputTypeDlS3(typ)
	dlS3.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputDlS3: &dlS3,
		Type:                   typ,
	}
}

func CreateCreateOutputRequestSecurityLake(securityLake CreateOutputOutputSecurityLake) CreateOutputRequest {
	typ := CreateOutputRequestTypeSecurityLake

	typStr := CreateOutputTypeSecurityLake(typ)
	securityLake.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputSecurityLake: &securityLake,
		Type:                           typ,
	}
}

func CreateCreateOutputRequestCriblLake(criblLake CreateOutputOutputCriblLake) CreateOutputRequest {
	typ := CreateOutputRequestTypeCriblLake

	typStr := CreateOutputTypeCriblLake(typ)
	criblLake.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputCriblLake: &criblLake,
		Type:                        typ,
	}
}

func CreateCreateOutputRequestDiskSpool(diskSpool CreateOutputOutputDiskSpool) CreateOutputRequest {
	typ := CreateOutputRequestTypeDiskSpool

	typStr := CreateOutputTypeDiskSpool(typ)
	diskSpool.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputDiskSpool: &diskSpool,
		Type:                        typ,
	}
}

func CreateCreateOutputRequestClickHouse(clickHouse CreateOutputOutputClickHouse) CreateOutputRequest {
	typ := CreateOutputRequestTypeClickHouse

	typStr := CreateOutputTypeClickHouse(typ)
	clickHouse.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputClickHouse: &clickHouse,
		Type:                         typ,
	}
}

func CreateCreateOutputRequestXsiam(xsiam CreateOutputOutputXsiam) CreateOutputRequest {
	typ := CreateOutputRequestTypeXsiam

	typStr := CreateOutputTypeXsiam(typ)
	xsiam.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputXsiam: &xsiam,
		Type:                    typ,
	}
}

func CreateCreateOutputRequestNetflow(netflow CreateOutputOutputNetflow) CreateOutputRequest {
	typ := CreateOutputRequestTypeNetflow

	typStr := CreateOutputTypeNetflow(typ)
	netflow.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputNetflow: &netflow,
		Type:                      typ,
	}
}

func CreateCreateOutputRequestDynatraceHTTP(dynatraceHTTP CreateOutputOutputDynatraceHTTP) CreateOutputRequest {
	typ := CreateOutputRequestTypeDynatraceHTTP

	typStr := CreateOutputTypeDynatraceHTTP(typ)
	dynatraceHTTP.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputDynatraceHTTP: &dynatraceHTTP,
		Type:                            typ,
	}
}

func CreateCreateOutputRequestDynatraceOtlp(dynatraceOtlp CreateOutputOutputDynatraceOtlp) CreateOutputRequest {
	typ := CreateOutputRequestTypeDynatraceOtlp

	typStr := CreateOutputTypeDynatraceOtlp(typ)
	dynatraceOtlp.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputDynatraceOtlp: &dynatraceOtlp,
		Type:                            typ,
	}
}

func CreateCreateOutputRequestSentinelOneAiSiem(sentinelOneAiSiem CreateOutputOutputSentinelOneAiSiem) CreateOutputRequest {
	typ := CreateOutputRequestTypeSentinelOneAiSiem

	typStr := CreateOutputTypeSentinelOneAiSiem(typ)
	sentinelOneAiSiem.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputSentinelOneAiSiem: &sentinelOneAiSiem,
		Type:                                typ,
	}
}

func CreateCreateOutputRequestChronicle(chronicle CreateOutputOutputChronicle) CreateOutputRequest {
	typ := CreateOutputRequestTypeChronicle

	typStr := CreateOutputTypeChronicle(typ)
	chronicle.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputChronicle: &chronicle,
		Type:                        typ,
	}
}

func CreateCreateOutputRequestDatabricks(databricks CreateOutputOutputDatabricks) CreateOutputRequest {
	typ := CreateOutputRequestTypeDatabricks

	typStr := CreateOutputTypeDatabricks(typ)
	databricks.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputDatabricks: &databricks,
		Type:                         typ,
	}
}

func CreateCreateOutputRequestMicrosoftFabric(microsoftFabric CreateOutputOutputMicrosoftFabric) CreateOutputRequest {
	typ := CreateOutputRequestTypeMicrosoftFabric

	typStr := CreateOutputTypeMicrosoftFabric(typ)
	microsoftFabric.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputMicrosoftFabric: &microsoftFabric,
		Type:                              typ,
	}
}

func CreateCreateOutputRequestCloudflareR2(cloudflareR2 CreateOutputOutputCloudflareR2) CreateOutputRequest {
	typ := CreateOutputRequestTypeCloudflareR2

	typStr := CreateOutputTypeCloudflareR2(typ)
	cloudflareR2.Type = typStr

	return CreateOutputRequest{
		CreateOutputOutputCloudflareR2: &cloudflareR2,
		Type:                           typ,
	}
}

func (u *CreateOutputRequest) UnmarshalJSON(data []byte) error {

	type discriminator struct {
		Type string `json:"type"`
	}

	dis := new(discriminator)
	if err := json.Unmarshal(data, &dis); err != nil {
		return fmt.Errorf("could not unmarshal discriminator: %w", err)
	}

	switch dis.Type {
	case "default":
		createOutputOutputDefault := new(CreateOutputOutputDefault)
		if err := utils.UnmarshalJSON(data, &createOutputOutputDefault, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == default) type CreateOutputOutputDefault within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputDefault = createOutputOutputDefault
		u.Type = CreateOutputRequestTypeDefault
		return nil
	case "webhook":
		createOutputOutputWebhook := new(CreateOutputOutputWebhook)
		if err := utils.UnmarshalJSON(data, &createOutputOutputWebhook, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == webhook) type CreateOutputOutputWebhook within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputWebhook = createOutputOutputWebhook
		u.Type = CreateOutputRequestTypeWebhook
		return nil
	case "sentinel":
		createOutputOutputSentinel := new(CreateOutputOutputSentinel)
		if err := utils.UnmarshalJSON(data, &createOutputOutputSentinel, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == sentinel) type CreateOutputOutputSentinel within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputSentinel = createOutputOutputSentinel
		u.Type = CreateOutputRequestTypeSentinel
		return nil
	case "devnull":
		createOutputOutputDevnull := new(CreateOutputOutputDevnull)
		if err := utils.UnmarshalJSON(data, &createOutputOutputDevnull, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == devnull) type CreateOutputOutputDevnull within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputDevnull = createOutputOutputDevnull
		u.Type = CreateOutputRequestTypeDevnull
		return nil
	case "syslog":
		createOutputOutputSyslog := new(CreateOutputOutputSyslog)
		if err := utils.UnmarshalJSON(data, &createOutputOutputSyslog, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == syslog) type CreateOutputOutputSyslog within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputSyslog = createOutputOutputSyslog
		u.Type = CreateOutputRequestTypeSyslog
		return nil
	case "splunk":
		createOutputOutputSplunk := new(CreateOutputOutputSplunk)
		if err := utils.UnmarshalJSON(data, &createOutputOutputSplunk, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == splunk) type CreateOutputOutputSplunk within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputSplunk = createOutputOutputSplunk
		u.Type = CreateOutputRequestTypeSplunk
		return nil
	case "splunk_lb":
		createOutputOutputSplunkLb := new(CreateOutputOutputSplunkLb)
		if err := utils.UnmarshalJSON(data, &createOutputOutputSplunkLb, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == splunk_lb) type CreateOutputOutputSplunkLb within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputSplunkLb = createOutputOutputSplunkLb
		u.Type = CreateOutputRequestTypeSplunkLb
		return nil
	case "splunk_hec":
		createOutputOutputSplunkHec := new(CreateOutputOutputSplunkHec)
		if err := utils.UnmarshalJSON(data, &createOutputOutputSplunkHec, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == splunk_hec) type CreateOutputOutputSplunkHec within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputSplunkHec = createOutputOutputSplunkHec
		u.Type = CreateOutputRequestTypeSplunkHec
		return nil
	case "wiz_hec":
		createOutputOutputWizHec := new(CreateOutputOutputWizHec)
		if err := utils.UnmarshalJSON(data, &createOutputOutputWizHec, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == wiz_hec) type CreateOutputOutputWizHec within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputWizHec = createOutputOutputWizHec
		u.Type = CreateOutputRequestTypeWizHec
		return nil
	case "tcpjson":
		createOutputOutputTcpjson := new(CreateOutputOutputTcpjson)
		if err := utils.UnmarshalJSON(data, &createOutputOutputTcpjson, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == tcpjson) type CreateOutputOutputTcpjson within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputTcpjson = createOutputOutputTcpjson
		u.Type = CreateOutputRequestTypeTcpjson
		return nil
	case "wavefront":
		createOutputOutputWavefront := new(CreateOutputOutputWavefront)
		if err := utils.UnmarshalJSON(data, &createOutputOutputWavefront, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == wavefront) type CreateOutputOutputWavefront within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputWavefront = createOutputOutputWavefront
		u.Type = CreateOutputRequestTypeWavefront
		return nil
	case "signalfx":
		createOutputOutputSignalfx := new(CreateOutputOutputSignalfx)
		if err := utils.UnmarshalJSON(data, &createOutputOutputSignalfx, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == signalfx) type CreateOutputOutputSignalfx within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputSignalfx = createOutputOutputSignalfx
		u.Type = CreateOutputRequestTypeSignalfx
		return nil
	case "filesystem":
		createOutputOutputFilesystem := new(CreateOutputOutputFilesystem)
		if err := utils.UnmarshalJSON(data, &createOutputOutputFilesystem, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == filesystem) type CreateOutputOutputFilesystem within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputFilesystem = createOutputOutputFilesystem
		u.Type = CreateOutputRequestTypeFilesystem
		return nil
	case "s3":
		createOutputOutputS3 := new(CreateOutputOutputS3)
		if err := utils.UnmarshalJSON(data, &createOutputOutputS3, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == s3) type CreateOutputOutputS3 within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputS3 = createOutputOutputS3
		u.Type = CreateOutputRequestTypeS3
		return nil
	case "azure_blob":
		createOutputOutputAzureBlob := new(CreateOutputOutputAzureBlob)
		if err := utils.UnmarshalJSON(data, &createOutputOutputAzureBlob, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == azure_blob) type CreateOutputOutputAzureBlob within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputAzureBlob = createOutputOutputAzureBlob
		u.Type = CreateOutputRequestTypeAzureBlob
		return nil
	case "azure_data_explorer":
		createOutputOutputAzureDataExplorer := new(CreateOutputOutputAzureDataExplorer)
		if err := utils.UnmarshalJSON(data, &createOutputOutputAzureDataExplorer, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == azure_data_explorer) type CreateOutputOutputAzureDataExplorer within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputAzureDataExplorer = createOutputOutputAzureDataExplorer
		u.Type = CreateOutputRequestTypeAzureDataExplorer
		return nil
	case "azure_logs":
		createOutputOutputAzureLogs := new(CreateOutputOutputAzureLogs)
		if err := utils.UnmarshalJSON(data, &createOutputOutputAzureLogs, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == azure_logs) type CreateOutputOutputAzureLogs within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputAzureLogs = createOutputOutputAzureLogs
		u.Type = CreateOutputRequestTypeAzureLogs
		return nil
	case "kinesis":
		createOutputOutputKinesis := new(CreateOutputOutputKinesis)
		if err := utils.UnmarshalJSON(data, &createOutputOutputKinesis, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == kinesis) type CreateOutputOutputKinesis within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputKinesis = createOutputOutputKinesis
		u.Type = CreateOutputRequestTypeKinesis
		return nil
	case "honeycomb":
		createOutputOutputHoneycomb := new(CreateOutputOutputHoneycomb)
		if err := utils.UnmarshalJSON(data, &createOutputOutputHoneycomb, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == honeycomb) type CreateOutputOutputHoneycomb within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputHoneycomb = createOutputOutputHoneycomb
		u.Type = CreateOutputRequestTypeHoneycomb
		return nil
	case "azure_eventhub":
		createOutputOutputAzureEventhub := new(CreateOutputOutputAzureEventhub)
		if err := utils.UnmarshalJSON(data, &createOutputOutputAzureEventhub, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == azure_eventhub) type CreateOutputOutputAzureEventhub within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputAzureEventhub = createOutputOutputAzureEventhub
		u.Type = CreateOutputRequestTypeAzureEventhub
		return nil
	case "google_chronicle":
		createOutputOutputGoogleChronicle := new(CreateOutputOutputGoogleChronicle)
		if err := utils.UnmarshalJSON(data, &createOutputOutputGoogleChronicle, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == google_chronicle) type CreateOutputOutputGoogleChronicle within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputGoogleChronicle = createOutputOutputGoogleChronicle
		u.Type = CreateOutputRequestTypeGoogleChronicle
		return nil
	case "google_cloud_storage":
		createOutputOutputGoogleCloudStorage := new(CreateOutputOutputGoogleCloudStorage)
		if err := utils.UnmarshalJSON(data, &createOutputOutputGoogleCloudStorage, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == google_cloud_storage) type CreateOutputOutputGoogleCloudStorage within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputGoogleCloudStorage = createOutputOutputGoogleCloudStorage
		u.Type = CreateOutputRequestTypeGoogleCloudStorage
		return nil
	case "google_cloud_logging":
		createOutputOutputGoogleCloudLogging := new(CreateOutputOutputGoogleCloudLogging)
		if err := utils.UnmarshalJSON(data, &createOutputOutputGoogleCloudLogging, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == google_cloud_logging) type CreateOutputOutputGoogleCloudLogging within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputGoogleCloudLogging = createOutputOutputGoogleCloudLogging
		u.Type = CreateOutputRequestTypeGoogleCloudLogging
		return nil
	case "google_pubsub":
		createOutputOutputGooglePubsub := new(CreateOutputOutputGooglePubsub)
		if err := utils.UnmarshalJSON(data, &createOutputOutputGooglePubsub, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == google_pubsub) type CreateOutputOutputGooglePubsub within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputGooglePubsub = createOutputOutputGooglePubsub
		u.Type = CreateOutputRequestTypeGooglePubsub
		return nil
	case "exabeam":
		createOutputOutputExabeam := new(CreateOutputOutputExabeam)
		if err := utils.UnmarshalJSON(data, &createOutputOutputExabeam, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == exabeam) type CreateOutputOutputExabeam within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputExabeam = createOutputOutputExabeam
		u.Type = CreateOutputRequestTypeExabeam
		return nil
	case "kafka":
		createOutputOutputKafka := new(CreateOutputOutputKafka)
		if err := utils.UnmarshalJSON(data, &createOutputOutputKafka, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == kafka) type CreateOutputOutputKafka within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputKafka = createOutputOutputKafka
		u.Type = CreateOutputRequestTypeKafka
		return nil
	case "confluent_cloud":
		createOutputOutputConfluentCloud := new(CreateOutputOutputConfluentCloud)
		if err := utils.UnmarshalJSON(data, &createOutputOutputConfluentCloud, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == confluent_cloud) type CreateOutputOutputConfluentCloud within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputConfluentCloud = createOutputOutputConfluentCloud
		u.Type = CreateOutputRequestTypeConfluentCloud
		return nil
	case "msk":
		createOutputOutputMsk := new(CreateOutputOutputMsk)
		if err := utils.UnmarshalJSON(data, &createOutputOutputMsk, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == msk) type CreateOutputOutputMsk within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputMsk = createOutputOutputMsk
		u.Type = CreateOutputRequestTypeMsk
		return nil
	case "elastic":
		createOutputOutputElastic := new(CreateOutputOutputElastic)
		if err := utils.UnmarshalJSON(data, &createOutputOutputElastic, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == elastic) type CreateOutputOutputElastic within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputElastic = createOutputOutputElastic
		u.Type = CreateOutputRequestTypeElastic
		return nil
	case "elastic_cloud":
		createOutputOutputElasticCloud := new(CreateOutputOutputElasticCloud)
		if err := utils.UnmarshalJSON(data, &createOutputOutputElasticCloud, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == elastic_cloud) type CreateOutputOutputElasticCloud within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputElasticCloud = createOutputOutputElasticCloud
		u.Type = CreateOutputRequestTypeElasticCloud
		return nil
	case "newrelic":
		createOutputOutputNewrelic := new(CreateOutputOutputNewrelic)
		if err := utils.UnmarshalJSON(data, &createOutputOutputNewrelic, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == newrelic) type CreateOutputOutputNewrelic within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputNewrelic = createOutputOutputNewrelic
		u.Type = CreateOutputRequestTypeNewrelic
		return nil
	case "newrelic_events":
		createOutputOutputNewrelicEvents := new(CreateOutputOutputNewrelicEvents)
		if err := utils.UnmarshalJSON(data, &createOutputOutputNewrelicEvents, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == newrelic_events) type CreateOutputOutputNewrelicEvents within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputNewrelicEvents = createOutputOutputNewrelicEvents
		u.Type = CreateOutputRequestTypeNewrelicEvents
		return nil
	case "influxdb":
		createOutputOutputInfluxdb := new(CreateOutputOutputInfluxdb)
		if err := utils.UnmarshalJSON(data, &createOutputOutputInfluxdb, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == influxdb) type CreateOutputOutputInfluxdb within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputInfluxdb = createOutputOutputInfluxdb
		u.Type = CreateOutputRequestTypeInfluxdb
		return nil
	case "cloudwatch":
		createOutputOutputCloudwatch := new(CreateOutputOutputCloudwatch)
		if err := utils.UnmarshalJSON(data, &createOutputOutputCloudwatch, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == cloudwatch) type CreateOutputOutputCloudwatch within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputCloudwatch = createOutputOutputCloudwatch
		u.Type = CreateOutputRequestTypeCloudwatch
		return nil
	case "minio":
		createOutputOutputMinio := new(CreateOutputOutputMinio)
		if err := utils.UnmarshalJSON(data, &createOutputOutputMinio, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == minio) type CreateOutputOutputMinio within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputMinio = createOutputOutputMinio
		u.Type = CreateOutputRequestTypeMinio
		return nil
	case "statsd":
		createOutputOutputStatsd := new(CreateOutputOutputStatsd)
		if err := utils.UnmarshalJSON(data, &createOutputOutputStatsd, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == statsd) type CreateOutputOutputStatsd within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputStatsd = createOutputOutputStatsd
		u.Type = CreateOutputRequestTypeStatsd
		return nil
	case "statsd_ext":
		createOutputOutputStatsdExt := new(CreateOutputOutputStatsdExt)
		if err := utils.UnmarshalJSON(data, &createOutputOutputStatsdExt, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == statsd_ext) type CreateOutputOutputStatsdExt within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputStatsdExt = createOutputOutputStatsdExt
		u.Type = CreateOutputRequestTypeStatsdExt
		return nil
	case "graphite":
		createOutputOutputGraphite := new(CreateOutputOutputGraphite)
		if err := utils.UnmarshalJSON(data, &createOutputOutputGraphite, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == graphite) type CreateOutputOutputGraphite within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputGraphite = createOutputOutputGraphite
		u.Type = CreateOutputRequestTypeGraphite
		return nil
	case "router":
		createOutputOutputRouter := new(CreateOutputOutputRouter)
		if err := utils.UnmarshalJSON(data, &createOutputOutputRouter, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == router) type CreateOutputOutputRouter within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputRouter = createOutputOutputRouter
		u.Type = CreateOutputRequestTypeRouter
		return nil
	case "sns":
		createOutputOutputSns := new(CreateOutputOutputSns)
		if err := utils.UnmarshalJSON(data, &createOutputOutputSns, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == sns) type CreateOutputOutputSns within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputSns = createOutputOutputSns
		u.Type = CreateOutputRequestTypeSns
		return nil
	case "sqs":
		createOutputOutputSqs := new(CreateOutputOutputSqs)
		if err := utils.UnmarshalJSON(data, &createOutputOutputSqs, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == sqs) type CreateOutputOutputSqs within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputSqs = createOutputOutputSqs
		u.Type = CreateOutputRequestTypeSqs
		return nil
	case "snmp":
		createOutputOutputSnmp := new(CreateOutputOutputSnmp)
		if err := utils.UnmarshalJSON(data, &createOutputOutputSnmp, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == snmp) type CreateOutputOutputSnmp within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputSnmp = createOutputOutputSnmp
		u.Type = CreateOutputRequestTypeSnmp
		return nil
	case "sumo_logic":
		createOutputOutputSumoLogic := new(CreateOutputOutputSumoLogic)
		if err := utils.UnmarshalJSON(data, &createOutputOutputSumoLogic, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == sumo_logic) type CreateOutputOutputSumoLogic within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputSumoLogic = createOutputOutputSumoLogic
		u.Type = CreateOutputRequestTypeSumoLogic
		return nil
	case "datadog":
		createOutputOutputDatadog := new(CreateOutputOutputDatadog)
		if err := utils.UnmarshalJSON(data, &createOutputOutputDatadog, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == datadog) type CreateOutputOutputDatadog within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputDatadog = createOutputOutputDatadog
		u.Type = CreateOutputRequestTypeDatadog
		return nil
	case "grafana_cloud":
		createOutputOutputGrafanaCloudUnion := new(CreateOutputOutputGrafanaCloudUnion)
		if err := utils.UnmarshalJSON(data, &createOutputOutputGrafanaCloudUnion, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == grafana_cloud) type CreateOutputOutputGrafanaCloudUnion within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputGrafanaCloudUnion = createOutputOutputGrafanaCloudUnion
		u.Type = CreateOutputRequestTypeGrafanaCloud
		return nil
	case "loki":
		createOutputOutputLoki := new(CreateOutputOutputLoki)
		if err := utils.UnmarshalJSON(data, &createOutputOutputLoki, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == loki) type CreateOutputOutputLoki within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputLoki = createOutputOutputLoki
		u.Type = CreateOutputRequestTypeLoki
		return nil
	case "prometheus":
		createOutputOutputPrometheus := new(CreateOutputOutputPrometheus)
		if err := utils.UnmarshalJSON(data, &createOutputOutputPrometheus, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == prometheus) type CreateOutputOutputPrometheus within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputPrometheus = createOutputOutputPrometheus
		u.Type = CreateOutputRequestTypePrometheus
		return nil
	case "ring":
		createOutputOutputRing := new(CreateOutputOutputRing)
		if err := utils.UnmarshalJSON(data, &createOutputOutputRing, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == ring) type CreateOutputOutputRing within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputRing = createOutputOutputRing
		u.Type = CreateOutputRequestTypeRing
		return nil
	case "open_telemetry":
		createOutputOutputOpenTelemetry := new(CreateOutputOutputOpenTelemetry)
		if err := utils.UnmarshalJSON(data, &createOutputOutputOpenTelemetry, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == open_telemetry) type CreateOutputOutputOpenTelemetry within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputOpenTelemetry = createOutputOutputOpenTelemetry
		u.Type = CreateOutputRequestTypeOpenTelemetry
		return nil
	case "service_now":
		createOutputOutputServiceNow := new(CreateOutputOutputServiceNow)
		if err := utils.UnmarshalJSON(data, &createOutputOutputServiceNow, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == service_now) type CreateOutputOutputServiceNow within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputServiceNow = createOutputOutputServiceNow
		u.Type = CreateOutputRequestTypeServiceNow
		return nil
	case "dataset":
		createOutputOutputDataset := new(CreateOutputOutputDataset)
		if err := utils.UnmarshalJSON(data, &createOutputOutputDataset, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == dataset) type CreateOutputOutputDataset within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputDataset = createOutputOutputDataset
		u.Type = CreateOutputRequestTypeDataset
		return nil
	case "cribl_tcp":
		createOutputOutputCriblTCP := new(CreateOutputOutputCriblTCP)
		if err := utils.UnmarshalJSON(data, &createOutputOutputCriblTCP, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == cribl_tcp) type CreateOutputOutputCriblTCP within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputCriblTCP = createOutputOutputCriblTCP
		u.Type = CreateOutputRequestTypeCriblTCP
		return nil
	case "cribl_http":
		createOutputOutputCriblHTTP := new(CreateOutputOutputCriblHTTP)
		if err := utils.UnmarshalJSON(data, &createOutputOutputCriblHTTP, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == cribl_http) type CreateOutputOutputCriblHTTP within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputCriblHTTP = createOutputOutputCriblHTTP
		u.Type = CreateOutputRequestTypeCriblHTTP
		return nil
	case "cribl_search_engine":
		createOutputOutputCriblSearchEngine := new(CreateOutputOutputCriblSearchEngine)
		if err := utils.UnmarshalJSON(data, &createOutputOutputCriblSearchEngine, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == cribl_search_engine) type CreateOutputOutputCriblSearchEngine within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputCriblSearchEngine = createOutputOutputCriblSearchEngine
		u.Type = CreateOutputRequestTypeCriblSearchEngine
		return nil
	case "humio_hec":
		createOutputOutputHumioHec := new(CreateOutputOutputHumioHec)
		if err := utils.UnmarshalJSON(data, &createOutputOutputHumioHec, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == humio_hec) type CreateOutputOutputHumioHec within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputHumioHec = createOutputOutputHumioHec
		u.Type = CreateOutputRequestTypeHumioHec
		return nil
	case "crowdstrike_next_gen_siem":
		createOutputOutputCrowdstrikeNextGenSiem := new(CreateOutputOutputCrowdstrikeNextGenSiem)
		if err := utils.UnmarshalJSON(data, &createOutputOutputCrowdstrikeNextGenSiem, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == crowdstrike_next_gen_siem) type CreateOutputOutputCrowdstrikeNextGenSiem within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputCrowdstrikeNextGenSiem = createOutputOutputCrowdstrikeNextGenSiem
		u.Type = CreateOutputRequestTypeCrowdstrikeNextGenSiem
		return nil
	case "dl_s3":
		createOutputOutputDlS3 := new(CreateOutputOutputDlS3)
		if err := utils.UnmarshalJSON(data, &createOutputOutputDlS3, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == dl_s3) type CreateOutputOutputDlS3 within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputDlS3 = createOutputOutputDlS3
		u.Type = CreateOutputRequestTypeDlS3
		return nil
	case "security_lake":
		createOutputOutputSecurityLake := new(CreateOutputOutputSecurityLake)
		if err := utils.UnmarshalJSON(data, &createOutputOutputSecurityLake, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == security_lake) type CreateOutputOutputSecurityLake within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputSecurityLake = createOutputOutputSecurityLake
		u.Type = CreateOutputRequestTypeSecurityLake
		return nil
	case "cribl_lake":
		createOutputOutputCriblLake := new(CreateOutputOutputCriblLake)
		if err := utils.UnmarshalJSON(data, &createOutputOutputCriblLake, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == cribl_lake) type CreateOutputOutputCriblLake within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputCriblLake = createOutputOutputCriblLake
		u.Type = CreateOutputRequestTypeCriblLake
		return nil
	case "disk_spool":
		createOutputOutputDiskSpool := new(CreateOutputOutputDiskSpool)
		if err := utils.UnmarshalJSON(data, &createOutputOutputDiskSpool, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == disk_spool) type CreateOutputOutputDiskSpool within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputDiskSpool = createOutputOutputDiskSpool
		u.Type = CreateOutputRequestTypeDiskSpool
		return nil
	case "click_house":
		createOutputOutputClickHouse := new(CreateOutputOutputClickHouse)
		if err := utils.UnmarshalJSON(data, &createOutputOutputClickHouse, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == click_house) type CreateOutputOutputClickHouse within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputClickHouse = createOutputOutputClickHouse
		u.Type = CreateOutputRequestTypeClickHouse
		return nil
	case "xsiam":
		createOutputOutputXsiam := new(CreateOutputOutputXsiam)
		if err := utils.UnmarshalJSON(data, &createOutputOutputXsiam, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == xsiam) type CreateOutputOutputXsiam within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputXsiam = createOutputOutputXsiam
		u.Type = CreateOutputRequestTypeXsiam
		return nil
	case "netflow":
		createOutputOutputNetflow := new(CreateOutputOutputNetflow)
		if err := utils.UnmarshalJSON(data, &createOutputOutputNetflow, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == netflow) type CreateOutputOutputNetflow within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputNetflow = createOutputOutputNetflow
		u.Type = CreateOutputRequestTypeNetflow
		return nil
	case "dynatrace_http":
		createOutputOutputDynatraceHTTP := new(CreateOutputOutputDynatraceHTTP)
		if err := utils.UnmarshalJSON(data, &createOutputOutputDynatraceHTTP, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == dynatrace_http) type CreateOutputOutputDynatraceHTTP within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputDynatraceHTTP = createOutputOutputDynatraceHTTP
		u.Type = CreateOutputRequestTypeDynatraceHTTP
		return nil
	case "dynatrace_otlp":
		createOutputOutputDynatraceOtlp := new(CreateOutputOutputDynatraceOtlp)
		if err := utils.UnmarshalJSON(data, &createOutputOutputDynatraceOtlp, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == dynatrace_otlp) type CreateOutputOutputDynatraceOtlp within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputDynatraceOtlp = createOutputOutputDynatraceOtlp
		u.Type = CreateOutputRequestTypeDynatraceOtlp
		return nil
	case "sentinel_one_ai_siem":
		createOutputOutputSentinelOneAiSiem := new(CreateOutputOutputSentinelOneAiSiem)
		if err := utils.UnmarshalJSON(data, &createOutputOutputSentinelOneAiSiem, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == sentinel_one_ai_siem) type CreateOutputOutputSentinelOneAiSiem within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputSentinelOneAiSiem = createOutputOutputSentinelOneAiSiem
		u.Type = CreateOutputRequestTypeSentinelOneAiSiem
		return nil
	case "chronicle":
		createOutputOutputChronicle := new(CreateOutputOutputChronicle)
		if err := utils.UnmarshalJSON(data, &createOutputOutputChronicle, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == chronicle) type CreateOutputOutputChronicle within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputChronicle = createOutputOutputChronicle
		u.Type = CreateOutputRequestTypeChronicle
		return nil
	case "databricks":
		createOutputOutputDatabricks := new(CreateOutputOutputDatabricks)
		if err := utils.UnmarshalJSON(data, &createOutputOutputDatabricks, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == databricks) type CreateOutputOutputDatabricks within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputDatabricks = createOutputOutputDatabricks
		u.Type = CreateOutputRequestTypeDatabricks
		return nil
	case "microsoft_fabric":
		createOutputOutputMicrosoftFabric := new(CreateOutputOutputMicrosoftFabric)
		if err := utils.UnmarshalJSON(data, &createOutputOutputMicrosoftFabric, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == microsoft_fabric) type CreateOutputOutputMicrosoftFabric within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputMicrosoftFabric = createOutputOutputMicrosoftFabric
		u.Type = CreateOutputRequestTypeMicrosoftFabric
		return nil
	case "cloudflare_r2":
		createOutputOutputCloudflareR2 := new(CreateOutputOutputCloudflareR2)
		if err := utils.UnmarshalJSON(data, &createOutputOutputCloudflareR2, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == cloudflare_r2) type CreateOutputOutputCloudflareR2 within CreateOutputRequest: %w", string(data), err)
		}

		u.CreateOutputOutputCloudflareR2 = createOutputOutputCloudflareR2
		u.Type = CreateOutputRequestTypeCloudflareR2
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for CreateOutputRequest", string(data))
}

func (u CreateOutputRequest) MarshalJSON() ([]byte, error) {
	if u.CreateOutputOutputDefault != nil {
		return utils.MarshalJSON(u.CreateOutputOutputDefault, "", true)
	}

	if u.CreateOutputOutputWebhook != nil {
		return utils.MarshalJSON(u.CreateOutputOutputWebhook, "", true)
	}

	if u.CreateOutputOutputSentinel != nil {
		return utils.MarshalJSON(u.CreateOutputOutputSentinel, "", true)
	}

	if u.CreateOutputOutputDevnull != nil {
		return utils.MarshalJSON(u.CreateOutputOutputDevnull, "", true)
	}

	if u.CreateOutputOutputSyslog != nil {
		return utils.MarshalJSON(u.CreateOutputOutputSyslog, "", true)
	}

	if u.CreateOutputOutputSplunk != nil {
		return utils.MarshalJSON(u.CreateOutputOutputSplunk, "", true)
	}

	if u.CreateOutputOutputSplunkLb != nil {
		return utils.MarshalJSON(u.CreateOutputOutputSplunkLb, "", true)
	}

	if u.CreateOutputOutputSplunkHec != nil {
		return utils.MarshalJSON(u.CreateOutputOutputSplunkHec, "", true)
	}

	if u.CreateOutputOutputWizHec != nil {
		return utils.MarshalJSON(u.CreateOutputOutputWizHec, "", true)
	}

	if u.CreateOutputOutputTcpjson != nil {
		return utils.MarshalJSON(u.CreateOutputOutputTcpjson, "", true)
	}

	if u.CreateOutputOutputWavefront != nil {
		return utils.MarshalJSON(u.CreateOutputOutputWavefront, "", true)
	}

	if u.CreateOutputOutputSignalfx != nil {
		return utils.MarshalJSON(u.CreateOutputOutputSignalfx, "", true)
	}

	if u.CreateOutputOutputFilesystem != nil {
		return utils.MarshalJSON(u.CreateOutputOutputFilesystem, "", true)
	}

	if u.CreateOutputOutputS3 != nil {
		return utils.MarshalJSON(u.CreateOutputOutputS3, "", true)
	}

	if u.CreateOutputOutputAzureBlob != nil {
		return utils.MarshalJSON(u.CreateOutputOutputAzureBlob, "", true)
	}

	if u.CreateOutputOutputAzureDataExplorer != nil {
		return utils.MarshalJSON(u.CreateOutputOutputAzureDataExplorer, "", true)
	}

	if u.CreateOutputOutputAzureLogs != nil {
		return utils.MarshalJSON(u.CreateOutputOutputAzureLogs, "", true)
	}

	if u.CreateOutputOutputKinesis != nil {
		return utils.MarshalJSON(u.CreateOutputOutputKinesis, "", true)
	}

	if u.CreateOutputOutputHoneycomb != nil {
		return utils.MarshalJSON(u.CreateOutputOutputHoneycomb, "", true)
	}

	if u.CreateOutputOutputAzureEventhub != nil {
		return utils.MarshalJSON(u.CreateOutputOutputAzureEventhub, "", true)
	}

	if u.CreateOutputOutputGoogleChronicle != nil {
		return utils.MarshalJSON(u.CreateOutputOutputGoogleChronicle, "", true)
	}

	if u.CreateOutputOutputGoogleCloudStorage != nil {
		return utils.MarshalJSON(u.CreateOutputOutputGoogleCloudStorage, "", true)
	}

	if u.CreateOutputOutputGoogleCloudLogging != nil {
		return utils.MarshalJSON(u.CreateOutputOutputGoogleCloudLogging, "", true)
	}

	if u.CreateOutputOutputGooglePubsub != nil {
		return utils.MarshalJSON(u.CreateOutputOutputGooglePubsub, "", true)
	}

	if u.CreateOutputOutputExabeam != nil {
		return utils.MarshalJSON(u.CreateOutputOutputExabeam, "", true)
	}

	if u.CreateOutputOutputKafka != nil {
		return utils.MarshalJSON(u.CreateOutputOutputKafka, "", true)
	}

	if u.CreateOutputOutputConfluentCloud != nil {
		return utils.MarshalJSON(u.CreateOutputOutputConfluentCloud, "", true)
	}

	if u.CreateOutputOutputMsk != nil {
		return utils.MarshalJSON(u.CreateOutputOutputMsk, "", true)
	}

	if u.CreateOutputOutputElastic != nil {
		return utils.MarshalJSON(u.CreateOutputOutputElastic, "", true)
	}

	if u.CreateOutputOutputElasticCloud != nil {
		return utils.MarshalJSON(u.CreateOutputOutputElasticCloud, "", true)
	}

	if u.CreateOutputOutputNewrelic != nil {
		return utils.MarshalJSON(u.CreateOutputOutputNewrelic, "", true)
	}

	if u.CreateOutputOutputNewrelicEvents != nil {
		return utils.MarshalJSON(u.CreateOutputOutputNewrelicEvents, "", true)
	}

	if u.CreateOutputOutputInfluxdb != nil {
		return utils.MarshalJSON(u.CreateOutputOutputInfluxdb, "", true)
	}

	if u.CreateOutputOutputCloudwatch != nil {
		return utils.MarshalJSON(u.CreateOutputOutputCloudwatch, "", true)
	}

	if u.CreateOutputOutputMinio != nil {
		return utils.MarshalJSON(u.CreateOutputOutputMinio, "", true)
	}

	if u.CreateOutputOutputStatsd != nil {
		return utils.MarshalJSON(u.CreateOutputOutputStatsd, "", true)
	}

	if u.CreateOutputOutputStatsdExt != nil {
		return utils.MarshalJSON(u.CreateOutputOutputStatsdExt, "", true)
	}

	if u.CreateOutputOutputGraphite != nil {
		return utils.MarshalJSON(u.CreateOutputOutputGraphite, "", true)
	}

	if u.CreateOutputOutputRouter != nil {
		return utils.MarshalJSON(u.CreateOutputOutputRouter, "", true)
	}

	if u.CreateOutputOutputSns != nil {
		return utils.MarshalJSON(u.CreateOutputOutputSns, "", true)
	}

	if u.CreateOutputOutputSqs != nil {
		return utils.MarshalJSON(u.CreateOutputOutputSqs, "", true)
	}

	if u.CreateOutputOutputSnmp != nil {
		return utils.MarshalJSON(u.CreateOutputOutputSnmp, "", true)
	}

	if u.CreateOutputOutputSumoLogic != nil {
		return utils.MarshalJSON(u.CreateOutputOutputSumoLogic, "", true)
	}

	if u.CreateOutputOutputDatadog != nil {
		return utils.MarshalJSON(u.CreateOutputOutputDatadog, "", true)
	}

	if u.CreateOutputOutputGrafanaCloudUnion != nil {
		return utils.MarshalJSON(u.CreateOutputOutputGrafanaCloudUnion, "", true)
	}

	if u.CreateOutputOutputLoki != nil {
		return utils.MarshalJSON(u.CreateOutputOutputLoki, "", true)
	}

	if u.CreateOutputOutputPrometheus != nil {
		return utils.MarshalJSON(u.CreateOutputOutputPrometheus, "", true)
	}

	if u.CreateOutputOutputRing != nil {
		return utils.MarshalJSON(u.CreateOutputOutputRing, "", true)
	}

	if u.CreateOutputOutputOpenTelemetry != nil {
		return utils.MarshalJSON(u.CreateOutputOutputOpenTelemetry, "", true)
	}

	if u.CreateOutputOutputServiceNow != nil {
		return utils.MarshalJSON(u.CreateOutputOutputServiceNow, "", true)
	}

	if u.CreateOutputOutputDataset != nil {
		return utils.MarshalJSON(u.CreateOutputOutputDataset, "", true)
	}

	if u.CreateOutputOutputCriblTCP != nil {
		return utils.MarshalJSON(u.CreateOutputOutputCriblTCP, "", true)
	}

	if u.CreateOutputOutputCriblHTTP != nil {
		return utils.MarshalJSON(u.CreateOutputOutputCriblHTTP, "", true)
	}

	if u.CreateOutputOutputCriblSearchEngine != nil {
		return utils.MarshalJSON(u.CreateOutputOutputCriblSearchEngine, "", true)
	}

	if u.CreateOutputOutputHumioHec != nil {
		return utils.MarshalJSON(u.CreateOutputOutputHumioHec, "", true)
	}

	if u.CreateOutputOutputCrowdstrikeNextGenSiem != nil {
		return utils.MarshalJSON(u.CreateOutputOutputCrowdstrikeNextGenSiem, "", true)
	}

	if u.CreateOutputOutputDlS3 != nil {
		return utils.MarshalJSON(u.CreateOutputOutputDlS3, "", true)
	}

	if u.CreateOutputOutputSecurityLake != nil {
		return utils.MarshalJSON(u.CreateOutputOutputSecurityLake, "", true)
	}

	if u.CreateOutputOutputCriblLake != nil {
		return utils.MarshalJSON(u.CreateOutputOutputCriblLake, "", true)
	}

	if u.CreateOutputOutputDiskSpool != nil {
		return utils.MarshalJSON(u.CreateOutputOutputDiskSpool, "", true)
	}

	if u.CreateOutputOutputClickHouse != nil {
		return utils.MarshalJSON(u.CreateOutputOutputClickHouse, "", true)
	}

	if u.CreateOutputOutputXsiam != nil {
		return utils.MarshalJSON(u.CreateOutputOutputXsiam, "", true)
	}

	if u.CreateOutputOutputNetflow != nil {
		return utils.MarshalJSON(u.CreateOutputOutputNetflow, "", true)
	}

	if u.CreateOutputOutputDynatraceHTTP != nil {
		return utils.MarshalJSON(u.CreateOutputOutputDynatraceHTTP, "", true)
	}

	if u.CreateOutputOutputDynatraceOtlp != nil {
		return utils.MarshalJSON(u.CreateOutputOutputDynatraceOtlp, "", true)
	}

	if u.CreateOutputOutputSentinelOneAiSiem != nil {
		return utils.MarshalJSON(u.CreateOutputOutputSentinelOneAiSiem, "", true)
	}

	if u.CreateOutputOutputChronicle != nil {
		return utils.MarshalJSON(u.CreateOutputOutputChronicle, "", true)
	}

	if u.CreateOutputOutputDatabricks != nil {
		return utils.MarshalJSON(u.CreateOutputOutputDatabricks, "", true)
	}

	if u.CreateOutputOutputMicrosoftFabric != nil {
		return utils.MarshalJSON(u.CreateOutputOutputMicrosoftFabric, "", true)
	}

	if u.CreateOutputOutputCloudflareR2 != nil {
		return utils.MarshalJSON(u.CreateOutputOutputCloudflareR2, "", true)
	}

	return nil, errors.New("could not marshal union type CreateOutputRequest: all fields are null")
}

type CreateOutputResponse struct {
	HTTPMeta components.HTTPMetadata `json:"-"`
	// a list of Destination objects
	CountedOutput *components.CountedOutput
}

func (c *CreateOutputResponse) GetHTTPMeta() components.HTTPMetadata {
	if c == nil {
		return components.HTTPMetadata{}
	}
	return c.HTTPMeta
}

func (c *CreateOutputResponse) GetCountedOutput() *components.CountedOutput {
	if c == nil {
		return nil
	}
	return c.CountedOutput
}
