// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package operations

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/criblio/cribl-control-plane-sdk-go/internal/utils"
	"github.com/criblio/cribl-control-plane-sdk-go/models/components"
)

type TypeCloudflareR2 string

const (
	TypeCloudflareR2CloudflareR2 TypeCloudflareR2 = "cloudflare_r2"
)

func (e TypeCloudflareR2) ToPointer() *TypeCloudflareR2 {
	return &e
}
func (e *TypeCloudflareR2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cloudflare_r2":
		*e = TypeCloudflareR2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCloudflareR2: %v", v)
	}
}

// AuthenticationMethodCloudflareR2 - AWS authentication method. Choose Auto to use IAM roles.
type AuthenticationMethodCloudflareR2 string

const (
	AuthenticationMethodCloudflareR2Auto   AuthenticationMethodCloudflareR2 = "auto"
	AuthenticationMethodCloudflareR2Secret AuthenticationMethodCloudflareR2 = "secret"
	AuthenticationMethodCloudflareR2Manual AuthenticationMethodCloudflareR2 = "manual"
)

func (e AuthenticationMethodCloudflareR2) ToPointer() *AuthenticationMethodCloudflareR2 {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *AuthenticationMethodCloudflareR2) IsExact() bool {
	if e != nil {
		switch *e {
		case "auto", "secret", "manual":
			return true
		}
	}
	return false
}

type OutputCloudflareR2 struct {
	// Unique ID for this output
	ID   string           `json:"id"`
	Type TypeCloudflareR2 `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Cloudflare R2 service URL (example: https://<ACCOUNT_ID>.r2.cloudflarestorage.com)
	Endpoint string `json:"endpoint"`
	// Name of the destination R2 bucket. This value can be a constant or a JavaScript expression that can only be evaluated at init time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
	Bucket string `json:"bucket"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *AuthenticationMethodCloudflareR2 `json:"awsAuthenticationMethod,omitempty"`
	// Secret key. This value can be a constant or a JavaScript expression, such as `${C.env.SOME_SECRET}`).
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	Region       any     `json:"region,omitempty"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
	StagePath string `json:"stagePath"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Root directory to prepend to path before uploading. Enter a constant, or a JavaScript expression enclosed in quotes or backticks.
	DestPath *string `json:"destPath,omitempty"`
	// Signature version to use for signing MinIO requests
	SignatureVersion *components.SignatureVersionOptions5 `json:"signatureVersion,omitempty"`
	ObjectACL        any                                  `json:"objectACL,omitempty"`
	// Storage class to select for uploaded objects
	StorageClass *components.StorageClassOptions2 `json:"storageClass,omitempty"`
	// Server-side encryption for uploaded objects
	ServerSideEncryption *components.ServerSideEncryptionOptions `json:"serverSideEncryption,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates)
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Disable if you can access files within the bucket but not the bucket itself
	VerifyPermissions *bool `json:"verifyPermissions,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
	PartitionExpr *string `json:"partitionExpr,omitempty"`
	// Format of the output data
	Format *components.DataFormatOptions `json:"format,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `json:"baseFileName,omitempty"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `json:"fileNameSuffix,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `json:"maxFileSizeMB,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `json:"maxOpenFiles,omitempty"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `json:"headerLine,omitempty"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `json:"writeHighWaterMark,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `json:"deadletterEnabled,omitempty"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *components.DiskSpaceProtectionOptions `json:"onDiskFullBackpressure,omitempty"`
	// Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
	ForceCloseOnShutdown *bool                         `json:"forceCloseOnShutdown,omitempty"`
	RetrySettings        *components.RetrySettingsType `json:"retrySettings,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *float64 `json:"maxConcurrentFileParts,omitempty"`
	Description            *string  `json:"description,omitempty"`
	// This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Data compression format to apply to HTTP content before it is delivered
	Compress *components.CompressionOptions2 `json:"compress,omitempty"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *components.CompressionLevelOptions `json:"compressionLevel,omitempty"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `json:"automaticSchema,omitempty"`
	// To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
	ParquetSchema *string `json:"parquetSchema,omitempty"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *components.ParquetVersionOptions `json:"parquetVersion,omitempty"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *components.DataPageVersionOptions `json:"parquetDataPageVersion,omitempty"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `json:"parquetRowGroupLength,omitempty"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
	KeyValueMetadata []components.ItemsTypeKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `json:"enableStatistics,omitempty"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `json:"enableWritePageIndex,omitempty"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `json:"enablePageChecksum,omitempty"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `json:"emptyDirCleanupSec,omitempty"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `json:"directoryBatchSize,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `json:"deadletterPath,omitempty"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `json:"maxRetryNum,omitempty"`
}

func (o OutputCloudflareR2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCloudflareR2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputCloudflareR2) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputCloudflareR2) GetType() TypeCloudflareR2 {
	if o == nil {
		return TypeCloudflareR2("")
	}
	return o.Type
}

func (o *OutputCloudflareR2) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputCloudflareR2) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputCloudflareR2) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputCloudflareR2) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputCloudflareR2) GetEndpoint() string {
	if o == nil {
		return ""
	}
	return o.Endpoint
}

func (o *OutputCloudflareR2) GetBucket() string {
	if o == nil {
		return ""
	}
	return o.Bucket
}

func (o *OutputCloudflareR2) GetAwsAuthenticationMethod() *AuthenticationMethodCloudflareR2 {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputCloudflareR2) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputCloudflareR2) GetRegion() any {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *OutputCloudflareR2) GetStagePath() string {
	if o == nil {
		return ""
	}
	return o.StagePath
}

func (o *OutputCloudflareR2) GetAddIDToStagePath() *bool {
	if o == nil {
		return nil
	}
	return o.AddIDToStagePath
}

func (o *OutputCloudflareR2) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

func (o *OutputCloudflareR2) GetSignatureVersion() *components.SignatureVersionOptions5 {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputCloudflareR2) GetObjectACL() any {
	if o == nil {
		return nil
	}
	return o.ObjectACL
}

func (o *OutputCloudflareR2) GetStorageClass() *components.StorageClassOptions2 {
	if o == nil {
		return nil
	}
	return o.StorageClass
}

func (o *OutputCloudflareR2) GetServerSideEncryption() *components.ServerSideEncryptionOptions {
	if o == nil {
		return nil
	}
	return o.ServerSideEncryption
}

func (o *OutputCloudflareR2) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputCloudflareR2) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputCloudflareR2) GetVerifyPermissions() *bool {
	if o == nil {
		return nil
	}
	return o.VerifyPermissions
}

func (o *OutputCloudflareR2) GetRemoveEmptyDirs() *bool {
	if o == nil {
		return nil
	}
	return o.RemoveEmptyDirs
}

func (o *OutputCloudflareR2) GetPartitionExpr() *string {
	if o == nil {
		return nil
	}
	return o.PartitionExpr
}

func (o *OutputCloudflareR2) GetFormat() *components.DataFormatOptions {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputCloudflareR2) GetBaseFileName() *string {
	if o == nil {
		return nil
	}
	return o.BaseFileName
}

func (o *OutputCloudflareR2) GetFileNameSuffix() *string {
	if o == nil {
		return nil
	}
	return o.FileNameSuffix
}

func (o *OutputCloudflareR2) GetMaxFileSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileSizeMB
}

func (o *OutputCloudflareR2) GetMaxOpenFiles() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxOpenFiles
}

func (o *OutputCloudflareR2) GetHeaderLine() *string {
	if o == nil {
		return nil
	}
	return o.HeaderLine
}

func (o *OutputCloudflareR2) GetWriteHighWaterMark() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteHighWaterMark
}

func (o *OutputCloudflareR2) GetOnBackpressure() *components.BackpressureBehaviorOptions1 {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputCloudflareR2) GetDeadletterEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.DeadletterEnabled
}

func (o *OutputCloudflareR2) GetOnDiskFullBackpressure() *components.DiskSpaceProtectionOptions {
	if o == nil {
		return nil
	}
	return o.OnDiskFullBackpressure
}

func (o *OutputCloudflareR2) GetForceCloseOnShutdown() *bool {
	if o == nil {
		return nil
	}
	return o.ForceCloseOnShutdown
}

func (o *OutputCloudflareR2) GetRetrySettings() *components.RetrySettingsType {
	if o == nil {
		return nil
	}
	return o.RetrySettings
}

func (o *OutputCloudflareR2) GetMaxFileOpenTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileOpenTimeSec
}

func (o *OutputCloudflareR2) GetMaxFileIdleTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileIdleTimeSec
}

func (o *OutputCloudflareR2) GetMaxConcurrentFileParts() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentFileParts
}

func (o *OutputCloudflareR2) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputCloudflareR2) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputCloudflareR2) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *OutputCloudflareR2) GetCompress() *components.CompressionOptions2 {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputCloudflareR2) GetCompressionLevel() *components.CompressionLevelOptions {
	if o == nil {
		return nil
	}
	return o.CompressionLevel
}

func (o *OutputCloudflareR2) GetAutomaticSchema() *bool {
	if o == nil {
		return nil
	}
	return o.AutomaticSchema
}

func (o *OutputCloudflareR2) GetParquetSchema() *string {
	if o == nil {
		return nil
	}
	return o.ParquetSchema
}

func (o *OutputCloudflareR2) GetParquetVersion() *components.ParquetVersionOptions {
	if o == nil {
		return nil
	}
	return o.ParquetVersion
}

func (o *OutputCloudflareR2) GetParquetDataPageVersion() *components.DataPageVersionOptions {
	if o == nil {
		return nil
	}
	return o.ParquetDataPageVersion
}

func (o *OutputCloudflareR2) GetParquetRowGroupLength() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetRowGroupLength
}

func (o *OutputCloudflareR2) GetParquetPageSize() *string {
	if o == nil {
		return nil
	}
	return o.ParquetPageSize
}

func (o *OutputCloudflareR2) GetShouldLogInvalidRows() *bool {
	if o == nil {
		return nil
	}
	return o.ShouldLogInvalidRows
}

func (o *OutputCloudflareR2) GetKeyValueMetadata() []components.ItemsTypeKeyValueMetadata {
	if o == nil {
		return nil
	}
	return o.KeyValueMetadata
}

func (o *OutputCloudflareR2) GetEnableStatistics() *bool {
	if o == nil {
		return nil
	}
	return o.EnableStatistics
}

func (o *OutputCloudflareR2) GetEnableWritePageIndex() *bool {
	if o == nil {
		return nil
	}
	return o.EnableWritePageIndex
}

func (o *OutputCloudflareR2) GetEnablePageChecksum() *bool {
	if o == nil {
		return nil
	}
	return o.EnablePageChecksum
}

func (o *OutputCloudflareR2) GetEmptyDirCleanupSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EmptyDirCleanupSec
}

func (o *OutputCloudflareR2) GetDirectoryBatchSize() *float64 {
	if o == nil {
		return nil
	}
	return o.DirectoryBatchSize
}

func (o *OutputCloudflareR2) GetDeadletterPath() *string {
	if o == nil {
		return nil
	}
	return o.DeadletterPath
}

func (o *OutputCloudflareR2) GetMaxRetryNum() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetryNum
}

type TypeMicrosoftFabric string

const (
	TypeMicrosoftFabricMicrosoftFabric TypeMicrosoftFabric = "microsoft_fabric"
)

func (e TypeMicrosoftFabric) ToPointer() *TypeMicrosoftFabric {
	return &e
}
func (e *TypeMicrosoftFabric) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "microsoft_fabric":
		*e = TypeMicrosoftFabric(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeMicrosoftFabric: %v", v)
	}
}

type ClientSecretAuthTypeAuthenticationMethod string

const (
	ClientSecretAuthTypeAuthenticationMethodSecret      ClientSecretAuthTypeAuthenticationMethod = "secret"
	ClientSecretAuthTypeAuthenticationMethodCertificate ClientSecretAuthTypeAuthenticationMethod = "certificate"
)

func (e ClientSecretAuthTypeAuthenticationMethod) ToPointer() *ClientSecretAuthTypeAuthenticationMethod {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *ClientSecretAuthTypeAuthenticationMethod) IsExact() bool {
	if e != nil {
		switch *e {
		case "secret", "certificate":
			return true
		}
	}
	return false
}

// Authentication parameters to use when connecting to bootstrap server. Using TLS is highly recommended.
type Authentication struct {
	Disabled  bool                                  `json:"disabled"`
	Mechanism *components.SaslMechanismOptionsSasl1 `json:"mechanism,omitempty"`
	// The username for authentication. This should always be $ConnectionString.
	Username *string `json:"username,omitempty"`
	// Select or create a stored text secret corresponding to the SASL JASS Password Primary or Password Secondary
	TextSecret           *string                                   `json:"textSecret,omitempty"`
	ClientSecretAuthType *ClientSecretAuthTypeAuthenticationMethod `json:"clientSecretAuthType,omitempty"`
	// Select or create a stored text secret
	ClientTextSecret *string `json:"clientTextSecret,omitempty"`
	// Select or create a stored certificate
	CertificateName *string `json:"certificateName,omitempty"`
	CertPath        *string `json:"certPath,omitempty"`
	PrivKeyPath     *string `json:"privKeyPath,omitempty"`
	Passphrase      *string `json:"passphrase,omitempty"`
	// Endpoint used to acquire authentication tokens from Azure
	OauthEndpoint *components.MicrosoftEntraIDAuthenticationEndpointOptionsSasl `json:"oauthEndpoint,omitempty"`
	// client_id to pass in the OAuth request parameter
	ClientID *string `json:"clientId,omitempty"`
	// Directory ID (tenant identifier) in Azure Active Directory
	TenantID *string `json:"tenantId,omitempty"`
	// Scope to pass in the OAuth request parameter
	Scope *string `json:"scope,omitempty"`
}

func (a Authentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *Authentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *Authentication) GetDisabled() bool {
	if a == nil {
		return false
	}
	return a.Disabled
}

func (a *Authentication) GetMechanism() *components.SaslMechanismOptionsSasl1 {
	if a == nil {
		return nil
	}
	return a.Mechanism
}

func (a *Authentication) GetUsername() *string {
	if a == nil {
		return nil
	}
	return a.Username
}

func (a *Authentication) GetTextSecret() *string {
	if a == nil {
		return nil
	}
	return a.TextSecret
}

func (a *Authentication) GetClientSecretAuthType() *ClientSecretAuthTypeAuthenticationMethod {
	if a == nil {
		return nil
	}
	return a.ClientSecretAuthType
}

func (a *Authentication) GetClientTextSecret() *string {
	if a == nil {
		return nil
	}
	return a.ClientTextSecret
}

func (a *Authentication) GetCertificateName() *string {
	if a == nil {
		return nil
	}
	return a.CertificateName
}

func (a *Authentication) GetCertPath() *string {
	if a == nil {
		return nil
	}
	return a.CertPath
}

func (a *Authentication) GetPrivKeyPath() *string {
	if a == nil {
		return nil
	}
	return a.PrivKeyPath
}

func (a *Authentication) GetPassphrase() *string {
	if a == nil {
		return nil
	}
	return a.Passphrase
}

func (a *Authentication) GetOauthEndpoint() *components.MicrosoftEntraIDAuthenticationEndpointOptionsSasl {
	if a == nil {
		return nil
	}
	return a.OauthEndpoint
}

func (a *Authentication) GetClientID() *string {
	if a == nil {
		return nil
	}
	return a.ClientID
}

func (a *Authentication) GetTenantID() *string {
	if a == nil {
		return nil
	}
	return a.TenantID
}

func (a *Authentication) GetScope() *string {
	if a == nil {
		return nil
	}
	return a.Scope
}

type PqControlsMicrosoftFabric struct {
}

func (p PqControlsMicrosoftFabric) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsMicrosoftFabric) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputMicrosoftFabric struct {
	// Unique ID for this output
	ID   string              `json:"id"`
	Type TypeMicrosoftFabric `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Topic name from Fabric Eventstream's endpoint
	Topic string `json:"topic"`
	// Control the number of required acknowledgments
	Ack *components.AcknowledgmentsOptions `json:"ack,omitempty"`
	// Format to use to serialize events before writing to the Event Hubs Kafka brokers
	Format *components.RecordDataFormatOptions `json:"format,omitempty"`
	// Maximum size of each record batch before compression. Setting should be < message.max.bytes settings in Event Hubs brokers.
	MaxRecordSizeKB *float64 `json:"maxRecordSizeKB,omitempty"`
	// Maximum number of events in a batch before forcing a flush
	FlushEventCount *float64 `json:"flushEventCount,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `json:"requestTimeout,omitempty"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `json:"maxRetries,omitempty"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `json:"maxBackOff,omitempty"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `json:"initialBackoff,omitempty"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `json:"backoffRate,omitempty"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `json:"authenticationTimeout,omitempty"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `json:"reauthenticationThreshold,omitempty"`
	// Authentication parameters to use when connecting to bootstrap server. Using TLS is highly recommended.
	Sasl *Authentication                       `json:"sasl,omitempty"`
	TLS  *components.TLSSettingsClientSideType `json:"tls,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Bootstrap server from Fabric Eventstream's endpoint
	BootstrapServer string  `json:"bootstrap_server"`
	Description     *string `json:"description,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsMicrosoftFabric           `json:"pqControls,omitempty"`
}

func (o OutputMicrosoftFabric) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputMicrosoftFabric) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputMicrosoftFabric) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputMicrosoftFabric) GetType() TypeMicrosoftFabric {
	if o == nil {
		return TypeMicrosoftFabric("")
	}
	return o.Type
}

func (o *OutputMicrosoftFabric) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputMicrosoftFabric) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputMicrosoftFabric) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputMicrosoftFabric) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputMicrosoftFabric) GetTopic() string {
	if o == nil {
		return ""
	}
	return o.Topic
}

func (o *OutputMicrosoftFabric) GetAck() *components.AcknowledgmentsOptions {
	if o == nil {
		return nil
	}
	return o.Ack
}

func (o *OutputMicrosoftFabric) GetFormat() *components.RecordDataFormatOptions {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputMicrosoftFabric) GetMaxRecordSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRecordSizeKB
}

func (o *OutputMicrosoftFabric) GetFlushEventCount() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushEventCount
}

func (o *OutputMicrosoftFabric) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputMicrosoftFabric) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputMicrosoftFabric) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *OutputMicrosoftFabric) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *OutputMicrosoftFabric) GetMaxBackOff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackOff
}

func (o *OutputMicrosoftFabric) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputMicrosoftFabric) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputMicrosoftFabric) GetAuthenticationTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.AuthenticationTimeout
}

func (o *OutputMicrosoftFabric) GetReauthenticationThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.ReauthenticationThreshold
}

func (o *OutputMicrosoftFabric) GetSasl() *Authentication {
	if o == nil {
		return nil
	}
	return o.Sasl
}

func (o *OutputMicrosoftFabric) GetTLS() *components.TLSSettingsClientSideType {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputMicrosoftFabric) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputMicrosoftFabric) GetBootstrapServer() string {
	if o == nil {
		return ""
	}
	return o.BootstrapServer
}

func (o *OutputMicrosoftFabric) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputMicrosoftFabric) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputMicrosoftFabric) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputMicrosoftFabric) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputMicrosoftFabric) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputMicrosoftFabric) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputMicrosoftFabric) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputMicrosoftFabric) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputMicrosoftFabric) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputMicrosoftFabric) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputMicrosoftFabric) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputMicrosoftFabric) GetPqControls() *PqControlsMicrosoftFabric {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type TypeDatabricks string

const (
	TypeDatabricksDatabricks TypeDatabricks = "databricks"
)

func (e TypeDatabricks) ToPointer() *TypeDatabricks {
	return &e
}
func (e *TypeDatabricks) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "databricks":
		*e = TypeDatabricks(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeDatabricks: %v", v)
	}
}

type OutputDatabricks struct {
	// Unique ID for this output
	ID   string         `json:"id"`
	Type TypeDatabricks `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Optional path to prepend to files before uploading.
	DestPath *string `json:"destPath,omitempty"`
	// Filesystem location in which to buffer files before compressing and moving to final destination. Use performant, stable storage.
	StagePath *string `json:"stagePath,omitempty"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
	PartitionExpr *string `json:"partitionExpr,omitempty"`
	// Format of the output data
	Format *components.DataFormatOptions `json:"format,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `json:"baseFileName,omitempty"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `json:"fileNameSuffix,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `json:"maxFileSizeMB,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `json:"maxOpenFiles,omitempty"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `json:"headerLine,omitempty"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `json:"writeHighWaterMark,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `json:"deadletterEnabled,omitempty"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *components.DiskSpaceProtectionOptions `json:"onDiskFullBackpressure,omitempty"`
	// Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
	ForceCloseOnShutdown *bool                         `json:"forceCloseOnShutdown,omitempty"`
	RetrySettings        *components.RetrySettingsType `json:"retrySettings,omitempty"`
	// Databricks workspace ID
	WorkspaceID string `json:"workspaceId"`
	// OAuth scope for Unity Catalog authentication
	Scope string `json:"scope"`
	// OAuth client ID for Unity Catalog authentication
	ClientID string `json:"clientId"`
	// Name of the catalog to use for the output
	Catalog string `json:"catalog"`
	// Name of the catalog schema to use for the output
	Schema string `json:"schema"`
	// Name of the events volume in Databricks
	EventsVolumeName string `json:"eventsVolumeName"`
	// OAuth client secret for Unity Catalog authentication
	ClientTextSecret string `json:"clientTextSecret"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec  *float64 `json:"timeoutSec,omitempty"`
	Description *string  `json:"description,omitempty"`
	// Data compression format to apply to HTTP content before it is delivered
	Compress *components.CompressionOptions2 `json:"compress,omitempty"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *components.CompressionLevelOptions `json:"compressionLevel,omitempty"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `json:"automaticSchema,omitempty"`
	// To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
	ParquetSchema *string `json:"parquetSchema,omitempty"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *components.ParquetVersionOptions `json:"parquetVersion,omitempty"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *components.DataPageVersionOptions `json:"parquetDataPageVersion,omitempty"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `json:"parquetRowGroupLength,omitempty"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
	KeyValueMetadata []components.ItemsTypeKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `json:"enableStatistics,omitempty"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `json:"enableWritePageIndex,omitempty"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `json:"enablePageChecksum,omitempty"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `json:"emptyDirCleanupSec,omitempty"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `json:"directoryBatchSize,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `json:"deadletterPath,omitempty"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `json:"maxRetryNum,omitempty"`
}

func (o OutputDatabricks) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDatabricks) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputDatabricks) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputDatabricks) GetType() TypeDatabricks {
	if o == nil {
		return TypeDatabricks("")
	}
	return o.Type
}

func (o *OutputDatabricks) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputDatabricks) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputDatabricks) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputDatabricks) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputDatabricks) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

func (o *OutputDatabricks) GetStagePath() *string {
	if o == nil {
		return nil
	}
	return o.StagePath
}

func (o *OutputDatabricks) GetAddIDToStagePath() *bool {
	if o == nil {
		return nil
	}
	return o.AddIDToStagePath
}

func (o *OutputDatabricks) GetRemoveEmptyDirs() *bool {
	if o == nil {
		return nil
	}
	return o.RemoveEmptyDirs
}

func (o *OutputDatabricks) GetPartitionExpr() *string {
	if o == nil {
		return nil
	}
	return o.PartitionExpr
}

func (o *OutputDatabricks) GetFormat() *components.DataFormatOptions {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputDatabricks) GetBaseFileName() *string {
	if o == nil {
		return nil
	}
	return o.BaseFileName
}

func (o *OutputDatabricks) GetFileNameSuffix() *string {
	if o == nil {
		return nil
	}
	return o.FileNameSuffix
}

func (o *OutputDatabricks) GetMaxFileSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileSizeMB
}

func (o *OutputDatabricks) GetMaxFileOpenTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileOpenTimeSec
}

func (o *OutputDatabricks) GetMaxFileIdleTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileIdleTimeSec
}

func (o *OutputDatabricks) GetMaxOpenFiles() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxOpenFiles
}

func (o *OutputDatabricks) GetHeaderLine() *string {
	if o == nil {
		return nil
	}
	return o.HeaderLine
}

func (o *OutputDatabricks) GetWriteHighWaterMark() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteHighWaterMark
}

func (o *OutputDatabricks) GetOnBackpressure() *components.BackpressureBehaviorOptions1 {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputDatabricks) GetDeadletterEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.DeadletterEnabled
}

func (o *OutputDatabricks) GetOnDiskFullBackpressure() *components.DiskSpaceProtectionOptions {
	if o == nil {
		return nil
	}
	return o.OnDiskFullBackpressure
}

func (o *OutputDatabricks) GetForceCloseOnShutdown() *bool {
	if o == nil {
		return nil
	}
	return o.ForceCloseOnShutdown
}

func (o *OutputDatabricks) GetRetrySettings() *components.RetrySettingsType {
	if o == nil {
		return nil
	}
	return o.RetrySettings
}

func (o *OutputDatabricks) GetWorkspaceID() string {
	if o == nil {
		return ""
	}
	return o.WorkspaceID
}

func (o *OutputDatabricks) GetScope() string {
	if o == nil {
		return ""
	}
	return o.Scope
}

func (o *OutputDatabricks) GetClientID() string {
	if o == nil {
		return ""
	}
	return o.ClientID
}

func (o *OutputDatabricks) GetCatalog() string {
	if o == nil {
		return ""
	}
	return o.Catalog
}

func (o *OutputDatabricks) GetSchema() string {
	if o == nil {
		return ""
	}
	return o.Schema
}

func (o *OutputDatabricks) GetEventsVolumeName() string {
	if o == nil {
		return ""
	}
	return o.EventsVolumeName
}

func (o *OutputDatabricks) GetClientTextSecret() string {
	if o == nil {
		return ""
	}
	return o.ClientTextSecret
}

func (o *OutputDatabricks) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputDatabricks) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputDatabricks) GetCompress() *components.CompressionOptions2 {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputDatabricks) GetCompressionLevel() *components.CompressionLevelOptions {
	if o == nil {
		return nil
	}
	return o.CompressionLevel
}

func (o *OutputDatabricks) GetAutomaticSchema() *bool {
	if o == nil {
		return nil
	}
	return o.AutomaticSchema
}

func (o *OutputDatabricks) GetParquetSchema() *string {
	if o == nil {
		return nil
	}
	return o.ParquetSchema
}

func (o *OutputDatabricks) GetParquetVersion() *components.ParquetVersionOptions {
	if o == nil {
		return nil
	}
	return o.ParquetVersion
}

func (o *OutputDatabricks) GetParquetDataPageVersion() *components.DataPageVersionOptions {
	if o == nil {
		return nil
	}
	return o.ParquetDataPageVersion
}

func (o *OutputDatabricks) GetParquetRowGroupLength() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetRowGroupLength
}

func (o *OutputDatabricks) GetParquetPageSize() *string {
	if o == nil {
		return nil
	}
	return o.ParquetPageSize
}

func (o *OutputDatabricks) GetShouldLogInvalidRows() *bool {
	if o == nil {
		return nil
	}
	return o.ShouldLogInvalidRows
}

func (o *OutputDatabricks) GetKeyValueMetadata() []components.ItemsTypeKeyValueMetadata {
	if o == nil {
		return nil
	}
	return o.KeyValueMetadata
}

func (o *OutputDatabricks) GetEnableStatistics() *bool {
	if o == nil {
		return nil
	}
	return o.EnableStatistics
}

func (o *OutputDatabricks) GetEnableWritePageIndex() *bool {
	if o == nil {
		return nil
	}
	return o.EnableWritePageIndex
}

func (o *OutputDatabricks) GetEnablePageChecksum() *bool {
	if o == nil {
		return nil
	}
	return o.EnablePageChecksum
}

func (o *OutputDatabricks) GetEmptyDirCleanupSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EmptyDirCleanupSec
}

func (o *OutputDatabricks) GetDirectoryBatchSize() *float64 {
	if o == nil {
		return nil
	}
	return o.DirectoryBatchSize
}

func (o *OutputDatabricks) GetDeadletterPath() *string {
	if o == nil {
		return nil
	}
	return o.DeadletterPath
}

func (o *OutputDatabricks) GetMaxRetryNum() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetryNum
}

type TypeChronicle string

const (
	TypeChronicleChronicle TypeChronicle = "chronicle"
)

func (e TypeChronicle) ToPointer() *TypeChronicle {
	return &e
}
func (e *TypeChronicle) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "chronicle":
		*e = TypeChronicle(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeChronicle: %v", v)
	}
}

type AuthenticationMethodChronicle string

const (
	AuthenticationMethodChronicleServiceAccount       AuthenticationMethodChronicle = "serviceAccount"
	AuthenticationMethodChronicleServiceAccountSecret AuthenticationMethodChronicle = "serviceAccountSecret"
)

func (e AuthenticationMethodChronicle) ToPointer() *AuthenticationMethodChronicle {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *AuthenticationMethodChronicle) IsExact() bool {
	if e != nil {
		switch *e {
		case "serviceAccount", "serviceAccountSecret":
			return true
		}
	}
	return false
}

type CustomLabel struct {
	Key   string `json:"key"`
	Value string `json:"value"`
	// Designate this label for role-based access control and filtering
	RbacEnabled *bool `json:"rbacEnabled,omitempty"`
}

func (c CustomLabel) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CustomLabel) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *CustomLabel) GetKey() string {
	if c == nil {
		return ""
	}
	return c.Key
}

func (c *CustomLabel) GetValue() string {
	if c == nil {
		return ""
	}
	return c.Value
}

func (c *CustomLabel) GetRbacEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.RbacEnabled
}

type PqControlsChronicle struct {
}

func (p PqControlsChronicle) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsChronicle) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputChronicle struct {
	// Unique ID for this output
	ID   string        `json:"id"`
	Type TypeChronicle `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags           []string                       `json:"streamtags,omitempty"`
	APIVersion           *string                        `json:"apiVersion,omitempty"`
	AuthenticationMethod *AuthenticationMethodChronicle `json:"authenticationMethod,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// Regional endpoint to send events to
	Region string `json:"region"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	IngestionMethod    *string  `json:"ingestionMethod,omitempty"`
	// User-configured environment namespace to identify the data domain the logs originated from. This namespace is used as a tag to identify the appropriate data domain for indexing and enrichment functionality. Can be overwritten by event field __namespace.
	Namespace *string `json:"namespace,omitempty"`
	// Default log type value to send to SecOps. Can be overwritten by event field __logType.
	LogType string `json:"logType"`
	// Name of the event field that contains the log text to send. If not specified, Stream sends a JSON representation of the whole event.
	LogTextField *string `json:"logTextField,omitempty"`
	// The Google Cloud Platform (GCP) project ID to send events to
	GcpProjectID string `json:"gcpProjectId"`
	// The Google Cloud Platform (GCP) instance to send events to. This is the Chronicle customer uuid.
	GcpInstance string `json:"gcpInstance"`
	// Custom labels to be added to every event
	CustomLabels []CustomLabel `json:"customLabels,omitempty"`
	Description  *string       `json:"description,omitempty"`
	// Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
	ServiceAccountCredentials *string `json:"serviceAccountCredentials,omitempty"`
	// Select or create a stored text secret
	ServiceAccountCredentialsSecret *string `json:"serviceAccountCredentialsSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsChronicle                 `json:"pqControls,omitempty"`
}

func (o OutputChronicle) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputChronicle) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputChronicle) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputChronicle) GetType() TypeChronicle {
	if o == nil {
		return TypeChronicle("")
	}
	return o.Type
}

func (o *OutputChronicle) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputChronicle) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputChronicle) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputChronicle) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputChronicle) GetAPIVersion() *string {
	if o == nil {
		return nil
	}
	return o.APIVersion
}

func (o *OutputChronicle) GetAuthenticationMethod() *AuthenticationMethodChronicle {
	if o == nil {
		return nil
	}
	return o.AuthenticationMethod
}

func (o *OutputChronicle) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputChronicle) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputChronicle) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputChronicle) GetRegion() string {
	if o == nil {
		return ""
	}
	return o.Region
}

func (o *OutputChronicle) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputChronicle) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputChronicle) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputChronicle) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputChronicle) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputChronicle) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputChronicle) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputChronicle) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputChronicle) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputChronicle) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputChronicle) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputChronicle) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputChronicle) GetTotalMemoryLimitKB() *float64 {
	if o == nil {
		return nil
	}
	return o.TotalMemoryLimitKB
}

func (o *OutputChronicle) GetIngestionMethod() *string {
	if o == nil {
		return nil
	}
	return o.IngestionMethod
}

func (o *OutputChronicle) GetNamespace() *string {
	if o == nil {
		return nil
	}
	return o.Namespace
}

func (o *OutputChronicle) GetLogType() string {
	if o == nil {
		return ""
	}
	return o.LogType
}

func (o *OutputChronicle) GetLogTextField() *string {
	if o == nil {
		return nil
	}
	return o.LogTextField
}

func (o *OutputChronicle) GetGcpProjectID() string {
	if o == nil {
		return ""
	}
	return o.GcpProjectID
}

func (o *OutputChronicle) GetGcpInstance() string {
	if o == nil {
		return ""
	}
	return o.GcpInstance
}

func (o *OutputChronicle) GetCustomLabels() []CustomLabel {
	if o == nil {
		return nil
	}
	return o.CustomLabels
}

func (o *OutputChronicle) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputChronicle) GetServiceAccountCredentials() *string {
	if o == nil {
		return nil
	}
	return o.ServiceAccountCredentials
}

func (o *OutputChronicle) GetServiceAccountCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.ServiceAccountCredentialsSecret
}

func (o *OutputChronicle) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputChronicle) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputChronicle) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputChronicle) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputChronicle) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputChronicle) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputChronicle) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputChronicle) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputChronicle) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputChronicle) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputChronicle) GetPqControls() *PqControlsChronicle {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type TypeSentinelOneAiSiem string

const (
	TypeSentinelOneAiSiemSentinelOneAiSiem TypeSentinelOneAiSiem = "sentinel_one_ai_siem"
)

func (e TypeSentinelOneAiSiem) ToPointer() *TypeSentinelOneAiSiem {
	return &e
}
func (e *TypeSentinelOneAiSiem) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sentinel_one_ai_siem":
		*e = TypeSentinelOneAiSiem(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeSentinelOneAiSiem: %v", v)
	}
}

// Region - The SentinelOne region to send events to. In most cases you can find the region by either looking at your SentinelOne URL or knowing what geographic region your SentinelOne instance is contained in.
type Region string

const (
	RegionUs     Region = "US"
	RegionCa     Region = "CA"
	RegionEmea   Region = "EMEA"
	RegionAp     Region = "AP"
	RegionAps    Region = "APS"
	RegionAu     Region = "AU"
	RegionCustom Region = "Custom"
)

func (e Region) ToPointer() *Region {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *Region) IsExact() bool {
	if e != nil {
		switch *e {
		case "US", "CA", "EMEA", "AP", "APS", "AU", "Custom":
			return true
		}
	}
	return false
}

// AISIEMEndpointPath - Endpoint to send events to. Use /services/collector/event for structured JSON payloads with standard HEC top-level fields. Use /services/collector/raw for unstructured log lines (plain text).
type AISIEMEndpointPath string

const (
	AISIEMEndpointPathRootServicesCollectorEvent AISIEMEndpointPath = "/services/collector/event"
	AISIEMEndpointPathRootServicesCollectorRaw   AISIEMEndpointPath = "/services/collector/raw"
)

func (e AISIEMEndpointPath) ToPointer() *AISIEMEndpointPath {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *AISIEMEndpointPath) IsExact() bool {
	if e != nil {
		switch *e {
		case "/services/collector/event", "/services/collector/raw":
			return true
		}
	}
	return false
}

type PqControlsSentinelOneAiSiem struct {
}

func (p PqControlsSentinelOneAiSiem) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsSentinelOneAiSiem) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputSentinelOneAiSiem struct {
	// Unique ID for this output
	ID   string                `json:"id"`
	Type TypeSentinelOneAiSiem `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The SentinelOne region to send events to. In most cases you can find the region by either looking at your SentinelOne URL or knowing what geographic region your SentinelOne instance is contained in.
	Region Region `json:"region"`
	// Endpoint to send events to. Use /services/collector/event for structured JSON payloads with standard HEC top-level fields. Use /services/collector/raw for unstructured log lines (plain text).
	Endpoint AISIEMEndpointPath `json:"endpoint"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// In the SentinelOne Console select Policy & Settings then select the Singularity AI SIEM section, API Keys will be at the bottom. Under Log Access Keys select a Write token and copy it here
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Base URL of the endpoint used to send events to, such as https://<Your-S1-Tenant>.sentinelone.net. Must begin with http:// or https://, can include a port number, and no trailing slashes. Matches pattern: ^https?://[a-zA-Z0-9.-]+(:[0-9]+)?$.
	BaseURL *string `json:"baseUrl,omitempty"`
	// Define serverHost for events using a JavaScript expression. You must enclose text constants in quotes (such as, 'myServer').
	HostExpression *string `json:"hostExpression,omitempty"`
	// Define logFile for events using a JavaScript expression. You must enclose text constants in quotes (such as, 'myLogFile.txt').
	SourceExpression *string `json:"sourceExpression,omitempty"`
	// Define the parser for events using a JavaScript expression. This value helps parse data into AI SIEM. You must enclose text constants in quotes (such as, 'dottedJson'). For custom parsers, substitute 'dottedJson' with your parser's name.
	SourceTypeExpression *string `json:"sourceTypeExpression,omitempty"`
	// Define the dataSource.category for events using a JavaScript expression. This value helps categorize data and helps enable extra features in SentinelOne AI SIEM. You must enclose text constants in quotes. The default value is 'security'.
	DataSourceCategoryExpression *string `json:"dataSourceCategoryExpression,omitempty"`
	// Define the dataSource.name for events using a JavaScript expression. This value should reflect the type of data being inserted into AI SIEM. You must enclose text constants in quotes (such as, 'networkActivity' or 'authLogs').
	DataSourceNameExpression *string `json:"dataSourceNameExpression,omitempty"`
	// Define the dataSource.vendor for events using a JavaScript expression. This value should reflect the vendor of the data being inserted into AI SIEM. You must enclose text constants in quotes (such as, 'Cisco' or 'Microsoft').
	DataSourceVendorExpression *string `json:"dataSourceVendorExpression,omitempty"`
	// Optionally, define the event.type for events using a JavaScript expression. This value acts as a label, grouping events into meaningful categories. You must enclose text constants in quotes (such as, 'Process Creation' or 'Network Connection').
	EventTypeExpression *string `json:"eventTypeExpression,omitempty"`
	// Define the serverHost for events using a JavaScript expression. This value will be passed to AI SIEM. You must enclose text constants in quotes (such as, 'myServerName').
	Host *string `json:"host,omitempty"`
	// Specify the logFile value to pass as a parameter to SentinelOne AI SIEM. Don't quote this value. The default is cribl.
	Source *string `json:"source,omitempty"`
	// Specify the sourcetype parameter for SentinelOne AI SIEM, which determines the parser. Don't quote this value. For custom parsers, substitute hecRawParser with your parser's name. The default is hecRawParser.
	SourceType *string `json:"sourceType,omitempty"`
	// Specify the dataSource.category value to pass as a parameter to SentinelOne AI SIEM. This value helps categorize data and enables additional features. Don't quote this value. The default is security.
	DataSourceCategory *string `json:"dataSourceCategory,omitempty"`
	// Specify the dataSource.name value to pass as a parameter to AI SIEM. This value should reflect the type of data being inserted. Don't quote this value. The default is cribl.
	DataSourceName *string `json:"dataSourceName,omitempty"`
	// Specify the dataSource.vendorvalue to pass as a parameter to AI SIEM. This value should reflect the vendor of the data being inserted. Don't quote this value. The default is cribl.
	DataSourceVendor *string `json:"dataSourceVendor,omitempty"`
	// Specify the event.type value to pass as an optional parameter to AI SIEM. This value acts as a label, grouping events into meaningful categories like Process Creation, File Modification, or Network Connection. Don't quote this value. By default, this field is empty.
	EventType *string `json:"eventType,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsSentinelOneAiSiem         `json:"pqControls,omitempty"`
}

func (o OutputSentinelOneAiSiem) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSentinelOneAiSiem) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputSentinelOneAiSiem) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputSentinelOneAiSiem) GetType() TypeSentinelOneAiSiem {
	if o == nil {
		return TypeSentinelOneAiSiem("")
	}
	return o.Type
}

func (o *OutputSentinelOneAiSiem) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputSentinelOneAiSiem) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputSentinelOneAiSiem) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputSentinelOneAiSiem) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputSentinelOneAiSiem) GetRegion() Region {
	if o == nil {
		return Region("")
	}
	return o.Region
}

func (o *OutputSentinelOneAiSiem) GetEndpoint() AISIEMEndpointPath {
	if o == nil {
		return AISIEMEndpointPath("")
	}
	return o.Endpoint
}

func (o *OutputSentinelOneAiSiem) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputSentinelOneAiSiem) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputSentinelOneAiSiem) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputSentinelOneAiSiem) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputSentinelOneAiSiem) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputSentinelOneAiSiem) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputSentinelOneAiSiem) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputSentinelOneAiSiem) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputSentinelOneAiSiem) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputSentinelOneAiSiem) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputSentinelOneAiSiem) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputSentinelOneAiSiem) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputSentinelOneAiSiem) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputSentinelOneAiSiem) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputSentinelOneAiSiem) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputSentinelOneAiSiem) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputSentinelOneAiSiem) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputSentinelOneAiSiem) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputSentinelOneAiSiem) GetBaseURL() *string {
	if o == nil {
		return nil
	}
	return o.BaseURL
}

func (o *OutputSentinelOneAiSiem) GetHostExpression() *string {
	if o == nil {
		return nil
	}
	return o.HostExpression
}

func (o *OutputSentinelOneAiSiem) GetSourceExpression() *string {
	if o == nil {
		return nil
	}
	return o.SourceExpression
}

func (o *OutputSentinelOneAiSiem) GetSourceTypeExpression() *string {
	if o == nil {
		return nil
	}
	return o.SourceTypeExpression
}

func (o *OutputSentinelOneAiSiem) GetDataSourceCategoryExpression() *string {
	if o == nil {
		return nil
	}
	return o.DataSourceCategoryExpression
}

func (o *OutputSentinelOneAiSiem) GetDataSourceNameExpression() *string {
	if o == nil {
		return nil
	}
	return o.DataSourceNameExpression
}

func (o *OutputSentinelOneAiSiem) GetDataSourceVendorExpression() *string {
	if o == nil {
		return nil
	}
	return o.DataSourceVendorExpression
}

func (o *OutputSentinelOneAiSiem) GetEventTypeExpression() *string {
	if o == nil {
		return nil
	}
	return o.EventTypeExpression
}

func (o *OutputSentinelOneAiSiem) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *OutputSentinelOneAiSiem) GetSource() *string {
	if o == nil {
		return nil
	}
	return o.Source
}

func (o *OutputSentinelOneAiSiem) GetSourceType() *string {
	if o == nil {
		return nil
	}
	return o.SourceType
}

func (o *OutputSentinelOneAiSiem) GetDataSourceCategory() *string {
	if o == nil {
		return nil
	}
	return o.DataSourceCategory
}

func (o *OutputSentinelOneAiSiem) GetDataSourceName() *string {
	if o == nil {
		return nil
	}
	return o.DataSourceName
}

func (o *OutputSentinelOneAiSiem) GetDataSourceVendor() *string {
	if o == nil {
		return nil
	}
	return o.DataSourceVendor
}

func (o *OutputSentinelOneAiSiem) GetEventType() *string {
	if o == nil {
		return nil
	}
	return o.EventType
}

func (o *OutputSentinelOneAiSiem) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputSentinelOneAiSiem) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputSentinelOneAiSiem) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputSentinelOneAiSiem) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputSentinelOneAiSiem) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputSentinelOneAiSiem) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputSentinelOneAiSiem) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputSentinelOneAiSiem) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputSentinelOneAiSiem) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputSentinelOneAiSiem) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputSentinelOneAiSiem) GetPqControls() *PqControlsSentinelOneAiSiem {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type TypeDynatraceOtlp string

const (
	TypeDynatraceOtlpDynatraceOtlp TypeDynatraceOtlp = "dynatrace_otlp"
)

func (e TypeDynatraceOtlp) ToPointer() *TypeDynatraceOtlp {
	return &e
}
func (e *TypeDynatraceOtlp) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "dynatrace_otlp":
		*e = TypeDynatraceOtlp(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeDynatraceOtlp: %v", v)
	}
}

// ProtocolDynatraceOtlp - Select a transport option for Dynatrace
type ProtocolDynatraceOtlp string

const (
	// ProtocolDynatraceOtlpHTTP HTTP
	ProtocolDynatraceOtlpHTTP ProtocolDynatraceOtlp = "http"
)

func (e ProtocolDynatraceOtlp) ToPointer() *ProtocolDynatraceOtlp {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *ProtocolDynatraceOtlp) IsExact() bool {
	if e != nil {
		switch *e {
		case "http":
			return true
		}
	}
	return false
}

// EndpointType - Select the type of Dynatrace endpoint configured
type EndpointType string

const (
	// EndpointTypeSaas SaaS
	EndpointTypeSaas EndpointType = "saas"
	// EndpointTypeAg ActiveGate
	EndpointTypeAg EndpointType = "ag"
)

func (e EndpointType) ToPointer() *EndpointType {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *EndpointType) IsExact() bool {
	if e != nil {
		switch *e {
		case "saas", "ag":
			return true
		}
	}
	return false
}

type PqControlsDynatraceOtlp struct {
}

func (p PqControlsDynatraceOtlp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsDynatraceOtlp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputDynatraceOtlp struct {
	// Unique ID for this output
	ID   string            `json:"id"`
	Type TypeDynatraceOtlp `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Select a transport option for Dynatrace
	Protocol ProtocolDynatraceOtlp `json:"protocol"`
	// The endpoint where Dynatrace events will be sent. Enter any valid URL or an IP address (IPv4 or IPv6; enclose IPv6 addresses in square brackets)
	Endpoint string `json:"endpoint"`
	// The version of OTLP Protobuf definitions to use when structuring data to send
	OtlpVersion components.OtlpVersionOptions1 `json:"otlpVersion"`
	// Type of compression to apply to messages sent to the OpenTelemetry endpoint
	Compress *components.CompressionOptions4 `json:"compress,omitempty"`
	// Type of compression to apply to messages sent to the OpenTelemetry endpoint
	HTTPCompress *components.CompressionOptions5 `json:"httpCompress,omitempty"`
	// If you want to send traces to the default `{endpoint}/v1/traces` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPTracesEndpointOverride *string `json:"httpTracesEndpointOverride,omitempty"`
	// If you want to send metrics to the default `{endpoint}/v1/metrics` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPMetricsEndpointOverride *string `json:"httpMetricsEndpointOverride,omitempty"`
	// If you want to send logs to the default `{endpoint}/v1/logs` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPLogsEndpointOverride *string `json:"httpLogsEndpointOverride,omitempty"`
	// List of key-value pairs to send with each gRPC request. Value supports JavaScript expressions that are evaluated just once, when the destination gets started. To pass credentials as metadata, use 'C.Secret'.
	Metadata []components.ItemsTypeKeyValueMetadata `json:"metadata,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size (in KB) of the request body. The maximum payload size is 4 MB. If this limit is exceeded, the entire OTLP message is dropped
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// How often the sender should ping the peer to keep the connection open
	KeepAliveTime *float64 `json:"keepAliveTime,omitempty"`
	// Disable to close the connection immediately after sending the outgoing request
	KeepAlive *bool `json:"keepAlive,omitempty"`
	// Select the type of Dynatrace endpoint configured
	EndpointType EndpointType `json:"endpointType"`
	// Select or create a stored text secret
	TokenSecret   string  `json:"tokenSecret"`
	AuthTokenName *string `json:"authTokenName,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsDynatraceOtlp             `json:"pqControls,omitempty"`
}

func (o OutputDynatraceOtlp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDynatraceOtlp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputDynatraceOtlp) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputDynatraceOtlp) GetType() TypeDynatraceOtlp {
	if o == nil {
		return TypeDynatraceOtlp("")
	}
	return o.Type
}

func (o *OutputDynatraceOtlp) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputDynatraceOtlp) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputDynatraceOtlp) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputDynatraceOtlp) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputDynatraceOtlp) GetProtocol() ProtocolDynatraceOtlp {
	if o == nil {
		return ProtocolDynatraceOtlp("")
	}
	return o.Protocol
}

func (o *OutputDynatraceOtlp) GetEndpoint() string {
	if o == nil {
		return ""
	}
	return o.Endpoint
}

func (o *OutputDynatraceOtlp) GetOtlpVersion() components.OtlpVersionOptions1 {
	if o == nil {
		return components.OtlpVersionOptions1("")
	}
	return o.OtlpVersion
}

func (o *OutputDynatraceOtlp) GetCompress() *components.CompressionOptions4 {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputDynatraceOtlp) GetHTTPCompress() *components.CompressionOptions5 {
	if o == nil {
		return nil
	}
	return o.HTTPCompress
}

func (o *OutputDynatraceOtlp) GetHTTPTracesEndpointOverride() *string {
	if o == nil {
		return nil
	}
	return o.HTTPTracesEndpointOverride
}

func (o *OutputDynatraceOtlp) GetHTTPMetricsEndpointOverride() *string {
	if o == nil {
		return nil
	}
	return o.HTTPMetricsEndpointOverride
}

func (o *OutputDynatraceOtlp) GetHTTPLogsEndpointOverride() *string {
	if o == nil {
		return nil
	}
	return o.HTTPLogsEndpointOverride
}

func (o *OutputDynatraceOtlp) GetMetadata() []components.ItemsTypeKeyValueMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *OutputDynatraceOtlp) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputDynatraceOtlp) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputDynatraceOtlp) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputDynatraceOtlp) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputDynatraceOtlp) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputDynatraceOtlp) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputDynatraceOtlp) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *OutputDynatraceOtlp) GetKeepAlive() *bool {
	if o == nil {
		return nil
	}
	return o.KeepAlive
}

func (o *OutputDynatraceOtlp) GetEndpointType() EndpointType {
	if o == nil {
		return EndpointType("")
	}
	return o.EndpointType
}

func (o *OutputDynatraceOtlp) GetTokenSecret() string {
	if o == nil {
		return ""
	}
	return o.TokenSecret
}

func (o *OutputDynatraceOtlp) GetAuthTokenName() *string {
	if o == nil {
		return nil
	}
	return o.AuthTokenName
}

func (o *OutputDynatraceOtlp) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputDynatraceOtlp) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputDynatraceOtlp) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputDynatraceOtlp) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputDynatraceOtlp) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputDynatraceOtlp) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputDynatraceOtlp) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputDynatraceOtlp) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputDynatraceOtlp) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputDynatraceOtlp) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputDynatraceOtlp) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputDynatraceOtlp) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputDynatraceOtlp) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputDynatraceOtlp) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputDynatraceOtlp) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputDynatraceOtlp) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputDynatraceOtlp) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputDynatraceOtlp) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputDynatraceOtlp) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputDynatraceOtlp) GetPqControls() *PqControlsDynatraceOtlp {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type TypeDynatraceHTTP string

const (
	TypeDynatraceHTTPDynatraceHTTP TypeDynatraceHTTP = "dynatrace_http"
)

func (e TypeDynatraceHTTP) ToPointer() *TypeDynatraceHTTP {
	return &e
}
func (e *TypeDynatraceHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "dynatrace_http":
		*e = TypeDynatraceHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeDynatraceHTTP: %v", v)
	}
}

type AuthenticationTypeDynatraceHTTP string

const (
	// AuthenticationTypeDynatraceHTTPToken Auth token
	AuthenticationTypeDynatraceHTTPToken AuthenticationTypeDynatraceHTTP = "token"
	// AuthenticationTypeDynatraceHTTPTextSecret Token (text secret)
	AuthenticationTypeDynatraceHTTPTextSecret AuthenticationTypeDynatraceHTTP = "textSecret"
)

func (e AuthenticationTypeDynatraceHTTP) ToPointer() *AuthenticationTypeDynatraceHTTP {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *AuthenticationTypeDynatraceHTTP) IsExact() bool {
	if e != nil {
		switch *e {
		case "token", "textSecret":
			return true
		}
	}
	return false
}

// FormatDynatraceHTTP - How to format events before sending. Defaults to JSON. Plaintext is not currently supported.
type FormatDynatraceHTTP string

const (
	// FormatDynatraceHTTPJSONArray JSON
	FormatDynatraceHTTPJSONArray FormatDynatraceHTTP = "json_array"
	// FormatDynatraceHTTPPlaintext Plaintext
	FormatDynatraceHTTPPlaintext FormatDynatraceHTTP = "plaintext"
)

func (e FormatDynatraceHTTP) ToPointer() *FormatDynatraceHTTP {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *FormatDynatraceHTTP) IsExact() bool {
	if e != nil {
		switch *e {
		case "json_array", "plaintext":
			return true
		}
	}
	return false
}

type Endpoint string

const (
	// EndpointCloud Cloud
	EndpointCloud Endpoint = "cloud"
	// EndpointActiveGate ActiveGate
	EndpointActiveGate Endpoint = "activeGate"
	// EndpointManual Manual
	EndpointManual Endpoint = "manual"
)

func (e Endpoint) ToPointer() *Endpoint {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *Endpoint) IsExact() bool {
	if e != nil {
		switch *e {
		case "cloud", "activeGate", "manual":
			return true
		}
	}
	return false
}

type TelemetryType string

const (
	// TelemetryTypeLogs Logs
	TelemetryTypeLogs TelemetryType = "logs"
	// TelemetryTypeMetrics Metrics
	TelemetryTypeMetrics TelemetryType = "metrics"
)

func (e TelemetryType) ToPointer() *TelemetryType {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *TelemetryType) IsExact() bool {
	if e != nil {
		switch *e {
		case "logs", "metrics":
			return true
		}
	}
	return false
}

type PqControlsDynatraceHTTP struct {
}

func (p PqControlsDynatraceHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsDynatraceHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputDynatraceHTTP struct {
	// Unique ID for this output
	ID   string            `json:"id"`
	Type TypeDynatraceHTTP `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The method to use when sending events
	Method *components.MethodOptions `json:"method,omitempty"`
	// Disable to close the connection immediately after sending the outgoing request
	KeepAlive *bool `json:"keepAlive,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events. You can also add headers dynamically on a per-event basis in the __headers field, as explained in [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook/#internal-fields).
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	AuthType       *AuthenticationTypeDynatraceHTTP        `json:"authType,omitempty"`
	// How to format events before sending. Defaults to JSON. Plaintext is not currently supported.
	Format        FormatDynatraceHTTP `json:"format"`
	Endpoint      Endpoint            `json:"endpoint"`
	TelemetryType TelemetryType       `json:"telemetryType"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsDynatraceHTTP             `json:"pqControls,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// ID of the environment to send to
	EnvironmentID *string `json:"environmentId,omitempty"`
	// ActiveGate domain with Log analytics collector module enabled. For example https://{activeGate-domain}:9999/e/{environment-id}/api/v2/logs/ingest.
	ActiveGateDomain *string `json:"activeGateDomain,omitempty"`
	// URL to send events to. Can be overwritten by an event's __url field.
	URL *string `json:"url,omitempty"`
}

func (o OutputDynatraceHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDynatraceHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputDynatraceHTTP) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputDynatraceHTTP) GetType() TypeDynatraceHTTP {
	if o == nil {
		return TypeDynatraceHTTP("")
	}
	return o.Type
}

func (o *OutputDynatraceHTTP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputDynatraceHTTP) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputDynatraceHTTP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputDynatraceHTTP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputDynatraceHTTP) GetMethod() *components.MethodOptions {
	if o == nil {
		return nil
	}
	return o.Method
}

func (o *OutputDynatraceHTTP) GetKeepAlive() *bool {
	if o == nil {
		return nil
	}
	return o.KeepAlive
}

func (o *OutputDynatraceHTTP) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputDynatraceHTTP) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputDynatraceHTTP) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputDynatraceHTTP) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputDynatraceHTTP) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputDynatraceHTTP) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputDynatraceHTTP) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputDynatraceHTTP) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputDynatraceHTTP) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputDynatraceHTTP) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputDynatraceHTTP) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputDynatraceHTTP) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputDynatraceHTTP) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputDynatraceHTTP) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputDynatraceHTTP) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputDynatraceHTTP) GetAuthType() *AuthenticationTypeDynatraceHTTP {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputDynatraceHTTP) GetFormat() FormatDynatraceHTTP {
	if o == nil {
		return FormatDynatraceHTTP("")
	}
	return o.Format
}

func (o *OutputDynatraceHTTP) GetEndpoint() Endpoint {
	if o == nil {
		return Endpoint("")
	}
	return o.Endpoint
}

func (o *OutputDynatraceHTTP) GetTelemetryType() TelemetryType {
	if o == nil {
		return TelemetryType("")
	}
	return o.TelemetryType
}

func (o *OutputDynatraceHTTP) GetTotalMemoryLimitKB() *float64 {
	if o == nil {
		return nil
	}
	return o.TotalMemoryLimitKB
}

func (o *OutputDynatraceHTTP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputDynatraceHTTP) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputDynatraceHTTP) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputDynatraceHTTP) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputDynatraceHTTP) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputDynatraceHTTP) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputDynatraceHTTP) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputDynatraceHTTP) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputDynatraceHTTP) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputDynatraceHTTP) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputDynatraceHTTP) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputDynatraceHTTP) GetPqControls() *PqControlsDynatraceHTTP {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputDynatraceHTTP) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputDynatraceHTTP) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputDynatraceHTTP) GetEnvironmentID() *string {
	if o == nil {
		return nil
	}
	return o.EnvironmentID
}

func (o *OutputDynatraceHTTP) GetActiveGateDomain() *string {
	if o == nil {
		return nil
	}
	return o.ActiveGateDomain
}

func (o *OutputDynatraceHTTP) GetURL() *string {
	if o == nil {
		return nil
	}
	return o.URL
}

type CreateOutputTypeNetflow string

const (
	CreateOutputTypeNetflowNetflow CreateOutputTypeNetflow = "netflow"
)

func (e CreateOutputTypeNetflow) ToPointer() *CreateOutputTypeNetflow {
	return &e
}
func (e *CreateOutputTypeNetflow) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "netflow":
		*e = CreateOutputTypeNetflow(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeNetflow: %v", v)
	}
}

type HostNetflow struct {
	// Destination host
	Host string `json:"host"`
	// Destination port, default is 2055
	Port float64 `json:"port"`
}

func (h HostNetflow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *HostNetflow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (h *HostNetflow) GetHost() string {
	if h == nil {
		return ""
	}
	return h.Host
}

func (h *HostNetflow) GetPort() float64 {
	if h == nil {
		return 0.0
	}
	return h.Port
}

type OutputNetflow struct {
	// Unique ID for this output
	ID   string                  `json:"id"`
	Type CreateOutputTypeNetflow `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// One or more NetFlow Destinations to forward events to
	Hosts []HostNetflow `json:"hosts"`
	// How often to resolve the destination hostname to an IP address. Ignored if all destinations are IP addresses. A value of 0 means every datagram sent will incur a DNS lookup.
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	// Send NetFlow traffic using the original event's Source IP and port. To enable this, you must install the external `udp-sender` helper binary at `/usr/bin/udp-sender` on all Worker Nodes and grant it the `CAP_NET_RAW` capability.
	EnableIPSpoofing *bool   `json:"enableIpSpoofing,omitempty"`
	Description      *string `json:"description,omitempty"`
	// MTU in bytes. The actual maximum NetFlow payload size will be MTU minus IP and UDP headers (28 bytes for IPv4, 48 bytes for IPv6). For example, with the default MTU of 1500, the max payload is 1472 bytes for IPv4. Payloads exceeding this limit will be dropped.
	MaxRecordSize *float64 `json:"maxRecordSize,omitempty"`
}

func (o OutputNetflow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputNetflow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputNetflow) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputNetflow) GetType() CreateOutputTypeNetflow {
	if o == nil {
		return CreateOutputTypeNetflow("")
	}
	return o.Type
}

func (o *OutputNetflow) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputNetflow) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputNetflow) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputNetflow) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputNetflow) GetHosts() []HostNetflow {
	if o == nil {
		return []HostNetflow{}
	}
	return o.Hosts
}

func (o *OutputNetflow) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputNetflow) GetEnableIPSpoofing() *bool {
	if o == nil {
		return nil
	}
	return o.EnableIPSpoofing
}

func (o *OutputNetflow) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputNetflow) GetMaxRecordSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRecordSize
}

type TypeXsiam string

const (
	TypeXsiamXsiam TypeXsiam = "xsiam"
)

func (e TypeXsiam) ToPointer() *TypeXsiam {
	return &e
}
func (e *TypeXsiam) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "xsiam":
		*e = TypeXsiam(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeXsiam: %v", v)
	}
}

// AuthenticationMethodXsiam - Enter a token directly, or provide a secret referencing a token
type AuthenticationMethodXsiam string

const (
	AuthenticationMethodXsiamToken  AuthenticationMethodXsiam = "token"
	AuthenticationMethodXsiamSecret AuthenticationMethodXsiam = "secret"
)

func (e AuthenticationMethodXsiam) ToPointer() *AuthenticationMethodXsiam {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *AuthenticationMethodXsiam) IsExact() bool {
	if e != nil {
		switch *e {
		case "token", "secret":
			return true
		}
	}
	return false
}

type URLXsiam struct {
	URL any `json:"url"`
	// Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
	Weight *float64 `json:"weight,omitempty"`
}

func (u URLXsiam) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(u, "", false)
}

func (u *URLXsiam) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &u, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (u *URLXsiam) GetURL() any {
	if u == nil {
		return nil
	}
	return u.URL
}

func (u *URLXsiam) GetWeight() *float64 {
	if u == nil {
		return nil
	}
	return u.Weight
}

type PqControlsXsiam struct {
}

func (p PqControlsXsiam) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsXsiam) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputXsiam struct {
	// Unique ID for this output
	ID   string    `json:"id"`
	Type TypeXsiam `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Enable for optimal performance. Even if you have one hostname, it can expand to multiple IPs. If disabled, consider enabling round-robin DNS.
	LoadBalanced *bool `json:"loadBalanced,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Enter a token directly, or provide a secret referencing a token
	AuthType *AuthenticationMethodXsiam `json:"authType,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// Maximum number of requests to limit to per second
	ThrottleRateReqPerSec *int64 `json:"throttleRateReqPerSec,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	// XSIAM endpoint URL to send events to, such as https://api-{tenant external URL}/logs/v1/event
	URL *string `json:"url,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Exclude all IPs of the current host from the list of any resolved hostnames
	ExcludeSelf *bool      `json:"excludeSelf,omitempty"`
	Urls        []URLXsiam `json:"urls,omitempty"`
	// The interval in which to re-resolve any hostnames and pick up destinations from A records
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	// How far back in time to keep traffic stats for load balancing purposes
	LoadBalanceStatsPeriodSec *float64 `json:"loadBalanceStatsPeriodSec,omitempty"`
	// XSIAM authentication token
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsXsiam                     `json:"pqControls,omitempty"`
}

func (o OutputXsiam) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputXsiam) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputXsiam) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputXsiam) GetType() TypeXsiam {
	if o == nil {
		return TypeXsiam("")
	}
	return o.Type
}

func (o *OutputXsiam) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputXsiam) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputXsiam) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputXsiam) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputXsiam) GetLoadBalanced() *bool {
	if o == nil {
		return nil
	}
	return o.LoadBalanced
}

func (o *OutputXsiam) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputXsiam) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputXsiam) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputXsiam) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputXsiam) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputXsiam) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputXsiam) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputXsiam) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputXsiam) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputXsiam) GetAuthType() *AuthenticationMethodXsiam {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputXsiam) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputXsiam) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputXsiam) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputXsiam) GetThrottleRateReqPerSec() *int64 {
	if o == nil {
		return nil
	}
	return o.ThrottleRateReqPerSec
}

func (o *OutputXsiam) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputXsiam) GetTotalMemoryLimitKB() *float64 {
	if o == nil {
		return nil
	}
	return o.TotalMemoryLimitKB
}

func (o *OutputXsiam) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputXsiam) GetURL() *string {
	if o == nil {
		return nil
	}
	return o.URL
}

func (o *OutputXsiam) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputXsiam) GetExcludeSelf() *bool {
	if o == nil {
		return nil
	}
	return o.ExcludeSelf
}

func (o *OutputXsiam) GetUrls() []URLXsiam {
	if o == nil {
		return nil
	}
	return o.Urls
}

func (o *OutputXsiam) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputXsiam) GetLoadBalanceStatsPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.LoadBalanceStatsPeriodSec
}

func (o *OutputXsiam) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputXsiam) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputXsiam) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputXsiam) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputXsiam) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputXsiam) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputXsiam) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputXsiam) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputXsiam) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputXsiam) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputXsiam) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputXsiam) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputXsiam) GetPqControls() *PqControlsXsiam {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type TypeClickHouse string

const (
	TypeClickHouseClickHouse TypeClickHouse = "click_house"
)

func (e TypeClickHouse) ToPointer() *TypeClickHouse {
	return &e
}
func (e *TypeClickHouse) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "click_house":
		*e = TypeClickHouse(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeClickHouse: %v", v)
	}
}

type AuthenticationTypeClickHouse string

const (
	AuthenticationTypeClickHouseNone               AuthenticationTypeClickHouse = "none"
	AuthenticationTypeClickHouseBasic              AuthenticationTypeClickHouse = "basic"
	AuthenticationTypeClickHouseCredentialsSecret  AuthenticationTypeClickHouse = "credentialsSecret"
	AuthenticationTypeClickHouseSslUserCertificate AuthenticationTypeClickHouse = "sslUserCertificate"
	AuthenticationTypeClickHouseToken              AuthenticationTypeClickHouse = "token"
	AuthenticationTypeClickHouseTextSecret         AuthenticationTypeClickHouse = "textSecret"
	AuthenticationTypeClickHouseOauth              AuthenticationTypeClickHouse = "oauth"
)

func (e AuthenticationTypeClickHouse) ToPointer() *AuthenticationTypeClickHouse {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *AuthenticationTypeClickHouse) IsExact() bool {
	if e != nil {
		switch *e {
		case "none", "basic", "credentialsSecret", "sslUserCertificate", "token", "textSecret", "oauth":
			return true
		}
	}
	return false
}

// FormatClickHouse - Data format to use when sending data to ClickHouse. Defaults to JSON Compact.
type FormatClickHouse string

const (
	// FormatClickHouseJSONCompactEachRowWithNames JSONCompactEachRowWithNames
	FormatClickHouseJSONCompactEachRowWithNames FormatClickHouse = "json-compact-each-row-with-names"
	// FormatClickHouseJSONEachRow JSONEachRow
	FormatClickHouseJSONEachRow FormatClickHouse = "json-each-row"
)

func (e FormatClickHouse) ToPointer() *FormatClickHouse {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *FormatClickHouse) IsExact() bool {
	if e != nil {
		switch *e {
		case "json-compact-each-row-with-names", "json-each-row":
			return true
		}
	}
	return false
}

// MappingType - How event fields are mapped to ClickHouse columns.
type MappingType string

const (
	// MappingTypeAutomatic Automatic
	MappingTypeAutomatic MappingType = "automatic"
	// MappingTypeCustom Custom
	MappingTypeCustom MappingType = "custom"
)

func (e MappingType) ToPointer() *MappingType {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *MappingType) IsExact() bool {
	if e != nil {
		switch *e {
		case "automatic", "custom":
			return true
		}
	}
	return false
}

type StatsDestination struct {
	URL         *string `json:"url,omitempty"`
	Database    *string `json:"database,omitempty"`
	TableName   *string `json:"tableName,omitempty"`
	AuthType    *string `json:"authType,omitempty"`
	Username    *string `json:"username,omitempty"`
	SQLUsername *string `json:"sqlUsername,omitempty"`
	Password    *string `json:"password,omitempty"`
}

func (s StatsDestination) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *StatsDestination) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (s *StatsDestination) GetURL() *string {
	if s == nil {
		return nil
	}
	return s.URL
}

func (s *StatsDestination) GetDatabase() *string {
	if s == nil {
		return nil
	}
	return s.Database
}

func (s *StatsDestination) GetTableName() *string {
	if s == nil {
		return nil
	}
	return s.TableName
}

func (s *StatsDestination) GetAuthType() *string {
	if s == nil {
		return nil
	}
	return s.AuthType
}

func (s *StatsDestination) GetUsername() *string {
	if s == nil {
		return nil
	}
	return s.Username
}

func (s *StatsDestination) GetSQLUsername() *string {
	if s == nil {
		return nil
	}
	return s.SQLUsername
}

func (s *StatsDestination) GetPassword() *string {
	if s == nil {
		return nil
	}
	return s.Password
}

type ColumnMapping struct {
	// Name of the column in ClickHouse that will store field value
	ColumnName string `json:"columnName"`
	// Type of the column in the ClickHouse database
	ColumnType *string `json:"columnType,omitempty"`
	// JavaScript expression to compute value to be inserted into ClickHouse table
	ColumnValueExpression string `json:"columnValueExpression"`
}

func (c ColumnMapping) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ColumnMapping) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *ColumnMapping) GetColumnName() string {
	if c == nil {
		return ""
	}
	return c.ColumnName
}

func (c *ColumnMapping) GetColumnType() *string {
	if c == nil {
		return nil
	}
	return c.ColumnType
}

func (c *ColumnMapping) GetColumnValueExpression() string {
	if c == nil {
		return ""
	}
	return c.ColumnValueExpression
}

type PqControlsClickHouse struct {
}

func (p PqControlsClickHouse) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsClickHouse) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputClickHouse struct {
	// Unique ID for this output
	ID   string         `json:"id"`
	Type TypeClickHouse `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// URL of the ClickHouse instance. Example: http://localhost:8123/
	URL      string                        `json:"url"`
	AuthType *AuthenticationTypeClickHouse `json:"authType,omitempty"`
	Database string                        `json:"database"`
	// Name of the ClickHouse table where data will be inserted. Name can contain letters (A-Z, a-z), numbers (0-9), and the character "_", and must start with either a letter or the character "_".
	TableName string `json:"tableName"`
	// Data format to use when sending data to ClickHouse. Defaults to JSON Compact.
	Format *FormatClickHouse `json:"format,omitempty"`
	// How event fields are mapped to ClickHouse columns.
	MappingType *MappingType `json:"mappingType,omitempty"`
	// Collect data into batches for later processing. Disable to write to a ClickHouse table immediately.
	AsyncInserts *bool                                  `json:"asyncInserts,omitempty"`
	TLS          *components.TLSSettingsClientSideType1 `json:"tls,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// Log the most recent event that fails to match the table schema
	DumpFormatErrorsToDisk *bool             `json:"dumpFormatErrorsToDisk,omitempty"`
	StatsDestination       *StatsDestination `json:"statsDestination,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	Username       *string                                 `json:"username,omitempty"`
	Password       *string                                 `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `json:"authHeaderExpr,omitempty"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `json:"tokenTimeoutSecs,omitempty"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []components.ItemsTypeOauthParams `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []components.ItemsTypeOauthHeaders `json:"oauthHeaders,omitempty"`
	// Username for certificate authentication
	SQLUsername *string `json:"sqlUsername,omitempty"`
	// Cribl will wait for confirmation that data has been fully inserted into the ClickHouse database before proceeding. Disabling this option can increase throughput, but Cribl won’t be able to verify data has been completely inserted.
	WaitForAsyncInserts *bool `json:"waitForAsyncInserts,omitempty"`
	// Fields to exclude from sending to ClickHouse
	ExcludeMappingFields []string `json:"excludeMappingFields,omitempty"`
	// Retrieves the table schema from ClickHouse and populates the Column Mapping table
	DescribeTable  *string         `json:"describeTable,omitempty"`
	ColumnMappings []ColumnMapping `json:"columnMappings,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsClickHouse                `json:"pqControls,omitempty"`
}

func (o OutputClickHouse) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputClickHouse) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputClickHouse) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputClickHouse) GetType() TypeClickHouse {
	if o == nil {
		return TypeClickHouse("")
	}
	return o.Type
}

func (o *OutputClickHouse) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputClickHouse) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputClickHouse) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputClickHouse) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputClickHouse) GetURL() string {
	if o == nil {
		return ""
	}
	return o.URL
}

func (o *OutputClickHouse) GetAuthType() *AuthenticationTypeClickHouse {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputClickHouse) GetDatabase() string {
	if o == nil {
		return ""
	}
	return o.Database
}

func (o *OutputClickHouse) GetTableName() string {
	if o == nil {
		return ""
	}
	return o.TableName
}

func (o *OutputClickHouse) GetFormat() *FormatClickHouse {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputClickHouse) GetMappingType() *MappingType {
	if o == nil {
		return nil
	}
	return o.MappingType
}

func (o *OutputClickHouse) GetAsyncInserts() *bool {
	if o == nil {
		return nil
	}
	return o.AsyncInserts
}

func (o *OutputClickHouse) GetTLS() *components.TLSSettingsClientSideType1 {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputClickHouse) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputClickHouse) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputClickHouse) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputClickHouse) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputClickHouse) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputClickHouse) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputClickHouse) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputClickHouse) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputClickHouse) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputClickHouse) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputClickHouse) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputClickHouse) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputClickHouse) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputClickHouse) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputClickHouse) GetDumpFormatErrorsToDisk() *bool {
	if o == nil {
		return nil
	}
	return o.DumpFormatErrorsToDisk
}

func (o *OutputClickHouse) GetStatsDestination() *StatsDestination {
	if o == nil {
		return nil
	}
	return o.StatsDestination
}

func (o *OutputClickHouse) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputClickHouse) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputClickHouse) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *OutputClickHouse) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *OutputClickHouse) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputClickHouse) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *OutputClickHouse) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputClickHouse) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *OutputClickHouse) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *OutputClickHouse) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *OutputClickHouse) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *OutputClickHouse) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *OutputClickHouse) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *OutputClickHouse) GetOauthParams() []components.ItemsTypeOauthParams {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *OutputClickHouse) GetOauthHeaders() []components.ItemsTypeOauthHeaders {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

func (o *OutputClickHouse) GetSQLUsername() *string {
	if o == nil {
		return nil
	}
	return o.SQLUsername
}

func (o *OutputClickHouse) GetWaitForAsyncInserts() *bool {
	if o == nil {
		return nil
	}
	return o.WaitForAsyncInserts
}

func (o *OutputClickHouse) GetExcludeMappingFields() []string {
	if o == nil {
		return nil
	}
	return o.ExcludeMappingFields
}

func (o *OutputClickHouse) GetDescribeTable() *string {
	if o == nil {
		return nil
	}
	return o.DescribeTable
}

func (o *OutputClickHouse) GetColumnMappings() []ColumnMapping {
	if o == nil {
		return nil
	}
	return o.ColumnMappings
}

func (o *OutputClickHouse) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputClickHouse) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputClickHouse) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputClickHouse) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputClickHouse) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputClickHouse) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputClickHouse) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputClickHouse) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputClickHouse) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputClickHouse) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputClickHouse) GetPqControls() *PqControlsClickHouse {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type TypeDiskSpool string

const (
	TypeDiskSpoolDiskSpool TypeDiskSpool = "disk_spool"
)

func (e TypeDiskSpool) ToPointer() *TypeDiskSpool {
	return &e
}
func (e *TypeDiskSpool) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "disk_spool":
		*e = TypeDiskSpool(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeDiskSpool: %v", v)
	}
}

type OutputDiskSpool struct {
	// Unique ID for this output
	ID   string        `json:"id"`
	Type TypeDiskSpool `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Time period for grouping spooled events. Default is 10m.
	TimeWindow *string `json:"timeWindow,omitempty"`
	// Maximum disk space that can be consumed before older buckets are deleted. Examples: 420MB, 4GB. Default is 1GB.
	MaxDataSize *string `json:"maxDataSize,omitempty"`
	// Maximum amount of time to retain data before older buckets are deleted. Examples: 2h, 4d. Default is 24h.
	MaxDataTime *string `json:"maxDataTime,omitempty"`
	// Data compression format. Default is gzip.
	Compress *components.CompressionOptionsPersistence `json:"compress,omitempty"`
	// JavaScript expression defining how files are partitioned and organized within the time-buckets. If blank, the event's __partition property is used and otherwise, events go directly into the time-bucket directory.
	PartitionExpr *string `json:"partitionExpr,omitempty"`
	Description   *string `json:"description,omitempty"`
}

func (o OutputDiskSpool) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDiskSpool) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputDiskSpool) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputDiskSpool) GetType() TypeDiskSpool {
	if o == nil {
		return TypeDiskSpool("")
	}
	return o.Type
}

func (o *OutputDiskSpool) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputDiskSpool) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputDiskSpool) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputDiskSpool) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputDiskSpool) GetTimeWindow() *string {
	if o == nil {
		return nil
	}
	return o.TimeWindow
}

func (o *OutputDiskSpool) GetMaxDataSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataSize
}

func (o *OutputDiskSpool) GetMaxDataTime() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataTime
}

func (o *OutputDiskSpool) GetCompress() *components.CompressionOptionsPersistence {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputDiskSpool) GetPartitionExpr() *string {
	if o == nil {
		return nil
	}
	return o.PartitionExpr
}

func (o *OutputDiskSpool) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type TypeCriblLake string

const (
	TypeCriblLakeCriblLake TypeCriblLake = "cribl_lake"
)

func (e TypeCriblLake) ToPointer() *TypeCriblLake {
	return &e
}
func (e *TypeCriblLake) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_lake":
		*e = TypeCriblLake(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCriblLake: %v", v)
	}
}

type OutputCriblLake struct {
	// Unique ID for this output
	ID   string        `json:"id"`
	Type TypeCriblLake `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
	Bucket *string `json:"bucket,omitempty"`
	// Region where the S3 bucket is located
	Region *string `json:"region,omitempty"`
	// Secret key. This value can be a constant or a JavaScript expression. Example: `${C.env.SOME_SECRET}`)
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *components.SignatureVersionOptionsS3CollectorConf `json:"signatureVersion,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `json:"enableAssumeRole,omitempty"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitempty"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
	StagePath *string `json:"stagePath,omitempty"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Lake dataset to send the data to.
	DestPath *string `json:"destPath,omitempty"`
	// Object ACL to assign to uploaded objects
	ObjectACL *components.ObjectACLOptions `json:"objectACL,omitempty"`
	// Storage class to select for uploaded objects
	StorageClass         *components.StorageClassOptions                           `json:"storageClass,omitempty"`
	ServerSideEncryption *components.ServerSideEncryptionForUploadedObjectsOptions `json:"serverSideEncryption,omitempty"`
	// ID or ARN of the KMS customer-managed key to use for encryption
	KmsKeyID *string `json:"kmsKeyId,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `json:"baseFileName,omitempty"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `json:"fileNameSuffix,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `json:"maxFileSizeMB,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `json:"maxOpenFiles,omitempty"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `json:"headerLine,omitempty"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `json:"writeHighWaterMark,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `json:"deadletterEnabled,omitempty"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *components.DiskSpaceProtectionOptions `json:"onDiskFullBackpressure,omitempty"`
	// Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
	ForceCloseOnShutdown *bool                         `json:"forceCloseOnShutdown,omitempty"`
	RetrySettings        *components.RetrySettingsType `json:"retrySettings,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `json:"maxFileIdleTimeSec,omitempty"`
	// Disable if you can access files within the bucket but not the bucket itself
	VerifyPermissions *bool `json:"verifyPermissions,omitempty"`
	// Maximum number of files that can be waiting for upload before backpressure is applied
	MaxClosingFilesToBackpressure *float64                                  `json:"maxClosingFilesToBackpressure,omitempty"`
	AwsAuthenticationMethod       *components.MethodOptionsCredentials      `json:"awsAuthenticationMethod,omitempty"`
	Format                        *components.FormatOptionsCriblLakeDataset `json:"format,omitempty"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *float64 `json:"maxConcurrentFileParts,omitempty"`
	Description            *string  `json:"description,omitempty"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `json:"emptyDirCleanupSec,omitempty"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `json:"directoryBatchSize,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `json:"deadletterPath,omitempty"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `json:"maxRetryNum,omitempty"`
}

func (o OutputCriblLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCriblLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputCriblLake) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputCriblLake) GetType() TypeCriblLake {
	if o == nil {
		return TypeCriblLake("")
	}
	return o.Type
}

func (o *OutputCriblLake) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputCriblLake) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputCriblLake) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputCriblLake) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputCriblLake) GetBucket() *string {
	if o == nil {
		return nil
	}
	return o.Bucket
}

func (o *OutputCriblLake) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *OutputCriblLake) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputCriblLake) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputCriblLake) GetSignatureVersion() *components.SignatureVersionOptionsS3CollectorConf {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputCriblLake) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputCriblLake) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputCriblLake) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *OutputCriblLake) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *OutputCriblLake) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *OutputCriblLake) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *OutputCriblLake) GetStagePath() *string {
	if o == nil {
		return nil
	}
	return o.StagePath
}

func (o *OutputCriblLake) GetAddIDToStagePath() *bool {
	if o == nil {
		return nil
	}
	return o.AddIDToStagePath
}

func (o *OutputCriblLake) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

func (o *OutputCriblLake) GetObjectACL() *components.ObjectACLOptions {
	if o == nil {
		return nil
	}
	return o.ObjectACL
}

func (o *OutputCriblLake) GetStorageClass() *components.StorageClassOptions {
	if o == nil {
		return nil
	}
	return o.StorageClass
}

func (o *OutputCriblLake) GetServerSideEncryption() *components.ServerSideEncryptionForUploadedObjectsOptions {
	if o == nil {
		return nil
	}
	return o.ServerSideEncryption
}

func (o *OutputCriblLake) GetKmsKeyID() *string {
	if o == nil {
		return nil
	}
	return o.KmsKeyID
}

func (o *OutputCriblLake) GetRemoveEmptyDirs() *bool {
	if o == nil {
		return nil
	}
	return o.RemoveEmptyDirs
}

func (o *OutputCriblLake) GetBaseFileName() *string {
	if o == nil {
		return nil
	}
	return o.BaseFileName
}

func (o *OutputCriblLake) GetFileNameSuffix() *string {
	if o == nil {
		return nil
	}
	return o.FileNameSuffix
}

func (o *OutputCriblLake) GetMaxFileSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileSizeMB
}

func (o *OutputCriblLake) GetMaxOpenFiles() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxOpenFiles
}

func (o *OutputCriblLake) GetHeaderLine() *string {
	if o == nil {
		return nil
	}
	return o.HeaderLine
}

func (o *OutputCriblLake) GetWriteHighWaterMark() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteHighWaterMark
}

func (o *OutputCriblLake) GetOnBackpressure() *components.BackpressureBehaviorOptions1 {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputCriblLake) GetDeadletterEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.DeadletterEnabled
}

func (o *OutputCriblLake) GetOnDiskFullBackpressure() *components.DiskSpaceProtectionOptions {
	if o == nil {
		return nil
	}
	return o.OnDiskFullBackpressure
}

func (o *OutputCriblLake) GetForceCloseOnShutdown() *bool {
	if o == nil {
		return nil
	}
	return o.ForceCloseOnShutdown
}

func (o *OutputCriblLake) GetRetrySettings() *components.RetrySettingsType {
	if o == nil {
		return nil
	}
	return o.RetrySettings
}

func (o *OutputCriblLake) GetMaxFileOpenTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileOpenTimeSec
}

func (o *OutputCriblLake) GetMaxFileIdleTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileIdleTimeSec
}

func (o *OutputCriblLake) GetVerifyPermissions() *bool {
	if o == nil {
		return nil
	}
	return o.VerifyPermissions
}

func (o *OutputCriblLake) GetMaxClosingFilesToBackpressure() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxClosingFilesToBackpressure
}

func (o *OutputCriblLake) GetAwsAuthenticationMethod() *components.MethodOptionsCredentials {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputCriblLake) GetFormat() *components.FormatOptionsCriblLakeDataset {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputCriblLake) GetMaxConcurrentFileParts() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentFileParts
}

func (o *OutputCriblLake) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputCriblLake) GetEmptyDirCleanupSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EmptyDirCleanupSec
}

func (o *OutputCriblLake) GetDirectoryBatchSize() *float64 {
	if o == nil {
		return nil
	}
	return o.DirectoryBatchSize
}

func (o *OutputCriblLake) GetDeadletterPath() *string {
	if o == nil {
		return nil
	}
	return o.DeadletterPath
}

func (o *OutputCriblLake) GetMaxRetryNum() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetryNum
}

type CreateOutputTypeSecurityLake string

const (
	CreateOutputTypeSecurityLakeSecurityLake CreateOutputTypeSecurityLake = "security_lake"
)

func (e CreateOutputTypeSecurityLake) ToPointer() *CreateOutputTypeSecurityLake {
	return &e
}
func (e *CreateOutputTypeSecurityLake) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "security_lake":
		*e = CreateOutputTypeSecurityLake(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeSecurityLake: %v", v)
	}
}

// SignatureVersionSecurityLake - Signature version to use for signing Amazon Security Lake requests
type SignatureVersionSecurityLake string

const (
	SignatureVersionSecurityLakeV2 SignatureVersionSecurityLake = "v2"
	SignatureVersionSecurityLakeV4 SignatureVersionSecurityLake = "v4"
)

func (e SignatureVersionSecurityLake) ToPointer() *SignatureVersionSecurityLake {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *SignatureVersionSecurityLake) IsExact() bool {
	if e != nil {
		switch *e {
		case "v2", "v4":
			return true
		}
	}
	return false
}

type OutputSecurityLake struct {
	// Unique ID for this output
	ID   string                       `json:"id"`
	Type CreateOutputTypeSecurityLake `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions and labels to generated metrics and logs, respectively.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
	Bucket string `json:"bucket"`
	// Region where the Amazon Security Lake is located.
	Region       string  `json:"region"`
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitempty"`
	// Amazon Security Lake service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to Amazon Security Lake-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing Amazon Security Lake requests
	SignatureVersion *SignatureVersionSecurityLake `json:"signatureVersion,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `json:"enableAssumeRole,omitempty"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn string `json:"assumeRoleArn"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitempty"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
	StagePath string `json:"stagePath"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Object ACL to assign to uploaded objects
	ObjectACL *components.ObjectACLOptions `json:"objectACL,omitempty"`
	// Storage class to select for uploaded objects
	StorageClass         *components.StorageClassOptions                           `json:"storageClass,omitempty"`
	ServerSideEncryption *components.ServerSideEncryptionForUploadedObjectsOptions `json:"serverSideEncryption,omitempty"`
	// ID or ARN of the KMS customer-managed key to use for encryption
	KmsKeyID *string `json:"kmsKeyId,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `json:"baseFileName,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `json:"maxFileSizeMB,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `json:"maxOpenFiles,omitempty"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `json:"headerLine,omitempty"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `json:"writeHighWaterMark,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `json:"deadletterEnabled,omitempty"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *components.DiskSpaceProtectionOptions `json:"onDiskFullBackpressure,omitempty"`
	// Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
	ForceCloseOnShutdown *bool                         `json:"forceCloseOnShutdown,omitempty"`
	RetrySettings        *components.RetrySettingsType `json:"retrySettings,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *float64 `json:"maxConcurrentFileParts,omitempty"`
	// Disable if you can access files within the bucket but not the bucket itself
	VerifyPermissions *bool `json:"verifyPermissions,omitempty"`
	// Maximum number of files that can be waiting for upload before backpressure is applied
	MaxClosingFilesToBackpressure *float64 `json:"maxClosingFilesToBackpressure,omitempty"`
	// ID of the AWS account whose data the Destination will write to Security Lake. This should have been configured when creating the Amazon Security Lake custom source.
	AccountID string `json:"accountId"`
	// Name of the custom source configured in Amazon Security Lake
	CustomSource string `json:"customSource"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `json:"automaticSchema,omitempty"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *components.ParquetVersionOptions `json:"parquetVersion,omitempty"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *components.DataPageVersionOptions `json:"parquetDataPageVersion,omitempty"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `json:"parquetRowGroupLength,omitempty"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
	KeyValueMetadata []components.ItemsTypeKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `json:"enableStatistics,omitempty"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `json:"enableWritePageIndex,omitempty"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool   `json:"enablePageChecksum,omitempty"`
	Description        *string `json:"description,omitempty"`
	// This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `json:"emptyDirCleanupSec,omitempty"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `json:"directoryBatchSize,omitempty"`
	// To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
	ParquetSchema *string `json:"parquetSchema,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `json:"deadletterPath,omitempty"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `json:"maxRetryNum,omitempty"`
}

func (o OutputSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputSecurityLake) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputSecurityLake) GetType() CreateOutputTypeSecurityLake {
	if o == nil {
		return CreateOutputTypeSecurityLake("")
	}
	return o.Type
}

func (o *OutputSecurityLake) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputSecurityLake) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputSecurityLake) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputSecurityLake) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputSecurityLake) GetBucket() string {
	if o == nil {
		return ""
	}
	return o.Bucket
}

func (o *OutputSecurityLake) GetRegion() string {
	if o == nil {
		return ""
	}
	return o.Region
}

func (o *OutputSecurityLake) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputSecurityLake) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputSecurityLake) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputSecurityLake) GetSignatureVersion() *SignatureVersionSecurityLake {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputSecurityLake) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputSecurityLake) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputSecurityLake) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *OutputSecurityLake) GetAssumeRoleArn() string {
	if o == nil {
		return ""
	}
	return o.AssumeRoleArn
}

func (o *OutputSecurityLake) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *OutputSecurityLake) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *OutputSecurityLake) GetStagePath() string {
	if o == nil {
		return ""
	}
	return o.StagePath
}

func (o *OutputSecurityLake) GetAddIDToStagePath() *bool {
	if o == nil {
		return nil
	}
	return o.AddIDToStagePath
}

func (o *OutputSecurityLake) GetObjectACL() *components.ObjectACLOptions {
	if o == nil {
		return nil
	}
	return o.ObjectACL
}

func (o *OutputSecurityLake) GetStorageClass() *components.StorageClassOptions {
	if o == nil {
		return nil
	}
	return o.StorageClass
}

func (o *OutputSecurityLake) GetServerSideEncryption() *components.ServerSideEncryptionForUploadedObjectsOptions {
	if o == nil {
		return nil
	}
	return o.ServerSideEncryption
}

func (o *OutputSecurityLake) GetKmsKeyID() *string {
	if o == nil {
		return nil
	}
	return o.KmsKeyID
}

func (o *OutputSecurityLake) GetRemoveEmptyDirs() *bool {
	if o == nil {
		return nil
	}
	return o.RemoveEmptyDirs
}

func (o *OutputSecurityLake) GetBaseFileName() *string {
	if o == nil {
		return nil
	}
	return o.BaseFileName
}

func (o *OutputSecurityLake) GetMaxFileSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileSizeMB
}

func (o *OutputSecurityLake) GetMaxOpenFiles() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxOpenFiles
}

func (o *OutputSecurityLake) GetHeaderLine() *string {
	if o == nil {
		return nil
	}
	return o.HeaderLine
}

func (o *OutputSecurityLake) GetWriteHighWaterMark() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteHighWaterMark
}

func (o *OutputSecurityLake) GetOnBackpressure() *components.BackpressureBehaviorOptions1 {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputSecurityLake) GetDeadletterEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.DeadletterEnabled
}

func (o *OutputSecurityLake) GetOnDiskFullBackpressure() *components.DiskSpaceProtectionOptions {
	if o == nil {
		return nil
	}
	return o.OnDiskFullBackpressure
}

func (o *OutputSecurityLake) GetForceCloseOnShutdown() *bool {
	if o == nil {
		return nil
	}
	return o.ForceCloseOnShutdown
}

func (o *OutputSecurityLake) GetRetrySettings() *components.RetrySettingsType {
	if o == nil {
		return nil
	}
	return o.RetrySettings
}

func (o *OutputSecurityLake) GetMaxFileOpenTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileOpenTimeSec
}

func (o *OutputSecurityLake) GetMaxFileIdleTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileIdleTimeSec
}

func (o *OutputSecurityLake) GetMaxConcurrentFileParts() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentFileParts
}

func (o *OutputSecurityLake) GetVerifyPermissions() *bool {
	if o == nil {
		return nil
	}
	return o.VerifyPermissions
}

func (o *OutputSecurityLake) GetMaxClosingFilesToBackpressure() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxClosingFilesToBackpressure
}

func (o *OutputSecurityLake) GetAccountID() string {
	if o == nil {
		return ""
	}
	return o.AccountID
}

func (o *OutputSecurityLake) GetCustomSource() string {
	if o == nil {
		return ""
	}
	return o.CustomSource
}

func (o *OutputSecurityLake) GetAutomaticSchema() *bool {
	if o == nil {
		return nil
	}
	return o.AutomaticSchema
}

func (o *OutputSecurityLake) GetParquetVersion() *components.ParquetVersionOptions {
	if o == nil {
		return nil
	}
	return o.ParquetVersion
}

func (o *OutputSecurityLake) GetParquetDataPageVersion() *components.DataPageVersionOptions {
	if o == nil {
		return nil
	}
	return o.ParquetDataPageVersion
}

func (o *OutputSecurityLake) GetParquetRowGroupLength() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetRowGroupLength
}

func (o *OutputSecurityLake) GetParquetPageSize() *string {
	if o == nil {
		return nil
	}
	return o.ParquetPageSize
}

func (o *OutputSecurityLake) GetShouldLogInvalidRows() *bool {
	if o == nil {
		return nil
	}
	return o.ShouldLogInvalidRows
}

func (o *OutputSecurityLake) GetKeyValueMetadata() []components.ItemsTypeKeyValueMetadata {
	if o == nil {
		return nil
	}
	return o.KeyValueMetadata
}

func (o *OutputSecurityLake) GetEnableStatistics() *bool {
	if o == nil {
		return nil
	}
	return o.EnableStatistics
}

func (o *OutputSecurityLake) GetEnableWritePageIndex() *bool {
	if o == nil {
		return nil
	}
	return o.EnableWritePageIndex
}

func (o *OutputSecurityLake) GetEnablePageChecksum() *bool {
	if o == nil {
		return nil
	}
	return o.EnablePageChecksum
}

func (o *OutputSecurityLake) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputSecurityLake) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputSecurityLake) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *OutputSecurityLake) GetEmptyDirCleanupSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EmptyDirCleanupSec
}

func (o *OutputSecurityLake) GetDirectoryBatchSize() *float64 {
	if o == nil {
		return nil
	}
	return o.DirectoryBatchSize
}

func (o *OutputSecurityLake) GetParquetSchema() *string {
	if o == nil {
		return nil
	}
	return o.ParquetSchema
}

func (o *OutputSecurityLake) GetDeadletterPath() *string {
	if o == nil {
		return nil
	}
	return o.DeadletterPath
}

func (o *OutputSecurityLake) GetMaxRetryNum() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetryNum
}

type TypeDlS3 string

const (
	TypeDlS3DlS3 TypeDlS3 = "dl_s3"
)

func (e TypeDlS3) ToPointer() *TypeDlS3 {
	return &e
}
func (e *TypeDlS3) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "dl_s3":
		*e = TypeDlS3(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeDlS3: %v", v)
	}
}

type OutputDlS3 struct {
	// Unique ID for this output
	ID   string   `json:"id"`
	Type TypeDlS3 `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
	Bucket string `json:"bucket"`
	// Region where the S3 bucket is located
	Region *string `json:"region,omitempty"`
	// Secret key. This value can be a constant or a JavaScript expression. Example: `${C.env.SOME_SECRET}`)
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *components.SignatureVersionOptionsS3CollectorConf `json:"signatureVersion,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `json:"enableAssumeRole,omitempty"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitempty"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
	StagePath string `json:"stagePath"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Prefix to prepend to files before uploading. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `myKeyPrefix-${C.vars.myVar}`
	DestPath *string `json:"destPath,omitempty"`
	// Object ACL to assign to uploaded objects
	ObjectACL *components.ObjectACLOptions `json:"objectACL,omitempty"`
	// Storage class to select for uploaded objects
	StorageClass         *components.StorageClassOptions                           `json:"storageClass,omitempty"`
	ServerSideEncryption *components.ServerSideEncryptionForUploadedObjectsOptions `json:"serverSideEncryption,omitempty"`
	// ID or ARN of the KMS customer-managed key to use for encryption
	KmsKeyID *string `json:"kmsKeyId,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// Format of the output data
	Format *components.DataFormatOptions `json:"format,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `json:"baseFileName,omitempty"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `json:"fileNameSuffix,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `json:"maxFileSizeMB,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `json:"maxOpenFiles,omitempty"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `json:"headerLine,omitempty"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `json:"writeHighWaterMark,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `json:"deadletterEnabled,omitempty"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *components.DiskSpaceProtectionOptions `json:"onDiskFullBackpressure,omitempty"`
	// Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
	ForceCloseOnShutdown *bool                         `json:"forceCloseOnShutdown,omitempty"`
	RetrySettings        *components.RetrySettingsType `json:"retrySettings,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *float64 `json:"maxConcurrentFileParts,omitempty"`
	// Disable if you can access files within the bucket but not the bucket itself
	VerifyPermissions *bool `json:"verifyPermissions,omitempty"`
	// Maximum number of files that can be waiting for upload before backpressure is applied
	MaxClosingFilesToBackpressure *float64 `json:"maxClosingFilesToBackpressure,omitempty"`
	// List of fields to partition the path by, in addition to time, which is included automatically. The effective partition will be YYYY/MM/DD/HH/<list/of/fields>.
	PartitioningFields []string `json:"partitioningFields,omitempty"`
	Description        *string  `json:"description,omitempty"`
	// This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Data compression format to apply to HTTP content before it is delivered
	Compress *components.CompressionOptions2 `json:"compress,omitempty"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *components.CompressionLevelOptions `json:"compressionLevel,omitempty"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `json:"automaticSchema,omitempty"`
	// To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
	ParquetSchema *string `json:"parquetSchema,omitempty"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *components.ParquetVersionOptions `json:"parquetVersion,omitempty"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *components.DataPageVersionOptions `json:"parquetDataPageVersion,omitempty"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `json:"parquetRowGroupLength,omitempty"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
	KeyValueMetadata []components.ItemsTypeKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `json:"enableStatistics,omitempty"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `json:"enableWritePageIndex,omitempty"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `json:"enablePageChecksum,omitempty"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `json:"emptyDirCleanupSec,omitempty"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `json:"directoryBatchSize,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `json:"deadletterPath,omitempty"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `json:"maxRetryNum,omitempty"`
}

func (o OutputDlS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDlS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputDlS3) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputDlS3) GetType() TypeDlS3 {
	if o == nil {
		return TypeDlS3("")
	}
	return o.Type
}

func (o *OutputDlS3) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputDlS3) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputDlS3) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputDlS3) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputDlS3) GetBucket() string {
	if o == nil {
		return ""
	}
	return o.Bucket
}

func (o *OutputDlS3) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *OutputDlS3) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputDlS3) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputDlS3) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputDlS3) GetSignatureVersion() *components.SignatureVersionOptionsS3CollectorConf {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputDlS3) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputDlS3) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputDlS3) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *OutputDlS3) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *OutputDlS3) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *OutputDlS3) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *OutputDlS3) GetStagePath() string {
	if o == nil {
		return ""
	}
	return o.StagePath
}

func (o *OutputDlS3) GetAddIDToStagePath() *bool {
	if o == nil {
		return nil
	}
	return o.AddIDToStagePath
}

func (o *OutputDlS3) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

func (o *OutputDlS3) GetObjectACL() *components.ObjectACLOptions {
	if o == nil {
		return nil
	}
	return o.ObjectACL
}

func (o *OutputDlS3) GetStorageClass() *components.StorageClassOptions {
	if o == nil {
		return nil
	}
	return o.StorageClass
}

func (o *OutputDlS3) GetServerSideEncryption() *components.ServerSideEncryptionForUploadedObjectsOptions {
	if o == nil {
		return nil
	}
	return o.ServerSideEncryption
}

func (o *OutputDlS3) GetKmsKeyID() *string {
	if o == nil {
		return nil
	}
	return o.KmsKeyID
}

func (o *OutputDlS3) GetRemoveEmptyDirs() *bool {
	if o == nil {
		return nil
	}
	return o.RemoveEmptyDirs
}

func (o *OutputDlS3) GetFormat() *components.DataFormatOptions {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputDlS3) GetBaseFileName() *string {
	if o == nil {
		return nil
	}
	return o.BaseFileName
}

func (o *OutputDlS3) GetFileNameSuffix() *string {
	if o == nil {
		return nil
	}
	return o.FileNameSuffix
}

func (o *OutputDlS3) GetMaxFileSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileSizeMB
}

func (o *OutputDlS3) GetMaxOpenFiles() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxOpenFiles
}

func (o *OutputDlS3) GetHeaderLine() *string {
	if o == nil {
		return nil
	}
	return o.HeaderLine
}

func (o *OutputDlS3) GetWriteHighWaterMark() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteHighWaterMark
}

func (o *OutputDlS3) GetOnBackpressure() *components.BackpressureBehaviorOptions1 {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputDlS3) GetDeadletterEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.DeadletterEnabled
}

func (o *OutputDlS3) GetOnDiskFullBackpressure() *components.DiskSpaceProtectionOptions {
	if o == nil {
		return nil
	}
	return o.OnDiskFullBackpressure
}

func (o *OutputDlS3) GetForceCloseOnShutdown() *bool {
	if o == nil {
		return nil
	}
	return o.ForceCloseOnShutdown
}

func (o *OutputDlS3) GetRetrySettings() *components.RetrySettingsType {
	if o == nil {
		return nil
	}
	return o.RetrySettings
}

func (o *OutputDlS3) GetMaxFileOpenTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileOpenTimeSec
}

func (o *OutputDlS3) GetMaxFileIdleTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileIdleTimeSec
}

func (o *OutputDlS3) GetMaxConcurrentFileParts() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentFileParts
}

func (o *OutputDlS3) GetVerifyPermissions() *bool {
	if o == nil {
		return nil
	}
	return o.VerifyPermissions
}

func (o *OutputDlS3) GetMaxClosingFilesToBackpressure() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxClosingFilesToBackpressure
}

func (o *OutputDlS3) GetPartitioningFields() []string {
	if o == nil {
		return nil
	}
	return o.PartitioningFields
}

func (o *OutputDlS3) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputDlS3) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputDlS3) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *OutputDlS3) GetCompress() *components.CompressionOptions2 {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputDlS3) GetCompressionLevel() *components.CompressionLevelOptions {
	if o == nil {
		return nil
	}
	return o.CompressionLevel
}

func (o *OutputDlS3) GetAutomaticSchema() *bool {
	if o == nil {
		return nil
	}
	return o.AutomaticSchema
}

func (o *OutputDlS3) GetParquetSchema() *string {
	if o == nil {
		return nil
	}
	return o.ParquetSchema
}

func (o *OutputDlS3) GetParquetVersion() *components.ParquetVersionOptions {
	if o == nil {
		return nil
	}
	return o.ParquetVersion
}

func (o *OutputDlS3) GetParquetDataPageVersion() *components.DataPageVersionOptions {
	if o == nil {
		return nil
	}
	return o.ParquetDataPageVersion
}

func (o *OutputDlS3) GetParquetRowGroupLength() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetRowGroupLength
}

func (o *OutputDlS3) GetParquetPageSize() *string {
	if o == nil {
		return nil
	}
	return o.ParquetPageSize
}

func (o *OutputDlS3) GetShouldLogInvalidRows() *bool {
	if o == nil {
		return nil
	}
	return o.ShouldLogInvalidRows
}

func (o *OutputDlS3) GetKeyValueMetadata() []components.ItemsTypeKeyValueMetadata {
	if o == nil {
		return nil
	}
	return o.KeyValueMetadata
}

func (o *OutputDlS3) GetEnableStatistics() *bool {
	if o == nil {
		return nil
	}
	return o.EnableStatistics
}

func (o *OutputDlS3) GetEnableWritePageIndex() *bool {
	if o == nil {
		return nil
	}
	return o.EnableWritePageIndex
}

func (o *OutputDlS3) GetEnablePageChecksum() *bool {
	if o == nil {
		return nil
	}
	return o.EnablePageChecksum
}

func (o *OutputDlS3) GetEmptyDirCleanupSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EmptyDirCleanupSec
}

func (o *OutputDlS3) GetDirectoryBatchSize() *float64 {
	if o == nil {
		return nil
	}
	return o.DirectoryBatchSize
}

func (o *OutputDlS3) GetDeadletterPath() *string {
	if o == nil {
		return nil
	}
	return o.DeadletterPath
}

func (o *OutputDlS3) GetMaxRetryNum() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetryNum
}

type TypeCrowdstrikeNextGenSiem string

const (
	TypeCrowdstrikeNextGenSiemCrowdstrikeNextGenSiem TypeCrowdstrikeNextGenSiem = "crowdstrike_next_gen_siem"
)

func (e TypeCrowdstrikeNextGenSiem) ToPointer() *TypeCrowdstrikeNextGenSiem {
	return &e
}
func (e *TypeCrowdstrikeNextGenSiem) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "crowdstrike_next_gen_siem":
		*e = TypeCrowdstrikeNextGenSiem(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCrowdstrikeNextGenSiem: %v", v)
	}
}

type PqControlsCrowdstrikeNextGenSiem struct {
}

func (p PqControlsCrowdstrikeNextGenSiem) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsCrowdstrikeNextGenSiem) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputCrowdstrikeNextGenSiem struct {
	// Unique ID for this output
	ID   string                     `json:"id"`
	Type TypeCrowdstrikeNextGenSiem `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// URL provided from a CrowdStrike data connector.
	// Example: https://ingest.<region>.crowdstrike.com/api/ingest/hec/<connection-id>/v1/services/collector
	URL string `json:"url"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// When set to JSON, the event is automatically formatted with required fields before sending. When set to Raw, only the event's `_raw` value is sent.
	Format components.RequestFormatOptions `json:"format"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	Token          *string                                 `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsCrowdstrikeNextGenSiem    `json:"pqControls,omitempty"`
}

func (o OutputCrowdstrikeNextGenSiem) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCrowdstrikeNextGenSiem) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputCrowdstrikeNextGenSiem) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputCrowdstrikeNextGenSiem) GetType() TypeCrowdstrikeNextGenSiem {
	if o == nil {
		return TypeCrowdstrikeNextGenSiem("")
	}
	return o.Type
}

func (o *OutputCrowdstrikeNextGenSiem) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputCrowdstrikeNextGenSiem) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputCrowdstrikeNextGenSiem) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputCrowdstrikeNextGenSiem) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputCrowdstrikeNextGenSiem) GetURL() string {
	if o == nil {
		return ""
	}
	return o.URL
}

func (o *OutputCrowdstrikeNextGenSiem) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputCrowdstrikeNextGenSiem) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputCrowdstrikeNextGenSiem) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputCrowdstrikeNextGenSiem) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputCrowdstrikeNextGenSiem) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputCrowdstrikeNextGenSiem) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputCrowdstrikeNextGenSiem) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputCrowdstrikeNextGenSiem) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputCrowdstrikeNextGenSiem) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputCrowdstrikeNextGenSiem) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputCrowdstrikeNextGenSiem) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputCrowdstrikeNextGenSiem) GetFormat() components.RequestFormatOptions {
	if o == nil {
		return components.RequestFormatOptions("")
	}
	return o.Format
}

func (o *OutputCrowdstrikeNextGenSiem) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputCrowdstrikeNextGenSiem) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputCrowdstrikeNextGenSiem) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputCrowdstrikeNextGenSiem) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputCrowdstrikeNextGenSiem) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputCrowdstrikeNextGenSiem) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputCrowdstrikeNextGenSiem) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputCrowdstrikeNextGenSiem) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputCrowdstrikeNextGenSiem) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputCrowdstrikeNextGenSiem) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputCrowdstrikeNextGenSiem) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputCrowdstrikeNextGenSiem) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputCrowdstrikeNextGenSiem) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputCrowdstrikeNextGenSiem) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputCrowdstrikeNextGenSiem) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputCrowdstrikeNextGenSiem) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputCrowdstrikeNextGenSiem) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputCrowdstrikeNextGenSiem) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputCrowdstrikeNextGenSiem) GetPqControls() *PqControlsCrowdstrikeNextGenSiem {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type TypeHumioHec string

const (
	TypeHumioHecHumioHec TypeHumioHec = "humio_hec"
)

func (e TypeHumioHec) ToPointer() *TypeHumioHec {
	return &e
}
func (e *TypeHumioHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "humio_hec":
		*e = TypeHumioHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeHumioHec: %v", v)
	}
}

type PqControlsHumioHec struct {
}

func (p PqControlsHumioHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsHumioHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputHumioHec struct {
	// Unique ID for this output
	ID   string       `json:"id"`
	Type TypeHumioHec `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// URL to a CrowdStrike Falcon LogScale endpoint to send events to. Examples: https://cloud.us.humio.com/api/v1/ingest/hec for JSON and https://cloud.us.humio.com/api/v1/ingest/hec/raw for raw
	URL string `json:"url"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// When set to JSON, the event is automatically formatted with required fields before sending. When set to Raw, only the event's `_raw` value is sent.
	Format components.RequestFormatOptions `json:"format"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// CrowdStrike Falcon LogScale authentication token
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsHumioHec                  `json:"pqControls,omitempty"`
}

func (o OutputHumioHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputHumioHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputHumioHec) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputHumioHec) GetType() TypeHumioHec {
	if o == nil {
		return TypeHumioHec("")
	}
	return o.Type
}

func (o *OutputHumioHec) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputHumioHec) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputHumioHec) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputHumioHec) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputHumioHec) GetURL() string {
	if o == nil {
		return ""
	}
	return o.URL
}

func (o *OutputHumioHec) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputHumioHec) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputHumioHec) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputHumioHec) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputHumioHec) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputHumioHec) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputHumioHec) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputHumioHec) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputHumioHec) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputHumioHec) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputHumioHec) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputHumioHec) GetFormat() components.RequestFormatOptions {
	if o == nil {
		return components.RequestFormatOptions("")
	}
	return o.Format
}

func (o *OutputHumioHec) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputHumioHec) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputHumioHec) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputHumioHec) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputHumioHec) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputHumioHec) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputHumioHec) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputHumioHec) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputHumioHec) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputHumioHec) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputHumioHec) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputHumioHec) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputHumioHec) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputHumioHec) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputHumioHec) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputHumioHec) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputHumioHec) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputHumioHec) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputHumioHec) GetPqControls() *PqControlsHumioHec {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type TypeCriblSearchEngine string

const (
	TypeCriblSearchEngineCriblSearchEngine TypeCriblSearchEngine = "cribl_search_engine"
)

func (e TypeCriblSearchEngine) ToPointer() *TypeCriblSearchEngine {
	return &e
}
func (e *TypeCriblSearchEngine) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_search_engine":
		*e = TypeCriblSearchEngine(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCriblSearchEngine: %v", v)
	}
}

type PqControlsCriblSearchEngine struct {
}

func (p PqControlsCriblSearchEngine) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsCriblSearchEngine) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputCriblSearchEngine struct {
	// Unique ID for this output
	ID   string                `json:"id"`
	Type TypeCriblSearchEngine `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// For optimal performance, enable load balancing even if you have one hostname, as it can expand to multiple IPs. If this setting is disabled, consider enabling round-robin DNS.
	LoadBalanced *bool                                                    `json:"loadBalanced,omitempty"`
	TLS          *components.TLSSettingsClientSideTypeKafkaSchemaRegistry `json:"tls,omitempty"`
	// The number of minutes before the internally generated authentication token expires. Valid values are between 1 and 60.
	TokenTTLMinutes *float64 `json:"tokenTTLMinutes,omitempty"`
	// Fields to exclude from the event. By default, all internal fields except `__output` are sent. Example: `cribl_pipe`, `c*`. Wildcards supported.
	ExcludeFields []string `json:"excludeFields,omitempty"`
	// Codec to use to compress the data before sending
	Compression *components.CompressionOptions1 `json:"compression,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `json:"throttleRatePerSec,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// Shared secrets to be used by connected environments to authorize connections. These tokens should also be installed in Cribl HTTP Source in Cribl.Cloud.
	AuthTokens []components.ItemsTypeAuthTokens1 `json:"authTokens,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool   `json:"useRoundRobinDns,omitempty"`
	Description      *string `json:"description,omitempty"`
	// URL of a Cribl Worker to send events to, such as http://localhost:10200
	URL *string `json:"url,omitempty"`
	// Exclude all IPs of the current host from the list of any resolved hostnames
	ExcludeSelf *bool                      `json:"excludeSelf,omitempty"`
	Urls        []components.ItemsTypeUrls `json:"urls,omitempty"`
	// The interval in which to re-resolve any hostnames and pick up destinations from A records
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	// How far back in time to keep traffic stats for load balancing purposes
	LoadBalanceStatsPeriodSec *float64 `json:"loadBalanceStatsPeriodSec,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsCriblSearchEngine         `json:"pqControls,omitempty"`
}

func (o OutputCriblSearchEngine) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCriblSearchEngine) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputCriblSearchEngine) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputCriblSearchEngine) GetType() TypeCriblSearchEngine {
	if o == nil {
		return TypeCriblSearchEngine("")
	}
	return o.Type
}

func (o *OutputCriblSearchEngine) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputCriblSearchEngine) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputCriblSearchEngine) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputCriblSearchEngine) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputCriblSearchEngine) GetLoadBalanced() *bool {
	if o == nil {
		return nil
	}
	return o.LoadBalanced
}

func (o *OutputCriblSearchEngine) GetTLS() *components.TLSSettingsClientSideTypeKafkaSchemaRegistry {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputCriblSearchEngine) GetTokenTTLMinutes() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTTLMinutes
}

func (o *OutputCriblSearchEngine) GetExcludeFields() []string {
	if o == nil {
		return nil
	}
	return o.ExcludeFields
}

func (o *OutputCriblSearchEngine) GetCompression() *components.CompressionOptions1 {
	if o == nil {
		return nil
	}
	return o.Compression
}

func (o *OutputCriblSearchEngine) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputCriblSearchEngine) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputCriblSearchEngine) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputCriblSearchEngine) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputCriblSearchEngine) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputCriblSearchEngine) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputCriblSearchEngine) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputCriblSearchEngine) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputCriblSearchEngine) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputCriblSearchEngine) GetThrottleRatePerSec() *string {
	if o == nil {
		return nil
	}
	return o.ThrottleRatePerSec
}

func (o *OutputCriblSearchEngine) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputCriblSearchEngine) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputCriblSearchEngine) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputCriblSearchEngine) GetAuthTokens() []components.ItemsTypeAuthTokens1 {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *OutputCriblSearchEngine) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputCriblSearchEngine) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputCriblSearchEngine) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputCriblSearchEngine) GetURL() *string {
	if o == nil {
		return nil
	}
	return o.URL
}

func (o *OutputCriblSearchEngine) GetExcludeSelf() *bool {
	if o == nil {
		return nil
	}
	return o.ExcludeSelf
}

func (o *OutputCriblSearchEngine) GetUrls() []components.ItemsTypeUrls {
	if o == nil {
		return nil
	}
	return o.Urls
}

func (o *OutputCriblSearchEngine) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputCriblSearchEngine) GetLoadBalanceStatsPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.LoadBalanceStatsPeriodSec
}

func (o *OutputCriblSearchEngine) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputCriblSearchEngine) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputCriblSearchEngine) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputCriblSearchEngine) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputCriblSearchEngine) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputCriblSearchEngine) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputCriblSearchEngine) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputCriblSearchEngine) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputCriblSearchEngine) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputCriblSearchEngine) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputCriblSearchEngine) GetPqControls() *PqControlsCriblSearchEngine {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type CreateOutputTypeCriblHTTP string

const (
	CreateOutputTypeCriblHTTPCriblHTTP CreateOutputTypeCriblHTTP = "cribl_http"
)

func (e CreateOutputTypeCriblHTTP) ToPointer() *CreateOutputTypeCriblHTTP {
	return &e
}
func (e *CreateOutputTypeCriblHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_http":
		*e = CreateOutputTypeCriblHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeCriblHTTP: %v", v)
	}
}

type PqControlsCriblHTTP struct {
}

func (p PqControlsCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputCriblHTTP struct {
	// Unique ID for this output
	ID   string                    `json:"id"`
	Type CreateOutputTypeCriblHTTP `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// For optimal performance, enable load balancing even if you have one hostname, as it can expand to multiple IPs. If this setting is disabled, consider enabling round-robin DNS.
	LoadBalanced *bool                                                    `json:"loadBalanced,omitempty"`
	TLS          *components.TLSSettingsClientSideTypeKafkaSchemaRegistry `json:"tls,omitempty"`
	// The number of minutes before the internally generated authentication token expires. Valid values are between 1 and 60.
	TokenTTLMinutes *float64 `json:"tokenTTLMinutes,omitempty"`
	// Fields to exclude from the event. By default, all internal fields except `__output` are sent. Example: `cribl_pipe`, `c*`. Wildcards supported.
	ExcludeFields []string `json:"excludeFields,omitempty"`
	// Codec to use to compress the data before sending
	Compression *components.CompressionOptions1 `json:"compression,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `json:"throttleRatePerSec,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// Shared secrets to be used by connected environments to authorize connections. These tokens should also be installed in Cribl HTTP Source in Cribl.Cloud.
	AuthTokens []components.ItemsTypeAuthTokens1 `json:"authTokens,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// URL of a Cribl Worker to send events to, such as http://localhost:10200
	URL *string `json:"url,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Exclude all IPs of the current host from the list of any resolved hostnames
	ExcludeSelf *bool                      `json:"excludeSelf,omitempty"`
	Urls        []components.ItemsTypeUrls `json:"urls,omitempty"`
	// The interval in which to re-resolve any hostnames and pick up destinations from A records
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	// How far back in time to keep traffic stats for load balancing purposes
	LoadBalanceStatsPeriodSec *float64 `json:"loadBalanceStatsPeriodSec,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsCriblHTTP                 `json:"pqControls,omitempty"`
}

func (o OutputCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputCriblHTTP) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputCriblHTTP) GetType() CreateOutputTypeCriblHTTP {
	if o == nil {
		return CreateOutputTypeCriblHTTP("")
	}
	return o.Type
}

func (o *OutputCriblHTTP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputCriblHTTP) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputCriblHTTP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputCriblHTTP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputCriblHTTP) GetLoadBalanced() *bool {
	if o == nil {
		return nil
	}
	return o.LoadBalanced
}

func (o *OutputCriblHTTP) GetTLS() *components.TLSSettingsClientSideTypeKafkaSchemaRegistry {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputCriblHTTP) GetTokenTTLMinutes() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTTLMinutes
}

func (o *OutputCriblHTTP) GetExcludeFields() []string {
	if o == nil {
		return nil
	}
	return o.ExcludeFields
}

func (o *OutputCriblHTTP) GetCompression() *components.CompressionOptions1 {
	if o == nil {
		return nil
	}
	return o.Compression
}

func (o *OutputCriblHTTP) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputCriblHTTP) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputCriblHTTP) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputCriblHTTP) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputCriblHTTP) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputCriblHTTP) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputCriblHTTP) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputCriblHTTP) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputCriblHTTP) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputCriblHTTP) GetThrottleRatePerSec() *string {
	if o == nil {
		return nil
	}
	return o.ThrottleRatePerSec
}

func (o *OutputCriblHTTP) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputCriblHTTP) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputCriblHTTP) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputCriblHTTP) GetAuthTokens() []components.ItemsTypeAuthTokens1 {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *OutputCriblHTTP) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputCriblHTTP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputCriblHTTP) GetURL() *string {
	if o == nil {
		return nil
	}
	return o.URL
}

func (o *OutputCriblHTTP) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputCriblHTTP) GetExcludeSelf() *bool {
	if o == nil {
		return nil
	}
	return o.ExcludeSelf
}

func (o *OutputCriblHTTP) GetUrls() []components.ItemsTypeUrls {
	if o == nil {
		return nil
	}
	return o.Urls
}

func (o *OutputCriblHTTP) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputCriblHTTP) GetLoadBalanceStatsPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.LoadBalanceStatsPeriodSec
}

func (o *OutputCriblHTTP) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputCriblHTTP) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputCriblHTTP) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputCriblHTTP) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputCriblHTTP) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputCriblHTTP) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputCriblHTTP) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputCriblHTTP) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputCriblHTTP) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputCriblHTTP) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputCriblHTTP) GetPqControls() *PqControlsCriblHTTP {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type CreateOutputTypeCriblTCP string

const (
	CreateOutputTypeCriblTCPCriblTCP CreateOutputTypeCriblTCP = "cribl_tcp"
)

func (e CreateOutputTypeCriblTCP) ToPointer() *CreateOutputTypeCriblTCP {
	return &e
}
func (e *CreateOutputTypeCriblTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_tcp":
		*e = CreateOutputTypeCriblTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeCriblTCP: %v", v)
	}
}

type PqControlsCriblTCP struct {
}

func (p PqControlsCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputCriblTCP struct {
	// Unique ID for this output
	ID   string                   `json:"id"`
	Type CreateOutputTypeCriblTCP `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Use load-balanced destinations
	LoadBalanced *bool `json:"loadBalanced,omitempty"`
	// Codec to use to compress the data before sending
	Compression *components.CompressionOptions1 `json:"compression,omitempty"`
	// Use to troubleshoot issues with sending data
	LogFailedRequests *bool `json:"logFailedRequests,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string                                                  `json:"throttleRatePerSec,omitempty"`
	TLS                *components.TLSSettingsClientSideTypeKafkaSchemaRegistry `json:"tls,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64 `json:"writeTimeout,omitempty"`
	// The number of minutes before the internally generated authentication token expires, valid values between 1 and 60
	TokenTTLMinutes *float64 `json:"tokenTTLMinutes,omitempty"`
	// Shared secrets to be used by connected environments to authorize connections. These tokens should also be installed in Cribl TCP Source in Cribl.Cloud.
	AuthTokens []components.ItemsTypeAuthTokens `json:"authTokens,omitempty"`
	// Fields to exclude from the event. By default, all internal fields except `__output` are sent. Example: `cribl_pipe`, `c*`. Wildcards supported.
	ExcludeFields []string `json:"excludeFields,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// The hostname of the receiver
	Host *string `json:"host,omitempty"`
	// The port to connect to on the provided host
	Port *float64 `json:"port,omitempty"`
	// Exclude all IPs of the current host from the list of any resolved hostnames
	ExcludeSelf *bool `json:"excludeSelf,omitempty"`
	// Set of hosts to load-balance data to
	Hosts []components.ItemsTypeHosts `json:"hosts,omitempty"`
	// The interval in which to re-resolve any hostnames and pick up destinations from A records
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	// How far back in time to keep traffic stats for load balancing purposes
	LoadBalanceStatsPeriodSec *float64 `json:"loadBalanceStatsPeriodSec,omitempty"`
	// Maximum number of concurrent connections (per Worker Process). A random set of IPs will be picked on every DNS resolution period. Use 0 for unlimited.
	MaxConcurrentSenders *float64 `json:"maxConcurrentSenders,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsCriblTCP                  `json:"pqControls,omitempty"`
}

func (o OutputCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputCriblTCP) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputCriblTCP) GetType() CreateOutputTypeCriblTCP {
	if o == nil {
		return CreateOutputTypeCriblTCP("")
	}
	return o.Type
}

func (o *OutputCriblTCP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputCriblTCP) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputCriblTCP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputCriblTCP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputCriblTCP) GetLoadBalanced() *bool {
	if o == nil {
		return nil
	}
	return o.LoadBalanced
}

func (o *OutputCriblTCP) GetCompression() *components.CompressionOptions1 {
	if o == nil {
		return nil
	}
	return o.Compression
}

func (o *OutputCriblTCP) GetLogFailedRequests() *bool {
	if o == nil {
		return nil
	}
	return o.LogFailedRequests
}

func (o *OutputCriblTCP) GetThrottleRatePerSec() *string {
	if o == nil {
		return nil
	}
	return o.ThrottleRatePerSec
}

func (o *OutputCriblTCP) GetTLS() *components.TLSSettingsClientSideTypeKafkaSchemaRegistry {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputCriblTCP) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputCriblTCP) GetWriteTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteTimeout
}

func (o *OutputCriblTCP) GetTokenTTLMinutes() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTTLMinutes
}

func (o *OutputCriblTCP) GetAuthTokens() []components.ItemsTypeAuthTokens {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *OutputCriblTCP) GetExcludeFields() []string {
	if o == nil {
		return nil
	}
	return o.ExcludeFields
}

func (o *OutputCriblTCP) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputCriblTCP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputCriblTCP) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *OutputCriblTCP) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *OutputCriblTCP) GetExcludeSelf() *bool {
	if o == nil {
		return nil
	}
	return o.ExcludeSelf
}

func (o *OutputCriblTCP) GetHosts() []components.ItemsTypeHosts {
	if o == nil {
		return nil
	}
	return o.Hosts
}

func (o *OutputCriblTCP) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputCriblTCP) GetLoadBalanceStatsPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.LoadBalanceStatsPeriodSec
}

func (o *OutputCriblTCP) GetMaxConcurrentSenders() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentSenders
}

func (o *OutputCriblTCP) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputCriblTCP) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputCriblTCP) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputCriblTCP) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputCriblTCP) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputCriblTCP) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputCriblTCP) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputCriblTCP) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputCriblTCP) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputCriblTCP) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputCriblTCP) GetPqControls() *PqControlsCriblTCP {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type TypeDataset string

const (
	TypeDatasetDataset TypeDataset = "dataset"
)

func (e TypeDataset) ToPointer() *TypeDataset {
	return &e
}
func (e *TypeDataset) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "dataset":
		*e = TypeDataset(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeDataset: %v", v)
	}
}

// DefaultSeveritySeverity - Default value for event severity. If the `sev` or `__severity` fields are set on an event, the first one matching will override this value.
type DefaultSeveritySeverity string

const (
	// DefaultSeveritySeverityFinest 0 - finest
	DefaultSeveritySeverityFinest DefaultSeveritySeverity = "finest"
	// DefaultSeveritySeverityFiner 1 - finer
	DefaultSeveritySeverityFiner DefaultSeveritySeverity = "finer"
	// DefaultSeveritySeverityFine 2 - fine
	DefaultSeveritySeverityFine DefaultSeveritySeverity = "fine"
	// DefaultSeveritySeverityInfo 3 - info
	DefaultSeveritySeverityInfo DefaultSeveritySeverity = "info"
	// DefaultSeveritySeverityWarning 4 - warning
	DefaultSeveritySeverityWarning DefaultSeveritySeverity = "warning"
	// DefaultSeveritySeverityError 5 - error
	DefaultSeveritySeverityError DefaultSeveritySeverity = "error"
	// DefaultSeveritySeverityFatal 6 - fatal
	DefaultSeveritySeverityFatal DefaultSeveritySeverity = "fatal"
)

func (e DefaultSeveritySeverity) ToPointer() *DefaultSeveritySeverity {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *DefaultSeveritySeverity) IsExact() bool {
	if e != nil {
		switch *e {
		case "finest", "finer", "fine", "info", "warning", "error", "fatal":
			return true
		}
	}
	return false
}

// DataSetSite - DataSet site to which events should be sent
type DataSetSite string

const (
	// DataSetSiteUs US
	DataSetSiteUs DataSetSite = "us"
	// DataSetSiteEu Europe
	DataSetSiteEu DataSetSite = "eu"
	// DataSetSiteCustom Custom
	DataSetSiteCustom DataSetSite = "custom"
)

func (e DataSetSite) ToPointer() *DataSetSite {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *DataSetSite) IsExact() bool {
	if e != nil {
		switch *e {
		case "us", "eu", "custom":
			return true
		}
	}
	return false
}

type PqControlsDataset struct {
}

func (p PqControlsDataset) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsDataset) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputDataset struct {
	// Unique ID for this output
	ID   string      `json:"id"`
	Type TypeDataset `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the event field that contains the message or attributes to send. If not specified, all of the event's non-internal fields will be sent as attributes.
	MessageField *string `json:"messageField,omitempty"`
	// Fields to exclude from the event if the Message field is either unspecified or refers to an object. Ignored if the Message field is a string. If empty, we send all non-internal fields.
	ExcludeFields []string `json:"excludeFields,omitempty"`
	// Name of the event field that contains the `serverHost` identifier. If not specified, defaults to `cribl_<outputId>`.
	ServerHostField *string `json:"serverHostField,omitempty"`
	// Name of the event field that contains the timestamp. If not specified, defaults to `ts`, `_time`, or `Date.now()`, in that order.
	TimestampField *string `json:"timestampField,omitempty"`
	// Default value for event severity. If the `sev` or `__severity` fields are set on an event, the first one matching will override this value.
	DefaultSeverity *DefaultSeveritySeverity `json:"defaultSeverity,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// DataSet site to which events should be sent
	Site *DataSetSite `json:"site,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Enter API key directly, or select a stored secret
	AuthType *components.AuthenticationMethodOptions2 `json:"authType,omitempty"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	CustomURL          *string  `json:"customUrl,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsDataset                   `json:"pqControls,omitempty"`
	// A 'Log Write Access' API key for the DataSet account
	APIKey *string `json:"apiKey,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
}

func (o OutputDataset) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDataset) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputDataset) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputDataset) GetType() TypeDataset {
	if o == nil {
		return TypeDataset("")
	}
	return o.Type
}

func (o *OutputDataset) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputDataset) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputDataset) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputDataset) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputDataset) GetMessageField() *string {
	if o == nil {
		return nil
	}
	return o.MessageField
}

func (o *OutputDataset) GetExcludeFields() []string {
	if o == nil {
		return nil
	}
	return o.ExcludeFields
}

func (o *OutputDataset) GetServerHostField() *string {
	if o == nil {
		return nil
	}
	return o.ServerHostField
}

func (o *OutputDataset) GetTimestampField() *string {
	if o == nil {
		return nil
	}
	return o.TimestampField
}

func (o *OutputDataset) GetDefaultSeverity() *DefaultSeveritySeverity {
	if o == nil {
		return nil
	}
	return o.DefaultSeverity
}

func (o *OutputDataset) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputDataset) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputDataset) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputDataset) GetSite() *DataSetSite {
	if o == nil {
		return nil
	}
	return o.Site
}

func (o *OutputDataset) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputDataset) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputDataset) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputDataset) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputDataset) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputDataset) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputDataset) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputDataset) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputDataset) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputDataset) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputDataset) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputDataset) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputDataset) GetAuthType() *components.AuthenticationMethodOptions2 {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputDataset) GetTotalMemoryLimitKB() *float64 {
	if o == nil {
		return nil
	}
	return o.TotalMemoryLimitKB
}

func (o *OutputDataset) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputDataset) GetCustomURL() *string {
	if o == nil {
		return nil
	}
	return o.CustomURL
}

func (o *OutputDataset) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputDataset) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputDataset) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputDataset) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputDataset) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputDataset) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputDataset) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputDataset) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputDataset) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputDataset) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputDataset) GetPqControls() *PqControlsDataset {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputDataset) GetAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.APIKey
}

func (o *OutputDataset) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

type TypeServiceNow string

const (
	TypeServiceNowServiceNow TypeServiceNow = "service_now"
)

func (e TypeServiceNow) ToPointer() *TypeServiceNow {
	return &e
}
func (e *TypeServiceNow) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "service_now":
		*e = TypeServiceNow(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeServiceNow: %v", v)
	}
}

type PqControlsServiceNow struct {
}

func (p PqControlsServiceNow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsServiceNow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputServiceNow struct {
	// Unique ID for this output
	ID   string         `json:"id"`
	Type TypeServiceNow `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The endpoint where ServiceNow events will be sent. Enter any valid URL or an IP address (IPv4 or IPv6; enclose IPv6 addresses in square brackets)
	Endpoint string `json:"endpoint"`
	// Select or create a stored text secret
	TokenSecret   string  `json:"tokenSecret"`
	AuthTokenName *string `json:"authTokenName,omitempty"`
	// The version of OTLP Protobuf definitions to use when structuring data to send
	OtlpVersion components.OtlpVersionOptions1 `json:"otlpVersion"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Select a transport option for OpenTelemetry
	Protocol components.ProtocolOptions `json:"protocol"`
	// Type of compression to apply to messages sent to the OpenTelemetry endpoint
	Compress *components.CompressionOptions4 `json:"compress,omitempty"`
	// Type of compression to apply to messages sent to the OpenTelemetry endpoint
	HTTPCompress *components.CompressionOptions5 `json:"httpCompress,omitempty"`
	// If you want to send traces to the default `{endpoint}/v1/traces` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPTracesEndpointOverride *string `json:"httpTracesEndpointOverride,omitempty"`
	// If you want to send metrics to the default `{endpoint}/v1/metrics` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPMetricsEndpointOverride *string `json:"httpMetricsEndpointOverride,omitempty"`
	// If you want to send logs to the default `{endpoint}/v1/logs` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPLogsEndpointOverride *string `json:"httpLogsEndpointOverride,omitempty"`
	// List of key-value pairs to send with each gRPC request. Value supports JavaScript expressions that are evaluated just once, when the destination gets started. To pass credentials as metadata, use 'C.Secret'.
	Metadata []components.ItemsTypeKeyValueMetadata `json:"metadata,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// How often the sender should ping the peer to keep the connection open
	KeepAliveTime *float64 `json:"keepAliveTime,omitempty"`
	// Disable to close the connection immediately after sending the outgoing request
	KeepAlive *bool `json:"keepAlive,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool                                  `json:"responseHonorRetryAfterHeader,omitempty"`
	TLS                           *components.TLSSettingsClientSideType2 `json:"tls,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsServiceNow                `json:"pqControls,omitempty"`
}

func (o OutputServiceNow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputServiceNow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputServiceNow) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputServiceNow) GetType() TypeServiceNow {
	if o == nil {
		return TypeServiceNow("")
	}
	return o.Type
}

func (o *OutputServiceNow) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputServiceNow) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputServiceNow) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputServiceNow) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputServiceNow) GetEndpoint() string {
	if o == nil {
		return ""
	}
	return o.Endpoint
}

func (o *OutputServiceNow) GetTokenSecret() string {
	if o == nil {
		return ""
	}
	return o.TokenSecret
}

func (o *OutputServiceNow) GetAuthTokenName() *string {
	if o == nil {
		return nil
	}
	return o.AuthTokenName
}

func (o *OutputServiceNow) GetOtlpVersion() components.OtlpVersionOptions1 {
	if o == nil {
		return components.OtlpVersionOptions1("")
	}
	return o.OtlpVersion
}

func (o *OutputServiceNow) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputServiceNow) GetProtocol() components.ProtocolOptions {
	if o == nil {
		return components.ProtocolOptions("")
	}
	return o.Protocol
}

func (o *OutputServiceNow) GetCompress() *components.CompressionOptions4 {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputServiceNow) GetHTTPCompress() *components.CompressionOptions5 {
	if o == nil {
		return nil
	}
	return o.HTTPCompress
}

func (o *OutputServiceNow) GetHTTPTracesEndpointOverride() *string {
	if o == nil {
		return nil
	}
	return o.HTTPTracesEndpointOverride
}

func (o *OutputServiceNow) GetHTTPMetricsEndpointOverride() *string {
	if o == nil {
		return nil
	}
	return o.HTTPMetricsEndpointOverride
}

func (o *OutputServiceNow) GetHTTPLogsEndpointOverride() *string {
	if o == nil {
		return nil
	}
	return o.HTTPLogsEndpointOverride
}

func (o *OutputServiceNow) GetMetadata() []components.ItemsTypeKeyValueMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *OutputServiceNow) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputServiceNow) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputServiceNow) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputServiceNow) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputServiceNow) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputServiceNow) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *OutputServiceNow) GetKeepAlive() *bool {
	if o == nil {
		return nil
	}
	return o.KeepAlive
}

func (o *OutputServiceNow) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputServiceNow) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputServiceNow) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputServiceNow) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputServiceNow) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputServiceNow) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputServiceNow) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputServiceNow) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputServiceNow) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputServiceNow) GetTLS() *components.TLSSettingsClientSideType2 {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputServiceNow) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputServiceNow) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputServiceNow) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputServiceNow) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputServiceNow) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputServiceNow) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputServiceNow) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputServiceNow) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputServiceNow) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputServiceNow) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputServiceNow) GetPqControls() *PqControlsServiceNow {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type CreateOutputTypeOpenTelemetry string

const (
	CreateOutputTypeOpenTelemetryOpenTelemetry CreateOutputTypeOpenTelemetry = "open_telemetry"
)

func (e CreateOutputTypeOpenTelemetry) ToPointer() *CreateOutputTypeOpenTelemetry {
	return &e
}
func (e *CreateOutputTypeOpenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "open_telemetry":
		*e = CreateOutputTypeOpenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeOpenTelemetry: %v", v)
	}
}

// CreateOutputOTLPVersion - The version of OTLP Protobuf definitions to use when structuring data to send
type CreateOutputOTLPVersion string

const (
	// CreateOutputOTLPVersionZeroDot10Dot0 0.10.0
	CreateOutputOTLPVersionZeroDot10Dot0 CreateOutputOTLPVersion = "0.10.0"
	// CreateOutputOTLPVersionOneDot3Dot1 1.3.1
	CreateOutputOTLPVersionOneDot3Dot1 CreateOutputOTLPVersion = "1.3.1"
)

func (e CreateOutputOTLPVersion) ToPointer() *CreateOutputOTLPVersion {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputOTLPVersion) IsExact() bool {
	if e != nil {
		switch *e {
		case "0.10.0", "1.3.1":
			return true
		}
	}
	return false
}

type PqControlsOpenTelemetry struct {
}

func (p PqControlsOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputOpenTelemetry struct {
	// Unique ID for this output
	ID   string                        `json:"id"`
	Type CreateOutputTypeOpenTelemetry `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Select a transport option for OpenTelemetry
	Protocol *components.ProtocolOptions `json:"protocol,omitempty"`
	// The endpoint where OTel events will be sent. Enter any valid URL or an IP address (IPv4 or IPv6; enclose IPv6 addresses in square brackets). Unspecified ports will default to 4317, unless the endpoint is an HTTPS-based URL or TLS is enabled, in which case 443 will be used.
	Endpoint string `json:"endpoint"`
	// The version of OTLP Protobuf definitions to use when structuring data to send
	OtlpVersion *CreateOutputOTLPVersion `json:"otlpVersion,omitempty"`
	// Type of compression to apply to messages sent to the OpenTelemetry endpoint
	Compress *components.CompressionOptions4 `json:"compress,omitempty"`
	// Type of compression to apply to messages sent to the OpenTelemetry endpoint
	HTTPCompress *components.CompressionOptions5 `json:"httpCompress,omitempty"`
	// OpenTelemetry authentication type
	AuthType *components.AuthenticationTypeOptions `json:"authType,omitempty"`
	// If you want to send traces to the default `{endpoint}/v1/traces` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPTracesEndpointOverride *string `json:"httpTracesEndpointOverride,omitempty"`
	// If you want to send metrics to the default `{endpoint}/v1/metrics` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPMetricsEndpointOverride *string `json:"httpMetricsEndpointOverride,omitempty"`
	// If you want to send logs to the default `{endpoint}/v1/logs` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPLogsEndpointOverride *string `json:"httpLogsEndpointOverride,omitempty"`
	// List of key-value pairs to send with each gRPC request. Value supports JavaScript expressions that are evaluated just once, when the destination gets started. To pass credentials as metadata, use 'C.Secret'.
	Metadata []components.ItemsTypeKeyValueMetadata `json:"metadata,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// How often the sender should ping the peer to keep the connection open
	KeepAliveTime *float64 `json:"keepAliveTime,omitempty"`
	// Disable to close the connection immediately after sending the outgoing request
	KeepAlive *bool `json:"keepAlive,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	Username       *string                                 `json:"username,omitempty"`
	Password       *string                                 `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `json:"authHeaderExpr,omitempty"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `json:"tokenTimeoutSecs,omitempty"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []components.ItemsTypeOauthParams `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []components.ItemsTypeOauthHeaders `json:"oauthHeaders,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool                                  `json:"responseHonorRetryAfterHeader,omitempty"`
	TLS                           *components.TLSSettingsClientSideType2 `json:"tls,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsOpenTelemetry             `json:"pqControls,omitempty"`
}

func (o OutputOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputOpenTelemetry) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputOpenTelemetry) GetType() CreateOutputTypeOpenTelemetry {
	if o == nil {
		return CreateOutputTypeOpenTelemetry("")
	}
	return o.Type
}

func (o *OutputOpenTelemetry) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputOpenTelemetry) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputOpenTelemetry) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputOpenTelemetry) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputOpenTelemetry) GetProtocol() *components.ProtocolOptions {
	if o == nil {
		return nil
	}
	return o.Protocol
}

func (o *OutputOpenTelemetry) GetEndpoint() string {
	if o == nil {
		return ""
	}
	return o.Endpoint
}

func (o *OutputOpenTelemetry) GetOtlpVersion() *CreateOutputOTLPVersion {
	if o == nil {
		return nil
	}
	return o.OtlpVersion
}

func (o *OutputOpenTelemetry) GetCompress() *components.CompressionOptions4 {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputOpenTelemetry) GetHTTPCompress() *components.CompressionOptions5 {
	if o == nil {
		return nil
	}
	return o.HTTPCompress
}

func (o *OutputOpenTelemetry) GetAuthType() *components.AuthenticationTypeOptions {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputOpenTelemetry) GetHTTPTracesEndpointOverride() *string {
	if o == nil {
		return nil
	}
	return o.HTTPTracesEndpointOverride
}

func (o *OutputOpenTelemetry) GetHTTPMetricsEndpointOverride() *string {
	if o == nil {
		return nil
	}
	return o.HTTPMetricsEndpointOverride
}

func (o *OutputOpenTelemetry) GetHTTPLogsEndpointOverride() *string {
	if o == nil {
		return nil
	}
	return o.HTTPLogsEndpointOverride
}

func (o *OutputOpenTelemetry) GetMetadata() []components.ItemsTypeKeyValueMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *OutputOpenTelemetry) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputOpenTelemetry) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputOpenTelemetry) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputOpenTelemetry) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputOpenTelemetry) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputOpenTelemetry) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputOpenTelemetry) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *OutputOpenTelemetry) GetKeepAlive() *bool {
	if o == nil {
		return nil
	}
	return o.KeepAlive
}

func (o *OutputOpenTelemetry) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputOpenTelemetry) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputOpenTelemetry) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *OutputOpenTelemetry) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *OutputOpenTelemetry) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputOpenTelemetry) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *OutputOpenTelemetry) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputOpenTelemetry) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *OutputOpenTelemetry) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *OutputOpenTelemetry) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *OutputOpenTelemetry) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *OutputOpenTelemetry) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *OutputOpenTelemetry) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *OutputOpenTelemetry) GetOauthParams() []components.ItemsTypeOauthParams {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *OutputOpenTelemetry) GetOauthHeaders() []components.ItemsTypeOauthHeaders {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

func (o *OutputOpenTelemetry) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputOpenTelemetry) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputOpenTelemetry) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputOpenTelemetry) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputOpenTelemetry) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputOpenTelemetry) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputOpenTelemetry) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputOpenTelemetry) GetTLS() *components.TLSSettingsClientSideType2 {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputOpenTelemetry) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputOpenTelemetry) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputOpenTelemetry) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputOpenTelemetry) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputOpenTelemetry) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputOpenTelemetry) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputOpenTelemetry) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputOpenTelemetry) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputOpenTelemetry) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputOpenTelemetry) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputOpenTelemetry) GetPqControls() *PqControlsOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type TypeRing string

const (
	TypeRingRing TypeRing = "ring"
)

func (e TypeRing) ToPointer() *TypeRing {
	return &e
}
func (e *TypeRing) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "ring":
		*e = TypeRing(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeRing: %v", v)
	}
}

// DataFormatRing - Format of the output data.
type DataFormatRing string

const (
	DataFormatRingJSON DataFormatRing = "json"
	DataFormatRingRaw  DataFormatRing = "raw"
)

func (e DataFormatRing) ToPointer() *DataFormatRing {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *DataFormatRing) IsExact() bool {
	if e != nil {
		switch *e {
		case "json", "raw":
			return true
		}
	}
	return false
}

type OutputRing struct {
	// Unique ID for this output
	ID   string   `json:"id"`
	Type TypeRing `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Format of the output data.
	Format *DataFormatRing `json:"format,omitempty"`
	// JS expression to define how files are partitioned and organized. If left blank, Cribl Stream will fallback on event.__partition.
	PartitionExpr *string `json:"partitionExpr,omitempty"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `json:"maxDataSize,omitempty"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                                             `json:"maxDataTime,omitempty"`
	Compress    *components.DataCompressionFormatOptionsPersistence `json:"compress,omitempty"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/<id>
	DestPath *string `json:"destPath,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	Description    *string                                  `json:"description,omitempty"`
}

func (o OutputRing) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputRing) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputRing) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputRing) GetType() TypeRing {
	if o == nil {
		return TypeRing("")
	}
	return o.Type
}

func (o *OutputRing) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputRing) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputRing) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputRing) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputRing) GetFormat() *DataFormatRing {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputRing) GetPartitionExpr() *string {
	if o == nil {
		return nil
	}
	return o.PartitionExpr
}

func (o *OutputRing) GetMaxDataSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataSize
}

func (o *OutputRing) GetMaxDataTime() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataTime
}

func (o *OutputRing) GetCompress() *components.DataCompressionFormatOptionsPersistence {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputRing) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

func (o *OutputRing) GetOnBackpressure() *components.BackpressureBehaviorOptions1 {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputRing) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type CreateOutputTypePrometheus string

const (
	CreateOutputTypePrometheusPrometheus CreateOutputTypePrometheus = "prometheus"
)

func (e CreateOutputTypePrometheus) ToPointer() *CreateOutputTypePrometheus {
	return &e
}
func (e *CreateOutputTypePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "prometheus":
		*e = CreateOutputTypePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypePrometheus: %v", v)
	}
}

type PqControlsPrometheus struct {
}

func (p PqControlsPrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsPrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputPrometheus struct {
	// Unique ID for this output
	ID   string                     `json:"id"`
	Type CreateOutputTypePrometheus `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions to generated metrics.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The endpoint to send metrics to
	URL string `json:"url"`
	// JavaScript expression that can be used to rename metrics. For example, name.replace(/\./g, '_') will replace all '.' characters in a metric's name with the supported '_' character. Use the 'name' global variable to access the metric's name. You can access event fields' values via __e.<fieldName>.
	MetricRenameExpr *string `json:"metricRenameExpr,omitempty"`
	// Generate and send metadata (`type` and `metricFamilyName`) requests
	SendMetadata *bool `json:"sendMetadata,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Remote Write authentication type
	AuthType    *components.AuthenticationTypeOptionsPrometheusAuth `json:"authType,omitempty"`
	Description *string                                             `json:"description,omitempty"`
	// How frequently metrics metadata is sent out. Value cannot be smaller than the base Flush period set above.
	MetricsFlushPeriodSec *float64 `json:"metricsFlushPeriodSec,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsPrometheus                `json:"pqControls,omitempty"`
	Username         *string                              `json:"username,omitempty"`
	Password         *string                              `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `json:"authHeaderExpr,omitempty"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `json:"tokenTimeoutSecs,omitempty"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []components.ItemsTypeOauthParams `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []components.ItemsTypeOauthHeaders `json:"oauthHeaders,omitempty"`
}

func (o OutputPrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputPrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputPrometheus) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputPrometheus) GetType() CreateOutputTypePrometheus {
	if o == nil {
		return CreateOutputTypePrometheus("")
	}
	return o.Type
}

func (o *OutputPrometheus) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputPrometheus) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputPrometheus) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputPrometheus) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputPrometheus) GetURL() string {
	if o == nil {
		return ""
	}
	return o.URL
}

func (o *OutputPrometheus) GetMetricRenameExpr() *string {
	if o == nil {
		return nil
	}
	return o.MetricRenameExpr
}

func (o *OutputPrometheus) GetSendMetadata() *bool {
	if o == nil {
		return nil
	}
	return o.SendMetadata
}

func (o *OutputPrometheus) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputPrometheus) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputPrometheus) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputPrometheus) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputPrometheus) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputPrometheus) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputPrometheus) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputPrometheus) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputPrometheus) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputPrometheus) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputPrometheus) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputPrometheus) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputPrometheus) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputPrometheus) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputPrometheus) GetAuthType() *components.AuthenticationTypeOptionsPrometheusAuth {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputPrometheus) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputPrometheus) GetMetricsFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MetricsFlushPeriodSec
}

func (o *OutputPrometheus) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputPrometheus) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputPrometheus) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputPrometheus) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputPrometheus) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputPrometheus) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputPrometheus) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputPrometheus) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputPrometheus) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputPrometheus) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputPrometheus) GetPqControls() *PqControlsPrometheus {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputPrometheus) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *OutputPrometheus) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *OutputPrometheus) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputPrometheus) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *OutputPrometheus) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputPrometheus) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *OutputPrometheus) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *OutputPrometheus) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *OutputPrometheus) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *OutputPrometheus) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *OutputPrometheus) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *OutputPrometheus) GetOauthParams() []components.ItemsTypeOauthParams {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *OutputPrometheus) GetOauthHeaders() []components.ItemsTypeOauthHeaders {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

type CreateOutputTypeLoki string

const (
	CreateOutputTypeLokiLoki CreateOutputTypeLoki = "loki"
)

func (e CreateOutputTypeLoki) ToPointer() *CreateOutputTypeLoki {
	return &e
}
func (e *CreateOutputTypeLoki) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "loki":
		*e = CreateOutputTypeLoki(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeLoki: %v", v)
	}
}

type PqControlsLoki struct {
}

func (p PqControlsLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputLoki struct {
	// Unique ID for this output
	ID   string               `json:"id"`
	Type CreateOutputTypeLoki `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as labels to generated logs.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The endpoint to send logs to
	URL string `json:"url"`
	// Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
	Message *string `json:"message,omitempty"`
	// Format to use when sending logs to Loki (Protobuf or JSON)
	MessageFormat *components.MessageFormatOptions `json:"messageFormat,omitempty"`
	// List of labels to send with logs. Labels define Loki streams, so use static labels to avoid proliferating label value combinations and streams. Can be merged and/or overridden by the event's __labels field. Example: '__labels: {host: "cribl.io", level: "error"}'
	Labels   []components.ItemsTypeLabels                         `json:"labels,omitempty"`
	AuthType *components.AuthenticationTypeOptionsPrometheusAuth1 `json:"authType,omitempty"`
	// Maximum number of ongoing requests before blocking. Warning: Setting this value > 1 can cause Loki to complain about entries being delivered out of order.
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki to complain about entries being delivered out of order.
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Defaults to 0 (unlimited). Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki to complain about entries being delivered out of order.
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Maximum time between requests. Small values can reduce the payload size below the configured 'Max record size' and 'Max events per request'. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki to complain about entries being delivered out of order.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// Add per-event HTTP headers from the __headers field to outgoing requests. Events with different headers are batched and sent separately.
	EnableDynamicHeaders *bool `json:"enableDynamicHeaders,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Bearer token to include in the authorization header. In Grafana Cloud, this is generally built by concatenating the username and the API key, separated by a colon. Example: <your-username>:<your-api-key>
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Username for authentication
	Username *string `json:"username,omitempty"`
	// Password (API key in Grafana Cloud domain) for authentication
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsLoki                      `json:"pqControls,omitempty"`
}

func (o OutputLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputLoki) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputLoki) GetType() CreateOutputTypeLoki {
	if o == nil {
		return CreateOutputTypeLoki("")
	}
	return o.Type
}

func (o *OutputLoki) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputLoki) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputLoki) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputLoki) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputLoki) GetURL() string {
	if o == nil {
		return ""
	}
	return o.URL
}

func (o *OutputLoki) GetMessage() *string {
	if o == nil {
		return nil
	}
	return o.Message
}

func (o *OutputLoki) GetMessageFormat() *components.MessageFormatOptions {
	if o == nil {
		return nil
	}
	return o.MessageFormat
}

func (o *OutputLoki) GetLabels() []components.ItemsTypeLabels {
	if o == nil {
		return nil
	}
	return o.Labels
}

func (o *OutputLoki) GetAuthType() *components.AuthenticationTypeOptionsPrometheusAuth1 {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputLoki) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputLoki) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputLoki) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputLoki) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputLoki) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputLoki) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputLoki) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputLoki) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputLoki) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputLoki) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputLoki) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputLoki) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputLoki) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputLoki) GetEnableDynamicHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.EnableDynamicHeaders
}

func (o *OutputLoki) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputLoki) GetTotalMemoryLimitKB() *float64 {
	if o == nil {
		return nil
	}
	return o.TotalMemoryLimitKB
}

func (o *OutputLoki) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputLoki) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputLoki) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputLoki) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputLoki) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *OutputLoki) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *OutputLoki) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *OutputLoki) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputLoki) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputLoki) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputLoki) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputLoki) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputLoki) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputLoki) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputLoki) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputLoki) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputLoki) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputLoki) GetPqControls() *PqControlsLoki {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type OutputGrafanaCloudType2 string

const (
	OutputGrafanaCloudType2GrafanaCloud OutputGrafanaCloudType2 = "grafana_cloud"
)

func (e OutputGrafanaCloudType2) ToPointer() *OutputGrafanaCloudType2 {
	return &e
}
func (e *OutputGrafanaCloudType2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grafana_cloud":
		*e = OutputGrafanaCloudType2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGrafanaCloudType2: %v", v)
	}
}

type OutputGrafanaCloudPqControls2 struct {
}

func (o OutputGrafanaCloudPqControls2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGrafanaCloudPqControls2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputGrafanaCloudGrafanaCloud2 struct {
	// Unique ID for this output
	ID   string                  `json:"id"`
	Type OutputGrafanaCloudType2 `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions and labels to generated metrics and logs, respectively.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The endpoint to send logs to, such as https://logs-prod-us-central1.grafana.net
	LokiURL *string `json:"lokiUrl,omitempty"`
	// The remote_write endpoint to send Prometheus metrics to, such as https://prometheus-blocks-prod-us-central1.grafana.net/api/prom/push
	PrometheusURL string `json:"prometheusUrl"`
	// Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
	Message *string `json:"message,omitempty"`
	// Format to use when sending logs to Loki (Protobuf or JSON)
	MessageFormat *components.MessageFormatOptions `json:"messageFormat,omitempty"`
	// List of labels to send with logs. Labels define Loki streams, so use static labels to avoid proliferating label value combinations and streams. Can be merged and/or overridden by the event's __labels field. Example: '__labels: {host: "cribl.io", level: "error"}'
	Labels []components.ItemsTypeLabels `json:"labels,omitempty"`
	// JavaScript expression that can be used to rename metrics. For example, name.replace(/\./g, '_') will replace all '.' characters in a metric's name with the supported '_' character. Use the 'name' global variable to access the metric's name. You can access event fields' values via __e.<fieldName>.
	MetricRenameExpr *string                        `json:"metricRenameExpr,omitempty"`
	PrometheusAuth   *components.PrometheusAuthType `json:"prometheusAuth,omitempty"`
	LokiAuth         *components.PrometheusAuthType `json:"lokiAuth,omitempty"`
	// Maximum number of ongoing requests before blocking. Warning: Setting this value > 1 can cause Loki and Prometheus to complain about entries being delivered out of order.
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited). Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Maximum time between requests. Small values can reduce the payload size below the configured 'Max record size' and 'Max events per request'. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// Compress the payload body before sending. Applies only to JSON payloads; the Protobuf variant for both Prometheus and Loki are snappy-compressed by default.
	Compress *bool `json:"compress,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *OutputGrafanaCloudPqControls2       `json:"pqControls,omitempty"`
}

func (o OutputGrafanaCloudGrafanaCloud2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGrafanaCloudGrafanaCloud2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetType() OutputGrafanaCloudType2 {
	if o == nil {
		return OutputGrafanaCloudType2("")
	}
	return o.Type
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetLokiURL() *string {
	if o == nil {
		return nil
	}
	return o.LokiURL
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetPrometheusURL() string {
	if o == nil {
		return ""
	}
	return o.PrometheusURL
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetMessage() *string {
	if o == nil {
		return nil
	}
	return o.Message
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetMessageFormat() *components.MessageFormatOptions {
	if o == nil {
		return nil
	}
	return o.MessageFormat
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetLabels() []components.ItemsTypeLabels {
	if o == nil {
		return nil
	}
	return o.Labels
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetMetricRenameExpr() *string {
	if o == nil {
		return nil
	}
	return o.MetricRenameExpr
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetPrometheusAuth() *components.PrometheusAuthType {
	if o == nil {
		return nil
	}
	return o.PrometheusAuth
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetLokiAuth() *components.PrometheusAuthType {
	if o == nil {
		return nil
	}
	return o.LokiAuth
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputGrafanaCloudGrafanaCloud2) GetPqControls() *OutputGrafanaCloudPqControls2 {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type OutputGrafanaCloudType1 string

const (
	OutputGrafanaCloudType1GrafanaCloud OutputGrafanaCloudType1 = "grafana_cloud"
)

func (e OutputGrafanaCloudType1) ToPointer() *OutputGrafanaCloudType1 {
	return &e
}
func (e *OutputGrafanaCloudType1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grafana_cloud":
		*e = OutputGrafanaCloudType1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGrafanaCloudType1: %v", v)
	}
}

type OutputGrafanaCloudPqControls1 struct {
}

func (o OutputGrafanaCloudPqControls1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGrafanaCloudPqControls1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputGrafanaCloudGrafanaCloud1 struct {
	// Unique ID for this output
	ID   string                  `json:"id"`
	Type OutputGrafanaCloudType1 `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions and labels to generated metrics and logs, respectively.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The endpoint to send logs to, such as https://logs-prod-us-central1.grafana.net
	LokiURL string `json:"lokiUrl"`
	// The remote_write endpoint to send Prometheus metrics to, such as https://prometheus-blocks-prod-us-central1.grafana.net/api/prom/push
	PrometheusURL *string `json:"prometheusUrl,omitempty"`
	// Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
	Message *string `json:"message,omitempty"`
	// Format to use when sending logs to Loki (Protobuf or JSON)
	MessageFormat *components.MessageFormatOptions `json:"messageFormat,omitempty"`
	// List of labels to send with logs. Labels define Loki streams, so use static labels to avoid proliferating label value combinations and streams. Can be merged and/or overridden by the event's __labels field. Example: '__labels: {host: "cribl.io", level: "error"}'
	Labels []components.ItemsTypeLabels `json:"labels,omitempty"`
	// JavaScript expression that can be used to rename metrics. For example, name.replace(/\./g, '_') will replace all '.' characters in a metric's name with the supported '_' character. Use the 'name' global variable to access the metric's name. You can access event fields' values via __e.<fieldName>.
	MetricRenameExpr *string                        `json:"metricRenameExpr,omitempty"`
	PrometheusAuth   *components.PrometheusAuthType `json:"prometheusAuth,omitempty"`
	LokiAuth         *components.PrometheusAuthType `json:"lokiAuth,omitempty"`
	// Maximum number of ongoing requests before blocking. Warning: Setting this value > 1 can cause Loki and Prometheus to complain about entries being delivered out of order.
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited). Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Maximum time between requests. Small values can reduce the payload size below the configured 'Max record size' and 'Max events per request'. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	// Compress the payload body before sending. Applies only to JSON payloads; the Protobuf variant for both Prometheus and Loki are snappy-compressed by default.
	Compress *bool `json:"compress,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *OutputGrafanaCloudPqControls1       `json:"pqControls,omitempty"`
}

func (o OutputGrafanaCloudGrafanaCloud1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGrafanaCloudGrafanaCloud1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetType() OutputGrafanaCloudType1 {
	if o == nil {
		return OutputGrafanaCloudType1("")
	}
	return o.Type
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetLokiURL() string {
	if o == nil {
		return ""
	}
	return o.LokiURL
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetPrometheusURL() *string {
	if o == nil {
		return nil
	}
	return o.PrometheusURL
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetMessage() *string {
	if o == nil {
		return nil
	}
	return o.Message
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetMessageFormat() *components.MessageFormatOptions {
	if o == nil {
		return nil
	}
	return o.MessageFormat
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetLabels() []components.ItemsTypeLabels {
	if o == nil {
		return nil
	}
	return o.Labels
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetMetricRenameExpr() *string {
	if o == nil {
		return nil
	}
	return o.MetricRenameExpr
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetPrometheusAuth() *components.PrometheusAuthType {
	if o == nil {
		return nil
	}
	return o.PrometheusAuth
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetLokiAuth() *components.PrometheusAuthType {
	if o == nil {
		return nil
	}
	return o.LokiAuth
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputGrafanaCloudGrafanaCloud1) GetPqControls() *OutputGrafanaCloudPqControls1 {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type OutputGrafanaCloudType string

const (
	OutputGrafanaCloudTypeOutputGrafanaCloudGrafanaCloud1 OutputGrafanaCloudType = "OutputGrafanaCloud_GrafanaCloud_1"
	OutputGrafanaCloudTypeOutputGrafanaCloudGrafanaCloud2 OutputGrafanaCloudType = "OutputGrafanaCloud_GrafanaCloud_2"
)

type OutputGrafanaCloud struct {
	OutputGrafanaCloudGrafanaCloud1 *OutputGrafanaCloudGrafanaCloud1 `queryParam:"inline" union:"member"`
	OutputGrafanaCloudGrafanaCloud2 *OutputGrafanaCloudGrafanaCloud2 `queryParam:"inline" union:"member"`

	Type OutputGrafanaCloudType
}

func CreateOutputGrafanaCloudOutputGrafanaCloudGrafanaCloud1(outputGrafanaCloudGrafanaCloud1 OutputGrafanaCloudGrafanaCloud1) OutputGrafanaCloud {
	typ := OutputGrafanaCloudTypeOutputGrafanaCloudGrafanaCloud1

	return OutputGrafanaCloud{
		OutputGrafanaCloudGrafanaCloud1: &outputGrafanaCloudGrafanaCloud1,
		Type:                            typ,
	}
}

func CreateOutputGrafanaCloudOutputGrafanaCloudGrafanaCloud2(outputGrafanaCloudGrafanaCloud2 OutputGrafanaCloudGrafanaCloud2) OutputGrafanaCloud {
	typ := OutputGrafanaCloudTypeOutputGrafanaCloudGrafanaCloud2

	return OutputGrafanaCloud{
		OutputGrafanaCloudGrafanaCloud2: &outputGrafanaCloudGrafanaCloud2,
		Type:                            typ,
	}
}

func (u *OutputGrafanaCloud) UnmarshalJSON(data []byte) error {

	var candidates []utils.UnionCandidate

	// Collect all valid candidates
	var outputGrafanaCloudGrafanaCloud1 OutputGrafanaCloudGrafanaCloud1 = OutputGrafanaCloudGrafanaCloud1{}
	if err := utils.UnmarshalJSON(data, &outputGrafanaCloudGrafanaCloud1, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  OutputGrafanaCloudTypeOutputGrafanaCloudGrafanaCloud1,
			Value: &outputGrafanaCloudGrafanaCloud1,
		})
	}

	var outputGrafanaCloudGrafanaCloud2 OutputGrafanaCloudGrafanaCloud2 = OutputGrafanaCloudGrafanaCloud2{}
	if err := utils.UnmarshalJSON(data, &outputGrafanaCloudGrafanaCloud2, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  OutputGrafanaCloudTypeOutputGrafanaCloudGrafanaCloud2,
			Value: &outputGrafanaCloudGrafanaCloud2,
		})
	}

	if len(candidates) == 0 {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for OutputGrafanaCloud", string(data))
	}

	// Pick the best candidate using multi-stage filtering
	best := utils.PickBestUnionCandidate(candidates, data)
	if best == nil {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for OutputGrafanaCloud", string(data))
	}

	// Set the union type and value based on the best candidate
	u.Type = best.Type.(OutputGrafanaCloudType)
	switch best.Type {
	case OutputGrafanaCloudTypeOutputGrafanaCloudGrafanaCloud1:
		u.OutputGrafanaCloudGrafanaCloud1 = best.Value.(*OutputGrafanaCloudGrafanaCloud1)
		return nil
	case OutputGrafanaCloudTypeOutputGrafanaCloudGrafanaCloud2:
		u.OutputGrafanaCloudGrafanaCloud2 = best.Value.(*OutputGrafanaCloudGrafanaCloud2)
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for OutputGrafanaCloud", string(data))
}

func (u OutputGrafanaCloud) MarshalJSON() ([]byte, error) {
	if u.OutputGrafanaCloudGrafanaCloud1 != nil {
		return utils.MarshalJSON(u.OutputGrafanaCloudGrafanaCloud1, "", true)
	}

	if u.OutputGrafanaCloudGrafanaCloud2 != nil {
		return utils.MarshalJSON(u.OutputGrafanaCloudGrafanaCloud2, "", true)
	}

	return nil, errors.New("could not marshal union type OutputGrafanaCloud: all fields are null")
}

type TypeDatadog string

const (
	TypeDatadogDatadog TypeDatadog = "datadog"
)

func (e TypeDatadog) ToPointer() *TypeDatadog {
	return &e
}
func (e *TypeDatadog) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "datadog":
		*e = TypeDatadog(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeDatadog: %v", v)
	}
}

// SendLogsAs - The content type to use when sending logs
type SendLogsAs string

const (
	// SendLogsAsText text/plain
	SendLogsAsText SendLogsAs = "text"
	// SendLogsAsJSON application/json
	SendLogsAsJSON SendLogsAs = "json"
)

func (e SendLogsAs) ToPointer() *SendLogsAs {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *SendLogsAs) IsExact() bool {
	if e != nil {
		switch *e {
		case "text", "json":
			return true
		}
	}
	return false
}

// SeverityDatadog - Default value for message severity. When you send logs as JSON objects, the event's '__severity' field (if set) will override this value.
type SeverityDatadog string

const (
	// SeverityDatadogEmergency emergency
	SeverityDatadogEmergency SeverityDatadog = "emergency"
	// SeverityDatadogAlert alert
	SeverityDatadogAlert SeverityDatadog = "alert"
	// SeverityDatadogCritical critical
	SeverityDatadogCritical SeverityDatadog = "critical"
	// SeverityDatadogError error
	SeverityDatadogError SeverityDatadog = "error"
	// SeverityDatadogWarning warning
	SeverityDatadogWarning SeverityDatadog = "warning"
	// SeverityDatadogNotice notice
	SeverityDatadogNotice SeverityDatadog = "notice"
	// SeverityDatadogInfo info
	SeverityDatadogInfo SeverityDatadog = "info"
	// SeverityDatadogDebug debug
	SeverityDatadogDebug SeverityDatadog = "debug"
)

func (e SeverityDatadog) ToPointer() *SeverityDatadog {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *SeverityDatadog) IsExact() bool {
	if e != nil {
		switch *e {
		case "emergency", "alert", "critical", "error", "warning", "notice", "info", "debug":
			return true
		}
	}
	return false
}

// DatadogSite - Datadog site to which events should be sent
type DatadogSite string

const (
	// DatadogSiteUs US
	DatadogSiteUs DatadogSite = "us"
	// DatadogSiteUs3 US3
	DatadogSiteUs3 DatadogSite = "us3"
	// DatadogSiteUs5 US5
	DatadogSiteUs5 DatadogSite = "us5"
	// DatadogSiteEu Europe
	DatadogSiteEu DatadogSite = "eu"
	// DatadogSiteFed1 US1-FED
	DatadogSiteFed1 DatadogSite = "fed1"
	// DatadogSiteAp1 AP1
	DatadogSiteAp1 DatadogSite = "ap1"
	// DatadogSiteCustom Custom
	DatadogSiteCustom DatadogSite = "custom"
)

func (e DatadogSite) ToPointer() *DatadogSite {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *DatadogSite) IsExact() bool {
	if e != nil {
		switch *e {
		case "us", "us3", "us5", "eu", "fed1", "ap1", "custom":
			return true
		}
	}
	return false
}

type PqControlsDatadog struct {
}

func (p PqControlsDatadog) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsDatadog) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputDatadog struct {
	// Unique ID for this output
	ID   string      `json:"id"`
	Type TypeDatadog `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The content type to use when sending logs
	ContentType *SendLogsAs `json:"contentType,omitempty"`
	// Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
	Message *string `json:"message,omitempty"`
	// Name of the source to send with logs. When you send logs as JSON objects, the event's 'source' field (if set) will override this value.
	Source *string `json:"source,omitempty"`
	// Name of the host to send with logs. When you send logs as JSON objects, the event's 'host' field (if set) will override this value.
	Host *string `json:"host,omitempty"`
	// Name of the service to send with logs. When you send logs as JSON objects, the event's '__service' field (if set) will override this value.
	Service *string `json:"service,omitempty"`
	// List of tags to send with logs, such as 'env:prod' and 'env_staging:east'
	Tags []string `json:"tags,omitempty"`
	// Batch events by API key and the ddtags field on the event. When disabled, batches events only by API key. If incoming events have high cardinality in the ddtags field, disabling this setting may improve Destination performance.
	BatchByTags *bool `json:"batchByTags,omitempty"`
	// Allow API key to be set from the event's '__agent_api_key' field
	AllowAPIKeyFromEvents *bool `json:"allowApiKeyFromEvents,omitempty"`
	// Default value for message severity. When you send logs as JSON objects, the event's '__severity' field (if set) will override this value.
	Severity *SeverityDatadog `json:"severity,omitempty"`
	// Datadog site to which events should be sent
	Site *DatadogSite `json:"site,omitempty"`
	// If not enabled, Datadog will transform 'counter' metrics to 'gauge'. [Learn more about Datadog metrics types.](https://docs.datadoghq.com/metrics/types/?tab=count)
	SendCountersAsCount *bool `json:"sendCountersAsCount,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Enter API key directly, or select a stored secret
	AuthType *components.AuthenticationMethodOptions2 `json:"authType,omitempty"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	CustomURL          *string  `json:"customUrl,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsDatadog                   `json:"pqControls,omitempty"`
	// Organization's API key in Datadog
	APIKey *string `json:"apiKey,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
}

func (o OutputDatadog) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDatadog) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputDatadog) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputDatadog) GetType() TypeDatadog {
	if o == nil {
		return TypeDatadog("")
	}
	return o.Type
}

func (o *OutputDatadog) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputDatadog) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputDatadog) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputDatadog) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputDatadog) GetContentType() *SendLogsAs {
	if o == nil {
		return nil
	}
	return o.ContentType
}

func (o *OutputDatadog) GetMessage() *string {
	if o == nil {
		return nil
	}
	return o.Message
}

func (o *OutputDatadog) GetSource() *string {
	if o == nil {
		return nil
	}
	return o.Source
}

func (o *OutputDatadog) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *OutputDatadog) GetService() *string {
	if o == nil {
		return nil
	}
	return o.Service
}

func (o *OutputDatadog) GetTags() []string {
	if o == nil {
		return nil
	}
	return o.Tags
}

func (o *OutputDatadog) GetBatchByTags() *bool {
	if o == nil {
		return nil
	}
	return o.BatchByTags
}

func (o *OutputDatadog) GetAllowAPIKeyFromEvents() *bool {
	if o == nil {
		return nil
	}
	return o.AllowAPIKeyFromEvents
}

func (o *OutputDatadog) GetSeverity() *SeverityDatadog {
	if o == nil {
		return nil
	}
	return o.Severity
}

func (o *OutputDatadog) GetSite() *DatadogSite {
	if o == nil {
		return nil
	}
	return o.Site
}

func (o *OutputDatadog) GetSendCountersAsCount() *bool {
	if o == nil {
		return nil
	}
	return o.SendCountersAsCount
}

func (o *OutputDatadog) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputDatadog) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputDatadog) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputDatadog) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputDatadog) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputDatadog) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputDatadog) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputDatadog) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputDatadog) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputDatadog) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputDatadog) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputDatadog) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputDatadog) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputDatadog) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputDatadog) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputDatadog) GetAuthType() *components.AuthenticationMethodOptions2 {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputDatadog) GetTotalMemoryLimitKB() *float64 {
	if o == nil {
		return nil
	}
	return o.TotalMemoryLimitKB
}

func (o *OutputDatadog) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputDatadog) GetCustomURL() *string {
	if o == nil {
		return nil
	}
	return o.CustomURL
}

func (o *OutputDatadog) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputDatadog) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputDatadog) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputDatadog) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputDatadog) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputDatadog) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputDatadog) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputDatadog) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputDatadog) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputDatadog) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputDatadog) GetPqControls() *PqControlsDatadog {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputDatadog) GetAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.APIKey
}

func (o *OutputDatadog) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

type TypeSumoLogic string

const (
	TypeSumoLogicSumoLogic TypeSumoLogic = "sumo_logic"
)

func (e TypeSumoLogic) ToPointer() *TypeSumoLogic {
	return &e
}
func (e *TypeSumoLogic) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sumo_logic":
		*e = TypeSumoLogic(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeSumoLogic: %v", v)
	}
}

// DataFormatSumoLogic - Preserve the raw event format instead of JSONifying it
type DataFormatSumoLogic string

const (
	// DataFormatSumoLogicJSON JSON
	DataFormatSumoLogicJSON DataFormatSumoLogic = "json"
	// DataFormatSumoLogicRaw Raw
	DataFormatSumoLogicRaw DataFormatSumoLogic = "raw"
)

func (e DataFormatSumoLogic) ToPointer() *DataFormatSumoLogic {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *DataFormatSumoLogic) IsExact() bool {
	if e != nil {
		switch *e {
		case "json", "raw":
			return true
		}
	}
	return false
}

type PqControlsSumoLogic struct {
}

func (p PqControlsSumoLogic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsSumoLogic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputSumoLogic struct {
	// Unique ID for this output
	ID   string        `json:"id"`
	Type TypeSumoLogic `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Sumo Logic HTTP collector URL to which events should be sent
	URL string `json:"url"`
	// Override the source name configured on the Sumo Logic HTTP collector. This can also be overridden at the event level with the __sourceName field.
	CustomSource *string `json:"customSource,omitempty"`
	// Override the source category configured on the Sumo Logic HTTP collector. This can also be overridden at the event level with the __sourceCategory field.
	CustomCategory *string `json:"customCategory,omitempty"`
	// Preserve the raw event format instead of JSONifying it
	Format *DataFormatSumoLogic `json:"format,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsSumoLogic                 `json:"pqControls,omitempty"`
}

func (o OutputSumoLogic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSumoLogic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputSumoLogic) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputSumoLogic) GetType() TypeSumoLogic {
	if o == nil {
		return TypeSumoLogic("")
	}
	return o.Type
}

func (o *OutputSumoLogic) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputSumoLogic) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputSumoLogic) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputSumoLogic) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputSumoLogic) GetURL() string {
	if o == nil {
		return ""
	}
	return o.URL
}

func (o *OutputSumoLogic) GetCustomSource() *string {
	if o == nil {
		return nil
	}
	return o.CustomSource
}

func (o *OutputSumoLogic) GetCustomCategory() *string {
	if o == nil {
		return nil
	}
	return o.CustomCategory
}

func (o *OutputSumoLogic) GetFormat() *DataFormatSumoLogic {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputSumoLogic) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputSumoLogic) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputSumoLogic) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputSumoLogic) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputSumoLogic) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputSumoLogic) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputSumoLogic) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputSumoLogic) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputSumoLogic) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputSumoLogic) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputSumoLogic) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputSumoLogic) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputSumoLogic) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputSumoLogic) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputSumoLogic) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputSumoLogic) GetTotalMemoryLimitKB() *float64 {
	if o == nil {
		return nil
	}
	return o.TotalMemoryLimitKB
}

func (o *OutputSumoLogic) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputSumoLogic) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputSumoLogic) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputSumoLogic) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputSumoLogic) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputSumoLogic) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputSumoLogic) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputSumoLogic) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputSumoLogic) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputSumoLogic) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputSumoLogic) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputSumoLogic) GetPqControls() *PqControlsSumoLogic {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type CreateOutputTypeSnmp string

const (
	CreateOutputTypeSnmpSnmp CreateOutputTypeSnmp = "snmp"
)

func (e CreateOutputTypeSnmp) ToPointer() *CreateOutputTypeSnmp {
	return &e
}
func (e *CreateOutputTypeSnmp) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "snmp":
		*e = CreateOutputTypeSnmp(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeSnmp: %v", v)
	}
}

type HostSnmp struct {
	// Destination host
	Host string `json:"host"`
	// Destination port, default is 162
	Port float64 `json:"port"`
}

func (h HostSnmp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *HostSnmp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (h *HostSnmp) GetHost() string {
	if h == nil {
		return ""
	}
	return h.Host
}

func (h *HostSnmp) GetPort() float64 {
	if h == nil {
		return 0.0
	}
	return h.Port
}

type OutputSnmp struct {
	// Unique ID for this output
	ID   string               `json:"id"`
	Type CreateOutputTypeSnmp `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// One or more SNMP destinations to forward traps to
	Hosts []HostSnmp `json:"hosts"`
	// How often to resolve the destination hostname to an IP address. Ignored if all destinations are IP addresses. A value of 0 means every trap sent will incur a DNS lookup.
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	Description         *string  `json:"description,omitempty"`
}

func (o OutputSnmp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSnmp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputSnmp) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputSnmp) GetType() CreateOutputTypeSnmp {
	if o == nil {
		return CreateOutputTypeSnmp("")
	}
	return o.Type
}

func (o *OutputSnmp) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputSnmp) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputSnmp) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputSnmp) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputSnmp) GetHosts() []HostSnmp {
	if o == nil {
		return []HostSnmp{}
	}
	return o.Hosts
}

func (o *OutputSnmp) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputSnmp) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type CreateOutputTypeSqs string

const (
	CreateOutputTypeSqsSqs CreateOutputTypeSqs = "sqs"
)

func (e CreateOutputTypeSqs) ToPointer() *CreateOutputTypeSqs {
	return &e
}
func (e *CreateOutputTypeSqs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sqs":
		*e = CreateOutputTypeSqs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateOutputTypeSqs: %v", v)
	}
}

// CreateOutputQueueType - The queue type used (or created). Defaults to Standard.
type CreateOutputQueueType string

const (
	// CreateOutputQueueTypeStandard Standard
	CreateOutputQueueTypeStandard CreateOutputQueueType = "standard"
	// CreateOutputQueueTypeFifo FIFO
	CreateOutputQueueTypeFifo CreateOutputQueueType = "fifo"
)

func (e CreateOutputQueueType) ToPointer() *CreateOutputQueueType {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateOutputQueueType) IsExact() bool {
	if e != nil {
		switch *e {
		case "standard", "fifo":
			return true
		}
	}
	return false
}

type PqControlsSqs struct {
}

func (p PqControlsSqs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsSqs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputSqs struct {
	// Unique ID for this output
	ID   string              `json:"id"`
	Type CreateOutputTypeSqs `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The name, URL, or ARN of the SQS queue to send events to. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// The queue type used (or created). Defaults to Standard.
	QueueType CreateOutputQueueType `json:"queueType"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// This parameter applies only to FIFO queues. The tag that specifies that a message belongs to a specific message group. Messages that belong to the same message group are processed in a FIFO manner. Use event field __messageGroupId to override this value.
	MessageGroupID *string `json:"messageGroupId,omitempty"`
	// Create queue if it does not exist.
	CreateQueue *bool `json:"createQueue,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitempty"`
	AwsSecretKey            *string                                                `json:"awsSecretKey,omitempty"`
	// AWS Region where the SQS queue is located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// SQS service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to SQS-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing SQS requests
	SignatureVersion *components.SignatureVersionOptions3 `json:"signatureVersion,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Use Assume Role credentials to access SQS
	EnableAssumeRole *bool `json:"enableAssumeRole,omitempty"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitempty"`
	// Maximum number of queued batches before blocking.
	MaxQueueSize *float64 `json:"maxQueueSize,omitempty"`
	// Maximum size (KB) of batches to send. Per the SQS spec, the max allowed value is 256 KB.
	MaxRecordSizeKB *float64 `json:"maxRecordSizeKB,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// The maximum number of in-progress API requests before backpressure is applied.
	MaxInProgress *float64 `json:"maxInProgress,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	AwsAPIKey      *string                                 `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsSqs                       `json:"pqControls,omitempty"`
}

func (o OutputSqs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSqs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputSqs) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputSqs) GetType() CreateOutputTypeSqs {
	if o == nil {
		return CreateOutputTypeSqs("")
	}
	return o.Type
}

func (o *OutputSqs) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputSqs) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputSqs) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputSqs) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputSqs) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *OutputSqs) GetQueueType() CreateOutputQueueType {
	if o == nil {
		return CreateOutputQueueType("")
	}
	return o.QueueType
}

func (o *OutputSqs) GetAwsAccountID() *string {
	if o == nil {
		return nil
	}
	return o.AwsAccountID
}

func (o *OutputSqs) GetMessageGroupID() *string {
	if o == nil {
		return nil
	}
	return o.MessageGroupID
}

func (o *OutputSqs) GetCreateQueue() *bool {
	if o == nil {
		return nil
	}
	return o.CreateQueue
}

func (o *OutputSqs) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputSqs) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputSqs) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *OutputSqs) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputSqs) GetSignatureVersion() *components.SignatureVersionOptions3 {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputSqs) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputSqs) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputSqs) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *OutputSqs) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *OutputSqs) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *OutputSqs) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *OutputSqs) GetMaxQueueSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxQueueSize
}

func (o *OutputSqs) GetMaxRecordSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRecordSizeKB
}

func (o *OutputSqs) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputSqs) GetMaxInProgress() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxInProgress
}

func (o *OutputSqs) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputSqs) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputSqs) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputSqs) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *OutputSqs) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputSqs) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputSqs) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputSqs) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputSqs) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputSqs) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputSqs) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputSqs) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputSqs) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputSqs) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputSqs) GetPqControls() *PqControlsSqs {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type TypeSns string

const (
	TypeSnsSns TypeSns = "sns"
)

func (e TypeSns) ToPointer() *TypeSns {
	return &e
}
func (e *TypeSns) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sns":
		*e = TypeSns(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeSns: %v", v)
	}
}

// SignatureVersionSns - Signature version to use for signing SNS requests
type SignatureVersionSns string

const (
	SignatureVersionSnsV2 SignatureVersionSns = "v2"
	SignatureVersionSnsV4 SignatureVersionSns = "v4"
)

func (e SignatureVersionSns) ToPointer() *SignatureVersionSns {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *SignatureVersionSns) IsExact() bool {
	if e != nil {
		switch *e {
		case "v2", "v4":
			return true
		}
	}
	return false
}

type PqControlsSns struct {
}

func (p PqControlsSns) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsSns) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputSns struct {
	// Unique ID for this output
	ID   string  `json:"id"`
	Type TypeSns `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The ARN of the SNS topic to send events to. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. E.g., 'https://host:port/myQueueName'. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`
	TopicArn string `json:"topicArn"`
	// Messages in the same group are processed in a FIFO manner. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	MessageGroupID string `json:"messageGroupId"`
	// Maximum number of retries before the output returns an error. Note that not all errors are retryable. The retries use an exponential backoff policy.
	MaxRetries *float64 `json:"maxRetries,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitempty"`
	AwsSecretKey            *string                                                `json:"awsSecretKey,omitempty"`
	// Region where the SNS is located
	Region *string `json:"region,omitempty"`
	// SNS service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to SNS-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing SNS requests
	SignatureVersion *SignatureVersionSns `json:"signatureVersion,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Use Assume Role credentials to access SNS
	EnableAssumeRole *bool `json:"enableAssumeRole,omitempty"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	AwsAPIKey      *string                                 `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsSns                       `json:"pqControls,omitempty"`
}

func (o OutputSns) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSns) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputSns) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputSns) GetType() TypeSns {
	if o == nil {
		return TypeSns("")
	}
	return o.Type
}

func (o *OutputSns) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputSns) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputSns) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputSns) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputSns) GetTopicArn() string {
	if o == nil {
		return ""
	}
	return o.TopicArn
}

func (o *OutputSns) GetMessageGroupID() string {
	if o == nil {
		return ""
	}
	return o.MessageGroupID
}

func (o *OutputSns) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *OutputSns) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputSns) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputSns) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *OutputSns) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputSns) GetSignatureVersion() *SignatureVersionSns {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputSns) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputSns) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputSns) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *OutputSns) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *OutputSns) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *OutputSns) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *OutputSns) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputSns) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputSns) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputSns) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *OutputSns) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputSns) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputSns) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputSns) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputSns) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputSns) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputSns) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputSns) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputSns) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputSns) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputSns) GetPqControls() *PqControlsSns {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type TypeRouter string

const (
	TypeRouterRouter TypeRouter = "router"
)

func (e TypeRouter) ToPointer() *TypeRouter {
	return &e
}
func (e *TypeRouter) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "router":
		*e = TypeRouter(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeRouter: %v", v)
	}
}

type CreateOutputRule struct {
	// JavaScript expression to select events to send to output
	Filter string `json:"filter"`
	// Output to send matching events to
	Output string `json:"output"`
	// Description of this rule's purpose
	Description *string `json:"description,omitempty"`
	// Flag to control whether to stop the event from being checked against other rules
	Final *bool `json:"final,omitempty"`
}

func (c CreateOutputRule) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateOutputRule) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *CreateOutputRule) GetFilter() string {
	if c == nil {
		return ""
	}
	return c.Filter
}

func (c *CreateOutputRule) GetOutput() string {
	if c == nil {
		return ""
	}
	return c.Output
}

func (c *CreateOutputRule) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *CreateOutputRule) GetFinal() *bool {
	if c == nil {
		return nil
	}
	return c.Final
}

type OutputRouter struct {
	// Unique ID for this output
	ID   string     `json:"id"`
	Type TypeRouter `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Event routing rules
	Rules       []CreateOutputRule `json:"rules"`
	Description *string            `json:"description,omitempty"`
}

func (o OutputRouter) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputRouter) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputRouter) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputRouter) GetType() TypeRouter {
	if o == nil {
		return TypeRouter("")
	}
	return o.Type
}

func (o *OutputRouter) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputRouter) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputRouter) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputRouter) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputRouter) GetRules() []CreateOutputRule {
	if o == nil {
		return []CreateOutputRule{}
	}
	return o.Rules
}

func (o *OutputRouter) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type TypeGraphite string

const (
	TypeGraphiteGraphite TypeGraphite = "graphite"
)

func (e TypeGraphite) ToPointer() *TypeGraphite {
	return &e
}
func (e *TypeGraphite) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "graphite":
		*e = TypeGraphite(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeGraphite: %v", v)
	}
}

type PqControlsGraphite struct {
}

func (p PqControlsGraphite) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsGraphite) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputGraphite struct {
	// Unique ID for this output
	ID   string       `json:"id"`
	Type TypeGraphite `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Protocol to use when communicating with the destination.
	Protocol components.DestinationProtocolOptions `json:"protocol"`
	// The hostname of the destination.
	Host string `json:"host"`
	// Destination port.
	Port float64 `json:"port"`
	// When protocol is UDP, specifies the maximum size of packets sent to the destination. Also known as the MTU for the network path to the destination system.
	Mtu *float64 `json:"mtu,omitempty"`
	// When protocol is TCP, specifies how often buffers should be flushed, resulting in records sent to the destination.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every batch sent will incur a DNS lookup.
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	Description         *string  `json:"description,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `json:"throttleRatePerSec,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64 `json:"writeTimeout,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsGraphite                  `json:"pqControls,omitempty"`
}

func (o OutputGraphite) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGraphite) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputGraphite) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputGraphite) GetType() TypeGraphite {
	if o == nil {
		return TypeGraphite("")
	}
	return o.Type
}

func (o *OutputGraphite) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputGraphite) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputGraphite) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputGraphite) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputGraphite) GetProtocol() components.DestinationProtocolOptions {
	if o == nil {
		return components.DestinationProtocolOptions("")
	}
	return o.Protocol
}

func (o *OutputGraphite) GetHost() string {
	if o == nil {
		return ""
	}
	return o.Host
}

func (o *OutputGraphite) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *OutputGraphite) GetMtu() *float64 {
	if o == nil {
		return nil
	}
	return o.Mtu
}

func (o *OutputGraphite) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputGraphite) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputGraphite) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputGraphite) GetThrottleRatePerSec() *string {
	if o == nil {
		return nil
	}
	return o.ThrottleRatePerSec
}

func (o *OutputGraphite) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputGraphite) GetWriteTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteTimeout
}

func (o *OutputGraphite) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputGraphite) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputGraphite) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputGraphite) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputGraphite) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputGraphite) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputGraphite) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputGraphite) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputGraphite) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputGraphite) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputGraphite) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputGraphite) GetPqControls() *PqControlsGraphite {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type TypeStatsdExt string

const (
	TypeStatsdExtStatsdExt TypeStatsdExt = "statsd_ext"
)

func (e TypeStatsdExt) ToPointer() *TypeStatsdExt {
	return &e
}
func (e *TypeStatsdExt) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "statsd_ext":
		*e = TypeStatsdExt(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeStatsdExt: %v", v)
	}
}

type PqControlsStatsdExt struct {
}

func (p PqControlsStatsdExt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsStatsdExt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputStatsdExt struct {
	// Unique ID for this output
	ID   string        `json:"id"`
	Type TypeStatsdExt `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Protocol to use when communicating with the destination.
	Protocol components.DestinationProtocolOptions `json:"protocol"`
	// The hostname of the destination.
	Host string `json:"host"`
	// Destination port.
	Port float64 `json:"port"`
	// When protocol is UDP, specifies the maximum size of packets sent to the destination. Also known as the MTU for the network path to the destination system.
	Mtu *float64 `json:"mtu,omitempty"`
	// When protocol is TCP, specifies how often buffers should be flushed, resulting in records sent to the destination.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every batch sent will incur a DNS lookup.
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	Description         *string  `json:"description,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `json:"throttleRatePerSec,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64 `json:"writeTimeout,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsStatsdExt                 `json:"pqControls,omitempty"`
}

func (o OutputStatsdExt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputStatsdExt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputStatsdExt) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputStatsdExt) GetType() TypeStatsdExt {
	if o == nil {
		return TypeStatsdExt("")
	}
	return o.Type
}

func (o *OutputStatsdExt) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputStatsdExt) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputStatsdExt) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputStatsdExt) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputStatsdExt) GetProtocol() components.DestinationProtocolOptions {
	if o == nil {
		return components.DestinationProtocolOptions("")
	}
	return o.Protocol
}

func (o *OutputStatsdExt) GetHost() string {
	if o == nil {
		return ""
	}
	return o.Host
}

func (o *OutputStatsdExt) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *OutputStatsdExt) GetMtu() *float64 {
	if o == nil {
		return nil
	}
	return o.Mtu
}

func (o *OutputStatsdExt) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputStatsdExt) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputStatsdExt) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputStatsdExt) GetThrottleRatePerSec() *string {
	if o == nil {
		return nil
	}
	return o.ThrottleRatePerSec
}

func (o *OutputStatsdExt) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputStatsdExt) GetWriteTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteTimeout
}

func (o *OutputStatsdExt) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputStatsdExt) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputStatsdExt) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputStatsdExt) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputStatsdExt) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputStatsdExt) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputStatsdExt) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputStatsdExt) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputStatsdExt) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputStatsdExt) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputStatsdExt) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputStatsdExt) GetPqControls() *PqControlsStatsdExt {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type TypeStatsd string

const (
	TypeStatsdStatsd TypeStatsd = "statsd"
)

func (e TypeStatsd) ToPointer() *TypeStatsd {
	return &e
}
func (e *TypeStatsd) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "statsd":
		*e = TypeStatsd(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeStatsd: %v", v)
	}
}

type PqControlsStatsd struct {
}

func (p PqControlsStatsd) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsStatsd) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputStatsd struct {
	// Unique ID for this output
	ID   string     `json:"id"`
	Type TypeStatsd `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Protocol to use when communicating with the destination.
	Protocol components.DestinationProtocolOptions `json:"protocol"`
	// The hostname of the destination.
	Host string `json:"host"`
	// Destination port.
	Port float64 `json:"port"`
	// When protocol is UDP, specifies the maximum size of packets sent to the destination. Also known as the MTU for the network path to the destination system.
	Mtu *float64 `json:"mtu,omitempty"`
	// When protocol is TCP, specifies how often buffers should be flushed, resulting in records sent to the destination.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every batch sent will incur a DNS lookup.
	DNSResolvePeriodSec *float64 `json:"dnsResolvePeriodSec,omitempty"`
	Description         *string  `json:"description,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `json:"throttleRatePerSec,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `json:"connectionTimeout,omitempty"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64 `json:"writeTimeout,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsStatsd                    `json:"pqControls,omitempty"`
}

func (o OutputStatsd) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputStatsd) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputStatsd) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputStatsd) GetType() TypeStatsd {
	if o == nil {
		return TypeStatsd("")
	}
	return o.Type
}

func (o *OutputStatsd) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputStatsd) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputStatsd) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputStatsd) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputStatsd) GetProtocol() components.DestinationProtocolOptions {
	if o == nil {
		return components.DestinationProtocolOptions("")
	}
	return o.Protocol
}

func (o *OutputStatsd) GetHost() string {
	if o == nil {
		return ""
	}
	return o.Host
}

func (o *OutputStatsd) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *OutputStatsd) GetMtu() *float64 {
	if o == nil {
		return nil
	}
	return o.Mtu
}

func (o *OutputStatsd) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputStatsd) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputStatsd) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputStatsd) GetThrottleRatePerSec() *string {
	if o == nil {
		return nil
	}
	return o.ThrottleRatePerSec
}

func (o *OutputStatsd) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputStatsd) GetWriteTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteTimeout
}

func (o *OutputStatsd) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputStatsd) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputStatsd) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputStatsd) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputStatsd) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputStatsd) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputStatsd) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputStatsd) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputStatsd) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputStatsd) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputStatsd) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputStatsd) GetPqControls() *PqControlsStatsd {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type TypeMinio string

const (
	TypeMinioMinio TypeMinio = "minio"
)

func (e TypeMinio) ToPointer() *TypeMinio {
	return &e
}
func (e *TypeMinio) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "minio":
		*e = TypeMinio(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeMinio: %v", v)
	}
}

type OutputMinio struct {
	// Unique ID for this output
	ID   string    `json:"id"`
	Type TypeMinio `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// MinIO service url (e.g. http://minioHost:9000)
	Endpoint string `json:"endpoint"`
	// Name of the destination MinIO bucket. This value can be a constant or a JavaScript expression that can only be evaluated at init time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
	Bucket string `json:"bucket"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitempty"`
	// Secret key. This value can be a constant or a JavaScript expression, such as `${C.env.SOME_SECRET}`).
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	// Region where the MinIO service/cluster is located
	Region *string `json:"region,omitempty"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
	StagePath string `json:"stagePath"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Root directory to prepend to path before uploading. Enter a constant, or a JavaScript expression enclosed in quotes or backticks.
	DestPath *string `json:"destPath,omitempty"`
	// Signature version to use for signing MinIO requests
	SignatureVersion *components.SignatureVersionOptions5 `json:"signatureVersion,omitempty"`
	// Object ACL to assign to uploaded objects
	ObjectACL *components.ObjectACLOptions `json:"objectACL,omitempty"`
	// Storage class to select for uploaded objects
	StorageClass *components.StorageClassOptions2 `json:"storageClass,omitempty"`
	// Server-side encryption for uploaded objects
	ServerSideEncryption *components.ServerSideEncryptionOptions `json:"serverSideEncryption,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates)
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Disable if you can access files within the bucket but not the bucket itself
	VerifyPermissions *bool `json:"verifyPermissions,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
	PartitionExpr *string `json:"partitionExpr,omitempty"`
	// Format of the output data
	Format *components.DataFormatOptions `json:"format,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `json:"baseFileName,omitempty"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `json:"fileNameSuffix,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `json:"maxFileSizeMB,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `json:"maxOpenFiles,omitempty"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `json:"headerLine,omitempty"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `json:"writeHighWaterMark,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions1 `json:"onBackpressure,omitempty"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `json:"deadletterEnabled,omitempty"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *components.DiskSpaceProtectionOptions `json:"onDiskFullBackpressure,omitempty"`
	// Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
	ForceCloseOnShutdown *bool                         `json:"forceCloseOnShutdown,omitempty"`
	RetrySettings        *components.RetrySettingsType `json:"retrySettings,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *float64 `json:"maxConcurrentFileParts,omitempty"`
	Description            *string  `json:"description,omitempty"`
	// This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Data compression format to apply to HTTP content before it is delivered
	Compress *components.CompressionOptions2 `json:"compress,omitempty"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *components.CompressionLevelOptions `json:"compressionLevel,omitempty"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `json:"automaticSchema,omitempty"`
	// To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
	ParquetSchema *string `json:"parquetSchema,omitempty"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *components.ParquetVersionOptions `json:"parquetVersion,omitempty"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *components.DataPageVersionOptions `json:"parquetDataPageVersion,omitempty"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `json:"parquetRowGroupLength,omitempty"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
	KeyValueMetadata []components.ItemsTypeKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `json:"enableStatistics,omitempty"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `json:"enableWritePageIndex,omitempty"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `json:"enablePageChecksum,omitempty"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `json:"emptyDirCleanupSec,omitempty"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `json:"directoryBatchSize,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `json:"deadletterPath,omitempty"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `json:"maxRetryNum,omitempty"`
}

func (o OutputMinio) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputMinio) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputMinio) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputMinio) GetType() TypeMinio {
	if o == nil {
		return TypeMinio("")
	}
	return o.Type
}

func (o *OutputMinio) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputMinio) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputMinio) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputMinio) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputMinio) GetEndpoint() string {
	if o == nil {
		return ""
	}
	return o.Endpoint
}

func (o *OutputMinio) GetBucket() string {
	if o == nil {
		return ""
	}
	return o.Bucket
}

func (o *OutputMinio) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputMinio) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputMinio) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *OutputMinio) GetStagePath() string {
	if o == nil {
		return ""
	}
	return o.StagePath
}

func (o *OutputMinio) GetAddIDToStagePath() *bool {
	if o == nil {
		return nil
	}
	return o.AddIDToStagePath
}

func (o *OutputMinio) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

func (o *OutputMinio) GetSignatureVersion() *components.SignatureVersionOptions5 {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputMinio) GetObjectACL() *components.ObjectACLOptions {
	if o == nil {
		return nil
	}
	return o.ObjectACL
}

func (o *OutputMinio) GetStorageClass() *components.StorageClassOptions2 {
	if o == nil {
		return nil
	}
	return o.StorageClass
}

func (o *OutputMinio) GetServerSideEncryption() *components.ServerSideEncryptionOptions {
	if o == nil {
		return nil
	}
	return o.ServerSideEncryption
}

func (o *OutputMinio) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputMinio) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputMinio) GetVerifyPermissions() *bool {
	if o == nil {
		return nil
	}
	return o.VerifyPermissions
}

func (o *OutputMinio) GetRemoveEmptyDirs() *bool {
	if o == nil {
		return nil
	}
	return o.RemoveEmptyDirs
}

func (o *OutputMinio) GetPartitionExpr() *string {
	if o == nil {
		return nil
	}
	return o.PartitionExpr
}

func (o *OutputMinio) GetFormat() *components.DataFormatOptions {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputMinio) GetBaseFileName() *string {
	if o == nil {
		return nil
	}
	return o.BaseFileName
}

func (o *OutputMinio) GetFileNameSuffix() *string {
	if o == nil {
		return nil
	}
	return o.FileNameSuffix
}

func (o *OutputMinio) GetMaxFileSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileSizeMB
}

func (o *OutputMinio) GetMaxOpenFiles() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxOpenFiles
}

func (o *OutputMinio) GetHeaderLine() *string {
	if o == nil {
		return nil
	}
	return o.HeaderLine
}

func (o *OutputMinio) GetWriteHighWaterMark() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteHighWaterMark
}

func (o *OutputMinio) GetOnBackpressure() *components.BackpressureBehaviorOptions1 {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputMinio) GetDeadletterEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.DeadletterEnabled
}

func (o *OutputMinio) GetOnDiskFullBackpressure() *components.DiskSpaceProtectionOptions {
	if o == nil {
		return nil
	}
	return o.OnDiskFullBackpressure
}

func (o *OutputMinio) GetForceCloseOnShutdown() *bool {
	if o == nil {
		return nil
	}
	return o.ForceCloseOnShutdown
}

func (o *OutputMinio) GetRetrySettings() *components.RetrySettingsType {
	if o == nil {
		return nil
	}
	return o.RetrySettings
}

func (o *OutputMinio) GetMaxFileOpenTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileOpenTimeSec
}

func (o *OutputMinio) GetMaxFileIdleTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileIdleTimeSec
}

func (o *OutputMinio) GetMaxConcurrentFileParts() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentFileParts
}

func (o *OutputMinio) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputMinio) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputMinio) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *OutputMinio) GetCompress() *components.CompressionOptions2 {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputMinio) GetCompressionLevel() *components.CompressionLevelOptions {
	if o == nil {
		return nil
	}
	return o.CompressionLevel
}

func (o *OutputMinio) GetAutomaticSchema() *bool {
	if o == nil {
		return nil
	}
	return o.AutomaticSchema
}

func (o *OutputMinio) GetParquetSchema() *string {
	if o == nil {
		return nil
	}
	return o.ParquetSchema
}

func (o *OutputMinio) GetParquetVersion() *components.ParquetVersionOptions {
	if o == nil {
		return nil
	}
	return o.ParquetVersion
}

func (o *OutputMinio) GetParquetDataPageVersion() *components.DataPageVersionOptions {
	if o == nil {
		return nil
	}
	return o.ParquetDataPageVersion
}

func (o *OutputMinio) GetParquetRowGroupLength() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetRowGroupLength
}

func (o *OutputMinio) GetParquetPageSize() *string {
	if o == nil {
		return nil
	}
	return o.ParquetPageSize
}

func (o *OutputMinio) GetShouldLogInvalidRows() *bool {
	if o == nil {
		return nil
	}
	return o.ShouldLogInvalidRows
}

func (o *OutputMinio) GetKeyValueMetadata() []components.ItemsTypeKeyValueMetadata {
	if o == nil {
		return nil
	}
	return o.KeyValueMetadata
}

func (o *OutputMinio) GetEnableStatistics() *bool {
	if o == nil {
		return nil
	}
	return o.EnableStatistics
}

func (o *OutputMinio) GetEnableWritePageIndex() *bool {
	if o == nil {
		return nil
	}
	return o.EnableWritePageIndex
}

func (o *OutputMinio) GetEnablePageChecksum() *bool {
	if o == nil {
		return nil
	}
	return o.EnablePageChecksum
}

func (o *OutputMinio) GetEmptyDirCleanupSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EmptyDirCleanupSec
}

func (o *OutputMinio) GetDirectoryBatchSize() *float64 {
	if o == nil {
		return nil
	}
	return o.DirectoryBatchSize
}

func (o *OutputMinio) GetDeadletterPath() *string {
	if o == nil {
		return nil
	}
	return o.DeadletterPath
}

func (o *OutputMinio) GetMaxRetryNum() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetryNum
}

type TypeCloudwatch string

const (
	TypeCloudwatchCloudwatch TypeCloudwatch = "cloudwatch"
)

func (e TypeCloudwatch) ToPointer() *TypeCloudwatch {
	return &e
}
func (e *TypeCloudwatch) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cloudwatch":
		*e = TypeCloudwatch(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCloudwatch: %v", v)
	}
}

type PqControlsCloudwatch struct {
}

func (p PqControlsCloudwatch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsCloudwatch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputCloudwatch struct {
	// Unique ID for this output
	ID   string         `json:"id"`
	Type TypeCloudwatch `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// CloudWatch log group to associate events with
	LogGroupName string `json:"logGroupName"`
	// Prefix for CloudWatch log stream name. This prefix will be used to generate a unique log stream name per cribl instance, for example: myStream_myHost_myOutputId
	LogStreamName string `json:"logStreamName"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitempty"`
	AwsSecretKey            *string                                                `json:"awsSecretKey,omitempty"`
	// Region where the CloudWatchLogs is located
	Region string `json:"region"`
	// CloudWatchLogs service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to CloudWatchLogs-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Use Assume Role credentials to access CloudWatchLogs
	EnableAssumeRole *bool `json:"enableAssumeRole,omitempty"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitempty"`
	// Maximum number of queued batches before blocking
	MaxQueueSize *float64 `json:"maxQueueSize,omitempty"`
	// Maximum size (KB) of each individual record before compression. For non compressible data 1MB is the max recommended size
	MaxRecordSizeKB *float64 `json:"maxRecordSizeKB,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	Description    *string                                 `json:"description,omitempty"`
	AwsAPIKey      *string                                 `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsCloudwatch                `json:"pqControls,omitempty"`
}

func (o OutputCloudwatch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCloudwatch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputCloudwatch) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputCloudwatch) GetType() TypeCloudwatch {
	if o == nil {
		return TypeCloudwatch("")
	}
	return o.Type
}

func (o *OutputCloudwatch) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputCloudwatch) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputCloudwatch) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputCloudwatch) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputCloudwatch) GetLogGroupName() string {
	if o == nil {
		return ""
	}
	return o.LogGroupName
}

func (o *OutputCloudwatch) GetLogStreamName() string {
	if o == nil {
		return ""
	}
	return o.LogStreamName
}

func (o *OutputCloudwatch) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputCloudwatch) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputCloudwatch) GetRegion() string {
	if o == nil {
		return ""
	}
	return o.Region
}

func (o *OutputCloudwatch) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputCloudwatch) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputCloudwatch) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputCloudwatch) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *OutputCloudwatch) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *OutputCloudwatch) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *OutputCloudwatch) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *OutputCloudwatch) GetMaxQueueSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxQueueSize
}

func (o *OutputCloudwatch) GetMaxRecordSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRecordSizeKB
}

func (o *OutputCloudwatch) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputCloudwatch) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputCloudwatch) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputCloudwatch) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputCloudwatch) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *OutputCloudwatch) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputCloudwatch) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputCloudwatch) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputCloudwatch) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputCloudwatch) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputCloudwatch) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputCloudwatch) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputCloudwatch) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputCloudwatch) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputCloudwatch) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputCloudwatch) GetPqControls() *PqControlsCloudwatch {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type TypeInfluxdb string

const (
	TypeInfluxdbInfluxdb TypeInfluxdb = "influxdb"
)

func (e TypeInfluxdb) ToPointer() *TypeInfluxdb {
	return &e
}
func (e *TypeInfluxdb) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "influxdb":
		*e = TypeInfluxdb(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeInfluxdb: %v", v)
	}
}

// TimestampPrecision - Sets the precision for the supplied Unix time values. Defaults to milliseconds.
type TimestampPrecision string

const (
	// TimestampPrecisionNs Nanoseconds
	TimestampPrecisionNs TimestampPrecision = "ns"
	// TimestampPrecisionU Microseconds
	TimestampPrecisionU TimestampPrecision = "u"
	// TimestampPrecisionMs Milliseconds
	TimestampPrecisionMs TimestampPrecision = "ms"
	// TimestampPrecisionS Seconds
	TimestampPrecisionS TimestampPrecision = "s"
	// TimestampPrecisionM Minutes
	TimestampPrecisionM TimestampPrecision = "m"
	// TimestampPrecisionH Hours
	TimestampPrecisionH TimestampPrecision = "h"
)

func (e TimestampPrecision) ToPointer() *TimestampPrecision {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *TimestampPrecision) IsExact() bool {
	if e != nil {
		switch *e {
		case "ns", "u", "ms", "s", "m", "h":
			return true
		}
	}
	return false
}

// AuthenticationTypeInfluxdb - InfluxDB authentication type
type AuthenticationTypeInfluxdb string

const (
	AuthenticationTypeInfluxdbNone              AuthenticationTypeInfluxdb = "none"
	AuthenticationTypeInfluxdbBasic             AuthenticationTypeInfluxdb = "basic"
	AuthenticationTypeInfluxdbCredentialsSecret AuthenticationTypeInfluxdb = "credentialsSecret"
	AuthenticationTypeInfluxdbToken             AuthenticationTypeInfluxdb = "token"
	AuthenticationTypeInfluxdbTextSecret        AuthenticationTypeInfluxdb = "textSecret"
	AuthenticationTypeInfluxdbOauth             AuthenticationTypeInfluxdb = "oauth"
)

func (e AuthenticationTypeInfluxdb) ToPointer() *AuthenticationTypeInfluxdb {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *AuthenticationTypeInfluxdb) IsExact() bool {
	if e != nil {
		switch *e {
		case "none", "basic", "credentialsSecret", "token", "textSecret", "oauth":
			return true
		}
	}
	return false
}

type PqControlsInfluxdb struct {
}

func (p PqControlsInfluxdb) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsInfluxdb) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputInfluxdb struct {
	// Unique ID for this output
	ID   string       `json:"id"`
	Type TypeInfluxdb `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// URL of an InfluxDB cluster to send events to, e.g., http://localhost:8086/write
	URL string `json:"url"`
	// The v2 API can be enabled with InfluxDB versions 1.8 and later.
	UseV2API *bool `json:"useV2API,omitempty"`
	// Sets the precision for the supplied Unix time values. Defaults to milliseconds.
	TimestampPrecision *TimestampPrecision `json:"timestampPrecision,omitempty"`
	// Enabling this will pull the value field from the metric name. E,g, 'db.query.user' will use 'db.query' as the measurement and 'user' as the value field.
	DynamicValueFieldName *bool `json:"dynamicValueFieldName,omitempty"`
	// Name of the field in which to store the metric when sending to InfluxDB. If dynamic generation is enabled and fails, this will be used as a fallback.
	ValueFieldName *string `json:"valueFieldName,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// InfluxDB authentication type
	AuthType    *AuthenticationTypeInfluxdb `json:"authType,omitempty"`
	Description *string                     `json:"description,omitempty"`
	// Database to write to.
	Database *string `json:"database,omitempty"`
	// Bucket to write to.
	Bucket *string `json:"bucket,omitempty"`
	// Organization ID for this bucket.
	Org *string `json:"org,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsInfluxdb                  `json:"pqControls,omitempty"`
	Username         *string                              `json:"username,omitempty"`
	Password         *string                              `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `json:"authHeaderExpr,omitempty"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `json:"tokenTimeoutSecs,omitempty"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []components.ItemsTypeOauthParams `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []components.ItemsTypeOauthHeaders `json:"oauthHeaders,omitempty"`
}

func (o OutputInfluxdb) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputInfluxdb) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputInfluxdb) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputInfluxdb) GetType() TypeInfluxdb {
	if o == nil {
		return TypeInfluxdb("")
	}
	return o.Type
}

func (o *OutputInfluxdb) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputInfluxdb) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputInfluxdb) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputInfluxdb) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputInfluxdb) GetURL() string {
	if o == nil {
		return ""
	}
	return o.URL
}

func (o *OutputInfluxdb) GetUseV2API() *bool {
	if o == nil {
		return nil
	}
	return o.UseV2API
}

func (o *OutputInfluxdb) GetTimestampPrecision() *TimestampPrecision {
	if o == nil {
		return nil
	}
	return o.TimestampPrecision
}

func (o *OutputInfluxdb) GetDynamicValueFieldName() *bool {
	if o == nil {
		return nil
	}
	return o.DynamicValueFieldName
}

func (o *OutputInfluxdb) GetValueFieldName() *string {
	if o == nil {
		return nil
	}
	return o.ValueFieldName
}

func (o *OutputInfluxdb) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputInfluxdb) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputInfluxdb) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputInfluxdb) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputInfluxdb) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputInfluxdb) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputInfluxdb) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputInfluxdb) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputInfluxdb) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputInfluxdb) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputInfluxdb) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputInfluxdb) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputInfluxdb) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputInfluxdb) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputInfluxdb) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputInfluxdb) GetAuthType() *AuthenticationTypeInfluxdb {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputInfluxdb) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputInfluxdb) GetDatabase() *string {
	if o == nil {
		return nil
	}
	return o.Database
}

func (o *OutputInfluxdb) GetBucket() *string {
	if o == nil {
		return nil
	}
	return o.Bucket
}

func (o *OutputInfluxdb) GetOrg() *string {
	if o == nil {
		return nil
	}
	return o.Org
}

func (o *OutputInfluxdb) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputInfluxdb) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputInfluxdb) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputInfluxdb) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputInfluxdb) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputInfluxdb) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputInfluxdb) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputInfluxdb) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputInfluxdb) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputInfluxdb) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputInfluxdb) GetPqControls() *PqControlsInfluxdb {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputInfluxdb) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *OutputInfluxdb) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *OutputInfluxdb) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputInfluxdb) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *OutputInfluxdb) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputInfluxdb) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *OutputInfluxdb) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *OutputInfluxdb) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *OutputInfluxdb) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *OutputInfluxdb) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *OutputInfluxdb) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *OutputInfluxdb) GetOauthParams() []components.ItemsTypeOauthParams {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *OutputInfluxdb) GetOauthHeaders() []components.ItemsTypeOauthHeaders {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

type TypeNewrelicEvents string

const (
	TypeNewrelicEventsNewrelicEvents TypeNewrelicEvents = "newrelic_events"
)

func (e TypeNewrelicEvents) ToPointer() *TypeNewrelicEvents {
	return &e
}
func (e *TypeNewrelicEvents) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "newrelic_events":
		*e = TypeNewrelicEvents(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeNewrelicEvents: %v", v)
	}
}

type PqControlsNewrelicEvents struct {
}

func (p PqControlsNewrelicEvents) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsNewrelicEvents) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputNewrelicEvents struct {
	// Unique ID for this output
	ID   string             `json:"id"`
	Type TypeNewrelicEvents `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Which New Relic region endpoint to use.
	Region *components.RegionOptions `json:"region,omitempty"`
	// New Relic account ID
	AccountID string `json:"accountId"`
	// Default eventType to use when not present in an event. For more information, see [here](https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/#reserved-words).
	EventType string `json:"eventType"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `json:"concurrency,omitempty"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `json:"maxPayloadSizeKB,omitempty"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `json:"maxPayloadEvents,omitempty"`
	// Compress the payload body before sending
	Compress *bool `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `json:"flushPeriodSec,omitempty"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *components.FailedRequestLoggingModeOptions `json:"failedRequestLoggingMode,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []components.ItemsTypeResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *components.TimeoutRetrySettingsType        `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `json:"responseHonorRetryAfterHeader,omitempty"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *components.BackpressureBehaviorOptions `json:"onBackpressure,omitempty"`
	// Enter API key directly, or select a stored secret
	AuthType    *components.AuthenticationMethodOptions2 `json:"authType,omitempty"`
	Description *string                                  `json:"description,omitempty"`
	CustomURL   *string                                  `json:"customUrl,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `json:"pqRatePerSec,omitempty"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *components.ModeOptions `json:"pqMode,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `json:"pqMaxBufferSize,omitempty"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `json:"pqMaxBackpressureSec,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Codec to use to compress the persisted data
	PqCompress *components.CompressionOptionsPq `json:"pqCompress,omitempty"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *components.QueueFullBehaviorOptions `json:"pqOnBackpressure,omitempty"`
	PqControls       *PqControlsNewrelicEvents            `json:"pqControls,omitempty"`
	// New Relic API key. Can be overridden using __newRelic_apiKey field.
	APIKey *string `json:"apiKey,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
}

func (o OutputNewrelicEvents) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputNewrelicEvents) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputNewrelicEvents) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputNewrelicEvents) GetType() TypeNewrelicEvents {
	if o == nil {
		return TypeNewrelicEvents("")
	}
	return o.Type
}

func (o *OutputNewrelicEvents) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputNewrelicEvents) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputNewrelicEvents) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputNewrelicEvents) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputNewrelicEvents) GetRegion() *components.RegionOptions {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *OutputNewrelicEvents) GetAccountID() string {
	if o == nil {
		return ""
	}
	return o.AccountID
}

func (o *OutputNewrelicEvents) GetEventType() string {
	if o == nil {
		return ""
	}
	return o.EventType
}

func (o *OutputNewrelicEvents) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputNewrelicEvents) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputNewrelicEvents) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputNewrelicEvents) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputNewrelicEvents) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputNewrelicEvents) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputNewrelicEvents) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputNewrelicEvents) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputNewrelicEvents) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputNewrelicEvents) GetFailedRequestLoggingMode() *components.FailedRequestLoggingModeOptions {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputNewrelicEvents) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputNewrelicEvents) GetResponseRetrySettings() []components.ItemsTypeResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputNewrelicEvents) GetTimeoutRetrySettings() *components.TimeoutRetrySettingsType {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputNewrelicEvents) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputNewrelicEvents) GetOnBackpressure() *components.BackpressureBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputNewrelicEvents) GetAuthType() *components.AuthenticationMethodOptions2 {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputNewrelicEvents) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputNewrelicEvents) GetCustomURL() *string {
	if o == nil {
		return nil
	}
	return o.CustomURL
}

func (o *OutputNewrelicEvents) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputNewrelicEvents) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputNewrelicEvents) GetPqMode() *components.ModeOptions {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputNewrelicEvents) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputNewrelicEvents) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputNewrelicEvents) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputNewrelicEvents) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputNewrelicEvents) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputNewrelicEvents) GetPqCompress() *components.CompressionOptionsPq {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputNewrelicEvents) GetPqOnBackpressure() *components.QueueFullBehaviorOptions {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputNewrelicEvents) GetPqControls() *PqControlsNewrelicEvents {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputNewrelicEvents) GetAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.APIKey
}

func (o *OutputNewrelicEvents) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

type TypeNewrelic string

const (
	TypeNewrelicNewrelic TypeNewrelic = "newrelic"
)

func (e TypeNewrelic) ToPointer() *TypeNewrelic {
	return &e
}
func (e *TypeNewrelic) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "newrelic":
		*e = TypeNewrelic(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeNewrelic: %v", v)
	}
}

type FieldName string

const (
	FieldNameService   FieldName = "service"
	FieldNameHostname  FieldName = "hostname"
	FieldNameTimestamp FieldName = "timestamp"
	FieldNameAuditID   FieldName = "auditId"
)

func (e FieldName) ToPointer() *FieldName {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *FieldName) IsExact() bool {
	if e != nil {
		switch *e {
		case "service", "hostname", "timestamp", "auditId":
			return true
		}
	}
	return false
}

type Metadatum struct {
	Name FieldName `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (m Metadatum) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *Metadatum) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (m *Metadatum) GetName() FieldName {
	if m == nil {
		return FieldName("")
	}
	return m.Name
}

func (m *Metadatum) GetValue() string {
	if m == nil {
		return ""
	}
	return m.Value
}

type PqControlsNewrelic struct {
}

func (p PqControlsNewrelic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqControlsNewrelic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}
