// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package operations

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/criblio/cribl-control-plane-sdk-go/internal/utils"
	"github.com/criblio/cribl-control-plane-sdk-go/models/components"
)

type CreateInputTypeCriblHTTP string

const (
	CreateInputTypeCriblHTTPCriblHTTP CreateInputTypeCriblHTTP = "cribl_http"
)

func (e CreateInputTypeCriblHTTP) ToPointer() *CreateInputTypeCriblHTTP {
	return &e
}
func (e *CreateInputTypeCriblHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_http":
		*e = CreateInputTypeCriblHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeCriblHTTP: %v", v)
	}
}

type InputCriblHTTP struct {
	// Unique ID for this input
	ID       string                   `json:"id"`
	Type     CreateInputTypeCriblHTTP `json:"type"`
	Disabled *bool                    `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be used by connected environments to authorize connections. These tokens should be installed in Cribl HTTP destinations in connected environments.
	AuthTokens []components.ItemsTypeAuthTokens      `json:"authTokens,omitzero"`
	TLS        *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `json:"maxActiveReq,omitzero"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `json:"maxRequestsPerSocket,omitzero"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `json:"captureHeaders,omitzero"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `json:"activityLogSampleRate,omitzero"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitzero"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `json:"enableHealthCheck,omitzero"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `json:"ipAllowlistRegex,omitzero"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `json:"ipDenylistRegex,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
}

func (i InputCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputCriblHTTP) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputCriblHTTP) GetType() CreateInputTypeCriblHTTP {
	if i == nil {
		return CreateInputTypeCriblHTTP("")
	}
	return i.Type
}

func (i *InputCriblHTTP) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputCriblHTTP) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputCriblHTTP) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputCriblHTTP) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputCriblHTTP) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputCriblHTTP) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputCriblHTTP) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputCriblHTTP) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputCriblHTTP) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputCriblHTTP) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputCriblHTTP) GetAuthTokens() []components.ItemsTypeAuthTokens {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputCriblHTTP) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputCriblHTTP) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputCriblHTTP) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputCriblHTTP) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputCriblHTTP) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputCriblHTTP) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputCriblHTTP) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputCriblHTTP) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputCriblHTTP) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputCriblHTTP) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputCriblHTTP) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputCriblHTTP) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputCriblHTTP) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputCriblHTTP) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type CreateInputTypeCriblTCP string

const (
	CreateInputTypeCriblTCPCriblTCP CreateInputTypeCriblTCP = "cribl_tcp"
)

func (e CreateInputTypeCriblTCP) ToPointer() *CreateInputTypeCriblTCP {
	return &e
}
func (e *CreateInputTypeCriblTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_tcp":
		*e = CreateInputTypeCriblTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeCriblTCP: %v", v)
	}
}

type InputCriblTCP struct {
	// Unique ID for this input
	ID       string                  `json:"id"`
	Type     CreateInputTypeCriblTCP `json:"type"`
	Disabled *bool                   `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64                               `json:"port"`
	TLS  *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `json:"maxActiveCxn,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `json:"socketIdleTimeout,omitzero"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `json:"socketEndingMaxWait,omitzero"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `json:"socketMaxLifespan,omitzero"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool `json:"enableLoadBalancing,omitzero"`
	// Shared secrets to be used by connected environments to authorize connections. These tokens should be installed in Cribl TCP destinations in connected environments.
	AuthTokens  []components.ItemsTypeAuthTokens `json:"authTokens,omitzero"`
	Description *string                          `json:"description,omitzero"`
}

func (i InputCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputCriblTCP) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputCriblTCP) GetType() CreateInputTypeCriblTCP {
	if i == nil {
		return CreateInputTypeCriblTCP("")
	}
	return i.Type
}

func (i *InputCriblTCP) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputCriblTCP) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputCriblTCP) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputCriblTCP) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputCriblTCP) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputCriblTCP) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputCriblTCP) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputCriblTCP) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputCriblTCP) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputCriblTCP) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputCriblTCP) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputCriblTCP) GetMaxActiveCxn() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveCxn
}

func (i *InputCriblTCP) GetSocketIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketIdleTimeout
}

func (i *InputCriblTCP) GetSocketEndingMaxWait() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketEndingMaxWait
}

func (i *InputCriblTCP) GetSocketMaxLifespan() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketMaxLifespan
}

func (i *InputCriblTCP) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputCriblTCP) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputCriblTCP) GetEnableLoadBalancing() *bool {
	if i == nil {
		return nil
	}
	return i.EnableLoadBalancing
}

func (i *InputCriblTCP) GetAuthTokens() []components.ItemsTypeAuthTokens {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputCriblTCP) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type TypeCribl string

const (
	TypeCriblCribl TypeCribl = "cribl"
)

func (e TypeCribl) ToPointer() *TypeCribl {
	return &e
}
func (e *TypeCribl) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl":
		*e = TypeCribl(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCribl: %v", v)
	}
}

type InputCribl struct {
	// Unique ID for this input
	ID       string    `json:"id"`
	Type     TypeCribl `json:"type"`
	Disabled *bool     `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	Filter      *string                                   `json:"filter,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
}

func (i InputCribl) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCribl) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputCribl) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputCribl) GetType() TypeCribl {
	if i == nil {
		return TypeCribl("")
	}
	return i.Type
}

func (i *InputCribl) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputCribl) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputCribl) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputCribl) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputCribl) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputCribl) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputCribl) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputCribl) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputCribl) GetFilter() *string {
	if i == nil {
		return nil
	}
	return i.Filter
}

func (i *InputCribl) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputCribl) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type CreateInputTypeGooglePubsub string

const (
	CreateInputTypeGooglePubsubGooglePubsub CreateInputTypeGooglePubsub = "google_pubsub"
)

func (e CreateInputTypeGooglePubsub) ToPointer() *CreateInputTypeGooglePubsub {
	return &e
}
func (e *CreateInputTypeGooglePubsub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "google_pubsub":
		*e = CreateInputTypeGooglePubsub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeGooglePubsub: %v", v)
	}
}

type InputGooglePubsub struct {
	// Unique ID for this input
	ID       string                      `json:"id"`
	Type     CreateInputTypeGooglePubsub `json:"type"`
	Disabled *bool                       `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// ID of the topic to receive events from. When Monitor subscription is enabled, any value may be entered.
	TopicName string `json:"topicName"`
	// ID of the subscription to use when receiving events. When Monitor subscription is enabled, the fully qualified subscription name must be entered. Example: projects/myProject/subscriptions/mySubscription
	SubscriptionName string `json:"subscriptionName"`
	// Use when the subscription is not created by this Source and topic is not known
	MonitorSubscription *bool `json:"monitorSubscription,omitzero"`
	// Create topic if it does not exist
	CreateTopic *bool `json:"createTopic,omitzero"`
	// Create subscription if it does not exist
	CreateSubscription *bool `json:"createSubscription,omitzero"`
	// Region to retrieve messages from. Select 'default' to allow Google to auto-select the nearest region. When using ordered delivery, the selected region must be allowed by message storage policy.
	Region *string `json:"region,omitzero"`
	// Choose Auto to use Google Application Default Credentials (ADC), Manual to enter Google service account credentials directly, or Secret to select or create a stored secret that references Google service account credentials.
	GoogleAuthMethod *components.GoogleAuthenticationMethodOptions `json:"googleAuthMethod,omitzero"`
	// Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
	ServiceAccountCredentials *string `json:"serviceAccountCredentials,omitzero"`
	// Select or create a stored text secret
	Secret *string `json:"secret,omitzero"`
	// If Destination exerts backpressure, this setting limits how many inbound events Stream will queue for processing before it stops retrieving events
	MaxBacklog *float64 `json:"maxBacklog,omitzero"`
	// How many streams to pull messages from at one time. Doubling the value doubles the number of messages this Source pulls from the topic (if available), while consuming more CPU and memory. Defaults to 5.
	Concurrency *float64 `json:"concurrency,omitzero"`
	// Pull request timeout, in milliseconds
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
	// Receive events in the order they were added to the queue. The process sending events must have ordering enabled.
	OrderedDelivery *bool `json:"orderedDelivery,omitzero"`
}

func (i InputGooglePubsub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGooglePubsub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputGooglePubsub) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputGooglePubsub) GetType() CreateInputTypeGooglePubsub {
	if i == nil {
		return CreateInputTypeGooglePubsub("")
	}
	return i.Type
}

func (i *InputGooglePubsub) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputGooglePubsub) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputGooglePubsub) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputGooglePubsub) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputGooglePubsub) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputGooglePubsub) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputGooglePubsub) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputGooglePubsub) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputGooglePubsub) GetTopicName() string {
	if i == nil {
		return ""
	}
	return i.TopicName
}

func (i *InputGooglePubsub) GetSubscriptionName() string {
	if i == nil {
		return ""
	}
	return i.SubscriptionName
}

func (i *InputGooglePubsub) GetMonitorSubscription() *bool {
	if i == nil {
		return nil
	}
	return i.MonitorSubscription
}

func (i *InputGooglePubsub) GetCreateTopic() *bool {
	if i == nil {
		return nil
	}
	return i.CreateTopic
}

func (i *InputGooglePubsub) GetCreateSubscription() *bool {
	if i == nil {
		return nil
	}
	return i.CreateSubscription
}

func (i *InputGooglePubsub) GetRegion() *string {
	if i == nil {
		return nil
	}
	return i.Region
}

func (i *InputGooglePubsub) GetGoogleAuthMethod() *components.GoogleAuthenticationMethodOptions {
	if i == nil {
		return nil
	}
	return i.GoogleAuthMethod
}

func (i *InputGooglePubsub) GetServiceAccountCredentials() *string {
	if i == nil {
		return nil
	}
	return i.ServiceAccountCredentials
}

func (i *InputGooglePubsub) GetSecret() *string {
	if i == nil {
		return nil
	}
	return i.Secret
}

func (i *InputGooglePubsub) GetMaxBacklog() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBacklog
}

func (i *InputGooglePubsub) GetConcurrency() *float64 {
	if i == nil {
		return nil
	}
	return i.Concurrency
}

func (i *InputGooglePubsub) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputGooglePubsub) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputGooglePubsub) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputGooglePubsub) GetOrderedDelivery() *bool {
	if i == nil {
		return nil
	}
	return i.OrderedDelivery
}

type TypeFirehose string

const (
	TypeFirehoseFirehose TypeFirehose = "firehose"
)

func (e TypeFirehose) ToPointer() *TypeFirehose {
	return &e
}
func (e *TypeFirehose) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "firehose":
		*e = TypeFirehose(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeFirehose: %v", v)
	}
}

type InputFirehose struct {
	// Unique ID for this input
	ID       string       `json:"id"`
	Type     TypeFirehose `json:"type"`
	Disabled *bool        `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                              `json:"authTokens,omitzero"`
	TLS        *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `json:"maxActiveReq,omitzero"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `json:"maxRequestsPerSocket,omitzero"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `json:"captureHeaders,omitzero"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `json:"activityLogSampleRate,omitzero"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitzero"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `json:"enableHealthCheck,omitzero"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `json:"ipAllowlistRegex,omitzero"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `json:"ipDenylistRegex,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
}

func (i InputFirehose) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFirehose) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputFirehose) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputFirehose) GetType() TypeFirehose {
	if i == nil {
		return TypeFirehose("")
	}
	return i.Type
}

func (i *InputFirehose) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputFirehose) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputFirehose) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputFirehose) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputFirehose) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputFirehose) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputFirehose) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputFirehose) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputFirehose) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputFirehose) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputFirehose) GetAuthTokens() []string {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputFirehose) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputFirehose) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputFirehose) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputFirehose) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputFirehose) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputFirehose) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputFirehose) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputFirehose) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputFirehose) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputFirehose) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputFirehose) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputFirehose) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputFirehose) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputFirehose) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type InputExecType string

const (
	InputExecTypeExec InputExecType = "exec"
)

func (e InputExecType) ToPointer() *InputExecType {
	return &e
}
func (e *InputExecType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "exec":
		*e = InputExecType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputExecType: %v", v)
	}
}

// ScheduleType - Select a schedule type; either an interval (in seconds) or a cron-style schedule.
type ScheduleType string

const (
	ScheduleTypeInterval     ScheduleType = "interval"
	ScheduleTypeCronSchedule ScheduleType = "cronSchedule"
)

func (e ScheduleType) ToPointer() *ScheduleType {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *ScheduleType) IsExact() bool {
	if e != nil {
		switch *e {
		case "interval", "cronSchedule":
			return true
		}
	}
	return false
}

type InputExec struct {
	// Unique ID for this input
	ID       string        `json:"id"`
	Type     InputExecType `json:"type"`
	Disabled *bool         `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Command to execute; supports Bourne shell (or CMD on Windows) syntax
	Command string `json:"command"`
	// Maximum number of retry attempts in the event that the command fails
	Retries *float64 `json:"retries,omitzero"`
	// Select a schedule type; either an interval (in seconds) or a cron-style schedule.
	ScheduleType *ScheduleType `json:"scheduleType,omitzero"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitzero"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `json:"staleChannelFlushMs,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
	// Interval between command executions in seconds.
	Interval *float64 `json:"interval,omitzero"`
	// Cron schedule to execute the command on.
	CronSchedule *string `json:"cronSchedule,omitzero"`
}

func (i InputExec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputExec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputExec) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputExec) GetType() InputExecType {
	if i == nil {
		return InputExecType("")
	}
	return i.Type
}

func (i *InputExec) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputExec) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputExec) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputExec) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputExec) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputExec) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputExec) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputExec) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputExec) GetCommand() string {
	if i == nil {
		return ""
	}
	return i.Command
}

func (i *InputExec) GetRetries() *float64 {
	if i == nil {
		return nil
	}
	return i.Retries
}

func (i *InputExec) GetScheduleType() *ScheduleType {
	if i == nil {
		return nil
	}
	return i.ScheduleType
}

func (i *InputExec) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputExec) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputExec) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputExec) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputExec) GetInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.Interval
}

func (i *InputExec) GetCronSchedule() *string {
	if i == nil {
		return nil
	}
	return i.CronSchedule
}

type TypeEventhub string

const (
	TypeEventhubEventhub TypeEventhub = "eventhub"
)

func (e TypeEventhub) ToPointer() *TypeEventhub {
	return &e
}
func (e *TypeEventhub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "eventhub":
		*e = TypeEventhub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeEventhub: %v", v)
	}
}

type InputEventhub struct {
	// Unique ID for this input
	ID       string       `json:"id"`
	Type     TypeEventhub `json:"type"`
	Disabled *bool        `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// List of Event Hubs Kafka brokers to connect to (example: yourdomain.servicebus.windows.net:9093). The hostname can be found in the host portion of the primary or secondary connection string in Shared Access Policies.
	Brokers []string `json:"brokers"`
	// The name of the Event Hub (Kafka topic) to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Event Hubs Source to only a single topic.
	Topics []string `json:"topics"`
	// The consumer group this instance belongs to. Default is 'Cribl'.
	GroupID *string `json:"groupId,omitzero"`
	// Start reading from earliest available data; relevant only during initial subscription
	FromBeginning *bool `json:"fromBeginning,omitzero"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `json:"connectionTimeout,omitzero"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `json:"maxRetries,omitzero"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `json:"maxBackOff,omitzero"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `json:"initialBackoff,omitzero"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `json:"backoffRate,omitzero"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `json:"authenticationTimeout,omitzero"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `json:"reauthenticationThreshold,omitzero"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *components.AuthenticationType1       `json:"sasl,omitzero"`
	TLS  *components.TLSSettingsClientSideType `json:"tls,omitzero"`
	//       Timeout (session.timeout.ms in Kafka domain) used to detect client failures when using Kafka's group-management facilities.
	//       If the client sends no heartbeats to the broker before the timeout expires, the broker will remove the client from the group and initiate a rebalance.
	//       Value must be lower than rebalanceTimeout.
	//       See details [here](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
	SessionTimeout *float64 `json:"sessionTimeout,omitzero"`
	//       Maximum allowed time (rebalance.timeout.ms in Kafka domain) for each worker to join the group after a rebalance begins.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See [Recommended configurations](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
	RebalanceTimeout *float64 `json:"rebalanceTimeout,omitzero"`
	//       Expected time (heartbeat.interval.ms in Kafka domain) between heartbeats to the consumer coordinator when using Kafka's group-management facilities.
	//       Value must be lower than sessionTimeout and typically should not exceed 1/3 of the sessionTimeout value.
	//       See [Recommended configurations](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
	HeartbeatInterval *float64 `json:"heartbeatInterval,omitzero"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitzero"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitzero"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `json:"maxBytesPerPartition,omitzero"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `json:"maxBytes,omitzero"`
	// Maximum number of network errors before the consumer re-creates a socket
	MaxSocketErrors *float64 `json:"maxSocketErrors,omitzero"`
	// Minimize duplicate events by starting only one consumer for each topic partition
	MinimizeDuplicates *bool `json:"minimizeDuplicates,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
}

func (i InputEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputEventhub) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputEventhub) GetType() TypeEventhub {
	if i == nil {
		return TypeEventhub("")
	}
	return i.Type
}

func (i *InputEventhub) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputEventhub) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputEventhub) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputEventhub) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputEventhub) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputEventhub) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputEventhub) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputEventhub) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputEventhub) GetBrokers() []string {
	if i == nil {
		return []string{}
	}
	return i.Brokers
}

func (i *InputEventhub) GetTopics() []string {
	if i == nil {
		return []string{}
	}
	return i.Topics
}

func (i *InputEventhub) GetGroupID() *string {
	if i == nil {
		return nil
	}
	return i.GroupID
}

func (i *InputEventhub) GetFromBeginning() *bool {
	if i == nil {
		return nil
	}
	return i.FromBeginning
}

func (i *InputEventhub) GetConnectionTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.ConnectionTimeout
}

func (i *InputEventhub) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputEventhub) GetMaxRetries() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxRetries
}

func (i *InputEventhub) GetMaxBackOff() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBackOff
}

func (i *InputEventhub) GetInitialBackoff() *float64 {
	if i == nil {
		return nil
	}
	return i.InitialBackoff
}

func (i *InputEventhub) GetBackoffRate() *float64 {
	if i == nil {
		return nil
	}
	return i.BackoffRate
}

func (i *InputEventhub) GetAuthenticationTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.AuthenticationTimeout
}

func (i *InputEventhub) GetReauthenticationThreshold() *float64 {
	if i == nil {
		return nil
	}
	return i.ReauthenticationThreshold
}

func (i *InputEventhub) GetSasl() *components.AuthenticationType1 {
	if i == nil {
		return nil
	}
	return i.Sasl
}

func (i *InputEventhub) GetTLS() *components.TLSSettingsClientSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputEventhub) GetSessionTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SessionTimeout
}

func (i *InputEventhub) GetRebalanceTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RebalanceTimeout
}

func (i *InputEventhub) GetHeartbeatInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.HeartbeatInterval
}

func (i *InputEventhub) GetAutoCommitInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.AutoCommitInterval
}

func (i *InputEventhub) GetAutoCommitThreshold() *float64 {
	if i == nil {
		return nil
	}
	return i.AutoCommitThreshold
}

func (i *InputEventhub) GetMaxBytesPerPartition() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBytesPerPartition
}

func (i *InputEventhub) GetMaxBytes() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBytes
}

func (i *InputEventhub) GetMaxSocketErrors() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxSocketErrors
}

func (i *InputEventhub) GetMinimizeDuplicates() *bool {
	if i == nil {
		return nil
	}
	return i.MinimizeDuplicates
}

func (i *InputEventhub) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputEventhub) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type TypeOffice365MsgTrace string

const (
	TypeOffice365MsgTraceOffice365MsgTrace TypeOffice365MsgTrace = "office365_msg_trace"
)

func (e TypeOffice365MsgTrace) ToPointer() *TypeOffice365MsgTrace {
	return &e
}
func (e *TypeOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "office365_msg_trace":
		*e = TypeOffice365MsgTrace(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeOffice365MsgTrace: %v", v)
	}
}

// AuthenticationMethodOffice365MsgTrace - Select authentication method.
type AuthenticationMethodOffice365MsgTrace string

const (
	AuthenticationMethodOffice365MsgTraceManual      AuthenticationMethodOffice365MsgTrace = "manual"
	AuthenticationMethodOffice365MsgTraceSecret      AuthenticationMethodOffice365MsgTrace = "secret"
	AuthenticationMethodOffice365MsgTraceOauth       AuthenticationMethodOffice365MsgTrace = "oauth"
	AuthenticationMethodOffice365MsgTraceOauthSecret AuthenticationMethodOffice365MsgTrace = "oauthSecret"
	AuthenticationMethodOffice365MsgTraceOauthCert   AuthenticationMethodOffice365MsgTrace = "oauthCert"
)

func (e AuthenticationMethodOffice365MsgTrace) ToPointer() *AuthenticationMethodOffice365MsgTrace {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *AuthenticationMethodOffice365MsgTrace) IsExact() bool {
	if e != nil {
		switch *e {
		case "manual", "secret", "oauth", "oauthSecret", "oauthCert":
			return true
		}
	}
	return false
}

// LogLevelOffice365MsgTrace - Log Level (verbosity) for collection runtime behavior.
type LogLevelOffice365MsgTrace string

const (
	LogLevelOffice365MsgTraceError LogLevelOffice365MsgTrace = "error"
	LogLevelOffice365MsgTraceWarn  LogLevelOffice365MsgTrace = "warn"
	LogLevelOffice365MsgTraceInfo  LogLevelOffice365MsgTrace = "info"
	LogLevelOffice365MsgTraceDebug LogLevelOffice365MsgTrace = "debug"
	LogLevelOffice365MsgTraceSilly LogLevelOffice365MsgTrace = "silly"
)

func (e LogLevelOffice365MsgTrace) ToPointer() *LogLevelOffice365MsgTrace {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *LogLevelOffice365MsgTrace) IsExact() bool {
	if e != nil {
		switch *e {
		case "error", "warn", "info", "debug", "silly":
			return true
		}
	}
	return false
}

type CertOptions struct {
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitzero"`
	// Path to the private key to use. Key should be in PEM format. Can reference $ENV_VARS.
	PrivKeyPath string `json:"privKeyPath"`
	// Passphrase to use to decrypt the private key.
	Passphrase *string `json:"passphrase,omitzero"`
	// Path to the certificate to use. Certificate should be in PEM format. Can reference $ENV_VARS.
	CertPath string `json:"certPath"`
}

func (c CertOptions) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CertOptions) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *CertOptions) GetCertificateName() *string {
	if c == nil {
		return nil
	}
	return c.CertificateName
}

func (c *CertOptions) GetPrivKeyPath() string {
	if c == nil {
		return ""
	}
	return c.PrivKeyPath
}

func (c *CertOptions) GetPassphrase() *string {
	if c == nil {
		return nil
	}
	return c.Passphrase
}

func (c *CertOptions) GetCertPath() string {
	if c == nil {
		return ""
	}
	return c.CertPath
}

type InputOffice365MsgTrace struct {
	// Unique ID for this input
	ID       string                `json:"id"`
	Type     TypeOffice365MsgTrace `json:"type"`
	Disabled *bool                 `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// URL to use when retrieving report data.
	URL string `json:"url"`
	// How often (in minutes) to run the report. Must divide evenly into 60 minutes to create a predictable schedule, or Save will fail.
	Interval float64 `json:"interval"`
	// Backward offset for the search range's head. (E.g.: -3h@h) Message Trace data is delayed; this parameter (with Date range end) compensates for delay and gaps.
	StartDate *string `json:"startDate,omitzero"`
	// Backward offset for the search range's tail. (E.g.: -2h@h) Message Trace data is delayed; this parameter (with Date range start) compensates for delay and gaps.
	EndDate *string `json:"endDate,omitzero"`
	// HTTP request inactivity timeout. Maximum is 2400 (40 minutes); enter 0 to wait indefinitely.
	Timeout *float64 `json:"timeout,omitzero"`
	// Disables time filtering of events when a date range is specified.
	DisableTimeFilter *bool `json:"disableTimeFilter,omitzero"`
	// Select authentication method.
	AuthType *AuthenticationMethodOffice365MsgTrace `json:"authType,omitzero"`
	// Reschedule tasks that failed with non-fatal errors
	RescheduleDroppedTasks *bool `json:"rescheduleDroppedTasks,omitzero"`
	// Maximum number of times a task can be rescheduled
	MaxTaskReschedule *float64 `json:"maxTaskReschedule,omitzero"`
	// Log Level (verbosity) for collection runtime behavior.
	LogLevel *LogLevelOffice365MsgTrace `json:"logLevel,omitzero"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `json:"jobTimeout,omitzero"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `json:"keepAliveTime,omitzero"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `json:"maxMissedKeepAlives,omitzero"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `json:"ttl,omitzero"`
	// When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
	IgnoreGroupJobsLimit *bool `json:"ignoreGroupJobsLimit,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	RetryRules  *components.RetryRulesType1                `json:"retryRules,omitzero"`
	Description *string                                    `json:"description,omitzero"`
	// Username to run Message Trace API call.
	Username *string `json:"username,omitzero"`
	// Password to run Message Trace API call.
	Password *string `json:"password,omitzero"`
	// Select or create a secret that references your credentials.
	CredentialsSecret *string `json:"credentialsSecret,omitzero"`
	// client_secret to pass in the OAuth request parameter.
	ClientSecret *string `json:"clientSecret,omitzero"`
	// Directory ID (tenant identifier) in Azure Active Directory.
	TenantID *string `json:"tenantId,omitzero"`
	// client_id to pass in the OAuth request parameter.
	ClientID *string `json:"clientId,omitzero"`
	// Resource to pass in the OAuth request parameter.
	Resource *string `json:"resource,omitzero"`
	// Office 365 subscription plan for your organization, typically Office 365 Enterprise
	PlanType *components.SubscriptionPlanOptions `json:"planType,omitzero"`
	// Select or create a secret that references your client_secret to pass in the OAuth request parameter.
	TextSecret  *string      `json:"textSecret,omitzero"`
	CertOptions *CertOptions `json:"certOptions,omitzero"`
}

func (i InputOffice365MsgTrace) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputOffice365MsgTrace) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputOffice365MsgTrace) GetType() TypeOffice365MsgTrace {
	if i == nil {
		return TypeOffice365MsgTrace("")
	}
	return i.Type
}

func (i *InputOffice365MsgTrace) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputOffice365MsgTrace) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputOffice365MsgTrace) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputOffice365MsgTrace) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputOffice365MsgTrace) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputOffice365MsgTrace) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputOffice365MsgTrace) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputOffice365MsgTrace) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputOffice365MsgTrace) GetURL() string {
	if i == nil {
		return ""
	}
	return i.URL
}

func (i *InputOffice365MsgTrace) GetInterval() float64 {
	if i == nil {
		return 0.0
	}
	return i.Interval
}

func (i *InputOffice365MsgTrace) GetStartDate() *string {
	if i == nil {
		return nil
	}
	return i.StartDate
}

func (i *InputOffice365MsgTrace) GetEndDate() *string {
	if i == nil {
		return nil
	}
	return i.EndDate
}

func (i *InputOffice365MsgTrace) GetTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.Timeout
}

func (i *InputOffice365MsgTrace) GetDisableTimeFilter() *bool {
	if i == nil {
		return nil
	}
	return i.DisableTimeFilter
}

func (i *InputOffice365MsgTrace) GetAuthType() *AuthenticationMethodOffice365MsgTrace {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputOffice365MsgTrace) GetRescheduleDroppedTasks() *bool {
	if i == nil {
		return nil
	}
	return i.RescheduleDroppedTasks
}

func (i *InputOffice365MsgTrace) GetMaxTaskReschedule() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxTaskReschedule
}

func (i *InputOffice365MsgTrace) GetLogLevel() *LogLevelOffice365MsgTrace {
	if i == nil {
		return nil
	}
	return i.LogLevel
}

func (i *InputOffice365MsgTrace) GetJobTimeout() *string {
	if i == nil {
		return nil
	}
	return i.JobTimeout
}

func (i *InputOffice365MsgTrace) GetKeepAliveTime() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTime
}

func (i *InputOffice365MsgTrace) GetMaxMissedKeepAlives() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMissedKeepAlives
}

func (i *InputOffice365MsgTrace) GetTTL() *string {
	if i == nil {
		return nil
	}
	return i.TTL
}

func (i *InputOffice365MsgTrace) GetIgnoreGroupJobsLimit() *bool {
	if i == nil {
		return nil
	}
	return i.IgnoreGroupJobsLimit
}

func (i *InputOffice365MsgTrace) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputOffice365MsgTrace) GetRetryRules() *components.RetryRulesType1 {
	if i == nil {
		return nil
	}
	return i.RetryRules
}

func (i *InputOffice365MsgTrace) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputOffice365MsgTrace) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputOffice365MsgTrace) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputOffice365MsgTrace) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputOffice365MsgTrace) GetClientSecret() *string {
	if i == nil {
		return nil
	}
	return i.ClientSecret
}

func (i *InputOffice365MsgTrace) GetTenantID() *string {
	if i == nil {
		return nil
	}
	return i.TenantID
}

func (i *InputOffice365MsgTrace) GetClientID() *string {
	if i == nil {
		return nil
	}
	return i.ClientID
}

func (i *InputOffice365MsgTrace) GetResource() *string {
	if i == nil {
		return nil
	}
	return i.Resource
}

func (i *InputOffice365MsgTrace) GetPlanType() *components.SubscriptionPlanOptions {
	if i == nil {
		return nil
	}
	return i.PlanType
}

func (i *InputOffice365MsgTrace) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputOffice365MsgTrace) GetCertOptions() *CertOptions {
	if i == nil {
		return nil
	}
	return i.CertOptions
}

type TypeOffice365Service string

const (
	TypeOffice365ServiceOffice365Service TypeOffice365Service = "office365_service"
)

func (e TypeOffice365Service) ToPointer() *TypeOffice365Service {
	return &e
}
func (e *TypeOffice365Service) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "office365_service":
		*e = TypeOffice365Service(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeOffice365Service: %v", v)
	}
}

type ContentConfigOffice365Service struct {
	// Office 365 Services API Content Type
	ContentType *string `json:"contentType,omitzero"`
	// If interval type is minutes the value entered must evenly divisible by 60 or save will fail
	Description *string  `json:"description,omitzero"`
	Interval    *float64 `json:"interval,omitzero"`
	// Collector runtime Log Level
	LogLevel *components.LogLevelOptionsContentConfigItems `json:"logLevel,omitzero"`
	Enabled  *bool                                         `json:"enabled,omitzero"`
}

func (c ContentConfigOffice365Service) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ContentConfigOffice365Service) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *ContentConfigOffice365Service) GetContentType() *string {
	if c == nil {
		return nil
	}
	return c.ContentType
}

func (c *ContentConfigOffice365Service) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *ContentConfigOffice365Service) GetInterval() *float64 {
	if c == nil {
		return nil
	}
	return c.Interval
}

func (c *ContentConfigOffice365Service) GetLogLevel() *components.LogLevelOptionsContentConfigItems {
	if c == nil {
		return nil
	}
	return c.LogLevel
}

func (c *ContentConfigOffice365Service) GetEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.Enabled
}

type InputOffice365Service struct {
	// Unique ID for this input
	ID       string               `json:"id"`
	Type     TypeOffice365Service `json:"type"`
	Disabled *bool                `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Office 365 subscription plan for your organization, typically Office 365 Enterprise
	PlanType *components.SubscriptionPlanOptions `json:"planType,omitzero"`
	// Office 365 Azure Tenant ID
	TenantID string `json:"tenantId"`
	// Office 365 Azure Application ID
	AppID string `json:"appId"`
	// HTTP request inactivity timeout, use 0 to disable
	Timeout *float64 `json:"timeout,omitzero"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `json:"keepAliveTime,omitzero"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `json:"jobTimeout,omitzero"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `json:"maxMissedKeepAlives,omitzero"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `json:"ttl,omitzero"`
	// When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
	IgnoreGroupJobsLimit *bool `json:"ignoreGroupJobsLimit,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// Enable Office 365 Service Communication API content types and polling intervals. Polling intervals are used to set up search date range and cron schedule, e.g.: */${interval} * * * *. Because of this, intervals entered for current and historical status must be evenly divisible by 60 to give a predictable schedule.
	ContentConfig []ContentConfigOffice365Service `json:"contentConfig,omitzero"`
	RetryRules    *components.RetryRulesType1     `json:"retryRules,omitzero"`
	// Enter client secret directly, or select a stored secret
	AuthType    *components.AuthenticationMethodOptions1 `json:"authType,omitzero"`
	Description *string                                  `json:"description,omitzero"`
	// Office 365 Azure client secret
	ClientSecret *string `json:"clientSecret,omitzero"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitzero"`
}

func (i InputOffice365Service) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365Service) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputOffice365Service) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputOffice365Service) GetType() TypeOffice365Service {
	if i == nil {
		return TypeOffice365Service("")
	}
	return i.Type
}

func (i *InputOffice365Service) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputOffice365Service) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputOffice365Service) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputOffice365Service) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputOffice365Service) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputOffice365Service) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputOffice365Service) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputOffice365Service) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputOffice365Service) GetPlanType() *components.SubscriptionPlanOptions {
	if i == nil {
		return nil
	}
	return i.PlanType
}

func (i *InputOffice365Service) GetTenantID() string {
	if i == nil {
		return ""
	}
	return i.TenantID
}

func (i *InputOffice365Service) GetAppID() string {
	if i == nil {
		return ""
	}
	return i.AppID
}

func (i *InputOffice365Service) GetTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.Timeout
}

func (i *InputOffice365Service) GetKeepAliveTime() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTime
}

func (i *InputOffice365Service) GetJobTimeout() *string {
	if i == nil {
		return nil
	}
	return i.JobTimeout
}

func (i *InputOffice365Service) GetMaxMissedKeepAlives() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMissedKeepAlives
}

func (i *InputOffice365Service) GetTTL() *string {
	if i == nil {
		return nil
	}
	return i.TTL
}

func (i *InputOffice365Service) GetIgnoreGroupJobsLimit() *bool {
	if i == nil {
		return nil
	}
	return i.IgnoreGroupJobsLimit
}

func (i *InputOffice365Service) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputOffice365Service) GetContentConfig() []ContentConfigOffice365Service {
	if i == nil {
		return nil
	}
	return i.ContentConfig
}

func (i *InputOffice365Service) GetRetryRules() *components.RetryRulesType1 {
	if i == nil {
		return nil
	}
	return i.RetryRules
}

func (i *InputOffice365Service) GetAuthType() *components.AuthenticationMethodOptions1 {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputOffice365Service) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputOffice365Service) GetClientSecret() *string {
	if i == nil {
		return nil
	}
	return i.ClientSecret
}

func (i *InputOffice365Service) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

type TypeOffice365Mgmt string

const (
	TypeOffice365MgmtOffice365Mgmt TypeOffice365Mgmt = "office365_mgmt"
)

func (e TypeOffice365Mgmt) ToPointer() *TypeOffice365Mgmt {
	return &e
}
func (e *TypeOffice365Mgmt) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "office365_mgmt":
		*e = TypeOffice365Mgmt(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeOffice365Mgmt: %v", v)
	}
}

type ContentConfigOffice365Mgmt struct {
	// Office 365 Management Activity API Content Type
	ContentType *string `json:"contentType,omitzero"`
	// If interval type is minutes the value entered must evenly divisible by 60 or save will fail
	Description *string  `json:"description,omitzero"`
	Interval    *float64 `json:"interval,omitzero"`
	// Collector runtime Log Level
	LogLevel *components.LogLevelOptionsContentConfigItems `json:"logLevel,omitzero"`
	Enabled  *bool                                         `json:"enabled,omitzero"`
}

func (c ContentConfigOffice365Mgmt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ContentConfigOffice365Mgmt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *ContentConfigOffice365Mgmt) GetContentType() *string {
	if c == nil {
		return nil
	}
	return c.ContentType
}

func (c *ContentConfigOffice365Mgmt) GetDescription() *string {
	if c == nil {
		return nil
	}
	return c.Description
}

func (c *ContentConfigOffice365Mgmt) GetInterval() *float64 {
	if c == nil {
		return nil
	}
	return c.Interval
}

func (c *ContentConfigOffice365Mgmt) GetLogLevel() *components.LogLevelOptionsContentConfigItems {
	if c == nil {
		return nil
	}
	return c.LogLevel
}

func (c *ContentConfigOffice365Mgmt) GetEnabled() *bool {
	if c == nil {
		return nil
	}
	return c.Enabled
}

type InputOffice365Mgmt struct {
	// Unique ID for this input
	ID       string            `json:"id"`
	Type     TypeOffice365Mgmt `json:"type"`
	Disabled *bool             `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Office 365 subscription plan for your organization, typically Office 365 Enterprise
	PlanType components.SubscriptionPlanOptions `json:"planType"`
	// Office 365 Azure Tenant ID
	TenantID string `json:"tenantId"`
	// Office 365 Azure Application ID
	AppID string `json:"appId"`
	// HTTP request inactivity timeout, use 0 to disable
	Timeout *float64 `json:"timeout,omitzero"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `json:"keepAliveTime,omitzero"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `json:"jobTimeout,omitzero"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `json:"maxMissedKeepAlives,omitzero"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `json:"ttl,omitzero"`
	// When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
	IgnoreGroupJobsLimit *bool `json:"ignoreGroupJobsLimit,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// Optional Publisher Identifier to use in API requests, defaults to tenant id if not defined. For more information see [here](https://docs.microsoft.com/en-us/office/office-365-management-api/office-365-management-activity-api-reference#start-a-subscription)
	PublisherIdentifier *string `json:"publisherIdentifier,omitzero"`
	// Enable Office 365 Management Activity API content types and polling intervals. Polling intervals are used to set up search date range and cron schedule, e.g.: */${interval} * * * *. Because of this, intervals entered must be evenly divisible by 60 to give a predictable schedule.
	ContentConfig []ContentConfigOffice365Mgmt `json:"contentConfig,omitzero"`
	// Use this setting to account for ingestion lag. This is necessary because there can be a lag of 60 - 90 minutes (or longer) before Office 365 events are available for retrieval.
	IngestionLag *float64                    `json:"ingestionLag,omitzero"`
	RetryRules   *components.RetryRulesType1 `json:"retryRules,omitzero"`
	// Enter client secret directly, or select a stored secret
	AuthType    *components.AuthenticationMethodOptions1 `json:"authType,omitzero"`
	Description *string                                  `json:"description,omitzero"`
	// Office 365 Azure client secret
	ClientSecret *string `json:"clientSecret,omitzero"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitzero"`
}

func (i InputOffice365Mgmt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365Mgmt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputOffice365Mgmt) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputOffice365Mgmt) GetType() TypeOffice365Mgmt {
	if i == nil {
		return TypeOffice365Mgmt("")
	}
	return i.Type
}

func (i *InputOffice365Mgmt) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputOffice365Mgmt) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputOffice365Mgmt) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputOffice365Mgmt) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputOffice365Mgmt) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputOffice365Mgmt) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputOffice365Mgmt) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputOffice365Mgmt) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputOffice365Mgmt) GetPlanType() components.SubscriptionPlanOptions {
	if i == nil {
		return components.SubscriptionPlanOptions("")
	}
	return i.PlanType
}

func (i *InputOffice365Mgmt) GetTenantID() string {
	if i == nil {
		return ""
	}
	return i.TenantID
}

func (i *InputOffice365Mgmt) GetAppID() string {
	if i == nil {
		return ""
	}
	return i.AppID
}

func (i *InputOffice365Mgmt) GetTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.Timeout
}

func (i *InputOffice365Mgmt) GetKeepAliveTime() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTime
}

func (i *InputOffice365Mgmt) GetJobTimeout() *string {
	if i == nil {
		return nil
	}
	return i.JobTimeout
}

func (i *InputOffice365Mgmt) GetMaxMissedKeepAlives() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMissedKeepAlives
}

func (i *InputOffice365Mgmt) GetTTL() *string {
	if i == nil {
		return nil
	}
	return i.TTL
}

func (i *InputOffice365Mgmt) GetIgnoreGroupJobsLimit() *bool {
	if i == nil {
		return nil
	}
	return i.IgnoreGroupJobsLimit
}

func (i *InputOffice365Mgmt) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputOffice365Mgmt) GetPublisherIdentifier() *string {
	if i == nil {
		return nil
	}
	return i.PublisherIdentifier
}

func (i *InputOffice365Mgmt) GetContentConfig() []ContentConfigOffice365Mgmt {
	if i == nil {
		return nil
	}
	return i.ContentConfig
}

func (i *InputOffice365Mgmt) GetIngestionLag() *float64 {
	if i == nil {
		return nil
	}
	return i.IngestionLag
}

func (i *InputOffice365Mgmt) GetRetryRules() *components.RetryRulesType1 {
	if i == nil {
		return nil
	}
	return i.RetryRules
}

func (i *InputOffice365Mgmt) GetAuthType() *components.AuthenticationMethodOptions1 {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputOffice365Mgmt) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputOffice365Mgmt) GetClientSecret() *string {
	if i == nil {
		return nil
	}
	return i.ClientSecret
}

func (i *InputOffice365Mgmt) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

type TypeEdgePrometheus string

const (
	TypeEdgePrometheusEdgePrometheus TypeEdgePrometheus = "edge_prometheus"
)

func (e TypeEdgePrometheus) ToPointer() *TypeEdgePrometheus {
	return &e
}
func (e *TypeEdgePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "edge_prometheus":
		*e = TypeEdgePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeEdgePrometheus: %v", v)
	}
}

// DiscoveryTypeEdgePrometheus - Target discovery mechanism. Use static to manually enter a list of targets.
type DiscoveryTypeEdgePrometheus string

const (
	// DiscoveryTypeEdgePrometheusStatic Static
	DiscoveryTypeEdgePrometheusStatic DiscoveryTypeEdgePrometheus = "static"
	// DiscoveryTypeEdgePrometheusDNS DNS
	DiscoveryTypeEdgePrometheusDNS DiscoveryTypeEdgePrometheus = "dns"
	// DiscoveryTypeEdgePrometheusEc2 AWS EC2
	DiscoveryTypeEdgePrometheusEc2 DiscoveryTypeEdgePrometheus = "ec2"
	// DiscoveryTypeEdgePrometheusK8sNode Kubernetes Node
	DiscoveryTypeEdgePrometheusK8sNode DiscoveryTypeEdgePrometheus = "k8s-node"
	// DiscoveryTypeEdgePrometheusK8sPods Kubernetes Pods
	DiscoveryTypeEdgePrometheusK8sPods DiscoveryTypeEdgePrometheus = "k8s-pods"
)

func (e DiscoveryTypeEdgePrometheus) ToPointer() *DiscoveryTypeEdgePrometheus {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *DiscoveryTypeEdgePrometheus) IsExact() bool {
	if e != nil {
		switch *e {
		case "static", "dns", "ec2", "k8s-node", "k8s-pods":
			return true
		}
	}
	return false
}

// AuthenticationMethodEdgePrometheus - Enter credentials directly, or select a stored secret
type AuthenticationMethodEdgePrometheus string

const (
	AuthenticationMethodEdgePrometheusManual     AuthenticationMethodEdgePrometheus = "manual"
	AuthenticationMethodEdgePrometheusSecret     AuthenticationMethodEdgePrometheus = "secret"
	AuthenticationMethodEdgePrometheusKubernetes AuthenticationMethodEdgePrometheus = "kubernetes"
)

func (e AuthenticationMethodEdgePrometheus) ToPointer() *AuthenticationMethodEdgePrometheus {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *AuthenticationMethodEdgePrometheus) IsExact() bool {
	if e != nil {
		switch *e {
		case "manual", "secret", "kubernetes":
			return true
		}
	}
	return false
}

type Target struct {
	// Protocol to use when collecting metrics
	Protocol *components.ProtocolOptionsTargetsItems `json:"protocol,omitzero"`
	// Name of host from which to pull metrics.
	Host string `json:"host"`
	// The port number in the metrics URL for discovered targets.
	Port *float64 `json:"port,omitzero"`
	// Path to use when collecting metrics from discovered targets
	Path *string `json:"path,omitzero"`
}

func (t Target) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *Target) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (t *Target) GetProtocol() *components.ProtocolOptionsTargetsItems {
	if t == nil {
		return nil
	}
	return t.Protocol
}

func (t *Target) GetHost() string {
	if t == nil {
		return ""
	}
	return t.Host
}

func (t *Target) GetPort() *float64 {
	if t == nil {
		return nil
	}
	return t.Port
}

func (t *Target) GetPath() *string {
	if t == nil {
		return nil
	}
	return t.Path
}

type PodFilter struct {
	// JavaScript expression applied to pods objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitzero"`
}

func (p PodFilter) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PodFilter) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PodFilter) GetFilter() string {
	if p == nil {
		return ""
	}
	return p.Filter
}

func (p *PodFilter) GetDescription() *string {
	if p == nil {
		return nil
	}
	return p.Description
}

type InputEdgePrometheus struct {
	// Unique ID for this input
	ID       string             `json:"id"`
	Type     TypeEdgePrometheus `json:"type"`
	Disabled *bool              `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Other dimensions to include in events
	DimensionList []string `json:"dimensionList,omitzero"`
	// Target discovery mechanism. Use static to manually enter a list of targets.
	DiscoveryType DiscoveryTypeEdgePrometheus `json:"discoveryType"`
	// How often in seconds to scrape targets for metrics.
	Interval float64 `json:"interval"`
	// Timeout, in milliseconds, before aborting HTTP connection attempts; 1-60000 or 0 to disable
	Timeout     *float64                     `json:"timeout,omitzero"`
	Persistence *components.DiskSpoolingType `json:"persistence,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// Enter credentials directly, or select a stored secret
	AuthType    *AuthenticationMethodEdgePrometheus `json:"authType,omitzero"`
	Description *string                             `json:"description,omitzero"`
	Targets     []Target                            `json:"targets,omitzero"`
	// DNS record type to resolve
	RecordType *components.RecordTypeOptions `json:"recordType,omitzero"`
	// The port number in the metrics URL for discovered targets.
	ScrapePort *float64 `json:"scrapePort,omitzero"`
	// List of DNS names to resolve
	NameList []string `json:"nameList,omitzero"`
	// Protocol to use when collecting metrics
	ScrapeProtocol *components.ProtocolOptionsTargetsItems `json:"scrapeProtocol,omitzero"`
	// Path to use when collecting metrics from discovered targets
	ScrapePath *string `json:"scrapePath,omitzero"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitzero"`
	AwsAPIKey               *string                                                `json:"awsApiKey,omitzero"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitzero"`
	// Use public IP address for discovered targets. Disable to use the private IP address.
	UsePublicIP *bool `json:"usePublicIp,omitzero"`
	// Filter to apply when searching for EC2 instances
	SearchFilter []components.ItemsTypeSearchFilter `json:"searchFilter,omitzero"`
	AwsSecretKey *string                            `json:"awsSecretKey,omitzero"`
	// Region where the EC2 is located
	Region *string `json:"region,omitzero"`
	// EC2 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to EC2-compatible endpoint.
	Endpoint *string `json:"endpoint,omitzero"`
	// Signature version to use for signing EC2 requests
	SignatureVersion *components.SignatureVersionOptions1 `json:"signatureVersion,omitzero"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitzero"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitzero"`
	// Use Assume Role credentials to access EC2
	EnableAssumeRole *bool `json:"enableAssumeRole,omitzero"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitzero"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitzero"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitzero"`
	// Protocol to use when collecting metrics
	ScrapeProtocolExpr *string `json:"scrapeProtocolExpr,omitzero"`
	// The port number in the metrics URL for discovered targets.
	ScrapePortExpr *string `json:"scrapePortExpr,omitzero"`
	// Path to use when collecting metrics from discovered targets
	ScrapePathExpr *string `json:"scrapePathExpr,omitzero"`
	//   Add rules to decide which pods to discover for metrics.
	//   Pods are searched if no rules are given or of all the rules'
	//   expressions evaluate to true.
	//
	PodFilter []PodFilter `json:"podFilter,omitzero"`
	// Username for Prometheus Basic authentication
	Username *string `json:"username,omitzero"`
	// Password for Prometheus Basic authentication
	Password *string `json:"password,omitzero"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitzero"`
}

func (i InputEdgePrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputEdgePrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputEdgePrometheus) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputEdgePrometheus) GetType() TypeEdgePrometheus {
	if i == nil {
		return TypeEdgePrometheus("")
	}
	return i.Type
}

func (i *InputEdgePrometheus) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputEdgePrometheus) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputEdgePrometheus) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputEdgePrometheus) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputEdgePrometheus) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputEdgePrometheus) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputEdgePrometheus) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputEdgePrometheus) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputEdgePrometheus) GetDimensionList() []string {
	if i == nil {
		return nil
	}
	return i.DimensionList
}

func (i *InputEdgePrometheus) GetDiscoveryType() DiscoveryTypeEdgePrometheus {
	if i == nil {
		return DiscoveryTypeEdgePrometheus("")
	}
	return i.DiscoveryType
}

func (i *InputEdgePrometheus) GetInterval() float64 {
	if i == nil {
		return 0.0
	}
	return i.Interval
}

func (i *InputEdgePrometheus) GetTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.Timeout
}

func (i *InputEdgePrometheus) GetPersistence() *components.DiskSpoolingType {
	if i == nil {
		return nil
	}
	return i.Persistence
}

func (i *InputEdgePrometheus) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputEdgePrometheus) GetAuthType() *AuthenticationMethodEdgePrometheus {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputEdgePrometheus) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputEdgePrometheus) GetTargets() []Target {
	if i == nil {
		return nil
	}
	return i.Targets
}

func (i *InputEdgePrometheus) GetRecordType() *components.RecordTypeOptions {
	if i == nil {
		return nil
	}
	return i.RecordType
}

func (i *InputEdgePrometheus) GetScrapePort() *float64 {
	if i == nil {
		return nil
	}
	return i.ScrapePort
}

func (i *InputEdgePrometheus) GetNameList() []string {
	if i == nil {
		return nil
	}
	return i.NameList
}

func (i *InputEdgePrometheus) GetScrapeProtocol() *components.ProtocolOptionsTargetsItems {
	if i == nil {
		return nil
	}
	return i.ScrapeProtocol
}

func (i *InputEdgePrometheus) GetScrapePath() *string {
	if i == nil {
		return nil
	}
	return i.ScrapePath
}

func (i *InputEdgePrometheus) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if i == nil {
		return nil
	}
	return i.AwsAuthenticationMethod
}

func (i *InputEdgePrometheus) GetAwsAPIKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsAPIKey
}

func (i *InputEdgePrometheus) GetAwsSecret() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecret
}

func (i *InputEdgePrometheus) GetUsePublicIP() *bool {
	if i == nil {
		return nil
	}
	return i.UsePublicIP
}

func (i *InputEdgePrometheus) GetSearchFilter() []components.ItemsTypeSearchFilter {
	if i == nil {
		return nil
	}
	return i.SearchFilter
}

func (i *InputEdgePrometheus) GetAwsSecretKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecretKey
}

func (i *InputEdgePrometheus) GetRegion() *string {
	if i == nil {
		return nil
	}
	return i.Region
}

func (i *InputEdgePrometheus) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputEdgePrometheus) GetSignatureVersion() *components.SignatureVersionOptions1 {
	if i == nil {
		return nil
	}
	return i.SignatureVersion
}

func (i *InputEdgePrometheus) GetReuseConnections() *bool {
	if i == nil {
		return nil
	}
	return i.ReuseConnections
}

func (i *InputEdgePrometheus) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputEdgePrometheus) GetEnableAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableAssumeRole
}

func (i *InputEdgePrometheus) GetAssumeRoleArn() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleArn
}

func (i *InputEdgePrometheus) GetAssumeRoleExternalID() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleExternalID
}

func (i *InputEdgePrometheus) GetDurationSeconds() *float64 {
	if i == nil {
		return nil
	}
	return i.DurationSeconds
}

func (i *InputEdgePrometheus) GetScrapeProtocolExpr() *string {
	if i == nil {
		return nil
	}
	return i.ScrapeProtocolExpr
}

func (i *InputEdgePrometheus) GetScrapePortExpr() *string {
	if i == nil {
		return nil
	}
	return i.ScrapePortExpr
}

func (i *InputEdgePrometheus) GetScrapePathExpr() *string {
	if i == nil {
		return nil
	}
	return i.ScrapePathExpr
}

func (i *InputEdgePrometheus) GetPodFilter() []PodFilter {
	if i == nil {
		return nil
	}
	return i.PodFilter
}

func (i *InputEdgePrometheus) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputEdgePrometheus) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputEdgePrometheus) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

type CreateInputTypePrometheus string

const (
	CreateInputTypePrometheusPrometheus CreateInputTypePrometheus = "prometheus"
)

func (e CreateInputTypePrometheus) ToPointer() *CreateInputTypePrometheus {
	return &e
}
func (e *CreateInputTypePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "prometheus":
		*e = CreateInputTypePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypePrometheus: %v", v)
	}
}

// DiscoveryTypePrometheus - Target discovery mechanism. Use static to manually enter a list of targets.
type DiscoveryTypePrometheus string

const (
	// DiscoveryTypePrometheusStatic Static
	DiscoveryTypePrometheusStatic DiscoveryTypePrometheus = "static"
	// DiscoveryTypePrometheusDNS DNS
	DiscoveryTypePrometheusDNS DiscoveryTypePrometheus = "dns"
	// DiscoveryTypePrometheusEc2 AWS EC2
	DiscoveryTypePrometheusEc2 DiscoveryTypePrometheus = "ec2"
)

func (e DiscoveryTypePrometheus) ToPointer() *DiscoveryTypePrometheus {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *DiscoveryTypePrometheus) IsExact() bool {
	if e != nil {
		switch *e {
		case "static", "dns", "ec2":
			return true
		}
	}
	return false
}

// LogLevelPrometheus - Collector runtime log level
type LogLevelPrometheus string

const (
	LogLevelPrometheusError LogLevelPrometheus = "error"
	LogLevelPrometheusWarn  LogLevelPrometheus = "warn"
	LogLevelPrometheusInfo  LogLevelPrometheus = "info"
	LogLevelPrometheusDebug LogLevelPrometheus = "debug"
)

func (e LogLevelPrometheus) ToPointer() *LogLevelPrometheus {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *LogLevelPrometheus) IsExact() bool {
	if e != nil {
		switch *e {
		case "error", "warn", "info", "debug":
			return true
		}
	}
	return false
}

// MetricsProtocol - Protocol to use when collecting metrics
type MetricsProtocol string

const (
	MetricsProtocolHTTP  MetricsProtocol = "http"
	MetricsProtocolHTTPS MetricsProtocol = "https"
)

func (e MetricsProtocol) ToPointer() *MetricsProtocol {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *MetricsProtocol) IsExact() bool {
	if e != nil {
		switch *e {
		case "http", "https":
			return true
		}
	}
	return false
}

type InputPrometheus struct {
	// Unique ID for this input
	ID       string                    `json:"id"`
	Type     CreateInputTypePrometheus `json:"type"`
	Disabled *bool                     `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Other dimensions to include in events
	DimensionList []string `json:"dimensionList,omitzero"`
	// Target discovery mechanism. Use static to manually enter a list of targets.
	DiscoveryType *DiscoveryTypePrometheus `json:"discoveryType,omitzero"`
	// How often, in minutes, to scrape targets for metrics. Maximum of 60 minutes. 60 must be evenly divisible by the value you enter.
	Interval float64 `json:"interval"`
	// Collector runtime log level
	LogLevel LogLevelPrometheus `json:"logLevel"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitzero"`
	// Time, in seconds, before aborting HTTP connection attempts; use 0 for no timeout
	Timeout *float64 `json:"timeout,omitzero"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `json:"keepAliveTime,omitzero"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `json:"jobTimeout,omitzero"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `json:"maxMissedKeepAlives,omitzero"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `json:"ttl,omitzero"`
	// When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
	IgnoreGroupJobsLimit *bool `json:"ignoreGroupJobsLimit,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// Enter credentials directly, or select a stored secret
	AuthType    *components.AuthenticationMethodOptionsSasl `json:"authType,omitzero"`
	Description *string                                     `json:"description,omitzero"`
	// List of Prometheus targets to pull metrics from. Values can be in URL or host[:port] format. For example: http://localhost:9090/metrics, localhost:9090, or localhost. In cases where just host[:port] is specified, the endpoint will resolve to 'http://host[:port]/metrics'.
	TargetList []string `json:"targetList,omitzero"`
	// DNS record type to resolve
	RecordType *components.RecordTypeOptions `json:"recordType,omitzero"`
	// The port number in the metrics URL for discovered targets
	ScrapePort *float64 `json:"scrapePort,omitzero"`
	// List of DNS names to resolve
	NameList []string `json:"nameList,omitzero"`
	// Protocol to use when collecting metrics
	ScrapeProtocol *MetricsProtocol `json:"scrapeProtocol,omitzero"`
	// Path to use when collecting metrics from discovered targets
	ScrapePath *string `json:"scrapePath,omitzero"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod,omitzero"`
	AwsAPIKey               *string                                                `json:"awsApiKey,omitzero"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitzero"`
	// Use public IP address for discovered targets. Disable to use the private IP address.
	UsePublicIP *bool `json:"usePublicIp,omitzero"`
	// Filter to apply when searching for EC2 instances
	SearchFilter []components.ItemsTypeSearchFilter `json:"searchFilter,omitzero"`
	AwsSecretKey *string                            `json:"awsSecretKey,omitzero"`
	// Region where the EC2 is located
	Region *string `json:"region,omitzero"`
	// EC2 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to EC2-compatible endpoint.
	Endpoint *string `json:"endpoint,omitzero"`
	// Signature version to use for signing EC2 requests
	SignatureVersion *components.SignatureVersionOptions1 `json:"signatureVersion,omitzero"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitzero"`
	// Use Assume Role credentials to access EC2
	EnableAssumeRole *bool `json:"enableAssumeRole,omitzero"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitzero"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitzero"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `json:"durationSeconds,omitzero"`
	// Username for Prometheus Basic authentication
	Username *string `json:"username,omitzero"`
	// Password for Prometheus Basic authentication
	Password *string `json:"password,omitzero"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitzero"`
}

func (i InputPrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputPrometheus) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputPrometheus) GetType() CreateInputTypePrometheus {
	if i == nil {
		return CreateInputTypePrometheus("")
	}
	return i.Type
}

func (i *InputPrometheus) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputPrometheus) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputPrometheus) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputPrometheus) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputPrometheus) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputPrometheus) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputPrometheus) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputPrometheus) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputPrometheus) GetDimensionList() []string {
	if i == nil {
		return nil
	}
	return i.DimensionList
}

func (i *InputPrometheus) GetDiscoveryType() *DiscoveryTypePrometheus {
	if i == nil {
		return nil
	}
	return i.DiscoveryType
}

func (i *InputPrometheus) GetInterval() float64 {
	if i == nil {
		return 0.0
	}
	return i.Interval
}

func (i *InputPrometheus) GetLogLevel() LogLevelPrometheus {
	if i == nil {
		return LogLevelPrometheus("")
	}
	return i.LogLevel
}

func (i *InputPrometheus) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputPrometheus) GetTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.Timeout
}

func (i *InputPrometheus) GetKeepAliveTime() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTime
}

func (i *InputPrometheus) GetJobTimeout() *string {
	if i == nil {
		return nil
	}
	return i.JobTimeout
}

func (i *InputPrometheus) GetMaxMissedKeepAlives() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMissedKeepAlives
}

func (i *InputPrometheus) GetTTL() *string {
	if i == nil {
		return nil
	}
	return i.TTL
}

func (i *InputPrometheus) GetIgnoreGroupJobsLimit() *bool {
	if i == nil {
		return nil
	}
	return i.IgnoreGroupJobsLimit
}

func (i *InputPrometheus) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputPrometheus) GetAuthType() *components.AuthenticationMethodOptionsSasl {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputPrometheus) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputPrometheus) GetTargetList() []string {
	if i == nil {
		return nil
	}
	return i.TargetList
}

func (i *InputPrometheus) GetRecordType() *components.RecordTypeOptions {
	if i == nil {
		return nil
	}
	return i.RecordType
}

func (i *InputPrometheus) GetScrapePort() *float64 {
	if i == nil {
		return nil
	}
	return i.ScrapePort
}

func (i *InputPrometheus) GetNameList() []string {
	if i == nil {
		return nil
	}
	return i.NameList
}

func (i *InputPrometheus) GetScrapeProtocol() *MetricsProtocol {
	if i == nil {
		return nil
	}
	return i.ScrapeProtocol
}

func (i *InputPrometheus) GetScrapePath() *string {
	if i == nil {
		return nil
	}
	return i.ScrapePath
}

func (i *InputPrometheus) GetAwsAuthenticationMethod() *components.AuthenticationMethodOptionsS3CollectorConf {
	if i == nil {
		return nil
	}
	return i.AwsAuthenticationMethod
}

func (i *InputPrometheus) GetAwsAPIKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsAPIKey
}

func (i *InputPrometheus) GetAwsSecret() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecret
}

func (i *InputPrometheus) GetUsePublicIP() *bool {
	if i == nil {
		return nil
	}
	return i.UsePublicIP
}

func (i *InputPrometheus) GetSearchFilter() []components.ItemsTypeSearchFilter {
	if i == nil {
		return nil
	}
	return i.SearchFilter
}

func (i *InputPrometheus) GetAwsSecretKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecretKey
}

func (i *InputPrometheus) GetRegion() *string {
	if i == nil {
		return nil
	}
	return i.Region
}

func (i *InputPrometheus) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputPrometheus) GetSignatureVersion() *components.SignatureVersionOptions1 {
	if i == nil {
		return nil
	}
	return i.SignatureVersion
}

func (i *InputPrometheus) GetReuseConnections() *bool {
	if i == nil {
		return nil
	}
	return i.ReuseConnections
}

func (i *InputPrometheus) GetEnableAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableAssumeRole
}

func (i *InputPrometheus) GetAssumeRoleArn() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleArn
}

func (i *InputPrometheus) GetAssumeRoleExternalID() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleExternalID
}

func (i *InputPrometheus) GetDurationSeconds() *float64 {
	if i == nil {
		return nil
	}
	return i.DurationSeconds
}

func (i *InputPrometheus) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputPrometheus) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputPrometheus) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

type TypePrometheusRw string

const (
	TypePrometheusRwPrometheusRw TypePrometheusRw = "prometheus_rw"
)

func (e TypePrometheusRw) ToPointer() *TypePrometheusRw {
	return &e
}
func (e *TypePrometheusRw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "prometheus_rw":
		*e = TypePrometheusRw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypePrometheusRw: %v", v)
	}
}

type InputPrometheusRw struct {
	// Unique ID for this input
	ID       string           `json:"id"`
	Type     TypePrometheusRw `json:"type"`
	Disabled *bool            `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64                               `json:"port"`
	TLS  *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `json:"maxActiveReq,omitzero"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `json:"maxRequestsPerSocket,omitzero"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `json:"captureHeaders,omitzero"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `json:"activityLogSampleRate,omitzero"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitzero"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `json:"enableHealthCheck,omitzero"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `json:"ipAllowlistRegex,omitzero"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `json:"ipDenylistRegex,omitzero"`
	// Absolute path on which to listen for Prometheus requests. Defaults to /write, which will expand as: http://<yourupstreamURL>:<yourport>/write.
	PrometheusAPI string `json:"prometheusAPI"`
	// Remote Write authentication type
	AuthType *components.AuthenticationTypeOptionsPrometheusAuth `json:"authType,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
	Username    *string                                    `json:"username,omitzero"`
	Password    *string                                    `json:"password,omitzero"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitzero"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitzero"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitzero"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitzero"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitzero"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitzero"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitzero"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `json:"authHeaderExpr,omitzero"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `json:"tokenTimeoutSecs,omitzero"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []components.ItemsTypeOauthParams `json:"oauthParams,omitzero"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []components.ItemsTypeOauthHeaders `json:"oauthHeaders,omitzero"`
}

func (i InputPrometheusRw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPrometheusRw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputPrometheusRw) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputPrometheusRw) GetType() TypePrometheusRw {
	if i == nil {
		return TypePrometheusRw("")
	}
	return i.Type
}

func (i *InputPrometheusRw) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputPrometheusRw) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputPrometheusRw) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputPrometheusRw) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputPrometheusRw) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputPrometheusRw) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputPrometheusRw) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputPrometheusRw) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputPrometheusRw) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputPrometheusRw) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputPrometheusRw) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputPrometheusRw) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputPrometheusRw) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputPrometheusRw) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputPrometheusRw) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputPrometheusRw) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputPrometheusRw) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputPrometheusRw) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputPrometheusRw) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputPrometheusRw) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputPrometheusRw) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputPrometheusRw) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputPrometheusRw) GetPrometheusAPI() string {
	if i == nil {
		return ""
	}
	return i.PrometheusAPI
}

func (i *InputPrometheusRw) GetAuthType() *components.AuthenticationTypeOptionsPrometheusAuth {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputPrometheusRw) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputPrometheusRw) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputPrometheusRw) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputPrometheusRw) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputPrometheusRw) GetToken() *string {
	if i == nil {
		return nil
	}
	return i.Token
}

func (i *InputPrometheusRw) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputPrometheusRw) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputPrometheusRw) GetLoginURL() *string {
	if i == nil {
		return nil
	}
	return i.LoginURL
}

func (i *InputPrometheusRw) GetSecretParamName() *string {
	if i == nil {
		return nil
	}
	return i.SecretParamName
}

func (i *InputPrometheusRw) GetSecret() *string {
	if i == nil {
		return nil
	}
	return i.Secret
}

func (i *InputPrometheusRw) GetTokenAttributeName() *string {
	if i == nil {
		return nil
	}
	return i.TokenAttributeName
}

func (i *InputPrometheusRw) GetAuthHeaderExpr() *string {
	if i == nil {
		return nil
	}
	return i.AuthHeaderExpr
}

func (i *InputPrometheusRw) GetTokenTimeoutSecs() *float64 {
	if i == nil {
		return nil
	}
	return i.TokenTimeoutSecs
}

func (i *InputPrometheusRw) GetOauthParams() []components.ItemsTypeOauthParams {
	if i == nil {
		return nil
	}
	return i.OauthParams
}

func (i *InputPrometheusRw) GetOauthHeaders() []components.ItemsTypeOauthHeaders {
	if i == nil {
		return nil
	}
	return i.OauthHeaders
}

type CreateInputTypeLoki string

const (
	CreateInputTypeLokiLoki CreateInputTypeLoki = "loki"
)

func (e CreateInputTypeLoki) ToPointer() *CreateInputTypeLoki {
	return &e
}
func (e *CreateInputTypeLoki) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "loki":
		*e = CreateInputTypeLoki(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeLoki: %v", v)
	}
}

type InputLoki struct {
	// Unique ID for this input
	ID       string              `json:"id"`
	Type     CreateInputTypeLoki `json:"type"`
	Disabled *bool               `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64                               `json:"port"`
	TLS  *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `json:"maxActiveReq,omitzero"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `json:"maxRequestsPerSocket,omitzero"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `json:"captureHeaders,omitzero"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `json:"activityLogSampleRate,omitzero"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitzero"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `json:"enableHealthCheck,omitzero"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `json:"ipAllowlistRegex,omitzero"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `json:"ipDenylistRegex,omitzero"`
	// Absolute path on which to listen for Loki logs requests. Defaults to /loki/api/v1/push, which will (in this example) expand as: 'http://<yourupstreamURL>:<yourport>/loki/api/v1/push'.
	LokiAPI string `json:"lokiAPI"`
	// Loki logs authentication type
	AuthType *components.AuthenticationTypeOptionsLokiAuth `json:"authType,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
	Username    *string                                    `json:"username,omitzero"`
	Password    *string                                    `json:"password,omitzero"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitzero"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitzero"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitzero"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitzero"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitzero"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitzero"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitzero"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `json:"authHeaderExpr,omitzero"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `json:"tokenTimeoutSecs,omitzero"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []components.ItemsTypeOauthParams `json:"oauthParams,omitzero"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []components.ItemsTypeOauthHeaders `json:"oauthHeaders,omitzero"`
}

func (i InputLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputLoki) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputLoki) GetType() CreateInputTypeLoki {
	if i == nil {
		return CreateInputTypeLoki("")
	}
	return i.Type
}

func (i *InputLoki) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputLoki) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputLoki) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputLoki) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputLoki) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputLoki) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputLoki) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputLoki) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputLoki) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputLoki) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputLoki) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputLoki) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputLoki) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputLoki) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputLoki) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputLoki) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputLoki) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputLoki) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputLoki) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputLoki) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputLoki) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputLoki) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputLoki) GetLokiAPI() string {
	if i == nil {
		return ""
	}
	return i.LokiAPI
}

func (i *InputLoki) GetAuthType() *components.AuthenticationTypeOptionsLokiAuth {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputLoki) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputLoki) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputLoki) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputLoki) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputLoki) GetToken() *string {
	if i == nil {
		return nil
	}
	return i.Token
}

func (i *InputLoki) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputLoki) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputLoki) GetLoginURL() *string {
	if i == nil {
		return nil
	}
	return i.LoginURL
}

func (i *InputLoki) GetSecretParamName() *string {
	if i == nil {
		return nil
	}
	return i.SecretParamName
}

func (i *InputLoki) GetSecret() *string {
	if i == nil {
		return nil
	}
	return i.Secret
}

func (i *InputLoki) GetTokenAttributeName() *string {
	if i == nil {
		return nil
	}
	return i.TokenAttributeName
}

func (i *InputLoki) GetAuthHeaderExpr() *string {
	if i == nil {
		return nil
	}
	return i.AuthHeaderExpr
}

func (i *InputLoki) GetTokenTimeoutSecs() *float64 {
	if i == nil {
		return nil
	}
	return i.TokenTimeoutSecs
}

func (i *InputLoki) GetOauthParams() []components.ItemsTypeOauthParams {
	if i == nil {
		return nil
	}
	return i.OauthParams
}

func (i *InputLoki) GetOauthHeaders() []components.ItemsTypeOauthHeaders {
	if i == nil {
		return nil
	}
	return i.OauthHeaders
}

type InputGrafanaType2 string

const (
	InputGrafanaType2Grafana InputGrafanaType2 = "grafana"
)

func (e InputGrafanaType2) ToPointer() *InputGrafanaType2 {
	return &e
}
func (e *InputGrafanaType2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grafana":
		*e = InputGrafanaType2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaType2: %v", v)
	}
}

type PrometheusAuth2 struct {
	// Remote Write authentication type
	AuthType *components.AuthenticationTypeOptionsPrometheusAuth `json:"authType,omitzero"`
	Username *string                                             `json:"username,omitzero"`
	Password *string                                             `json:"password,omitzero"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitzero"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitzero"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitzero"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitzero"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitzero"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitzero"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitzero"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `json:"authHeaderExpr,omitzero"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `json:"tokenTimeoutSecs,omitzero"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []components.ItemsTypeOauthParams `json:"oauthParams,omitzero"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []components.ItemsTypeOauthHeaders `json:"oauthHeaders,omitzero"`
}

func (p PrometheusAuth2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PrometheusAuth2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PrometheusAuth2) GetAuthType() *components.AuthenticationTypeOptionsPrometheusAuth {
	if p == nil {
		return nil
	}
	return p.AuthType
}

func (p *PrometheusAuth2) GetUsername() *string {
	if p == nil {
		return nil
	}
	return p.Username
}

func (p *PrometheusAuth2) GetPassword() *string {
	if p == nil {
		return nil
	}
	return p.Password
}

func (p *PrometheusAuth2) GetToken() *string {
	if p == nil {
		return nil
	}
	return p.Token
}

func (p *PrometheusAuth2) GetCredentialsSecret() *string {
	if p == nil {
		return nil
	}
	return p.CredentialsSecret
}

func (p *PrometheusAuth2) GetTextSecret() *string {
	if p == nil {
		return nil
	}
	return p.TextSecret
}

func (p *PrometheusAuth2) GetLoginURL() *string {
	if p == nil {
		return nil
	}
	return p.LoginURL
}

func (p *PrometheusAuth2) GetSecretParamName() *string {
	if p == nil {
		return nil
	}
	return p.SecretParamName
}

func (p *PrometheusAuth2) GetSecret() *string {
	if p == nil {
		return nil
	}
	return p.Secret
}

func (p *PrometheusAuth2) GetTokenAttributeName() *string {
	if p == nil {
		return nil
	}
	return p.TokenAttributeName
}

func (p *PrometheusAuth2) GetAuthHeaderExpr() *string {
	if p == nil {
		return nil
	}
	return p.AuthHeaderExpr
}

func (p *PrometheusAuth2) GetTokenTimeoutSecs() *float64 {
	if p == nil {
		return nil
	}
	return p.TokenTimeoutSecs
}

func (p *PrometheusAuth2) GetOauthParams() []components.ItemsTypeOauthParams {
	if p == nil {
		return nil
	}
	return p.OauthParams
}

func (p *PrometheusAuth2) GetOauthHeaders() []components.ItemsTypeOauthHeaders {
	if p == nil {
		return nil
	}
	return p.OauthHeaders
}

type LokiAuth2 struct {
	// Loki logs authentication type
	AuthType *components.AuthenticationTypeOptionsLokiAuth `json:"authType,omitzero"`
	Username *string                                       `json:"username,omitzero"`
	Password *string                                       `json:"password,omitzero"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitzero"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitzero"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitzero"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitzero"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitzero"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitzero"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitzero"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `json:"authHeaderExpr,omitzero"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `json:"tokenTimeoutSecs,omitzero"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []components.ItemsTypeOauthParams `json:"oauthParams,omitzero"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []components.ItemsTypeOauthHeaders `json:"oauthHeaders,omitzero"`
}

func (l LokiAuth2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(l, "", false)
}

func (l *LokiAuth2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &l, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (l *LokiAuth2) GetAuthType() *components.AuthenticationTypeOptionsLokiAuth {
	if l == nil {
		return nil
	}
	return l.AuthType
}

func (l *LokiAuth2) GetUsername() *string {
	if l == nil {
		return nil
	}
	return l.Username
}

func (l *LokiAuth2) GetPassword() *string {
	if l == nil {
		return nil
	}
	return l.Password
}

func (l *LokiAuth2) GetToken() *string {
	if l == nil {
		return nil
	}
	return l.Token
}

func (l *LokiAuth2) GetCredentialsSecret() *string {
	if l == nil {
		return nil
	}
	return l.CredentialsSecret
}

func (l *LokiAuth2) GetTextSecret() *string {
	if l == nil {
		return nil
	}
	return l.TextSecret
}

func (l *LokiAuth2) GetLoginURL() *string {
	if l == nil {
		return nil
	}
	return l.LoginURL
}

func (l *LokiAuth2) GetSecretParamName() *string {
	if l == nil {
		return nil
	}
	return l.SecretParamName
}

func (l *LokiAuth2) GetSecret() *string {
	if l == nil {
		return nil
	}
	return l.Secret
}

func (l *LokiAuth2) GetTokenAttributeName() *string {
	if l == nil {
		return nil
	}
	return l.TokenAttributeName
}

func (l *LokiAuth2) GetAuthHeaderExpr() *string {
	if l == nil {
		return nil
	}
	return l.AuthHeaderExpr
}

func (l *LokiAuth2) GetTokenTimeoutSecs() *float64 {
	if l == nil {
		return nil
	}
	return l.TokenTimeoutSecs
}

func (l *LokiAuth2) GetOauthParams() []components.ItemsTypeOauthParams {
	if l == nil {
		return nil
	}
	return l.OauthParams
}

func (l *LokiAuth2) GetOauthHeaders() []components.ItemsTypeOauthHeaders {
	if l == nil {
		return nil
	}
	return l.OauthHeaders
}

type InputGrafanaGrafana2 struct {
	// Unique ID for this input
	ID       string            `json:"id"`
	Type     InputGrafanaType2 `json:"type"`
	Disabled *bool             `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64                               `json:"port"`
	TLS  *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `json:"maxActiveReq,omitzero"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `json:"maxRequestsPerSocket,omitzero"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `json:"captureHeaders,omitzero"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `json:"activityLogSampleRate,omitzero"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// Maximum time to wait for additional data, after the last response was sent, before closing a socket connection. This can be very useful when Grafana Agent remote write's request frequency is high so, reusing connections, would help mitigating the cost of creating a new connection per request. Note that Grafana Agent's embedded Prometheus would attempt to keep connections open for up to 5 minutes.
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitzero"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `json:"enableHealthCheck,omitzero"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `json:"ipAllowlistRegex,omitzero"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `json:"ipDenylistRegex,omitzero"`
	// Absolute path on which to listen for Grafana Agent's Remote Write requests. Defaults to /api/prom/push, which will expand as: 'http://<yourupstreamURL>:<yourport>/api/prom/push'. Either this field or 'Logs API endpoint' must be configured.
	PrometheusAPI *string `json:"prometheusAPI,omitzero"`
	// Absolute path on which to listen for Loki logs requests. Defaults to /loki/api/v1/push, which will (in this example) expand as: 'http://<yourupstreamURL>:<yourport>/loki/api/v1/push'. Either this field or 'Remote Write API endpoint' must be configured.
	LokiAPI        string           `json:"lokiAPI"`
	PrometheusAuth *PrometheusAuth2 `json:"prometheusAuth,omitzero"`
	LokiAuth       *LokiAuth2       `json:"lokiAuth,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
}

func (i InputGrafanaGrafana2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaGrafana2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputGrafanaGrafana2) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputGrafanaGrafana2) GetType() InputGrafanaType2 {
	if i == nil {
		return InputGrafanaType2("")
	}
	return i.Type
}

func (i *InputGrafanaGrafana2) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputGrafanaGrafana2) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputGrafanaGrafana2) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputGrafanaGrafana2) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputGrafanaGrafana2) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputGrafanaGrafana2) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputGrafanaGrafana2) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputGrafanaGrafana2) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputGrafanaGrafana2) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputGrafanaGrafana2) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputGrafanaGrafana2) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputGrafanaGrafana2) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputGrafanaGrafana2) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputGrafanaGrafana2) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputGrafanaGrafana2) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputGrafanaGrafana2) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputGrafanaGrafana2) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputGrafanaGrafana2) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputGrafanaGrafana2) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputGrafanaGrafana2) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputGrafanaGrafana2) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputGrafanaGrafana2) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputGrafanaGrafana2) GetPrometheusAPI() *string {
	if i == nil {
		return nil
	}
	return i.PrometheusAPI
}

func (i *InputGrafanaGrafana2) GetLokiAPI() string {
	if i == nil {
		return ""
	}
	return i.LokiAPI
}

func (i *InputGrafanaGrafana2) GetPrometheusAuth() *PrometheusAuth2 {
	if i == nil {
		return nil
	}
	return i.PrometheusAuth
}

func (i *InputGrafanaGrafana2) GetLokiAuth() *LokiAuth2 {
	if i == nil {
		return nil
	}
	return i.LokiAuth
}

func (i *InputGrafanaGrafana2) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputGrafanaGrafana2) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type InputGrafanaType1 string

const (
	InputGrafanaType1Grafana InputGrafanaType1 = "grafana"
)

func (e InputGrafanaType1) ToPointer() *InputGrafanaType1 {
	return &e
}
func (e *InputGrafanaType1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grafana":
		*e = InputGrafanaType1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaType1: %v", v)
	}
}

type PrometheusAuth1 struct {
	// Remote Write authentication type
	AuthType *components.AuthenticationTypeOptionsPrometheusAuth `json:"authType,omitzero"`
	Username *string                                             `json:"username,omitzero"`
	Password *string                                             `json:"password,omitzero"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitzero"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitzero"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitzero"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitzero"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitzero"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitzero"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitzero"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `json:"authHeaderExpr,omitzero"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `json:"tokenTimeoutSecs,omitzero"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []components.ItemsTypeOauthParams `json:"oauthParams,omitzero"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []components.ItemsTypeOauthHeaders `json:"oauthHeaders,omitzero"`
}

func (p PrometheusAuth1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PrometheusAuth1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *PrometheusAuth1) GetAuthType() *components.AuthenticationTypeOptionsPrometheusAuth {
	if p == nil {
		return nil
	}
	return p.AuthType
}

func (p *PrometheusAuth1) GetUsername() *string {
	if p == nil {
		return nil
	}
	return p.Username
}

func (p *PrometheusAuth1) GetPassword() *string {
	if p == nil {
		return nil
	}
	return p.Password
}

func (p *PrometheusAuth1) GetToken() *string {
	if p == nil {
		return nil
	}
	return p.Token
}

func (p *PrometheusAuth1) GetCredentialsSecret() *string {
	if p == nil {
		return nil
	}
	return p.CredentialsSecret
}

func (p *PrometheusAuth1) GetTextSecret() *string {
	if p == nil {
		return nil
	}
	return p.TextSecret
}

func (p *PrometheusAuth1) GetLoginURL() *string {
	if p == nil {
		return nil
	}
	return p.LoginURL
}

func (p *PrometheusAuth1) GetSecretParamName() *string {
	if p == nil {
		return nil
	}
	return p.SecretParamName
}

func (p *PrometheusAuth1) GetSecret() *string {
	if p == nil {
		return nil
	}
	return p.Secret
}

func (p *PrometheusAuth1) GetTokenAttributeName() *string {
	if p == nil {
		return nil
	}
	return p.TokenAttributeName
}

func (p *PrometheusAuth1) GetAuthHeaderExpr() *string {
	if p == nil {
		return nil
	}
	return p.AuthHeaderExpr
}

func (p *PrometheusAuth1) GetTokenTimeoutSecs() *float64 {
	if p == nil {
		return nil
	}
	return p.TokenTimeoutSecs
}

func (p *PrometheusAuth1) GetOauthParams() []components.ItemsTypeOauthParams {
	if p == nil {
		return nil
	}
	return p.OauthParams
}

func (p *PrometheusAuth1) GetOauthHeaders() []components.ItemsTypeOauthHeaders {
	if p == nil {
		return nil
	}
	return p.OauthHeaders
}

type LokiAuth1 struct {
	// Loki logs authentication type
	AuthType *components.AuthenticationTypeOptionsLokiAuth `json:"authType,omitzero"`
	Username *string                                       `json:"username,omitzero"`
	Password *string                                       `json:"password,omitzero"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitzero"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitzero"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitzero"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitzero"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitzero"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitzero"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitzero"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `json:"authHeaderExpr,omitzero"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `json:"tokenTimeoutSecs,omitzero"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []components.ItemsTypeOauthParams `json:"oauthParams,omitzero"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []components.ItemsTypeOauthHeaders `json:"oauthHeaders,omitzero"`
}

func (l LokiAuth1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(l, "", false)
}

func (l *LokiAuth1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &l, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (l *LokiAuth1) GetAuthType() *components.AuthenticationTypeOptionsLokiAuth {
	if l == nil {
		return nil
	}
	return l.AuthType
}

func (l *LokiAuth1) GetUsername() *string {
	if l == nil {
		return nil
	}
	return l.Username
}

func (l *LokiAuth1) GetPassword() *string {
	if l == nil {
		return nil
	}
	return l.Password
}

func (l *LokiAuth1) GetToken() *string {
	if l == nil {
		return nil
	}
	return l.Token
}

func (l *LokiAuth1) GetCredentialsSecret() *string {
	if l == nil {
		return nil
	}
	return l.CredentialsSecret
}

func (l *LokiAuth1) GetTextSecret() *string {
	if l == nil {
		return nil
	}
	return l.TextSecret
}

func (l *LokiAuth1) GetLoginURL() *string {
	if l == nil {
		return nil
	}
	return l.LoginURL
}

func (l *LokiAuth1) GetSecretParamName() *string {
	if l == nil {
		return nil
	}
	return l.SecretParamName
}

func (l *LokiAuth1) GetSecret() *string {
	if l == nil {
		return nil
	}
	return l.Secret
}

func (l *LokiAuth1) GetTokenAttributeName() *string {
	if l == nil {
		return nil
	}
	return l.TokenAttributeName
}

func (l *LokiAuth1) GetAuthHeaderExpr() *string {
	if l == nil {
		return nil
	}
	return l.AuthHeaderExpr
}

func (l *LokiAuth1) GetTokenTimeoutSecs() *float64 {
	if l == nil {
		return nil
	}
	return l.TokenTimeoutSecs
}

func (l *LokiAuth1) GetOauthParams() []components.ItemsTypeOauthParams {
	if l == nil {
		return nil
	}
	return l.OauthParams
}

func (l *LokiAuth1) GetOauthHeaders() []components.ItemsTypeOauthHeaders {
	if l == nil {
		return nil
	}
	return l.OauthHeaders
}

type InputGrafanaGrafana1 struct {
	// Unique ID for this input
	ID       string            `json:"id"`
	Type     InputGrafanaType1 `json:"type"`
	Disabled *bool             `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64                               `json:"port"`
	TLS  *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `json:"maxActiveReq,omitzero"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `json:"maxRequestsPerSocket,omitzero"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `json:"captureHeaders,omitzero"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `json:"activityLogSampleRate,omitzero"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// Maximum time to wait for additional data, after the last response was sent, before closing a socket connection. This can be very useful when Grafana Agent remote write's request frequency is high so, reusing connections, would help mitigating the cost of creating a new connection per request. Note that Grafana Agent's embedded Prometheus would attempt to keep connections open for up to 5 minutes.
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitzero"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `json:"enableHealthCheck,omitzero"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `json:"ipAllowlistRegex,omitzero"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `json:"ipDenylistRegex,omitzero"`
	// Absolute path on which to listen for Grafana Agent's Remote Write requests. Defaults to /api/prom/push, which will expand as: 'http://<yourupstreamURL>:<yourport>/api/prom/push'. Either this field or 'Logs API endpoint' must be configured.
	PrometheusAPI string `json:"prometheusAPI"`
	// Absolute path on which to listen for Loki logs requests. Defaults to /loki/api/v1/push, which will (in this example) expand as: 'http://<yourupstreamURL>:<yourport>/loki/api/v1/push'. Either this field or 'Remote Write API endpoint' must be configured.
	LokiAPI        *string          `json:"lokiAPI,omitzero"`
	PrometheusAuth *PrometheusAuth1 `json:"prometheusAuth,omitzero"`
	LokiAuth       *LokiAuth1       `json:"lokiAuth,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
}

func (i InputGrafanaGrafana1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaGrafana1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputGrafanaGrafana1) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputGrafanaGrafana1) GetType() InputGrafanaType1 {
	if i == nil {
		return InputGrafanaType1("")
	}
	return i.Type
}

func (i *InputGrafanaGrafana1) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputGrafanaGrafana1) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputGrafanaGrafana1) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputGrafanaGrafana1) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputGrafanaGrafana1) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputGrafanaGrafana1) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputGrafanaGrafana1) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputGrafanaGrafana1) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputGrafanaGrafana1) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputGrafanaGrafana1) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputGrafanaGrafana1) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputGrafanaGrafana1) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputGrafanaGrafana1) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputGrafanaGrafana1) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputGrafanaGrafana1) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputGrafanaGrafana1) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputGrafanaGrafana1) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputGrafanaGrafana1) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputGrafanaGrafana1) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputGrafanaGrafana1) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputGrafanaGrafana1) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputGrafanaGrafana1) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputGrafanaGrafana1) GetPrometheusAPI() string {
	if i == nil {
		return ""
	}
	return i.PrometheusAPI
}

func (i *InputGrafanaGrafana1) GetLokiAPI() *string {
	if i == nil {
		return nil
	}
	return i.LokiAPI
}

func (i *InputGrafanaGrafana1) GetPrometheusAuth() *PrometheusAuth1 {
	if i == nil {
		return nil
	}
	return i.PrometheusAuth
}

func (i *InputGrafanaGrafana1) GetLokiAuth() *LokiAuth1 {
	if i == nil {
		return nil
	}
	return i.LokiAuth
}

func (i *InputGrafanaGrafana1) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputGrafanaGrafana1) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type InputGrafanaType string

const (
	InputGrafanaTypeInputGrafanaGrafana1 InputGrafanaType = "InputGrafana_Grafana_1"
	InputGrafanaTypeInputGrafanaGrafana2 InputGrafanaType = "InputGrafana_Grafana_2"
)

type InputGrafana struct {
	InputGrafanaGrafana1 *InputGrafanaGrafana1 `queryParam:"inline" union:"member"`
	InputGrafanaGrafana2 *InputGrafanaGrafana2 `queryParam:"inline" union:"member"`

	Type InputGrafanaType
}

func CreateInputGrafanaInputGrafanaGrafana1(inputGrafanaGrafana1 InputGrafanaGrafana1) InputGrafana {
	typ := InputGrafanaTypeInputGrafanaGrafana1

	return InputGrafana{
		InputGrafanaGrafana1: &inputGrafanaGrafana1,
		Type:                 typ,
	}
}

func CreateInputGrafanaInputGrafanaGrafana2(inputGrafanaGrafana2 InputGrafanaGrafana2) InputGrafana {
	typ := InputGrafanaTypeInputGrafanaGrafana2

	return InputGrafana{
		InputGrafanaGrafana2: &inputGrafanaGrafana2,
		Type:                 typ,
	}
}

func (u *InputGrafana) UnmarshalJSON(data []byte) error {

	var candidates []utils.UnionCandidate

	// Collect all valid candidates
	var inputGrafanaGrafana1 InputGrafanaGrafana1 = InputGrafanaGrafana1{}
	if err := utils.UnmarshalJSON(data, &inputGrafanaGrafana1, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  InputGrafanaTypeInputGrafanaGrafana1,
			Value: &inputGrafanaGrafana1,
		})
	}

	var inputGrafanaGrafana2 InputGrafanaGrafana2 = InputGrafanaGrafana2{}
	if err := utils.UnmarshalJSON(data, &inputGrafanaGrafana2, "", true, nil); err == nil {
		candidates = append(candidates, utils.UnionCandidate{
			Type:  InputGrafanaTypeInputGrafanaGrafana2,
			Value: &inputGrafanaGrafana2,
		})
	}

	if len(candidates) == 0 {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for InputGrafana", string(data))
	}

	// Pick the best candidate using multi-stage filtering
	best := utils.PickBestUnionCandidate(candidates, data)
	if best == nil {
		return fmt.Errorf("could not unmarshal `%s` into any supported union types for InputGrafana", string(data))
	}

	// Set the union type and value based on the best candidate
	u.Type = best.Type.(InputGrafanaType)
	switch best.Type {
	case InputGrafanaTypeInputGrafanaGrafana1:
		u.InputGrafanaGrafana1 = best.Value.(*InputGrafanaGrafana1)
		return nil
	case InputGrafanaTypeInputGrafanaGrafana2:
		u.InputGrafanaGrafana2 = best.Value.(*InputGrafanaGrafana2)
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for InputGrafana", string(data))
}

func (u InputGrafana) MarshalJSON() ([]byte, error) {
	if u.InputGrafanaGrafana1 != nil {
		return utils.MarshalJSON(u.InputGrafanaGrafana1, "", true)
	}

	if u.InputGrafanaGrafana2 != nil {
		return utils.MarshalJSON(u.InputGrafanaGrafana2, "", true)
	}

	return nil, errors.New("could not marshal union type InputGrafana: all fields are null")
}

type CreateInputTypeConfluentCloud string

const (
	CreateInputTypeConfluentCloudConfluentCloud CreateInputTypeConfluentCloud = "confluent_cloud"
)

func (e CreateInputTypeConfluentCloud) ToPointer() *CreateInputTypeConfluentCloud {
	return &e
}
func (e *CreateInputTypeConfluentCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "confluent_cloud":
		*e = CreateInputTypeConfluentCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeConfluentCloud: %v", v)
	}
}

type InputConfluentCloud struct {
	// Unique ID for this input
	ID       string                        `json:"id"`
	Type     CreateInputTypeConfluentCloud `json:"type"`
	Disabled *bool                         `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// List of Confluent Cloud bootstrap servers to use, such as yourAccount.confluent.cloud:9092
	Brokers []string                                                 `json:"brokers"`
	TLS     *components.TLSSettingsClientSideTypeKafkaSchemaRegistry `json:"tls,omitzero"`
	// Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to a single topic only.
	Topics []string `json:"topics"`
	// The consumer group to which this instance belongs. Defaults to 'Cribl'.
	GroupID *string `json:"groupId,omitzero"`
	// Leave enabled if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
	FromBeginning       *bool                                             `json:"fromBeginning,omitzero"`
	KafkaSchemaRegistry *components.KafkaSchemaRegistryAuthenticationType `json:"kafkaSchemaRegistry,omitzero"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `json:"connectionTimeout,omitzero"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `json:"maxRetries,omitzero"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `json:"maxBackOff,omitzero"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `json:"initialBackoff,omitzero"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `json:"backoffRate,omitzero"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `json:"authenticationTimeout,omitzero"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `json:"reauthenticationThreshold,omitzero"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *components.AuthenticationType `json:"sasl,omitzero"`
	//       Timeout used to detect client failures when using Kafka's group-management facilities.
	//       If the client sends no heartbeats to the broker before the timeout expires,
	//       the broker will remove the client from the group and initiate a rebalance.
	//       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms) for details.
	SessionTimeout *float64 `json:"sessionTimeout,omitzero"`
	//       Maximum allowed time for each worker to join the group after a rebalance begins.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms) for details.
	RebalanceTimeout *float64 `json:"rebalanceTimeout,omitzero"`
	//       Expected time between heartbeats to the consumer coordinator when using Kafka's group-management facilities.
	//       Value must be lower than sessionTimeout and typically should not exceed 1/3 of the sessionTimeout value.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms) for details.
	HeartbeatInterval *float64 `json:"heartbeatInterval,omitzero"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitzero"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitzero"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `json:"maxBytesPerPartition,omitzero"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `json:"maxBytes,omitzero"`
	// Maximum number of network errors before the consumer re-creates a socket
	MaxSocketErrors *float64 `json:"maxSocketErrors,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
}

func (i InputConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputConfluentCloud) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputConfluentCloud) GetType() CreateInputTypeConfluentCloud {
	if i == nil {
		return CreateInputTypeConfluentCloud("")
	}
	return i.Type
}

func (i *InputConfluentCloud) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputConfluentCloud) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputConfluentCloud) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputConfluentCloud) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputConfluentCloud) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputConfluentCloud) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputConfluentCloud) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputConfluentCloud) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputConfluentCloud) GetBrokers() []string {
	if i == nil {
		return []string{}
	}
	return i.Brokers
}

func (i *InputConfluentCloud) GetTLS() *components.TLSSettingsClientSideTypeKafkaSchemaRegistry {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputConfluentCloud) GetTopics() []string {
	if i == nil {
		return []string{}
	}
	return i.Topics
}

func (i *InputConfluentCloud) GetGroupID() *string {
	if i == nil {
		return nil
	}
	return i.GroupID
}

func (i *InputConfluentCloud) GetFromBeginning() *bool {
	if i == nil {
		return nil
	}
	return i.FromBeginning
}

func (i *InputConfluentCloud) GetKafkaSchemaRegistry() *components.KafkaSchemaRegistryAuthenticationType {
	if i == nil {
		return nil
	}
	return i.KafkaSchemaRegistry
}

func (i *InputConfluentCloud) GetConnectionTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.ConnectionTimeout
}

func (i *InputConfluentCloud) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputConfluentCloud) GetMaxRetries() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxRetries
}

func (i *InputConfluentCloud) GetMaxBackOff() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBackOff
}

func (i *InputConfluentCloud) GetInitialBackoff() *float64 {
	if i == nil {
		return nil
	}
	return i.InitialBackoff
}

func (i *InputConfluentCloud) GetBackoffRate() *float64 {
	if i == nil {
		return nil
	}
	return i.BackoffRate
}

func (i *InputConfluentCloud) GetAuthenticationTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.AuthenticationTimeout
}

func (i *InputConfluentCloud) GetReauthenticationThreshold() *float64 {
	if i == nil {
		return nil
	}
	return i.ReauthenticationThreshold
}

func (i *InputConfluentCloud) GetSasl() *components.AuthenticationType {
	if i == nil {
		return nil
	}
	return i.Sasl
}

func (i *InputConfluentCloud) GetSessionTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SessionTimeout
}

func (i *InputConfluentCloud) GetRebalanceTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RebalanceTimeout
}

func (i *InputConfluentCloud) GetHeartbeatInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.HeartbeatInterval
}

func (i *InputConfluentCloud) GetAutoCommitInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.AutoCommitInterval
}

func (i *InputConfluentCloud) GetAutoCommitThreshold() *float64 {
	if i == nil {
		return nil
	}
	return i.AutoCommitThreshold
}

func (i *InputConfluentCloud) GetMaxBytesPerPartition() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBytesPerPartition
}

func (i *InputConfluentCloud) GetMaxBytes() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBytes
}

func (i *InputConfluentCloud) GetMaxSocketErrors() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxSocketErrors
}

func (i *InputConfluentCloud) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputConfluentCloud) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type CreateInputTypeElastic string

const (
	CreateInputTypeElasticElastic CreateInputTypeElastic = "elastic"
)

func (e CreateInputTypeElastic) ToPointer() *CreateInputTypeElastic {
	return &e
}
func (e *CreateInputTypeElastic) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "elastic":
		*e = CreateInputTypeElastic(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeElastic: %v", v)
	}
}

type AuthenticationTypeElastic string

const (
	// AuthenticationTypeElasticNone None
	AuthenticationTypeElasticNone AuthenticationTypeElastic = "none"
	// AuthenticationTypeElasticBasic Basic
	AuthenticationTypeElasticBasic AuthenticationTypeElastic = "basic"
	// AuthenticationTypeElasticCredentialsSecret Basic (credentials secret)
	AuthenticationTypeElasticCredentialsSecret AuthenticationTypeElastic = "credentialsSecret"
	// AuthenticationTypeElasticAuthTokens Auth Tokens
	AuthenticationTypeElasticAuthTokens AuthenticationTypeElastic = "authTokens"
)

func (e AuthenticationTypeElastic) ToPointer() *AuthenticationTypeElastic {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *AuthenticationTypeElastic) IsExact() bool {
	if e != nil {
		switch *e {
		case "none", "basic", "credentialsSecret", "authTokens":
			return true
		}
	}
	return false
}

// CreateInputAPIVersion - The API version to use for communicating with the server
type CreateInputAPIVersion string

const (
	// CreateInputAPIVersionSixDot8Dot4 6.8.4
	CreateInputAPIVersionSixDot8Dot4 CreateInputAPIVersion = "6.8.4"
	// CreateInputAPIVersionEightDot3Dot2 8.3.2
	CreateInputAPIVersionEightDot3Dot2 CreateInputAPIVersion = "8.3.2"
	// CreateInputAPIVersionCustom Custom
	CreateInputAPIVersionCustom CreateInputAPIVersion = "custom"
)

func (e CreateInputAPIVersion) ToPointer() *CreateInputAPIVersion {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateInputAPIVersion) IsExact() bool {
	if e != nil {
		switch *e {
		case "6.8.4", "8.3.2", "custom":
			return true
		}
	}
	return false
}

// ProxyModeAuthenticationMethod - Enter credentials directly, or select a stored secret
type ProxyModeAuthenticationMethod string

const (
	ProxyModeAuthenticationMethodNone   ProxyModeAuthenticationMethod = "none"
	ProxyModeAuthenticationMethodManual ProxyModeAuthenticationMethod = "manual"
	ProxyModeAuthenticationMethodSecret ProxyModeAuthenticationMethod = "secret"
)

func (e ProxyModeAuthenticationMethod) ToPointer() *ProxyModeAuthenticationMethod {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *ProxyModeAuthenticationMethod) IsExact() bool {
	if e != nil {
		switch *e {
		case "none", "manual", "secret":
			return true
		}
	}
	return false
}

type ProxyModeElastic struct {
	// Enable proxying of non-bulk API requests to an external Elastic server. Enable this only if you understand the implications. See [Cribl Docs](https://docs.cribl.io/stream/sources-elastic/#proxy-mode) for more details.
	Enabled bool `json:"enabled"`
	// Enter credentials directly, or select a stored secret
	AuthType *ProxyModeAuthenticationMethod `json:"authType,omitzero"`
	Username *string                        `json:"username,omitzero"`
	Password *string                        `json:"password,omitzero"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitzero"`
	// URL of the Elastic server to proxy non-bulk requests to, such as http://elastic:9200
	URL *string `json:"url,omitzero"`
	// Reject certificates that cannot be verified against a valid CA (such as self-signed certificates)
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitzero"`
	// List of headers to remove from the request to proxy
	RemoveHeaders []string `json:"removeHeaders,omitzero"`
	// Amount of time, in seconds, to wait for a proxy request to complete before canceling it
	TimeoutSec *float64 `json:"timeoutSec,omitzero"`
}

func (p ProxyModeElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *ProxyModeElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *ProxyModeElastic) GetEnabled() bool {
	if p == nil {
		return false
	}
	return p.Enabled
}

func (p *ProxyModeElastic) GetAuthType() *ProxyModeAuthenticationMethod {
	if p == nil {
		return nil
	}
	return p.AuthType
}

func (p *ProxyModeElastic) GetUsername() *string {
	if p == nil {
		return nil
	}
	return p.Username
}

func (p *ProxyModeElastic) GetPassword() *string {
	if p == nil {
		return nil
	}
	return p.Password
}

func (p *ProxyModeElastic) GetCredentialsSecret() *string {
	if p == nil {
		return nil
	}
	return p.CredentialsSecret
}

func (p *ProxyModeElastic) GetURL() *string {
	if p == nil {
		return nil
	}
	return p.URL
}

func (p *ProxyModeElastic) GetRejectUnauthorized() *bool {
	if p == nil {
		return nil
	}
	return p.RejectUnauthorized
}

func (p *ProxyModeElastic) GetRemoveHeaders() []string {
	if p == nil {
		return nil
	}
	return p.RemoveHeaders
}

func (p *ProxyModeElastic) GetTimeoutSec() *float64 {
	if p == nil {
		return nil
	}
	return p.TimeoutSec
}

type InputElastic struct {
	// Unique ID for this input
	ID       string                 `json:"id"`
	Type     CreateInputTypeElastic `json:"type"`
	Disabled *bool                  `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64                               `json:"port"`
	TLS  *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `json:"maxActiveReq,omitzero"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `json:"maxRequestsPerSocket,omitzero"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `json:"captureHeaders,omitzero"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `json:"activityLogSampleRate,omitzero"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitzero"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `json:"enableHealthCheck,omitzero"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `json:"ipAllowlistRegex,omitzero"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `json:"ipDenylistRegex,omitzero"`
	// Absolute path on which to listen for Elasticsearch API requests. Defaults to /. _bulk will be appended automatically. For example, /myPath becomes /myPath/_bulk. Requests can then be made to either /myPath/_bulk or /myPath/<myIndexName>/_bulk. Other entries are faked as success.
	ElasticAPI string                     `json:"elasticAPI"`
	AuthType   *AuthenticationTypeElastic `json:"authType,omitzero"`
	// The API version to use for communicating with the server
	APIVersion *CreateInputAPIVersion `json:"apiVersion,omitzero"`
	// Headers to add to all events
	ExtraHTTPHeaders []components.ItemsTypeExtraHTTPHeaders `json:"extraHttpHeaders,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	ProxyMode   *ProxyModeElastic                          `json:"proxyMode,omitzero"`
	Description *string                                    `json:"description,omitzero"`
	Username    *string                                    `json:"username,omitzero"`
	Password    *string                                    `json:"password,omitzero"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitzero"`
	// Bearer tokens to include in the authorization header
	AuthTokens []string `json:"authTokens,omitzero"`
	// Custom version information to respond to requests
	CustomAPIVersion *string `json:"customAPIVersion,omitzero"`
}

func (i InputElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputElastic) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputElastic) GetType() CreateInputTypeElastic {
	if i == nil {
		return CreateInputTypeElastic("")
	}
	return i.Type
}

func (i *InputElastic) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputElastic) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputElastic) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputElastic) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputElastic) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputElastic) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputElastic) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputElastic) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputElastic) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputElastic) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputElastic) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputElastic) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputElastic) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputElastic) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputElastic) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputElastic) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputElastic) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputElastic) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputElastic) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputElastic) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputElastic) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputElastic) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputElastic) GetElasticAPI() string {
	if i == nil {
		return ""
	}
	return i.ElasticAPI
}

func (i *InputElastic) GetAuthType() *AuthenticationTypeElastic {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputElastic) GetAPIVersion() *CreateInputAPIVersion {
	if i == nil {
		return nil
	}
	return i.APIVersion
}

func (i *InputElastic) GetExtraHTTPHeaders() []components.ItemsTypeExtraHTTPHeaders {
	if i == nil {
		return nil
	}
	return i.ExtraHTTPHeaders
}

func (i *InputElastic) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputElastic) GetProxyMode() *ProxyModeElastic {
	if i == nil {
		return nil
	}
	return i.ProxyMode
}

func (i *InputElastic) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputElastic) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputElastic) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputElastic) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputElastic) GetAuthTokens() []string {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputElastic) GetCustomAPIVersion() *string {
	if i == nil {
		return nil
	}
	return i.CustomAPIVersion
}

type CreateInputTypeAzureBlob string

const (
	CreateInputTypeAzureBlobAzureBlob CreateInputTypeAzureBlob = "azure_blob"
)

func (e CreateInputTypeAzureBlob) ToPointer() *CreateInputTypeAzureBlob {
	return &e
}
func (e *CreateInputTypeAzureBlob) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_blob":
		*e = CreateInputTypeAzureBlob(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeAzureBlob: %v", v)
	}
}

type InputAzureBlob struct {
	// Unique ID for this input
	ID       string                   `json:"id"`
	Type     CreateInputTypeAzureBlob `json:"type"`
	Disabled *bool                    `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// The storage account queue name blob notifications will be read from. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myQueue-${C.vars.myVar}`
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `json:"fileFilter,omitzero"`
	// The duration (in seconds) that the received messages are hidden from subsequent retrieve requests after being retrieved by a ReceiveMessage request.
	VisibilityTimeout *float64 `json:"visibilityTimeout,omitzero"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `json:"numReceivers,omitzero"`
	// The maximum number of messages to return in a poll request. Azure storage queues never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 32.
	MaxMessages *float64 `json:"maxMessages,omitzero"`
	// The duration (in seconds) which pollers should be validated and restarted if exited
	ServicePeriodSecs *float64 `json:"servicePeriodSecs,omitzero"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `json:"skipOnError,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitzero"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `json:"staleChannelFlushMs,omitzero"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `json:"parquetChunkSizeMB,omitzero"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64                                `json:"parquetChunkDownloadTimeout,omitzero"`
	AuthType                    *components.AuthenticationMethodOptions `json:"authType,omitzero"`
	Description                 *string                                 `json:"description,omitzero"`
	// Enter your Azure Storage account connection string. If left blank, Stream will fall back to env.AZURE_STORAGE_CONNECTION_STRING.
	ConnectionString *string `json:"connectionString,omitzero"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitzero"`
	// The name of your Azure storage account
	StorageAccountName *string `json:"storageAccountName,omitzero"`
	// The service principal's tenant ID
	TenantID *string `json:"tenantId,omitzero"`
	// The service principal's client ID
	ClientID *string `json:"clientId,omitzero"`
	// The Azure cloud to use. Defaults to Azure Public Cloud.
	AzureCloud *string `json:"azureCloud,omitzero"`
	// Endpoint suffix for the service URL. Takes precedence over the Azure Cloud setting. Defaults to core.windows.net.
	EndpointSuffix *string `json:"endpointSuffix,omitzero"`
	// Select or create a stored text secret
	ClientTextSecret *string                                                `json:"clientTextSecret,omitzero"`
	Certificate      *components.CertificateTypeAzureBlobAuthTypeClientCert `json:"certificate,omitzero"`
}

func (i InputAzureBlob) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAzureBlob) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputAzureBlob) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputAzureBlob) GetType() CreateInputTypeAzureBlob {
	if i == nil {
		return CreateInputTypeAzureBlob("")
	}
	return i.Type
}

func (i *InputAzureBlob) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputAzureBlob) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputAzureBlob) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputAzureBlob) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputAzureBlob) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputAzureBlob) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputAzureBlob) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputAzureBlob) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputAzureBlob) GetQueueName() string {
	if i == nil {
		return ""
	}
	return i.QueueName
}

func (i *InputAzureBlob) GetFileFilter() *string {
	if i == nil {
		return nil
	}
	return i.FileFilter
}

func (i *InputAzureBlob) GetVisibilityTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.VisibilityTimeout
}

func (i *InputAzureBlob) GetNumReceivers() *float64 {
	if i == nil {
		return nil
	}
	return i.NumReceivers
}

func (i *InputAzureBlob) GetMaxMessages() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMessages
}

func (i *InputAzureBlob) GetServicePeriodSecs() *float64 {
	if i == nil {
		return nil
	}
	return i.ServicePeriodSecs
}

func (i *InputAzureBlob) GetSkipOnError() *bool {
	if i == nil {
		return nil
	}
	return i.SkipOnError
}

func (i *InputAzureBlob) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputAzureBlob) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputAzureBlob) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputAzureBlob) GetParquetChunkSizeMB() *float64 {
	if i == nil {
		return nil
	}
	return i.ParquetChunkSizeMB
}

func (i *InputAzureBlob) GetParquetChunkDownloadTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.ParquetChunkDownloadTimeout
}

func (i *InputAzureBlob) GetAuthType() *components.AuthenticationMethodOptions {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputAzureBlob) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputAzureBlob) GetConnectionString() *string {
	if i == nil {
		return nil
	}
	return i.ConnectionString
}

func (i *InputAzureBlob) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputAzureBlob) GetStorageAccountName() *string {
	if i == nil {
		return nil
	}
	return i.StorageAccountName
}

func (i *InputAzureBlob) GetTenantID() *string {
	if i == nil {
		return nil
	}
	return i.TenantID
}

func (i *InputAzureBlob) GetClientID() *string {
	if i == nil {
		return nil
	}
	return i.ClientID
}

func (i *InputAzureBlob) GetAzureCloud() *string {
	if i == nil {
		return nil
	}
	return i.AzureCloud
}

func (i *InputAzureBlob) GetEndpointSuffix() *string {
	if i == nil {
		return nil
	}
	return i.EndpointSuffix
}

func (i *InputAzureBlob) GetClientTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.ClientTextSecret
}

func (i *InputAzureBlob) GetCertificate() *components.CertificateTypeAzureBlobAuthTypeClientCert {
	if i == nil {
		return nil
	}
	return i.Certificate
}

type CreateInputTypeSplunkHec string

const (
	CreateInputTypeSplunkHecSplunkHec CreateInputTypeSplunkHec = "splunk_hec"
)

func (e CreateInputTypeSplunkHec) ToPointer() *CreateInputTypeSplunkHec {
	return &e
}
func (e *CreateInputTypeSplunkHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk_hec":
		*e = CreateInputTypeSplunkHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeSplunkHec: %v", v)
	}
}

type AuthTokenSplunkHec struct {
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *components.AuthenticationMethodOptionsAuthTokensItems `json:"authType,omitzero"`
	// Select or create a stored text secret
	TokenSecret *string `json:"tokenSecret,omitzero"`
	// Shared secret to be provided by any client (Authorization: <token>)
	Token   string `json:"token"`
	Enabled *bool  `json:"enabled,omitzero"`
	// Optional token description
	Description *string `json:"description,omitzero"`
	// Enter the values you want to allow in the HEC event index field at the token level. Supports wildcards. To skip validation, leave blank.
	AllowedIndexesAtToken []string `json:"allowedIndexesAtToken,omitzero"`
	// Fields to add to events referencing this token
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
}

func (a AuthTokenSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokenSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokenSplunkHec) GetAuthType() *components.AuthenticationMethodOptionsAuthTokensItems {
	if a == nil {
		return nil
	}
	return a.AuthType
}

func (a *AuthTokenSplunkHec) GetTokenSecret() *string {
	if a == nil {
		return nil
	}
	return a.TokenSecret
}

func (a *AuthTokenSplunkHec) GetToken() string {
	if a == nil {
		return ""
	}
	return a.Token
}

func (a *AuthTokenSplunkHec) GetEnabled() *bool {
	if a == nil {
		return nil
	}
	return a.Enabled
}

func (a *AuthTokenSplunkHec) GetDescription() *string {
	if a == nil {
		return nil
	}
	return a.Description
}

func (a *AuthTokenSplunkHec) GetAllowedIndexesAtToken() []string {
	if a == nil {
		return nil
	}
	return a.AllowedIndexesAtToken
}

func (a *AuthTokenSplunkHec) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if a == nil {
		return nil
	}
	return a.Metadata
}

type InputSplunkHec struct {
	// Unique ID for this input
	ID       string                   `json:"id"`
	Type     CreateInputTypeSplunkHec `json:"type"`
	Disabled *bool                    `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []AuthTokenSplunkHec                  `json:"authTokens,omitzero"`
	TLS        *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `json:"maxActiveReq,omitzero"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `json:"maxRequestsPerSocket,omitzero"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `json:"captureHeaders,omitzero"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `json:"activityLogSampleRate,omitzero"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout  *float64 `json:"keepAliveTimeout,omitzero"`
	EnableHealthCheck any      `json:"enableHealthCheck,omitzero"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `json:"ipAllowlistRegex,omitzero"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `json:"ipDenylistRegex,omitzero"`
	// Absolute path on which to listen for the Splunk HTTP Event Collector API requests. This input supports the /event, /raw and /s2s endpoints.
	SplunkHecAPI string `json:"splunkHecAPI"`
	// Fields to add to every event. Overrides fields added at the token or request level. See [the Source documentation](https://docs.cribl.io/stream/sources-splunk-hec/#fields) for more info.
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// List values allowed in HEC event index field. Leave blank to skip validation. Supports wildcards. The values here can expand index validation at the token level.
	AllowedIndexes []string `json:"allowedIndexes,omitzero"`
	// Enable Splunk HEC acknowledgements
	SplunkHecAcks *bool `json:"splunkHecAcks,omitzero"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitzero"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `json:"staleChannelFlushMs,omitzero"`
	// Event Breakers will determine events' time zone from UF-provided metadata, when TZ can't be inferred from the raw event
	UseFwdTimezone *bool `json:"useFwdTimezone,omitzero"`
	// Drop Splunk control fields such as `crcSalt` and `_savedPort`. If disabled, control fields are stored in the internal field `__ctrlFields`.
	DropControlFields *bool `json:"dropControlFields,omitzero"`
	// Extract and process Splunk-generated metrics as Cribl metrics
	ExtractMetrics *bool `json:"extractMetrics,omitzero"`
	// Optionally, list HTTP origins to which @{product} should send CORS (cross-origin resource sharing) Access-Control-Allow-* headers. Supports wildcards.
	AccessControlAllowOrigin []string `json:"accessControlAllowOrigin,omitzero"`
	// Optionally, list HTTP headers that @{product} will send to allowed origins as "Access-Control-Allow-Headers" in a CORS preflight response. Use "*" to allow all headers.
	AccessControlAllowHeaders []string `json:"accessControlAllowHeaders,omitzero"`
	// Emit per-token (<prefix>.http.perToken) and summary (<prefix>.http.summary) request metrics
	EmitTokenMetrics *bool   `json:"emitTokenMetrics,omitzero"`
	Description      *string `json:"description,omitzero"`
}

func (i InputSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputSplunkHec) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputSplunkHec) GetType() CreateInputTypeSplunkHec {
	if i == nil {
		return CreateInputTypeSplunkHec("")
	}
	return i.Type
}

func (i *InputSplunkHec) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSplunkHec) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSplunkHec) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputSplunkHec) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputSplunkHec) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputSplunkHec) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputSplunkHec) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputSplunkHec) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputSplunkHec) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputSplunkHec) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputSplunkHec) GetAuthTokens() []AuthTokenSplunkHec {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputSplunkHec) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputSplunkHec) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputSplunkHec) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputSplunkHec) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputSplunkHec) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputSplunkHec) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputSplunkHec) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputSplunkHec) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputSplunkHec) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputSplunkHec) GetEnableHealthCheck() any {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputSplunkHec) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputSplunkHec) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputSplunkHec) GetSplunkHecAPI() string {
	if i == nil {
		return ""
	}
	return i.SplunkHecAPI
}

func (i *InputSplunkHec) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputSplunkHec) GetAllowedIndexes() []string {
	if i == nil {
		return nil
	}
	return i.AllowedIndexes
}

func (i *InputSplunkHec) GetSplunkHecAcks() *bool {
	if i == nil {
		return nil
	}
	return i.SplunkHecAcks
}

func (i *InputSplunkHec) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputSplunkHec) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputSplunkHec) GetUseFwdTimezone() *bool {
	if i == nil {
		return nil
	}
	return i.UseFwdTimezone
}

func (i *InputSplunkHec) GetDropControlFields() *bool {
	if i == nil {
		return nil
	}
	return i.DropControlFields
}

func (i *InputSplunkHec) GetExtractMetrics() *bool {
	if i == nil {
		return nil
	}
	return i.ExtractMetrics
}

func (i *InputSplunkHec) GetAccessControlAllowOrigin() []string {
	if i == nil {
		return nil
	}
	return i.AccessControlAllowOrigin
}

func (i *InputSplunkHec) GetAccessControlAllowHeaders() []string {
	if i == nil {
		return nil
	}
	return i.AccessControlAllowHeaders
}

func (i *InputSplunkHec) GetEmitTokenMetrics() *bool {
	if i == nil {
		return nil
	}
	return i.EmitTokenMetrics
}

func (i *InputSplunkHec) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type TypeSplunkSearch string

const (
	TypeSplunkSearchSplunkSearch TypeSplunkSearch = "splunk_search"
)

func (e TypeSplunkSearch) ToPointer() *TypeSplunkSearch {
	return &e
}
func (e *TypeSplunkSearch) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk_search":
		*e = TypeSplunkSearch(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeSplunkSearch: %v", v)
	}
}

type EndpointParam struct {
	Name string `json:"name"`
	// JavaScript expression to compute the parameter's value, normally enclosed in backticks (e.g.,`${earliest}`). Ifa constant, use single quotes (e.g.,'earliest'). Valueswithout delimiters (e.g.,earliest) are evaluated as strings.
	Value string `json:"value"`
}

func (e EndpointParam) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(e, "", false)
}

func (e *EndpointParam) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &e, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (e *EndpointParam) GetName() string {
	if e == nil {
		return ""
	}
	return e.Name
}

func (e *EndpointParam) GetValue() string {
	if e == nil {
		return ""
	}
	return e.Value
}

type EndpointHeader struct {
	Name string `json:"name"`
	// JavaScript expression to compute the header's value, normally enclosed in backticks (e.g.,`${earliest}`). Ifa constant, use single quotes (e.g.,'earliest'). Valueswithout delimiters (e.g.,earliest) are evaluated as strings.
	Value string `json:"value"`
}

func (e EndpointHeader) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(e, "", false)
}

func (e *EndpointHeader) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &e, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (e *EndpointHeader) GetName() string {
	if e == nil {
		return ""
	}
	return e.Name
}

func (e *EndpointHeader) GetValue() string {
	if e == nil {
		return ""
	}
	return e.Value
}

// LogLevelSplunkSearch - Collector runtime log level (verbosity)
type LogLevelSplunkSearch string

const (
	LogLevelSplunkSearchError LogLevelSplunkSearch = "error"
	LogLevelSplunkSearchWarn  LogLevelSplunkSearch = "warn"
	LogLevelSplunkSearchInfo  LogLevelSplunkSearch = "info"
	LogLevelSplunkSearchDebug LogLevelSplunkSearch = "debug"
)

func (e LogLevelSplunkSearch) ToPointer() *LogLevelSplunkSearch {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *LogLevelSplunkSearch) IsExact() bool {
	if e != nil {
		switch *e {
		case "error", "warn", "info", "debug":
			return true
		}
	}
	return false
}

// AuthenticationTypeSplunkSearch - Splunk Search authentication type
type AuthenticationTypeSplunkSearch string

const (
	AuthenticationTypeSplunkSearchNone              AuthenticationTypeSplunkSearch = "none"
	AuthenticationTypeSplunkSearchBasic             AuthenticationTypeSplunkSearch = "basic"
	AuthenticationTypeSplunkSearchCredentialsSecret AuthenticationTypeSplunkSearch = "credentialsSecret"
	AuthenticationTypeSplunkSearchToken             AuthenticationTypeSplunkSearch = "token"
	AuthenticationTypeSplunkSearchTextSecret        AuthenticationTypeSplunkSearch = "textSecret"
	AuthenticationTypeSplunkSearchOauth             AuthenticationTypeSplunkSearch = "oauth"
)

func (e AuthenticationTypeSplunkSearch) ToPointer() *AuthenticationTypeSplunkSearch {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *AuthenticationTypeSplunkSearch) IsExact() bool {
	if e != nil {
		switch *e {
		case "none", "basic", "credentialsSecret", "token", "textSecret", "oauth":
			return true
		}
	}
	return false
}

type InputSplunkSearch struct {
	// Unique ID for this input
	ID       string           `json:"id"`
	Type     TypeSplunkSearch `json:"type"`
	Disabled *bool            `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Search head base URL. Can be an expression. Default is https://localhost:8089.
	SearchHead string `json:"searchHead"`
	// Enter Splunk search here. Examples: 'index=myAppLogs level=error channel=myApp' OR '| mstats avg(myStat) as myStat WHERE index=myStatsIndex.'
	Search string `json:"search"`
	// The earliest time boundary for the search. Can be an exact or relative time. Examples: '2022-01-14T12:00:00Z' or '-16m@m'
	Earliest *string `json:"earliest,omitzero"`
	// The latest time boundary for the search. Can be an exact or relative time. Examples: '2022-01-14T12:00:00Z' or '-1m@m'
	Latest *string `json:"latest,omitzero"`
	// A cron schedule on which to run this job
	CronSchedule string `json:"cronSchedule"`
	// REST API used to create a search
	Endpoint string `json:"endpoint"`
	// Format of the returned output
	OutputMode components.OutputModeOptionsSplunkCollectorConf `json:"outputMode"`
	// Optional request parameters to send to the endpoint
	EndpointParams []EndpointParam `json:"endpointParams,omitzero"`
	// Optional request headers to send to the endpoint
	EndpointHeaders []EndpointHeader `json:"endpointHeaders,omitzero"`
	// Collector runtime log level (verbosity)
	LogLevel *LogLevelSplunkSearch `json:"logLevel,omitzero"`
	// HTTP request inactivity timeout. Use 0 for no timeout.
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned
	UseRoundRobinDNS *bool `json:"useRoundRobinDns,omitzero"`
	// Reject certificates that cannot be verified against a valid CA (such as self-signed certificates)
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitzero"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding *string `json:"encoding,omitzero"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `json:"keepAliveTime,omitzero"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `json:"jobTimeout,omitzero"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `json:"maxMissedKeepAlives,omitzero"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `json:"ttl,omitzero"`
	// When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
	IgnoreGroupJobsLimit *bool `json:"ignoreGroupJobsLimit,omitzero"`
	// Fields to add to events from this input
	Metadata   []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	RetryRules *components.RetryRulesType                 `json:"retryRules,omitzero"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitzero"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `json:"staleChannelFlushMs,omitzero"`
	// Splunk Search authentication type
	AuthType    *AuthenticationTypeSplunkSearch `json:"authType,omitzero"`
	Description *string                         `json:"description,omitzero"`
	Username    *string                         `json:"username,omitzero"`
	Password    *string                         `json:"password,omitzero"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitzero"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitzero"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitzero"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitzero"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitzero"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitzero"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitzero"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `json:"authHeaderExpr,omitzero"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `json:"tokenTimeoutSecs,omitzero"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []components.ItemsTypeOauthParams `json:"oauthParams,omitzero"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []components.ItemsTypeOauthHeaders `json:"oauthHeaders,omitzero"`
}

func (i InputSplunkSearch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunkSearch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputSplunkSearch) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputSplunkSearch) GetType() TypeSplunkSearch {
	if i == nil {
		return TypeSplunkSearch("")
	}
	return i.Type
}

func (i *InputSplunkSearch) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSplunkSearch) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSplunkSearch) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputSplunkSearch) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputSplunkSearch) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputSplunkSearch) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputSplunkSearch) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputSplunkSearch) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputSplunkSearch) GetSearchHead() string {
	if i == nil {
		return ""
	}
	return i.SearchHead
}

func (i *InputSplunkSearch) GetSearch() string {
	if i == nil {
		return ""
	}
	return i.Search
}

func (i *InputSplunkSearch) GetEarliest() *string {
	if i == nil {
		return nil
	}
	return i.Earliest
}

func (i *InputSplunkSearch) GetLatest() *string {
	if i == nil {
		return nil
	}
	return i.Latest
}

func (i *InputSplunkSearch) GetCronSchedule() string {
	if i == nil {
		return ""
	}
	return i.CronSchedule
}

func (i *InputSplunkSearch) GetEndpoint() string {
	if i == nil {
		return ""
	}
	return i.Endpoint
}

func (i *InputSplunkSearch) GetOutputMode() components.OutputModeOptionsSplunkCollectorConf {
	if i == nil {
		return components.OutputModeOptionsSplunkCollectorConf("")
	}
	return i.OutputMode
}

func (i *InputSplunkSearch) GetEndpointParams() []EndpointParam {
	if i == nil {
		return nil
	}
	return i.EndpointParams
}

func (i *InputSplunkSearch) GetEndpointHeaders() []EndpointHeader {
	if i == nil {
		return nil
	}
	return i.EndpointHeaders
}

func (i *InputSplunkSearch) GetLogLevel() *LogLevelSplunkSearch {
	if i == nil {
		return nil
	}
	return i.LogLevel
}

func (i *InputSplunkSearch) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputSplunkSearch) GetUseRoundRobinDNS() *bool {
	if i == nil {
		return nil
	}
	return i.UseRoundRobinDNS
}

func (i *InputSplunkSearch) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputSplunkSearch) GetEncoding() *string {
	if i == nil {
		return nil
	}
	return i.Encoding
}

func (i *InputSplunkSearch) GetKeepAliveTime() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTime
}

func (i *InputSplunkSearch) GetJobTimeout() *string {
	if i == nil {
		return nil
	}
	return i.JobTimeout
}

func (i *InputSplunkSearch) GetMaxMissedKeepAlives() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxMissedKeepAlives
}

func (i *InputSplunkSearch) GetTTL() *string {
	if i == nil {
		return nil
	}
	return i.TTL
}

func (i *InputSplunkSearch) GetIgnoreGroupJobsLimit() *bool {
	if i == nil {
		return nil
	}
	return i.IgnoreGroupJobsLimit
}

func (i *InputSplunkSearch) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputSplunkSearch) GetRetryRules() *components.RetryRulesType {
	if i == nil {
		return nil
	}
	return i.RetryRules
}

func (i *InputSplunkSearch) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputSplunkSearch) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputSplunkSearch) GetAuthType() *AuthenticationTypeSplunkSearch {
	if i == nil {
		return nil
	}
	return i.AuthType
}

func (i *InputSplunkSearch) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputSplunkSearch) GetUsername() *string {
	if i == nil {
		return nil
	}
	return i.Username
}

func (i *InputSplunkSearch) GetPassword() *string {
	if i == nil {
		return nil
	}
	return i.Password
}

func (i *InputSplunkSearch) GetToken() *string {
	if i == nil {
		return nil
	}
	return i.Token
}

func (i *InputSplunkSearch) GetCredentialsSecret() *string {
	if i == nil {
		return nil
	}
	return i.CredentialsSecret
}

func (i *InputSplunkSearch) GetTextSecret() *string {
	if i == nil {
		return nil
	}
	return i.TextSecret
}

func (i *InputSplunkSearch) GetLoginURL() *string {
	if i == nil {
		return nil
	}
	return i.LoginURL
}

func (i *InputSplunkSearch) GetSecretParamName() *string {
	if i == nil {
		return nil
	}
	return i.SecretParamName
}

func (i *InputSplunkSearch) GetSecret() *string {
	if i == nil {
		return nil
	}
	return i.Secret
}

func (i *InputSplunkSearch) GetTokenAttributeName() *string {
	if i == nil {
		return nil
	}
	return i.TokenAttributeName
}

func (i *InputSplunkSearch) GetAuthHeaderExpr() *string {
	if i == nil {
		return nil
	}
	return i.AuthHeaderExpr
}

func (i *InputSplunkSearch) GetTokenTimeoutSecs() *float64 {
	if i == nil {
		return nil
	}
	return i.TokenTimeoutSecs
}

func (i *InputSplunkSearch) GetOauthParams() []components.ItemsTypeOauthParams {
	if i == nil {
		return nil
	}
	return i.OauthParams
}

func (i *InputSplunkSearch) GetOauthHeaders() []components.ItemsTypeOauthHeaders {
	if i == nil {
		return nil
	}
	return i.OauthHeaders
}

type CreateInputTypeSplunk string

const (
	CreateInputTypeSplunkSplunk CreateInputTypeSplunk = "splunk"
)

func (e CreateInputTypeSplunk) ToPointer() *CreateInputTypeSplunk {
	return &e
}
func (e *CreateInputTypeSplunk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk":
		*e = CreateInputTypeSplunk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeSplunk: %v", v)
	}
}

type AuthTokenSplunk struct {
	// Shared secrets to be provided by any Splunk forwarder. Ifempty, unauthorized access is permitted.
	Token       string  `json:"token"`
	Description *string `json:"description,omitzero"`
}

func (a AuthTokenSplunk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokenSplunk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AuthTokenSplunk) GetToken() string {
	if a == nil {
		return ""
	}
	return a.Token
}

func (a *AuthTokenSplunk) GetDescription() *string {
	if a == nil {
		return nil
	}
	return a.Description
}

// MaxS2SVersion - The highest S2S protocol version to advertise during handshake
type MaxS2SVersion string

const (
	// MaxS2SVersionV3 v3
	MaxS2SVersionV3 MaxS2SVersion = "v3"
	// MaxS2SVersionV4 v4
	MaxS2SVersionV4 MaxS2SVersion = "v4"
)

func (e MaxS2SVersion) ToPointer() *MaxS2SVersion {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *MaxS2SVersion) IsExact() bool {
	if e != nil {
		switch *e {
		case "v3", "v4":
			return true
		}
	}
	return false
}

// CreateInputCompression - Controls whether to support reading compressed data from a forwarder. Select 'Automatic' to match the forwarder's configuration, or 'Disabled' to reject compressed connections.
type CreateInputCompression string

const (
	// CreateInputCompressionDisabled Disabled
	CreateInputCompressionDisabled CreateInputCompression = "disabled"
	// CreateInputCompressionAuto Automatic
	CreateInputCompressionAuto CreateInputCompression = "auto"
	// CreateInputCompressionAlways Always
	CreateInputCompressionAlways CreateInputCompression = "always"
)

func (e CreateInputCompression) ToPointer() *CreateInputCompression {
	return &e
}

// IsExact returns true if the value matches a known enum value, false otherwise.
func (e *CreateInputCompression) IsExact() bool {
	if e != nil {
		switch *e {
		case "disabled", "auto", "always":
			return true
		}
	}
	return false
}

type InputSplunk struct {
	// Unique ID for this input
	ID       string                `json:"id"`
	Type     CreateInputTypeSplunk `json:"type"`
	Disabled *bool                 `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64                               `json:"port"`
	TLS  *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Regex matching IP addresses that are allowed to establish a connection
	IPWhitelistRegex *string `json:"ipWhitelistRegex,omitzero"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `json:"maxActiveCxn,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `json:"socketIdleTimeout,omitzero"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `json:"socketEndingMaxWait,omitzero"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `json:"socketMaxLifespan,omitzero"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitzero"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `json:"staleChannelFlushMs,omitzero"`
	// Shared secrets to be provided by any Splunk forwarder. Ifempty, unauthorized access is permitted.
	AuthTokens []AuthTokenSplunk `json:"authTokens,omitzero"`
	// The highest S2S protocol version to advertise during handshake
	MaxS2Sversion *MaxS2SVersion `json:"maxS2Sversion,omitzero"`
	Description   *string        `json:"description,omitzero"`
	// Event Breakers will determine events' time zone from UF-provided metadata, when TZ can't be inferred from the raw event
	UseFwdTimezone *bool `json:"useFwdTimezone,omitzero"`
	// Drop Splunk control fields such as `crcSalt` and `_savedPort`. If disabled, control fields are stored in the internal field `__ctrlFields`.
	DropControlFields *bool `json:"dropControlFields,omitzero"`
	// Extract and process Splunk-generated metrics as Cribl metrics
	ExtractMetrics *bool `json:"extractMetrics,omitzero"`
	// Controls whether to support reading compressed data from a forwarder. Select 'Automatic' to match the forwarder's configuration, or 'Disabled' to reject compressed connections.
	Compress *CreateInputCompression `json:"compress,omitzero"`
}

func (i InputSplunk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputSplunk) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputSplunk) GetType() CreateInputTypeSplunk {
	if i == nil {
		return CreateInputTypeSplunk("")
	}
	return i.Type
}

func (i *InputSplunk) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputSplunk) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputSplunk) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputSplunk) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputSplunk) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputSplunk) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputSplunk) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputSplunk) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputSplunk) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputSplunk) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputSplunk) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputSplunk) GetIPWhitelistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPWhitelistRegex
}

func (i *InputSplunk) GetMaxActiveCxn() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveCxn
}

func (i *InputSplunk) GetSocketIdleTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketIdleTimeout
}

func (i *InputSplunk) GetSocketEndingMaxWait() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketEndingMaxWait
}

func (i *InputSplunk) GetSocketMaxLifespan() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketMaxLifespan
}

func (i *InputSplunk) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputSplunk) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputSplunk) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputSplunk) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputSplunk) GetAuthTokens() []AuthTokenSplunk {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputSplunk) GetMaxS2Sversion() *MaxS2SVersion {
	if i == nil {
		return nil
	}
	return i.MaxS2Sversion
}

func (i *InputSplunk) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputSplunk) GetUseFwdTimezone() *bool {
	if i == nil {
		return nil
	}
	return i.UseFwdTimezone
}

func (i *InputSplunk) GetDropControlFields() *bool {
	if i == nil {
		return nil
	}
	return i.DropControlFields
}

func (i *InputSplunk) GetExtractMetrics() *bool {
	if i == nil {
		return nil
	}
	return i.ExtractMetrics
}

func (i *InputSplunk) GetCompress() *CreateInputCompression {
	if i == nil {
		return nil
	}
	return i.Compress
}

type TypeHTTP string

const (
	TypeHTTPHTTP TypeHTTP = "http"
)

func (e TypeHTTP) ToPointer() *TypeHTTP {
	return &e
}
func (e *TypeHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http":
		*e = TypeHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeHTTP: %v", v)
	}
}

type InputHTTP struct {
	// Unique ID for this input
	ID       string   `json:"id"`
	Type     TypeHTTP `json:"type"`
	Disabled *bool    `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host string `json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                              `json:"authTokens,omitzero"`
	TLS        *components.TLSSettingsServerSideType `json:"tls,omitzero"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `json:"maxActiveReq,omitzero"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `json:"maxRequestsPerSocket,omitzero"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `json:"enableProxyHeader,omitzero"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `json:"captureHeaders,omitzero"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `json:"activityLogSampleRate,omitzero"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `json:"socketTimeout,omitzero"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `json:"keepAliveTimeout,omitzero"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `json:"enableHealthCheck,omitzero"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `json:"ipAllowlistRegex,omitzero"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `json:"ipDenylistRegex,omitzero"`
	// Absolute path on which to listen for the Cribl HTTP API requests. Only _bulk (default /cribl/_bulk) is available. Use empty string to disable.
	CriblAPI *string `json:"criblAPI,omitzero"`
	// Absolute path on which to listen for the Elasticsearch API requests. Only _bulk (default /elastic/_bulk) is available. Use empty string to disable.
	ElasticAPI *string `json:"elasticAPI,omitzero"`
	// Absolute path on which listen for the Splunk HTTP Event Collector API requests. Use empty string to disable.
	SplunkHecAPI  *string `json:"splunkHecAPI,omitzero"`
	SplunkHecAcks *bool   `json:"splunkHecAcks,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokensExt []components.ItemsTypeAuthTokensExt `json:"authTokensExt,omitzero"`
	Description   *string                             `json:"description,omitzero"`
}

func (i InputHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputHTTP) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputHTTP) GetType() TypeHTTP {
	if i == nil {
		return TypeHTTP("")
	}
	return i.Type
}

func (i *InputHTTP) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputHTTP) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputHTTP) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputHTTP) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputHTTP) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputHTTP) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputHTTP) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputHTTP) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputHTTP) GetHost() string {
	if i == nil {
		return ""
	}
	return i.Host
}

func (i *InputHTTP) GetPort() float64 {
	if i == nil {
		return 0.0
	}
	return i.Port
}

func (i *InputHTTP) GetAuthTokens() []string {
	if i == nil {
		return nil
	}
	return i.AuthTokens
}

func (i *InputHTTP) GetTLS() *components.TLSSettingsServerSideType {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputHTTP) GetMaxActiveReq() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxActiveReq
}

func (i *InputHTTP) GetMaxRequestsPerSocket() *int64 {
	if i == nil {
		return nil
	}
	return i.MaxRequestsPerSocket
}

func (i *InputHTTP) GetEnableProxyHeader() *bool {
	if i == nil {
		return nil
	}
	return i.EnableProxyHeader
}

func (i *InputHTTP) GetCaptureHeaders() *bool {
	if i == nil {
		return nil
	}
	return i.CaptureHeaders
}

func (i *InputHTTP) GetActivityLogSampleRate() *float64 {
	if i == nil {
		return nil
	}
	return i.ActivityLogSampleRate
}

func (i *InputHTTP) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputHTTP) GetSocketTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SocketTimeout
}

func (i *InputHTTP) GetKeepAliveTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.KeepAliveTimeout
}

func (i *InputHTTP) GetEnableHealthCheck() *bool {
	if i == nil {
		return nil
	}
	return i.EnableHealthCheck
}

func (i *InputHTTP) GetIPAllowlistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPAllowlistRegex
}

func (i *InputHTTP) GetIPDenylistRegex() *string {
	if i == nil {
		return nil
	}
	return i.IPDenylistRegex
}

func (i *InputHTTP) GetCriblAPI() *string {
	if i == nil {
		return nil
	}
	return i.CriblAPI
}

func (i *InputHTTP) GetElasticAPI() *string {
	if i == nil {
		return nil
	}
	return i.ElasticAPI
}

func (i *InputHTTP) GetSplunkHecAPI() *string {
	if i == nil {
		return nil
	}
	return i.SplunkHecAPI
}

func (i *InputHTTP) GetSplunkHecAcks() *bool {
	if i == nil {
		return nil
	}
	return i.SplunkHecAcks
}

func (i *InputHTTP) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputHTTP) GetAuthTokensExt() []components.ItemsTypeAuthTokensExt {
	if i == nil {
		return nil
	}
	return i.AuthTokensExt
}

func (i *InputHTTP) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type CreateInputTypeMsk string

const (
	CreateInputTypeMskMsk CreateInputTypeMsk = "msk"
)

func (e CreateInputTypeMsk) ToPointer() *CreateInputTypeMsk {
	return &e
}
func (e *CreateInputTypeMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "msk":
		*e = CreateInputTypeMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeMsk: %v", v)
	}
}

type InputMsk struct {
	// Unique ID for this input
	ID       string             `json:"id"`
	Type     CreateInputTypeMsk `json:"type"`
	Disabled *bool              `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Enter each Kafka bootstrap server you want to use. Specify the hostname and port (such as mykafkabroker:9092) or just the hostname (in which case @{product} will assign port 9092).
	Brokers []string `json:"brokers"`
	// Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to a single topic only.
	Topics []string `json:"topics"`
	// The consumer group to which this instance belongs. Defaults to 'Cribl'.
	GroupID *string `json:"groupId,omitzero"`
	// Leave enabled if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
	FromBeginning *bool `json:"fromBeginning,omitzero"`
	//       Timeout used to detect client failures when using Kafka's group-management facilities.
	//       If the client sends no heartbeats to the broker before the timeout expires,
	//       the broker will remove the client from the group and initiate a rebalance.
	//       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms) for details.
	SessionTimeout *float64 `json:"sessionTimeout,omitzero"`
	//       Maximum allowed time for each worker to join the group after a rebalance begins.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms) for details.
	RebalanceTimeout *float64 `json:"rebalanceTimeout,omitzero"`
	//       Expected time between heartbeats to the consumer coordinator when using Kafka's group-management facilities.
	//       Value must be lower than sessionTimeout and typically should not exceed 1/3 of the sessionTimeout value.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms) for details.
	HeartbeatInterval *float64 `json:"heartbeatInterval,omitzero"`
	// Fields to add to events from this input
	Metadata            []components.ItemsTypeNotificationMetadata        `json:"metadata,omitzero"`
	KafkaSchemaRegistry *components.KafkaSchemaRegistryAuthenticationType `json:"kafkaSchemaRegistry,omitzero"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `json:"connectionTimeout,omitzero"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `json:"maxRetries,omitzero"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `json:"maxBackOff,omitzero"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `json:"initialBackoff,omitzero"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `json:"backoffRate,omitzero"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `json:"authenticationTimeout,omitzero"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `json:"reauthenticationThreshold,omitzero"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod components.AuthenticationMethodOptionsS3CollectorConf `json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                                               `json:"awsSecretKey,omitzero"`
	// Region where the MSK cluster is located
	Region string `json:"region"`
	// MSK cluster service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to MSK cluster-compatible endpoint.
	Endpoint *string `json:"endpoint,omitzero"`
	// Signature version to use for signing MSK cluster requests
	SignatureVersion *components.SignatureVersionOptions `json:"signatureVersion,omitzero"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `json:"reuseConnections,omitzero"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitzero"`
	// Use Assume Role credentials to access MSK
	EnableAssumeRole *bool `json:"enableAssumeRole,omitzero"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitzero"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitzero"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64                                                 `json:"durationSeconds,omitzero"`
	TLS             *components.TLSSettingsClientSideTypeKafkaSchemaRegistry `json:"tls,omitzero"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitzero"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitzero"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `json:"maxBytesPerPartition,omitzero"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `json:"maxBytes,omitzero"`
	// Maximum number of network errors before the consumer re-creates a socket
	MaxSocketErrors *float64 `json:"maxSocketErrors,omitzero"`
	Description     *string  `json:"description,omitzero"`
	AwsAPIKey       *string  `json:"awsApiKey,omitzero"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitzero"`
}

func (i InputMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputMsk) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputMsk) GetType() CreateInputTypeMsk {
	if i == nil {
		return CreateInputTypeMsk("")
	}
	return i.Type
}

func (i *InputMsk) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputMsk) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputMsk) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputMsk) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputMsk) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputMsk) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputMsk) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputMsk) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputMsk) GetBrokers() []string {
	if i == nil {
		return []string{}
	}
	return i.Brokers
}

func (i *InputMsk) GetTopics() []string {
	if i == nil {
		return []string{}
	}
	return i.Topics
}

func (i *InputMsk) GetGroupID() *string {
	if i == nil {
		return nil
	}
	return i.GroupID
}

func (i *InputMsk) GetFromBeginning() *bool {
	if i == nil {
		return nil
	}
	return i.FromBeginning
}

func (i *InputMsk) GetSessionTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SessionTimeout
}

func (i *InputMsk) GetRebalanceTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RebalanceTimeout
}

func (i *InputMsk) GetHeartbeatInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.HeartbeatInterval
}

func (i *InputMsk) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputMsk) GetKafkaSchemaRegistry() *components.KafkaSchemaRegistryAuthenticationType {
	if i == nil {
		return nil
	}
	return i.KafkaSchemaRegistry
}

func (i *InputMsk) GetConnectionTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.ConnectionTimeout
}

func (i *InputMsk) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputMsk) GetMaxRetries() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxRetries
}

func (i *InputMsk) GetMaxBackOff() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBackOff
}

func (i *InputMsk) GetInitialBackoff() *float64 {
	if i == nil {
		return nil
	}
	return i.InitialBackoff
}

func (i *InputMsk) GetBackoffRate() *float64 {
	if i == nil {
		return nil
	}
	return i.BackoffRate
}

func (i *InputMsk) GetAuthenticationTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.AuthenticationTimeout
}

func (i *InputMsk) GetReauthenticationThreshold() *float64 {
	if i == nil {
		return nil
	}
	return i.ReauthenticationThreshold
}

func (i *InputMsk) GetAwsAuthenticationMethod() components.AuthenticationMethodOptionsS3CollectorConf {
	if i == nil {
		return components.AuthenticationMethodOptionsS3CollectorConf("")
	}
	return i.AwsAuthenticationMethod
}

func (i *InputMsk) GetAwsSecretKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecretKey
}

func (i *InputMsk) GetRegion() string {
	if i == nil {
		return ""
	}
	return i.Region
}

func (i *InputMsk) GetEndpoint() *string {
	if i == nil {
		return nil
	}
	return i.Endpoint
}

func (i *InputMsk) GetSignatureVersion() *components.SignatureVersionOptions {
	if i == nil {
		return nil
	}
	return i.SignatureVersion
}

func (i *InputMsk) GetReuseConnections() *bool {
	if i == nil {
		return nil
	}
	return i.ReuseConnections
}

func (i *InputMsk) GetRejectUnauthorized() *bool {
	if i == nil {
		return nil
	}
	return i.RejectUnauthorized
}

func (i *InputMsk) GetEnableAssumeRole() *bool {
	if i == nil {
		return nil
	}
	return i.EnableAssumeRole
}

func (i *InputMsk) GetAssumeRoleArn() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleArn
}

func (i *InputMsk) GetAssumeRoleExternalID() *string {
	if i == nil {
		return nil
	}
	return i.AssumeRoleExternalID
}

func (i *InputMsk) GetDurationSeconds() *float64 {
	if i == nil {
		return nil
	}
	return i.DurationSeconds
}

func (i *InputMsk) GetTLS() *components.TLSSettingsClientSideTypeKafkaSchemaRegistry {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputMsk) GetAutoCommitInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.AutoCommitInterval
}

func (i *InputMsk) GetAutoCommitThreshold() *float64 {
	if i == nil {
		return nil
	}
	return i.AutoCommitThreshold
}

func (i *InputMsk) GetMaxBytesPerPartition() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBytesPerPartition
}

func (i *InputMsk) GetMaxBytes() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBytes
}

func (i *InputMsk) GetMaxSocketErrors() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxSocketErrors
}

func (i *InputMsk) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

func (i *InputMsk) GetAwsAPIKey() *string {
	if i == nil {
		return nil
	}
	return i.AwsAPIKey
}

func (i *InputMsk) GetAwsSecret() *string {
	if i == nil {
		return nil
	}
	return i.AwsSecret
}

type CreateInputTypeKafka string

const (
	CreateInputTypeKafkaKafka CreateInputTypeKafka = "kafka"
)

func (e CreateInputTypeKafka) ToPointer() *CreateInputTypeKafka {
	return &e
}
func (e *CreateInputTypeKafka) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kafka":
		*e = CreateInputTypeKafka(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeKafka: %v", v)
	}
}

type InputKafka struct {
	// Unique ID for this input
	ID       string               `json:"id"`
	Type     CreateInputTypeKafka `json:"type"`
	Disabled *bool                `json:"disabled,omitzero"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitzero"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// Enter each Kafka bootstrap server you want to use. Specify the hostname and port (such as mykafkabroker:9092) or just the hostname (in which case @{product} will assign port 9092).
	Brokers []string `json:"brokers"`
	// Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to a single topic only.
	Topics []string `json:"topics"`
	// The consumer group to which this instance belongs. Defaults to 'Cribl'.
	GroupID *string `json:"groupId,omitzero"`
	// Leave enabled if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
	FromBeginning       *bool                                             `json:"fromBeginning,omitzero"`
	KafkaSchemaRegistry *components.KafkaSchemaRegistryAuthenticationType `json:"kafkaSchemaRegistry,omitzero"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `json:"connectionTimeout,omitzero"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `json:"requestTimeout,omitzero"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `json:"maxRetries,omitzero"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `json:"maxBackOff,omitzero"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `json:"initialBackoff,omitzero"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `json:"backoffRate,omitzero"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `json:"authenticationTimeout,omitzero"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `json:"reauthenticationThreshold,omitzero"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *components.AuthenticationType                           `json:"sasl,omitzero"`
	TLS  *components.TLSSettingsClientSideTypeKafkaSchemaRegistry `json:"tls,omitzero"`
	//       Timeout used to detect client failures when using Kafka's group-management facilities.
	//       If the client sends no heartbeats to the broker before the timeout expires,
	//       the broker will remove the client from the group and initiate a rebalance.
	//       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms) for details.
	SessionTimeout *float64 `json:"sessionTimeout,omitzero"`
	//       Maximum allowed time for each worker to join the group after a rebalance begins.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms) for details.
	RebalanceTimeout *float64 `json:"rebalanceTimeout,omitzero"`
	//       Expected time between heartbeats to the consumer coordinator when using Kafka's group-management facilities.
	//       Value must be lower than sessionTimeout and typically should not exceed 1/3 of the sessionTimeout value.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms) for details.
	HeartbeatInterval *float64 `json:"heartbeatInterval,omitzero"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitzero"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitzero"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `json:"maxBytesPerPartition,omitzero"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `json:"maxBytes,omitzero"`
	// Maximum number of network errors before the consumer re-creates a socket
	MaxSocketErrors *float64 `json:"maxSocketErrors,omitzero"`
	// Fields to add to events from this input
	Metadata    []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	Description *string                                    `json:"description,omitzero"`
}

func (i InputKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputKafka) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputKafka) GetType() CreateInputTypeKafka {
	if i == nil {
		return CreateInputTypeKafka("")
	}
	return i.Type
}

func (i *InputKafka) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputKafka) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputKafka) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputKafka) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputKafka) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputKafka) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputKafka) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputKafka) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputKafka) GetBrokers() []string {
	if i == nil {
		return []string{}
	}
	return i.Brokers
}

func (i *InputKafka) GetTopics() []string {
	if i == nil {
		return []string{}
	}
	return i.Topics
}

func (i *InputKafka) GetGroupID() *string {
	if i == nil {
		return nil
	}
	return i.GroupID
}

func (i *InputKafka) GetFromBeginning() *bool {
	if i == nil {
		return nil
	}
	return i.FromBeginning
}

func (i *InputKafka) GetKafkaSchemaRegistry() *components.KafkaSchemaRegistryAuthenticationType {
	if i == nil {
		return nil
	}
	return i.KafkaSchemaRegistry
}

func (i *InputKafka) GetConnectionTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.ConnectionTimeout
}

func (i *InputKafka) GetRequestTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RequestTimeout
}

func (i *InputKafka) GetMaxRetries() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxRetries
}

func (i *InputKafka) GetMaxBackOff() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBackOff
}

func (i *InputKafka) GetInitialBackoff() *float64 {
	if i == nil {
		return nil
	}
	return i.InitialBackoff
}

func (i *InputKafka) GetBackoffRate() *float64 {
	if i == nil {
		return nil
	}
	return i.BackoffRate
}

func (i *InputKafka) GetAuthenticationTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.AuthenticationTimeout
}

func (i *InputKafka) GetReauthenticationThreshold() *float64 {
	if i == nil {
		return nil
	}
	return i.ReauthenticationThreshold
}

func (i *InputKafka) GetSasl() *components.AuthenticationType {
	if i == nil {
		return nil
	}
	return i.Sasl
}

func (i *InputKafka) GetTLS() *components.TLSSettingsClientSideTypeKafkaSchemaRegistry {
	if i == nil {
		return nil
	}
	return i.TLS
}

func (i *InputKafka) GetSessionTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.SessionTimeout
}

func (i *InputKafka) GetRebalanceTimeout() *float64 {
	if i == nil {
		return nil
	}
	return i.RebalanceTimeout
}

func (i *InputKafka) GetHeartbeatInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.HeartbeatInterval
}

func (i *InputKafka) GetAutoCommitInterval() *float64 {
	if i == nil {
		return nil
	}
	return i.AutoCommitInterval
}

func (i *InputKafka) GetAutoCommitThreshold() *float64 {
	if i == nil {
		return nil
	}
	return i.AutoCommitThreshold
}

func (i *InputKafka) GetMaxBytesPerPartition() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBytesPerPartition
}

func (i *InputKafka) GetMaxBytes() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxBytes
}

func (i *InputKafka) GetMaxSocketErrors() *float64 {
	if i == nil {
		return nil
	}
	return i.MaxSocketErrors
}

func (i *InputKafka) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputKafka) GetDescription() *string {
	if i == nil {
		return nil
	}
	return i.Description
}

type TypeCollection string

const (
	TypeCollectionCollection TypeCollection = "collection"
)

func (e TypeCollection) ToPointer() *TypeCollection {
	return &e
}
func (e *TypeCollection) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "collection":
		*e = TypeCollection(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCollection: %v", v)
	}
}

type InputCollection struct {
	// Unique ID for this input
	ID       string         `json:"id"`
	Type     TypeCollection `json:"type"`
	Disabled *bool          `json:"disabled,omitzero"`
	// Pipeline to process results
	Pipeline *string `json:"pipeline,omitzero"`
	// Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.
	SendToRoutes *bool `json:"sendToRoutes,omitzero"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitzero"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `json:"pqEnabled,omitzero"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitzero"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []components.ItemsTypeConnectionsOptional `json:"connections,omitzero"`
	Pq          *components.PqType                        `json:"pq,omitzero"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitzero"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64                                          `json:"staleChannelFlushMs,omitzero"`
	Preprocess          *components.PreprocessTypeSavedJobCollectionInput `json:"preprocess,omitzero"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `json:"throttleRatePerSec,omitzero"`
	// Fields to add to events from this input
	Metadata []components.ItemsTypeNotificationMetadata `json:"metadata,omitzero"`
	// Destination to send results to
	Output *string `json:"output,omitzero"`
}

func (i InputCollection) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollection) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (i *InputCollection) GetID() string {
	if i == nil {
		return ""
	}
	return i.ID
}

func (i *InputCollection) GetType() TypeCollection {
	if i == nil {
		return TypeCollection("")
	}
	return i.Type
}

func (i *InputCollection) GetDisabled() *bool {
	if i == nil {
		return nil
	}
	return i.Disabled
}

func (i *InputCollection) GetPipeline() *string {
	if i == nil {
		return nil
	}
	return i.Pipeline
}

func (i *InputCollection) GetSendToRoutes() *bool {
	if i == nil {
		return nil
	}
	return i.SendToRoutes
}

func (i *InputCollection) GetEnvironment() *string {
	if i == nil {
		return nil
	}
	return i.Environment
}

func (i *InputCollection) GetPqEnabled() *bool {
	if i == nil {
		return nil
	}
	return i.PqEnabled
}

func (i *InputCollection) GetStreamtags() []string {
	if i == nil {
		return nil
	}
	return i.Streamtags
}

func (i *InputCollection) GetConnections() []components.ItemsTypeConnectionsOptional {
	if i == nil {
		return nil
	}
	return i.Connections
}

func (i *InputCollection) GetPq() *components.PqType {
	if i == nil {
		return nil
	}
	return i.Pq
}

func (i *InputCollection) GetBreakerRulesets() []string {
	if i == nil {
		return nil
	}
	return i.BreakerRulesets
}

func (i *InputCollection) GetStaleChannelFlushMs() *float64 {
	if i == nil {
		return nil
	}
	return i.StaleChannelFlushMs
}

func (i *InputCollection) GetPreprocess() *components.PreprocessTypeSavedJobCollectionInput {
	if i == nil {
		return nil
	}
	return i.Preprocess
}

func (i *InputCollection) GetThrottleRatePerSec() *string {
	if i == nil {
		return nil
	}
	return i.ThrottleRatePerSec
}

func (i *InputCollection) GetMetadata() []components.ItemsTypeNotificationMetadata {
	if i == nil {
		return nil
	}
	return i.Metadata
}

func (i *InputCollection) GetOutput() *string {
	if i == nil {
		return nil
	}
	return i.Output
}

type CreateInputRequestType string

const (
	CreateInputRequestTypeCollection           CreateInputRequestType = "collection"
	CreateInputRequestTypeKafka                CreateInputRequestType = "kafka"
	CreateInputRequestTypeMsk                  CreateInputRequestType = "msk"
	CreateInputRequestTypeHTTP                 CreateInputRequestType = "http"
	CreateInputRequestTypeSplunk               CreateInputRequestType = "splunk"
	CreateInputRequestTypeSplunkSearch         CreateInputRequestType = "splunk_search"
	CreateInputRequestTypeSplunkHec            CreateInputRequestType = "splunk_hec"
	CreateInputRequestTypeAzureBlob            CreateInputRequestType = "azure_blob"
	CreateInputRequestTypeElastic              CreateInputRequestType = "elastic"
	CreateInputRequestTypeConfluentCloud       CreateInputRequestType = "confluent_cloud"
	CreateInputRequestTypeGrafana              CreateInputRequestType = "grafana"
	CreateInputRequestTypeLoki                 CreateInputRequestType = "loki"
	CreateInputRequestTypePrometheusRw         CreateInputRequestType = "prometheus_rw"
	CreateInputRequestTypePrometheus           CreateInputRequestType = "prometheus"
	CreateInputRequestTypeEdgePrometheus       CreateInputRequestType = "edge_prometheus"
	CreateInputRequestTypeOffice365Mgmt        CreateInputRequestType = "office365_mgmt"
	CreateInputRequestTypeOffice365Service     CreateInputRequestType = "office365_service"
	CreateInputRequestTypeOffice365MsgTrace    CreateInputRequestType = "office365_msg_trace"
	CreateInputRequestTypeEventhub             CreateInputRequestType = "eventhub"
	CreateInputRequestTypeExec                 CreateInputRequestType = "exec"
	CreateInputRequestTypeFirehose             CreateInputRequestType = "firehose"
	CreateInputRequestTypeGooglePubsub         CreateInputRequestType = "google_pubsub"
	CreateInputRequestTypeCribl                CreateInputRequestType = "cribl"
	CreateInputRequestTypeCriblTCP             CreateInputRequestType = "cribl_tcp"
	CreateInputRequestTypeCriblHTTP            CreateInputRequestType = "cribl_http"
	CreateInputRequestTypeCriblLakeHTTP        CreateInputRequestType = "cribl_lake_http"
	CreateInputRequestTypeTcpjson              CreateInputRequestType = "tcpjson"
	CreateInputRequestTypeSystemMetrics        CreateInputRequestType = "system_metrics"
	CreateInputRequestTypeSystemState          CreateInputRequestType = "system_state"
	CreateInputRequestTypeKubeMetrics          CreateInputRequestType = "kube_metrics"
	CreateInputRequestTypeKubeLogs             CreateInputRequestType = "kube_logs"
	CreateInputRequestTypeKubeEvents           CreateInputRequestType = "kube_events"
	CreateInputRequestTypeWindowsMetrics       CreateInputRequestType = "windows_metrics"
	CreateInputRequestTypeCrowdstrike          CreateInputRequestType = "crowdstrike"
	CreateInputRequestTypeDatadogAgent         CreateInputRequestType = "datadog_agent"
	CreateInputRequestTypeDatagen              CreateInputRequestType = "datagen"
	CreateInputRequestTypeHTTPRaw              CreateInputRequestType = "http_raw"
	CreateInputRequestTypeKinesis              CreateInputRequestType = "kinesis"
	CreateInputRequestTypeCriblmetrics         CreateInputRequestType = "criblmetrics"
	CreateInputRequestTypeMetrics              CreateInputRequestType = "metrics"
	CreateInputRequestTypeS3                   CreateInputRequestType = "s3"
	CreateInputRequestTypeS3Inventory          CreateInputRequestType = "s3_inventory"
	CreateInputRequestTypeSnmp                 CreateInputRequestType = "snmp"
	CreateInputRequestTypeOpenTelemetry        CreateInputRequestType = "open_telemetry"
	CreateInputRequestTypeModelDrivenTelemetry CreateInputRequestType = "model_driven_telemetry"
	CreateInputRequestTypeSqs                  CreateInputRequestType = "sqs"
	CreateInputRequestTypeSyslog               CreateInputRequestType = "syslog"
	CreateInputRequestTypeFile                 CreateInputRequestType = "file"
	CreateInputRequestTypeTCP                  CreateInputRequestType = "tcp"
	CreateInputRequestTypeAppscope             CreateInputRequestType = "appscope"
	CreateInputRequestTypeWef                  CreateInputRequestType = "wef"
	CreateInputRequestTypeWinEventLogs         CreateInputRequestType = "win_event_logs"
	CreateInputRequestTypeRawUDP               CreateInputRequestType = "raw_udp"
	CreateInputRequestTypeJournalFiles         CreateInputRequestType = "journal_files"
	CreateInputRequestTypeWiz                  CreateInputRequestType = "wiz"
	CreateInputRequestTypeWizWebhook           CreateInputRequestType = "wiz_webhook"
	CreateInputRequestTypeNetflow              CreateInputRequestType = "netflow"
	CreateInputRequestTypeSecurityLake         CreateInputRequestType = "security_lake"
	CreateInputRequestTypeZscalerHec           CreateInputRequestType = "zscaler_hec"
	CreateInputRequestTypeCloudflareHec        CreateInputRequestType = "cloudflare_hec"
)

// CreateInputRequest - Input object
type CreateInputRequest struct {
	InputCollection           *InputCollection           `queryParam:"inline" union:"member"`
	InputKafka                *InputKafka                `queryParam:"inline" union:"member"`
	InputMsk                  *InputMsk                  `queryParam:"inline" union:"member"`
	InputHTTP                 *InputHTTP                 `queryParam:"inline" union:"member"`
	InputSplunk               *InputSplunk               `queryParam:"inline" union:"member"`
	InputSplunkSearch         *InputSplunkSearch         `queryParam:"inline" union:"member"`
	InputSplunkHec            *InputSplunkHec            `queryParam:"inline" union:"member"`
	InputAzureBlob            *InputAzureBlob            `queryParam:"inline" union:"member"`
	InputElastic              *InputElastic              `queryParam:"inline" union:"member"`
	InputConfluentCloud       *InputConfluentCloud       `queryParam:"inline" union:"member"`
	InputGrafana              *InputGrafana              `queryParam:"inline" union:"member"`
	InputLoki                 *InputLoki                 `queryParam:"inline" union:"member"`
	InputPrometheusRw         *InputPrometheusRw         `queryParam:"inline" union:"member"`
	InputPrometheus           *InputPrometheus           `queryParam:"inline" union:"member"`
	InputEdgePrometheus       *InputEdgePrometheus       `queryParam:"inline" union:"member"`
	InputOffice365Mgmt        *InputOffice365Mgmt        `queryParam:"inline" union:"member"`
	InputOffice365Service     *InputOffice365Service     `queryParam:"inline" union:"member"`
	InputOffice365MsgTrace    *InputOffice365MsgTrace    `queryParam:"inline" union:"member"`
	InputEventhub             *InputEventhub             `queryParam:"inline" union:"member"`
	InputExec                 *InputExec                 `queryParam:"inline" union:"member"`
	InputFirehose             *InputFirehose             `queryParam:"inline" union:"member"`
	InputGooglePubsub         *InputGooglePubsub         `queryParam:"inline" union:"member"`
	InputCribl                *InputCribl                `queryParam:"inline" union:"member"`
	InputCriblTCP             *InputCriblTCP             `queryParam:"inline" union:"member"`
	InputCriblHTTP            *InputCriblHTTP            `queryParam:"inline" union:"member"`
	InputCriblLakeHTTP        *InputCriblLakeHTTP        `queryParam:"inline" union:"member"`
	InputTcpjson              *InputTcpjson              `queryParam:"inline" union:"member"`
	InputSystemMetrics        *InputSystemMetrics        `queryParam:"inline" union:"member"`
	InputSystemState          *InputSystemState          `queryParam:"inline" union:"member"`
	InputKubeMetrics          *InputKubeMetrics          `queryParam:"inline" union:"member"`
	InputKubeLogs             *InputKubeLogs             `queryParam:"inline" union:"member"`
	InputKubeEvents           *InputKubeEvents           `queryParam:"inline" union:"member"`
	InputWindowsMetrics       *InputWindowsMetrics       `queryParam:"inline" union:"member"`
	InputCrowdstrike          *InputCrowdstrike          `queryParam:"inline" union:"member"`
	InputDatadogAgent         *InputDatadogAgent         `queryParam:"inline" union:"member"`
	InputDatagen              *InputDatagen              `queryParam:"inline" union:"member"`
	InputHTTPRaw              *InputHTTPRaw              `queryParam:"inline" union:"member"`
	InputKinesis              *InputKinesis              `queryParam:"inline" union:"member"`
	InputCriblmetrics         *InputCriblmetrics         `queryParam:"inline" union:"member"`
	InputMetrics              *InputMetrics              `queryParam:"inline" union:"member"`
	InputS3                   *InputS3                   `queryParam:"inline" union:"member"`
	InputS3Inventory          *InputS3Inventory          `queryParam:"inline" union:"member"`
	InputSnmp                 *InputSnmp                 `queryParam:"inline" union:"member"`
	InputOpenTelemetry        *InputOpenTelemetry        `queryParam:"inline" union:"member"`
	InputModelDrivenTelemetry *InputModelDrivenTelemetry `queryParam:"inline" union:"member"`
	InputSqs                  *InputSqs                  `queryParam:"inline" union:"member"`
	InputSyslog               *InputSyslog               `queryParam:"inline" union:"member"`
	InputFile                 *InputFile                 `queryParam:"inline" union:"member"`
	InputTCP                  *InputTCP                  `queryParam:"inline" union:"member"`
	InputAppscope             *InputAppscope             `queryParam:"inline" union:"member"`
	InputWef                  *InputWef                  `queryParam:"inline" union:"member"`
	InputWinEventLogs         *InputWinEventLogs         `queryParam:"inline" union:"member"`
	InputRawUDP               *InputRawUDP               `queryParam:"inline" union:"member"`
	InputJournalFiles         *InputJournalFiles         `queryParam:"inline" union:"member"`
	InputWiz                  *InputWiz                  `queryParam:"inline" union:"member"`
	InputWizWebhook           *InputWizWebhook           `queryParam:"inline" union:"member"`
	InputNetflow              *InputNetflow              `queryParam:"inline" union:"member"`
	InputSecurityLake         *InputSecurityLake         `queryParam:"inline" union:"member"`
	InputZscalerHec           *InputZscalerHec           `queryParam:"inline" union:"member"`
	InputCloudflareHec        *InputCloudflareHec        `queryParam:"inline" union:"member"`

	Type CreateInputRequestType
}

func CreateCreateInputRequestCollection(collection InputCollection) CreateInputRequest {
	typ := CreateInputRequestTypeCollection

	typStr := TypeCollection(typ)
	collection.Type = typStr

	return CreateInputRequest{
		InputCollection: &collection,
		Type:            typ,
	}
}

func CreateCreateInputRequestKafka(kafka InputKafka) CreateInputRequest {
	typ := CreateInputRequestTypeKafka

	typStr := CreateInputTypeKafka(typ)
	kafka.Type = typStr

	return CreateInputRequest{
		InputKafka: &kafka,
		Type:       typ,
	}
}

func CreateCreateInputRequestMsk(msk InputMsk) CreateInputRequest {
	typ := CreateInputRequestTypeMsk

	typStr := CreateInputTypeMsk(typ)
	msk.Type = typStr

	return CreateInputRequest{
		InputMsk: &msk,
		Type:     typ,
	}
}

func CreateCreateInputRequestHTTP(http InputHTTP) CreateInputRequest {
	typ := CreateInputRequestTypeHTTP

	typStr := TypeHTTP(typ)
	http.Type = typStr

	return CreateInputRequest{
		InputHTTP: &http,
		Type:      typ,
	}
}

func CreateCreateInputRequestSplunk(splunk InputSplunk) CreateInputRequest {
	typ := CreateInputRequestTypeSplunk

	typStr := CreateInputTypeSplunk(typ)
	splunk.Type = typStr

	return CreateInputRequest{
		InputSplunk: &splunk,
		Type:        typ,
	}
}

func CreateCreateInputRequestSplunkSearch(splunkSearch InputSplunkSearch) CreateInputRequest {
	typ := CreateInputRequestTypeSplunkSearch

	typStr := TypeSplunkSearch(typ)
	splunkSearch.Type = typStr

	return CreateInputRequest{
		InputSplunkSearch: &splunkSearch,
		Type:              typ,
	}
}

func CreateCreateInputRequestSplunkHec(splunkHec InputSplunkHec) CreateInputRequest {
	typ := CreateInputRequestTypeSplunkHec

	typStr := CreateInputTypeSplunkHec(typ)
	splunkHec.Type = typStr

	return CreateInputRequest{
		InputSplunkHec: &splunkHec,
		Type:           typ,
	}
}

func CreateCreateInputRequestAzureBlob(azureBlob InputAzureBlob) CreateInputRequest {
	typ := CreateInputRequestTypeAzureBlob

	typStr := CreateInputTypeAzureBlob(typ)
	azureBlob.Type = typStr

	return CreateInputRequest{
		InputAzureBlob: &azureBlob,
		Type:           typ,
	}
}

func CreateCreateInputRequestElastic(elastic InputElastic) CreateInputRequest {
	typ := CreateInputRequestTypeElastic

	typStr := CreateInputTypeElastic(typ)
	elastic.Type = typStr

	return CreateInputRequest{
		InputElastic: &elastic,
		Type:         typ,
	}
}

func CreateCreateInputRequestConfluentCloud(confluentCloud InputConfluentCloud) CreateInputRequest {
	typ := CreateInputRequestTypeConfluentCloud

	typStr := CreateInputTypeConfluentCloud(typ)
	confluentCloud.Type = typStr

	return CreateInputRequest{
		InputConfluentCloud: &confluentCloud,
		Type:                typ,
	}
}

func CreateCreateInputRequestGrafana(grafana InputGrafana) CreateInputRequest {
	typ := CreateInputRequestTypeGrafana

	return CreateInputRequest{
		InputGrafana: &grafana,
		Type:         typ,
	}
}

func CreateCreateInputRequestLoki(loki InputLoki) CreateInputRequest {
	typ := CreateInputRequestTypeLoki

	typStr := CreateInputTypeLoki(typ)
	loki.Type = typStr

	return CreateInputRequest{
		InputLoki: &loki,
		Type:      typ,
	}
}

func CreateCreateInputRequestPrometheusRw(prometheusRw InputPrometheusRw) CreateInputRequest {
	typ := CreateInputRequestTypePrometheusRw

	typStr := TypePrometheusRw(typ)
	prometheusRw.Type = typStr

	return CreateInputRequest{
		InputPrometheusRw: &prometheusRw,
		Type:              typ,
	}
}

func CreateCreateInputRequestPrometheus(prometheus InputPrometheus) CreateInputRequest {
	typ := CreateInputRequestTypePrometheus

	typStr := CreateInputTypePrometheus(typ)
	prometheus.Type = typStr

	return CreateInputRequest{
		InputPrometheus: &prometheus,
		Type:            typ,
	}
}

func CreateCreateInputRequestEdgePrometheus(edgePrometheus InputEdgePrometheus) CreateInputRequest {
	typ := CreateInputRequestTypeEdgePrometheus

	typStr := TypeEdgePrometheus(typ)
	edgePrometheus.Type = typStr

	return CreateInputRequest{
		InputEdgePrometheus: &edgePrometheus,
		Type:                typ,
	}
}

func CreateCreateInputRequestOffice365Mgmt(office365Mgmt InputOffice365Mgmt) CreateInputRequest {
	typ := CreateInputRequestTypeOffice365Mgmt

	typStr := TypeOffice365Mgmt(typ)
	office365Mgmt.Type = typStr

	return CreateInputRequest{
		InputOffice365Mgmt: &office365Mgmt,
		Type:               typ,
	}
}

func CreateCreateInputRequestOffice365Service(office365Service InputOffice365Service) CreateInputRequest {
	typ := CreateInputRequestTypeOffice365Service

	typStr := TypeOffice365Service(typ)
	office365Service.Type = typStr

	return CreateInputRequest{
		InputOffice365Service: &office365Service,
		Type:                  typ,
	}
}

func CreateCreateInputRequestOffice365MsgTrace(office365MsgTrace InputOffice365MsgTrace) CreateInputRequest {
	typ := CreateInputRequestTypeOffice365MsgTrace

	typStr := TypeOffice365MsgTrace(typ)
	office365MsgTrace.Type = typStr

	return CreateInputRequest{
		InputOffice365MsgTrace: &office365MsgTrace,
		Type:                   typ,
	}
}

func CreateCreateInputRequestEventhub(eventhub InputEventhub) CreateInputRequest {
	typ := CreateInputRequestTypeEventhub

	typStr := TypeEventhub(typ)
	eventhub.Type = typStr

	return CreateInputRequest{
		InputEventhub: &eventhub,
		Type:          typ,
	}
}

func CreateCreateInputRequestExec(exec InputExec) CreateInputRequest {
	typ := CreateInputRequestTypeExec

	typStr := InputExecType(typ)
	exec.Type = typStr

	return CreateInputRequest{
		InputExec: &exec,
		Type:      typ,
	}
}

func CreateCreateInputRequestFirehose(firehose InputFirehose) CreateInputRequest {
	typ := CreateInputRequestTypeFirehose

	typStr := TypeFirehose(typ)
	firehose.Type = typStr

	return CreateInputRequest{
		InputFirehose: &firehose,
		Type:          typ,
	}
}

func CreateCreateInputRequestGooglePubsub(googlePubsub InputGooglePubsub) CreateInputRequest {
	typ := CreateInputRequestTypeGooglePubsub

	typStr := CreateInputTypeGooglePubsub(typ)
	googlePubsub.Type = typStr

	return CreateInputRequest{
		InputGooglePubsub: &googlePubsub,
		Type:              typ,
	}
}

func CreateCreateInputRequestCribl(cribl InputCribl) CreateInputRequest {
	typ := CreateInputRequestTypeCribl

	typStr := TypeCribl(typ)
	cribl.Type = typStr

	return CreateInputRequest{
		InputCribl: &cribl,
		Type:       typ,
	}
}

func CreateCreateInputRequestCriblTCP(criblTCP InputCriblTCP) CreateInputRequest {
	typ := CreateInputRequestTypeCriblTCP

	typStr := CreateInputTypeCriblTCP(typ)
	criblTCP.Type = typStr

	return CreateInputRequest{
		InputCriblTCP: &criblTCP,
		Type:          typ,
	}
}

func CreateCreateInputRequestCriblHTTP(criblHTTP InputCriblHTTP) CreateInputRequest {
	typ := CreateInputRequestTypeCriblHTTP

	typStr := CreateInputTypeCriblHTTP(typ)
	criblHTTP.Type = typStr

	return CreateInputRequest{
		InputCriblHTTP: &criblHTTP,
		Type:           typ,
	}
}

func CreateCreateInputRequestCriblLakeHTTP(criblLakeHTTP InputCriblLakeHTTP) CreateInputRequest {
	typ := CreateInputRequestTypeCriblLakeHTTP

	typStr := TypeCriblLakeHTTP(typ)
	criblLakeHTTP.Type = typStr

	return CreateInputRequest{
		InputCriblLakeHTTP: &criblLakeHTTP,
		Type:               typ,
	}
}

func CreateCreateInputRequestTcpjson(tcpjson InputTcpjson) CreateInputRequest {
	typ := CreateInputRequestTypeTcpjson

	typStr := CreateInputTypeTcpjson(typ)
	tcpjson.Type = typStr

	return CreateInputRequest{
		InputTcpjson: &tcpjson,
		Type:         typ,
	}
}

func CreateCreateInputRequestSystemMetrics(systemMetrics InputSystemMetrics) CreateInputRequest {
	typ := CreateInputRequestTypeSystemMetrics

	typStr := TypeSystemMetrics(typ)
	systemMetrics.Type = typStr

	return CreateInputRequest{
		InputSystemMetrics: &systemMetrics,
		Type:               typ,
	}
}

func CreateCreateInputRequestSystemState(systemState InputSystemState) CreateInputRequest {
	typ := CreateInputRequestTypeSystemState

	typStr := TypeSystemState(typ)
	systemState.Type = typStr

	return CreateInputRequest{
		InputSystemState: &systemState,
		Type:             typ,
	}
}

func CreateCreateInputRequestKubeMetrics(kubeMetrics InputKubeMetrics) CreateInputRequest {
	typ := CreateInputRequestTypeKubeMetrics

	typStr := TypeKubeMetrics(typ)
	kubeMetrics.Type = typStr

	return CreateInputRequest{
		InputKubeMetrics: &kubeMetrics,
		Type:             typ,
	}
}

func CreateCreateInputRequestKubeLogs(kubeLogs InputKubeLogs) CreateInputRequest {
	typ := CreateInputRequestTypeKubeLogs

	typStr := TypeKubeLogs(typ)
	kubeLogs.Type = typStr

	return CreateInputRequest{
		InputKubeLogs: &kubeLogs,
		Type:          typ,
	}
}

func CreateCreateInputRequestKubeEvents(kubeEvents InputKubeEvents) CreateInputRequest {
	typ := CreateInputRequestTypeKubeEvents

	typStr := TypeKubeEvents(typ)
	kubeEvents.Type = typStr

	return CreateInputRequest{
		InputKubeEvents: &kubeEvents,
		Type:            typ,
	}
}

func CreateCreateInputRequestWindowsMetrics(windowsMetrics InputWindowsMetrics) CreateInputRequest {
	typ := CreateInputRequestTypeWindowsMetrics

	typStr := TypeWindowsMetrics(typ)
	windowsMetrics.Type = typStr

	return CreateInputRequest{
		InputWindowsMetrics: &windowsMetrics,
		Type:                typ,
	}
}

func CreateCreateInputRequestCrowdstrike(crowdstrike InputCrowdstrike) CreateInputRequest {
	typ := CreateInputRequestTypeCrowdstrike

	typStr := TypeCrowdstrike(typ)
	crowdstrike.Type = typStr

	return CreateInputRequest{
		InputCrowdstrike: &crowdstrike,
		Type:             typ,
	}
}

func CreateCreateInputRequestDatadogAgent(datadogAgent InputDatadogAgent) CreateInputRequest {
	typ := CreateInputRequestTypeDatadogAgent

	typStr := TypeDatadogAgent(typ)
	datadogAgent.Type = typStr

	return CreateInputRequest{
		InputDatadogAgent: &datadogAgent,
		Type:              typ,
	}
}

func CreateCreateInputRequestDatagen(datagen InputDatagen) CreateInputRequest {
	typ := CreateInputRequestTypeDatagen

	typStr := TypeDatagen(typ)
	datagen.Type = typStr

	return CreateInputRequest{
		InputDatagen: &datagen,
		Type:         typ,
	}
}

func CreateCreateInputRequestHTTPRaw(httpRaw InputHTTPRaw) CreateInputRequest {
	typ := CreateInputRequestTypeHTTPRaw

	typStr := TypeHTTPRaw(typ)
	httpRaw.Type = typStr

	return CreateInputRequest{
		InputHTTPRaw: &httpRaw,
		Type:         typ,
	}
}

func CreateCreateInputRequestKinesis(kinesis InputKinesis) CreateInputRequest {
	typ := CreateInputRequestTypeKinesis

	typStr := CreateInputTypeKinesis(typ)
	kinesis.Type = typStr

	return CreateInputRequest{
		InputKinesis: &kinesis,
		Type:         typ,
	}
}

func CreateCreateInputRequestCriblmetrics(criblmetrics InputCriblmetrics) CreateInputRequest {
	typ := CreateInputRequestTypeCriblmetrics

	typStr := TypeCriblmetrics(typ)
	criblmetrics.Type = typStr

	return CreateInputRequest{
		InputCriblmetrics: &criblmetrics,
		Type:              typ,
	}
}

func CreateCreateInputRequestMetrics(metrics InputMetrics) CreateInputRequest {
	typ := CreateInputRequestTypeMetrics

	typStr := TypeMetrics(typ)
	metrics.Type = typStr

	return CreateInputRequest{
		InputMetrics: &metrics,
		Type:         typ,
	}
}

func CreateCreateInputRequestS3(s3 InputS3) CreateInputRequest {
	typ := CreateInputRequestTypeS3

	typStr := CreateInputTypeS3(typ)
	s3.Type = typStr

	return CreateInputRequest{
		InputS3: &s3,
		Type:    typ,
	}
}

func CreateCreateInputRequestS3Inventory(s3Inventory InputS3Inventory) CreateInputRequest {
	typ := CreateInputRequestTypeS3Inventory

	typStr := TypeS3Inventory(typ)
	s3Inventory.Type = typStr

	return CreateInputRequest{
		InputS3Inventory: &s3Inventory,
		Type:             typ,
	}
}

func CreateCreateInputRequestSnmp(snmp InputSnmp) CreateInputRequest {
	typ := CreateInputRequestTypeSnmp

	typStr := CreateInputTypeSnmp(typ)
	snmp.Type = typStr

	return CreateInputRequest{
		InputSnmp: &snmp,
		Type:      typ,
	}
}

func CreateCreateInputRequestOpenTelemetry(openTelemetry InputOpenTelemetry) CreateInputRequest {
	typ := CreateInputRequestTypeOpenTelemetry

	typStr := CreateInputTypeOpenTelemetry(typ)
	openTelemetry.Type = typStr

	return CreateInputRequest{
		InputOpenTelemetry: &openTelemetry,
		Type:               typ,
	}
}

func CreateCreateInputRequestModelDrivenTelemetry(modelDrivenTelemetry InputModelDrivenTelemetry) CreateInputRequest {
	typ := CreateInputRequestTypeModelDrivenTelemetry

	typStr := TypeModelDrivenTelemetry(typ)
	modelDrivenTelemetry.Type = typStr

	return CreateInputRequest{
		InputModelDrivenTelemetry: &modelDrivenTelemetry,
		Type:                      typ,
	}
}

func CreateCreateInputRequestSqs(sqs InputSqs) CreateInputRequest {
	typ := CreateInputRequestTypeSqs

	typStr := CreateInputTypeSqs(typ)
	sqs.Type = typStr

	return CreateInputRequest{
		InputSqs: &sqs,
		Type:     typ,
	}
}

func CreateCreateInputRequestSyslog(syslog InputSyslog) CreateInputRequest {
	typ := CreateInputRequestTypeSyslog

	return CreateInputRequest{
		InputSyslog: &syslog,
		Type:        typ,
	}
}

func CreateCreateInputRequestFile(file InputFile) CreateInputRequest {
	typ := CreateInputRequestTypeFile

	typStr := InputFileType(typ)
	file.Type = typStr

	return CreateInputRequest{
		InputFile: &file,
		Type:      typ,
	}
}

func CreateCreateInputRequestTCP(tcp InputTCP) CreateInputRequest {
	typ := CreateInputRequestTypeTCP

	typStr := TypeTCP(typ)
	tcp.Type = typStr

	return CreateInputRequest{
		InputTCP: &tcp,
		Type:     typ,
	}
}

func CreateCreateInputRequestAppscope(appscope InputAppscope) CreateInputRequest {
	typ := CreateInputRequestTypeAppscope

	typStr := TypeAppscope(typ)
	appscope.Type = typStr

	return CreateInputRequest{
		InputAppscope: &appscope,
		Type:          typ,
	}
}

func CreateCreateInputRequestWef(wef InputWef) CreateInputRequest {
	typ := CreateInputRequestTypeWef

	typStr := TypeWef(typ)
	wef.Type = typStr

	return CreateInputRequest{
		InputWef: &wef,
		Type:     typ,
	}
}

func CreateCreateInputRequestWinEventLogs(winEventLogs InputWinEventLogs) CreateInputRequest {
	typ := CreateInputRequestTypeWinEventLogs

	typStr := TypeWinEventLogs(typ)
	winEventLogs.Type = typStr

	return CreateInputRequest{
		InputWinEventLogs: &winEventLogs,
		Type:              typ,
	}
}

func CreateCreateInputRequestRawUDP(rawUDP InputRawUDP) CreateInputRequest {
	typ := CreateInputRequestTypeRawUDP

	typStr := TypeRawUDP(typ)
	rawUDP.Type = typStr

	return CreateInputRequest{
		InputRawUDP: &rawUDP,
		Type:        typ,
	}
}

func CreateCreateInputRequestJournalFiles(journalFiles InputJournalFiles) CreateInputRequest {
	typ := CreateInputRequestTypeJournalFiles

	typStr := InputJournalFilesType(typ)
	journalFiles.Type = typStr

	return CreateInputRequest{
		InputJournalFiles: &journalFiles,
		Type:              typ,
	}
}

func CreateCreateInputRequestWiz(wiz InputWiz) CreateInputRequest {
	typ := CreateInputRequestTypeWiz

	typStr := TypeWiz(typ)
	wiz.Type = typStr

	return CreateInputRequest{
		InputWiz: &wiz,
		Type:     typ,
	}
}

func CreateCreateInputRequestWizWebhook(wizWebhook InputWizWebhook) CreateInputRequest {
	typ := CreateInputRequestTypeWizWebhook

	typStr := TypeWizWebhook(typ)
	wizWebhook.Type = typStr

	return CreateInputRequest{
		InputWizWebhook: &wizWebhook,
		Type:            typ,
	}
}

func CreateCreateInputRequestNetflow(netflow InputNetflow) CreateInputRequest {
	typ := CreateInputRequestTypeNetflow

	typStr := CreateInputTypeNetflow(typ)
	netflow.Type = typStr

	return CreateInputRequest{
		InputNetflow: &netflow,
		Type:         typ,
	}
}

func CreateCreateInputRequestSecurityLake(securityLake InputSecurityLake) CreateInputRequest {
	typ := CreateInputRequestTypeSecurityLake

	typStr := CreateInputTypeSecurityLake(typ)
	securityLake.Type = typStr

	return CreateInputRequest{
		InputSecurityLake: &securityLake,
		Type:              typ,
	}
}

func CreateCreateInputRequestZscalerHec(zscalerHec InputZscalerHec) CreateInputRequest {
	typ := CreateInputRequestTypeZscalerHec

	typStr := TypeZscalerHec(typ)
	zscalerHec.Type = typStr

	return CreateInputRequest{
		InputZscalerHec: &zscalerHec,
		Type:            typ,
	}
}

func CreateCreateInputRequestCloudflareHec(cloudflareHec InputCloudflareHec) CreateInputRequest {
	typ := CreateInputRequestTypeCloudflareHec

	typStr := TypeCloudflareHec(typ)
	cloudflareHec.Type = typStr

	return CreateInputRequest{
		InputCloudflareHec: &cloudflareHec,
		Type:               typ,
	}
}

func (u *CreateInputRequest) UnmarshalJSON(data []byte) error {

	type discriminator struct {
		Type string `json:"type"`
	}

	dis := new(discriminator)
	if err := json.Unmarshal(data, &dis); err != nil {
		return fmt.Errorf("could not unmarshal discriminator: %w", err)
	}

	switch dis.Type {
	case "collection":
		inputCollection := new(InputCollection)
		if err := utils.UnmarshalJSON(data, &inputCollection, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == collection) type InputCollection within CreateInputRequest: %w", string(data), err)
		}

		u.InputCollection = inputCollection
		u.Type = CreateInputRequestTypeCollection
		return nil
	case "kafka":
		inputKafka := new(InputKafka)
		if err := utils.UnmarshalJSON(data, &inputKafka, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == kafka) type InputKafka within CreateInputRequest: %w", string(data), err)
		}

		u.InputKafka = inputKafka
		u.Type = CreateInputRequestTypeKafka
		return nil
	case "msk":
		inputMsk := new(InputMsk)
		if err := utils.UnmarshalJSON(data, &inputMsk, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == msk) type InputMsk within CreateInputRequest: %w", string(data), err)
		}

		u.InputMsk = inputMsk
		u.Type = CreateInputRequestTypeMsk
		return nil
	case "http":
		inputHTTP := new(InputHTTP)
		if err := utils.UnmarshalJSON(data, &inputHTTP, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == http) type InputHTTP within CreateInputRequest: %w", string(data), err)
		}

		u.InputHTTP = inputHTTP
		u.Type = CreateInputRequestTypeHTTP
		return nil
	case "splunk":
		inputSplunk := new(InputSplunk)
		if err := utils.UnmarshalJSON(data, &inputSplunk, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == splunk) type InputSplunk within CreateInputRequest: %w", string(data), err)
		}

		u.InputSplunk = inputSplunk
		u.Type = CreateInputRequestTypeSplunk
		return nil
	case "splunk_search":
		inputSplunkSearch := new(InputSplunkSearch)
		if err := utils.UnmarshalJSON(data, &inputSplunkSearch, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == splunk_search) type InputSplunkSearch within CreateInputRequest: %w", string(data), err)
		}

		u.InputSplunkSearch = inputSplunkSearch
		u.Type = CreateInputRequestTypeSplunkSearch
		return nil
	case "splunk_hec":
		inputSplunkHec := new(InputSplunkHec)
		if err := utils.UnmarshalJSON(data, &inputSplunkHec, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == splunk_hec) type InputSplunkHec within CreateInputRequest: %w", string(data), err)
		}

		u.InputSplunkHec = inputSplunkHec
		u.Type = CreateInputRequestTypeSplunkHec
		return nil
	case "azure_blob":
		inputAzureBlob := new(InputAzureBlob)
		if err := utils.UnmarshalJSON(data, &inputAzureBlob, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == azure_blob) type InputAzureBlob within CreateInputRequest: %w", string(data), err)
		}

		u.InputAzureBlob = inputAzureBlob
		u.Type = CreateInputRequestTypeAzureBlob
		return nil
	case "elastic":
		inputElastic := new(InputElastic)
		if err := utils.UnmarshalJSON(data, &inputElastic, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == elastic) type InputElastic within CreateInputRequest: %w", string(data), err)
		}

		u.InputElastic = inputElastic
		u.Type = CreateInputRequestTypeElastic
		return nil
	case "confluent_cloud":
		inputConfluentCloud := new(InputConfluentCloud)
		if err := utils.UnmarshalJSON(data, &inputConfluentCloud, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == confluent_cloud) type InputConfluentCloud within CreateInputRequest: %w", string(data), err)
		}

		u.InputConfluentCloud = inputConfluentCloud
		u.Type = CreateInputRequestTypeConfluentCloud
		return nil
	case "grafana":
		inputGrafana := new(InputGrafana)
		if err := utils.UnmarshalJSON(data, &inputGrafana, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == grafana) type InputGrafana within CreateInputRequest: %w", string(data), err)
		}

		u.InputGrafana = inputGrafana
		u.Type = CreateInputRequestTypeGrafana
		return nil
	case "loki":
		inputLoki := new(InputLoki)
		if err := utils.UnmarshalJSON(data, &inputLoki, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == loki) type InputLoki within CreateInputRequest: %w", string(data), err)
		}

		u.InputLoki = inputLoki
		u.Type = CreateInputRequestTypeLoki
		return nil
	case "prometheus_rw":
		inputPrometheusRw := new(InputPrometheusRw)
		if err := utils.UnmarshalJSON(data, &inputPrometheusRw, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == prometheus_rw) type InputPrometheusRw within CreateInputRequest: %w", string(data), err)
		}

		u.InputPrometheusRw = inputPrometheusRw
		u.Type = CreateInputRequestTypePrometheusRw
		return nil
	case "prometheus":
		inputPrometheus := new(InputPrometheus)
		if err := utils.UnmarshalJSON(data, &inputPrometheus, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == prometheus) type InputPrometheus within CreateInputRequest: %w", string(data), err)
		}

		u.InputPrometheus = inputPrometheus
		u.Type = CreateInputRequestTypePrometheus
		return nil
	case "edge_prometheus":
		inputEdgePrometheus := new(InputEdgePrometheus)
		if err := utils.UnmarshalJSON(data, &inputEdgePrometheus, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == edge_prometheus) type InputEdgePrometheus within CreateInputRequest: %w", string(data), err)
		}

		u.InputEdgePrometheus = inputEdgePrometheus
		u.Type = CreateInputRequestTypeEdgePrometheus
		return nil
	case "office365_mgmt":
		inputOffice365Mgmt := new(InputOffice365Mgmt)
		if err := utils.UnmarshalJSON(data, &inputOffice365Mgmt, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == office365_mgmt) type InputOffice365Mgmt within CreateInputRequest: %w", string(data), err)
		}

		u.InputOffice365Mgmt = inputOffice365Mgmt
		u.Type = CreateInputRequestTypeOffice365Mgmt
		return nil
	case "office365_service":
		inputOffice365Service := new(InputOffice365Service)
		if err := utils.UnmarshalJSON(data, &inputOffice365Service, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == office365_service) type InputOffice365Service within CreateInputRequest: %w", string(data), err)
		}

		u.InputOffice365Service = inputOffice365Service
		u.Type = CreateInputRequestTypeOffice365Service
		return nil
	case "office365_msg_trace":
		inputOffice365MsgTrace := new(InputOffice365MsgTrace)
		if err := utils.UnmarshalJSON(data, &inputOffice365MsgTrace, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == office365_msg_trace) type InputOffice365MsgTrace within CreateInputRequest: %w", string(data), err)
		}

		u.InputOffice365MsgTrace = inputOffice365MsgTrace
		u.Type = CreateInputRequestTypeOffice365MsgTrace
		return nil
	case "eventhub":
		inputEventhub := new(InputEventhub)
		if err := utils.UnmarshalJSON(data, &inputEventhub, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == eventhub) type InputEventhub within CreateInputRequest: %w", string(data), err)
		}

		u.InputEventhub = inputEventhub
		u.Type = CreateInputRequestTypeEventhub
		return nil
	case "exec":
		inputExec := new(InputExec)
		if err := utils.UnmarshalJSON(data, &inputExec, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == exec) type InputExec within CreateInputRequest: %w", string(data), err)
		}

		u.InputExec = inputExec
		u.Type = CreateInputRequestTypeExec
		return nil
	case "firehose":
		inputFirehose := new(InputFirehose)
		if err := utils.UnmarshalJSON(data, &inputFirehose, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == firehose) type InputFirehose within CreateInputRequest: %w", string(data), err)
		}

		u.InputFirehose = inputFirehose
		u.Type = CreateInputRequestTypeFirehose
		return nil
	case "google_pubsub":
		inputGooglePubsub := new(InputGooglePubsub)
		if err := utils.UnmarshalJSON(data, &inputGooglePubsub, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == google_pubsub) type InputGooglePubsub within CreateInputRequest: %w", string(data), err)
		}

		u.InputGooglePubsub = inputGooglePubsub
		u.Type = CreateInputRequestTypeGooglePubsub
		return nil
	case "cribl":
		inputCribl := new(InputCribl)
		if err := utils.UnmarshalJSON(data, &inputCribl, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == cribl) type InputCribl within CreateInputRequest: %w", string(data), err)
		}

		u.InputCribl = inputCribl
		u.Type = CreateInputRequestTypeCribl
		return nil
	case "cribl_tcp":
		inputCriblTCP := new(InputCriblTCP)
		if err := utils.UnmarshalJSON(data, &inputCriblTCP, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == cribl_tcp) type InputCriblTCP within CreateInputRequest: %w", string(data), err)
		}

		u.InputCriblTCP = inputCriblTCP
		u.Type = CreateInputRequestTypeCriblTCP
		return nil
	case "cribl_http":
		inputCriblHTTP := new(InputCriblHTTP)
		if err := utils.UnmarshalJSON(data, &inputCriblHTTP, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == cribl_http) type InputCriblHTTP within CreateInputRequest: %w", string(data), err)
		}

		u.InputCriblHTTP = inputCriblHTTP
		u.Type = CreateInputRequestTypeCriblHTTP
		return nil
	case "cribl_lake_http":
		inputCriblLakeHTTP := new(InputCriblLakeHTTP)
		if err := utils.UnmarshalJSON(data, &inputCriblLakeHTTP, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == cribl_lake_http) type InputCriblLakeHTTP within CreateInputRequest: %w", string(data), err)
		}

		u.InputCriblLakeHTTP = inputCriblLakeHTTP
		u.Type = CreateInputRequestTypeCriblLakeHTTP
		return nil
	case "tcpjson":
		inputTcpjson := new(InputTcpjson)
		if err := utils.UnmarshalJSON(data, &inputTcpjson, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == tcpjson) type InputTcpjson within CreateInputRequest: %w", string(data), err)
		}

		u.InputTcpjson = inputTcpjson
		u.Type = CreateInputRequestTypeTcpjson
		return nil
	case "system_metrics":
		inputSystemMetrics := new(InputSystemMetrics)
		if err := utils.UnmarshalJSON(data, &inputSystemMetrics, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == system_metrics) type InputSystemMetrics within CreateInputRequest: %w", string(data), err)
		}

		u.InputSystemMetrics = inputSystemMetrics
		u.Type = CreateInputRequestTypeSystemMetrics
		return nil
	case "system_state":
		inputSystemState := new(InputSystemState)
		if err := utils.UnmarshalJSON(data, &inputSystemState, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == system_state) type InputSystemState within CreateInputRequest: %w", string(data), err)
		}

		u.InputSystemState = inputSystemState
		u.Type = CreateInputRequestTypeSystemState
		return nil
	case "kube_metrics":
		inputKubeMetrics := new(InputKubeMetrics)
		if err := utils.UnmarshalJSON(data, &inputKubeMetrics, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == kube_metrics) type InputKubeMetrics within CreateInputRequest: %w", string(data), err)
		}

		u.InputKubeMetrics = inputKubeMetrics
		u.Type = CreateInputRequestTypeKubeMetrics
		return nil
	case "kube_logs":
		inputKubeLogs := new(InputKubeLogs)
		if err := utils.UnmarshalJSON(data, &inputKubeLogs, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == kube_logs) type InputKubeLogs within CreateInputRequest: %w", string(data), err)
		}

		u.InputKubeLogs = inputKubeLogs
		u.Type = CreateInputRequestTypeKubeLogs
		return nil
	case "kube_events":
		inputKubeEvents := new(InputKubeEvents)
		if err := utils.UnmarshalJSON(data, &inputKubeEvents, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == kube_events) type InputKubeEvents within CreateInputRequest: %w", string(data), err)
		}

		u.InputKubeEvents = inputKubeEvents
		u.Type = CreateInputRequestTypeKubeEvents
		return nil
	case "windows_metrics":
		inputWindowsMetrics := new(InputWindowsMetrics)
		if err := utils.UnmarshalJSON(data, &inputWindowsMetrics, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == windows_metrics) type InputWindowsMetrics within CreateInputRequest: %w", string(data), err)
		}

		u.InputWindowsMetrics = inputWindowsMetrics
		u.Type = CreateInputRequestTypeWindowsMetrics
		return nil
	case "crowdstrike":
		inputCrowdstrike := new(InputCrowdstrike)
		if err := utils.UnmarshalJSON(data, &inputCrowdstrike, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == crowdstrike) type InputCrowdstrike within CreateInputRequest: %w", string(data), err)
		}

		u.InputCrowdstrike = inputCrowdstrike
		u.Type = CreateInputRequestTypeCrowdstrike
		return nil
	case "datadog_agent":
		inputDatadogAgent := new(InputDatadogAgent)
		if err := utils.UnmarshalJSON(data, &inputDatadogAgent, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == datadog_agent) type InputDatadogAgent within CreateInputRequest: %w", string(data), err)
		}

		u.InputDatadogAgent = inputDatadogAgent
		u.Type = CreateInputRequestTypeDatadogAgent
		return nil
	case "datagen":
		inputDatagen := new(InputDatagen)
		if err := utils.UnmarshalJSON(data, &inputDatagen, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == datagen) type InputDatagen within CreateInputRequest: %w", string(data), err)
		}

		u.InputDatagen = inputDatagen
		u.Type = CreateInputRequestTypeDatagen
		return nil
	case "http_raw":
		inputHTTPRaw := new(InputHTTPRaw)
		if err := utils.UnmarshalJSON(data, &inputHTTPRaw, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == http_raw) type InputHTTPRaw within CreateInputRequest: %w", string(data), err)
		}

		u.InputHTTPRaw = inputHTTPRaw
		u.Type = CreateInputRequestTypeHTTPRaw
		return nil
	case "kinesis":
		inputKinesis := new(InputKinesis)
		if err := utils.UnmarshalJSON(data, &inputKinesis, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == kinesis) type InputKinesis within CreateInputRequest: %w", string(data), err)
		}

		u.InputKinesis = inputKinesis
		u.Type = CreateInputRequestTypeKinesis
		return nil
	case "criblmetrics":
		inputCriblmetrics := new(InputCriblmetrics)
		if err := utils.UnmarshalJSON(data, &inputCriblmetrics, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == criblmetrics) type InputCriblmetrics within CreateInputRequest: %w", string(data), err)
		}

		u.InputCriblmetrics = inputCriblmetrics
		u.Type = CreateInputRequestTypeCriblmetrics
		return nil
	case "metrics":
		inputMetrics := new(InputMetrics)
		if err := utils.UnmarshalJSON(data, &inputMetrics, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == metrics) type InputMetrics within CreateInputRequest: %w", string(data), err)
		}

		u.InputMetrics = inputMetrics
		u.Type = CreateInputRequestTypeMetrics
		return nil
	case "s3":
		inputS3 := new(InputS3)
		if err := utils.UnmarshalJSON(data, &inputS3, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == s3) type InputS3 within CreateInputRequest: %w", string(data), err)
		}

		u.InputS3 = inputS3
		u.Type = CreateInputRequestTypeS3
		return nil
	case "s3_inventory":
		inputS3Inventory := new(InputS3Inventory)
		if err := utils.UnmarshalJSON(data, &inputS3Inventory, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == s3_inventory) type InputS3Inventory within CreateInputRequest: %w", string(data), err)
		}

		u.InputS3Inventory = inputS3Inventory
		u.Type = CreateInputRequestTypeS3Inventory
		return nil
	case "snmp":
		inputSnmp := new(InputSnmp)
		if err := utils.UnmarshalJSON(data, &inputSnmp, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == snmp) type InputSnmp within CreateInputRequest: %w", string(data), err)
		}

		u.InputSnmp = inputSnmp
		u.Type = CreateInputRequestTypeSnmp
		return nil
	case "open_telemetry":
		inputOpenTelemetry := new(InputOpenTelemetry)
		if err := utils.UnmarshalJSON(data, &inputOpenTelemetry, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == open_telemetry) type InputOpenTelemetry within CreateInputRequest: %w", string(data), err)
		}

		u.InputOpenTelemetry = inputOpenTelemetry
		u.Type = CreateInputRequestTypeOpenTelemetry
		return nil
	case "model_driven_telemetry":
		inputModelDrivenTelemetry := new(InputModelDrivenTelemetry)
		if err := utils.UnmarshalJSON(data, &inputModelDrivenTelemetry, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == model_driven_telemetry) type InputModelDrivenTelemetry within CreateInputRequest: %w", string(data), err)
		}

		u.InputModelDrivenTelemetry = inputModelDrivenTelemetry
		u.Type = CreateInputRequestTypeModelDrivenTelemetry
		return nil
	case "sqs":
		inputSqs := new(InputSqs)
		if err := utils.UnmarshalJSON(data, &inputSqs, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == sqs) type InputSqs within CreateInputRequest: %w", string(data), err)
		}

		u.InputSqs = inputSqs
		u.Type = CreateInputRequestTypeSqs
		return nil
	case "syslog":
		inputSyslog := new(InputSyslog)
		if err := utils.UnmarshalJSON(data, &inputSyslog, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == syslog) type InputSyslog within CreateInputRequest: %w", string(data), err)
		}

		u.InputSyslog = inputSyslog
		u.Type = CreateInputRequestTypeSyslog
		return nil
	case "file":
		inputFile := new(InputFile)
		if err := utils.UnmarshalJSON(data, &inputFile, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == file) type InputFile within CreateInputRequest: %w", string(data), err)
		}

		u.InputFile = inputFile
		u.Type = CreateInputRequestTypeFile
		return nil
	case "tcp":
		inputTCP := new(InputTCP)
		if err := utils.UnmarshalJSON(data, &inputTCP, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == tcp) type InputTCP within CreateInputRequest: %w", string(data), err)
		}

		u.InputTCP = inputTCP
		u.Type = CreateInputRequestTypeTCP
		return nil
	case "appscope":
		inputAppscope := new(InputAppscope)
		if err := utils.UnmarshalJSON(data, &inputAppscope, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == appscope) type InputAppscope within CreateInputRequest: %w", string(data), err)
		}

		u.InputAppscope = inputAppscope
		u.Type = CreateInputRequestTypeAppscope
		return nil
	case "wef":
		inputWef := new(InputWef)
		if err := utils.UnmarshalJSON(data, &inputWef, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == wef) type InputWef within CreateInputRequest: %w", string(data), err)
		}

		u.InputWef = inputWef
		u.Type = CreateInputRequestTypeWef
		return nil
	case "win_event_logs":
		inputWinEventLogs := new(InputWinEventLogs)
		if err := utils.UnmarshalJSON(data, &inputWinEventLogs, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == win_event_logs) type InputWinEventLogs within CreateInputRequest: %w", string(data), err)
		}

		u.InputWinEventLogs = inputWinEventLogs
		u.Type = CreateInputRequestTypeWinEventLogs
		return nil
	case "raw_udp":
		inputRawUDP := new(InputRawUDP)
		if err := utils.UnmarshalJSON(data, &inputRawUDP, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == raw_udp) type InputRawUDP within CreateInputRequest: %w", string(data), err)
		}

		u.InputRawUDP = inputRawUDP
		u.Type = CreateInputRequestTypeRawUDP
		return nil
	case "journal_files":
		inputJournalFiles := new(InputJournalFiles)
		if err := utils.UnmarshalJSON(data, &inputJournalFiles, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == journal_files) type InputJournalFiles within CreateInputRequest: %w", string(data), err)
		}

		u.InputJournalFiles = inputJournalFiles
		u.Type = CreateInputRequestTypeJournalFiles
		return nil
	case "wiz":
		inputWiz := new(InputWiz)
		if err := utils.UnmarshalJSON(data, &inputWiz, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == wiz) type InputWiz within CreateInputRequest: %w", string(data), err)
		}

		u.InputWiz = inputWiz
		u.Type = CreateInputRequestTypeWiz
		return nil
	case "wiz_webhook":
		inputWizWebhook := new(InputWizWebhook)
		if err := utils.UnmarshalJSON(data, &inputWizWebhook, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == wiz_webhook) type InputWizWebhook within CreateInputRequest: %w", string(data), err)
		}

		u.InputWizWebhook = inputWizWebhook
		u.Type = CreateInputRequestTypeWizWebhook
		return nil
	case "netflow":
		inputNetflow := new(InputNetflow)
		if err := utils.UnmarshalJSON(data, &inputNetflow, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == netflow) type InputNetflow within CreateInputRequest: %w", string(data), err)
		}

		u.InputNetflow = inputNetflow
		u.Type = CreateInputRequestTypeNetflow
		return nil
	case "security_lake":
		inputSecurityLake := new(InputSecurityLake)
		if err := utils.UnmarshalJSON(data, &inputSecurityLake, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == security_lake) type InputSecurityLake within CreateInputRequest: %w", string(data), err)
		}

		u.InputSecurityLake = inputSecurityLake
		u.Type = CreateInputRequestTypeSecurityLake
		return nil
	case "zscaler_hec":
		inputZscalerHec := new(InputZscalerHec)
		if err := utils.UnmarshalJSON(data, &inputZscalerHec, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == zscaler_hec) type InputZscalerHec within CreateInputRequest: %w", string(data), err)
		}

		u.InputZscalerHec = inputZscalerHec
		u.Type = CreateInputRequestTypeZscalerHec
		return nil
	case "cloudflare_hec":
		inputCloudflareHec := new(InputCloudflareHec)
		if err := utils.UnmarshalJSON(data, &inputCloudflareHec, "", true, nil); err != nil {
			return fmt.Errorf("could not unmarshal `%s` into expected (Type == cloudflare_hec) type InputCloudflareHec within CreateInputRequest: %w", string(data), err)
		}

		u.InputCloudflareHec = inputCloudflareHec
		u.Type = CreateInputRequestTypeCloudflareHec
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for CreateInputRequest", string(data))
}

func (u CreateInputRequest) MarshalJSON() ([]byte, error) {
	if u.InputCollection != nil {
		return utils.MarshalJSON(u.InputCollection, "", true)
	}

	if u.InputKafka != nil {
		return utils.MarshalJSON(u.InputKafka, "", true)
	}

	if u.InputMsk != nil {
		return utils.MarshalJSON(u.InputMsk, "", true)
	}

	if u.InputHTTP != nil {
		return utils.MarshalJSON(u.InputHTTP, "", true)
	}

	if u.InputSplunk != nil {
		return utils.MarshalJSON(u.InputSplunk, "", true)
	}

	if u.InputSplunkSearch != nil {
		return utils.MarshalJSON(u.InputSplunkSearch, "", true)
	}

	if u.InputSplunkHec != nil {
		return utils.MarshalJSON(u.InputSplunkHec, "", true)
	}

	if u.InputAzureBlob != nil {
		return utils.MarshalJSON(u.InputAzureBlob, "", true)
	}

	if u.InputElastic != nil {
		return utils.MarshalJSON(u.InputElastic, "", true)
	}

	if u.InputConfluentCloud != nil {
		return utils.MarshalJSON(u.InputConfluentCloud, "", true)
	}

	if u.InputGrafana != nil {
		return utils.MarshalJSON(u.InputGrafana, "", true)
	}

	if u.InputLoki != nil {
		return utils.MarshalJSON(u.InputLoki, "", true)
	}

	if u.InputPrometheusRw != nil {
		return utils.MarshalJSON(u.InputPrometheusRw, "", true)
	}

	if u.InputPrometheus != nil {
		return utils.MarshalJSON(u.InputPrometheus, "", true)
	}

	if u.InputEdgePrometheus != nil {
		return utils.MarshalJSON(u.InputEdgePrometheus, "", true)
	}

	if u.InputOffice365Mgmt != nil {
		return utils.MarshalJSON(u.InputOffice365Mgmt, "", true)
	}

	if u.InputOffice365Service != nil {
		return utils.MarshalJSON(u.InputOffice365Service, "", true)
	}

	if u.InputOffice365MsgTrace != nil {
		return utils.MarshalJSON(u.InputOffice365MsgTrace, "", true)
	}

	if u.InputEventhub != nil {
		return utils.MarshalJSON(u.InputEventhub, "", true)
	}

	if u.InputExec != nil {
		return utils.MarshalJSON(u.InputExec, "", true)
	}

	if u.InputFirehose != nil {
		return utils.MarshalJSON(u.InputFirehose, "", true)
	}

	if u.InputGooglePubsub != nil {
		return utils.MarshalJSON(u.InputGooglePubsub, "", true)
	}

	if u.InputCribl != nil {
		return utils.MarshalJSON(u.InputCribl, "", true)
	}

	if u.InputCriblTCP != nil {
		return utils.MarshalJSON(u.InputCriblTCP, "", true)
	}

	if u.InputCriblHTTP != nil {
		return utils.MarshalJSON(u.InputCriblHTTP, "", true)
	}

	if u.InputCriblLakeHTTP != nil {
		return utils.MarshalJSON(u.InputCriblLakeHTTP, "", true)
	}

	if u.InputTcpjson != nil {
		return utils.MarshalJSON(u.InputTcpjson, "", true)
	}

	if u.InputSystemMetrics != nil {
		return utils.MarshalJSON(u.InputSystemMetrics, "", true)
	}

	if u.InputSystemState != nil {
		return utils.MarshalJSON(u.InputSystemState, "", true)
	}

	if u.InputKubeMetrics != nil {
		return utils.MarshalJSON(u.InputKubeMetrics, "", true)
	}

	if u.InputKubeLogs != nil {
		return utils.MarshalJSON(u.InputKubeLogs, "", true)
	}

	if u.InputKubeEvents != nil {
		return utils.MarshalJSON(u.InputKubeEvents, "", true)
	}

	if u.InputWindowsMetrics != nil {
		return utils.MarshalJSON(u.InputWindowsMetrics, "", true)
	}

	if u.InputCrowdstrike != nil {
		return utils.MarshalJSON(u.InputCrowdstrike, "", true)
	}

	if u.InputDatadogAgent != nil {
		return utils.MarshalJSON(u.InputDatadogAgent, "", true)
	}

	if u.InputDatagen != nil {
		return utils.MarshalJSON(u.InputDatagen, "", true)
	}

	if u.InputHTTPRaw != nil {
		return utils.MarshalJSON(u.InputHTTPRaw, "", true)
	}

	if u.InputKinesis != nil {
		return utils.MarshalJSON(u.InputKinesis, "", true)
	}

	if u.InputCriblmetrics != nil {
		return utils.MarshalJSON(u.InputCriblmetrics, "", true)
	}

	if u.InputMetrics != nil {
		return utils.MarshalJSON(u.InputMetrics, "", true)
	}

	if u.InputS3 != nil {
		return utils.MarshalJSON(u.InputS3, "", true)
	}

	if u.InputS3Inventory != nil {
		return utils.MarshalJSON(u.InputS3Inventory, "", true)
	}

	if u.InputSnmp != nil {
		return utils.MarshalJSON(u.InputSnmp, "", true)
	}

	if u.InputOpenTelemetry != nil {
		return utils.MarshalJSON(u.InputOpenTelemetry, "", true)
	}

	if u.InputModelDrivenTelemetry != nil {
		return utils.MarshalJSON(u.InputModelDrivenTelemetry, "", true)
	}

	if u.InputSqs != nil {
		return utils.MarshalJSON(u.InputSqs, "", true)
	}

	if u.InputSyslog != nil {
		return utils.MarshalJSON(u.InputSyslog, "", true)
	}

	if u.InputFile != nil {
		return utils.MarshalJSON(u.InputFile, "", true)
	}

	if u.InputTCP != nil {
		return utils.MarshalJSON(u.InputTCP, "", true)
	}

	if u.InputAppscope != nil {
		return utils.MarshalJSON(u.InputAppscope, "", true)
	}

	if u.InputWef != nil {
		return utils.MarshalJSON(u.InputWef, "", true)
	}

	if u.InputWinEventLogs != nil {
		return utils.MarshalJSON(u.InputWinEventLogs, "", true)
	}

	if u.InputRawUDP != nil {
		return utils.MarshalJSON(u.InputRawUDP, "", true)
	}

	if u.InputJournalFiles != nil {
		return utils.MarshalJSON(u.InputJournalFiles, "", true)
	}

	if u.InputWiz != nil {
		return utils.MarshalJSON(u.InputWiz, "", true)
	}

	if u.InputWizWebhook != nil {
		return utils.MarshalJSON(u.InputWizWebhook, "", true)
	}

	if u.InputNetflow != nil {
		return utils.MarshalJSON(u.InputNetflow, "", true)
	}

	if u.InputSecurityLake != nil {
		return utils.MarshalJSON(u.InputSecurityLake, "", true)
	}

	if u.InputZscalerHec != nil {
		return utils.MarshalJSON(u.InputZscalerHec, "", true)
	}

	if u.InputCloudflareHec != nil {
		return utils.MarshalJSON(u.InputCloudflareHec, "", true)
	}

	return nil, errors.New("could not marshal union type CreateInputRequest: all fields are null")
}

type CreateInputResponse struct {
	HTTPMeta components.HTTPMetadata `json:"-"`
	// a list of Source objects
	CountedInput *components.CountedInput
}

func (c CreateInputResponse) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateInputResponse) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (c *CreateInputResponse) GetHTTPMeta() components.HTTPMetadata {
	if c == nil {
		return components.HTTPMetadata{}
	}
	return c.HTTPMeta
}

func (c *CreateInputResponse) GetCountedInput() *components.CountedInput {
	if c == nil {
		return nil
	}
	return c.CountedInput
}
